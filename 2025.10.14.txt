1, TITLE: MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL Via Agentic Training
AUTHORS: Taicheng Guo; Hai Wang; ChaoChun Liu; Mohsen Golalikhani; Xin Chen; Xiangliang Zhang; Chandan K. Reddy
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present MTSQL-R1, an agentictraining framework for long-horizon multi-turn Text-to-SQL.

2, TITLE: Diffusion Transformers with Representation Autoencoders
AUTHORS: Boyang Zheng; Nanye Ma; Shengbang Tong; Saining Xie
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Since these latent spaces aretypically high-dimensional, a key challenge is enabling diffusion transformersto operate effectively within them. We analyze the sources of this difficulty,propose theoretically motivated solutions, and validate them empirically.

3, TITLE: Ctrl-World: A Controllable Generative World Model for Robot Manipulation
AUTHORS: Yanjiang Guo; Lucy Xiaoyang Shi; Jianyu Chen; Chelsea Finn
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this paper, we make astep forward by introducing a controllable multi-view world model that can beused to evaluate and improve the instruction-following ability of generalistrobot policies.

4, TITLE: LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models Via Likelihood Preference
AUTHORS: Jianhao Yuan; Fabio Pizzati; Francesco Pinto; Lars Kunze; Ivan Laptev; Paul Newman; Philip Torr; Daniele De Martini
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To the end, we introduce LikePhys, a training-free method thatevaluates intuitive physics in video diffusion models by distinguishingphysically valid and impossible videos using the denoising objective as anELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs.

5, TITLE: Merlin's Whisper: Enabling Efficient Reasoning in LLMs Via Black-box Adversarial Prompting
AUTHORS: Heming Xia; Cunxiao Du; Rui Li; Chak Tou Leong; Yongqi Li; Wenjie Li
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, wepresent a new perspective on mitigating overthinking in LRMs via black-boxadversarial prompting.

6, TITLE: Semantic Visual Anomaly Detection and Reasoning in AI-Generated Images
AUTHORS: Chuangchuang Tan; Xiang Ming; Jinglu Wang; Renshuai Tao; Bin Li; Yunchao Wei; Yao Zhao; Yan Lu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we formalize \textbf{semantic anomaly detection and reasoning} for AIGCimages and introduce \textbf{AnomReason}, a large-scale benchmark with structuredannotations as quadruples \emph{(Name, Phenomenon, Reasoning, Severity)}.

7, TITLE: BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions
AUTHORS: Tao Yu; Zhengbo Zhang; Zhiheng Lyu; Junhao Gong; Hongzhu Yi; Xinming Wang; Yuxuan Zhou; Jiabing Yang; Ping Nie; Yan Huang; Wenhu Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: While recent research like Search-R1 andWebDancer demonstrates strong performance in solving web tasks, they heavilyrely on additional tools to convert the interactive web environment into statictext content. This is in contrast to human browsing behaviors, which involvediverse interactions with the browser, such as scrolling, clicking, and typing.In this paper, we propose BrowserAgent, a more interactive agent that solvescomplex tasks through human-inspired browser actions.

8, TITLE: Source-Free Object Detection with Detection Transformer
AUTHORS: Huizai Yao; Sicheng Zhao; Shuo Lu; Hui Chen; Yangyang Li; Guoping Liu; Tengfei Xing; Chenggang Yan; Jianhua Tao; Guiguang Ding
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we introduce Feature Reweighting ANdContrastive Learning NetworK (FRANCK), a novel SFOD framework specificallydesigned to perform query-centric feature enhancement for DETRs.

9, TITLE: Enhancing Long Chain-of-Thought Reasoning Through Multi-Path Plan Aggregation
AUTHORS: Siheng Xiong; Ali Payani; Faramarz Fekri
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Our analysis reveals that most reasoning errors stem fromincorrect planning. Motivated by this observation, we propose Multi-Path PlanAggregation (MPPA), a framework that augments single-pass reasoning with planexploration and aggregation.

10, TITLE: Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages
AUTHORS: Paloma Piot; José Ramom Pichel Campos; Javier Parapar
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: At the same time,large language models require substantial amounts of data to perform reliably,a requirement that low-resource languages often cannot meet. In this work, weaddress these gaps by compiling a meta-collection of hate speech datasets forEuropean Spanish, standardised with unified labels and metadata.

11, TITLE: Don't Throw Away Your Pretrained Model
AUTHORS: Shangbin Feng; Wenhao Yu; Yike Wang; Hongming Zhang; Yulia Tsvetkov; Dong Yu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We aimto make the best of both worlds through model collaboration, where differentmodels in the training pipeline collaborate and complement each other.

12, TITLE: A Survey on Agentic Multimodal Large Language Models
AUTHORS: Huanjin Yao; Ruifei Zhang; Jiaxing Huang; Jingyi Zhang; Yibo Wang; Bo Fang; Ruolin Zhu; Yongcheng Jing; Shunyu Liu; Guanbin Li; Dacheng Tao
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Motivated by the growing interest in agentic AI andits potential trajectory toward AGI, we present a comprehensive survey onAgentic Multimodal Large Language Models (Agentic MLLMs).

13, TITLE: Where on Earth? A Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales
AUTHORS: Zhaofang Qian; Hardy Chen; Zeyu Wang; Li Zhang; Zijun Wang; Xiaoke Huang; Hui Liu; Xianfeng Tang; Zeyu Zheng; Haoqin Tu; Cihang Xie; Yuyin Zhou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: For evaluation, we adopt the final-prediction metrics: locationaccuracies within k km (Acc@k) for coordinates and hierarchical path scores fortextual localization. Beyond this, we propose to explicitly score intermediatereasoning chains using human-verified key visual clues and a Shapley-reweightedthinking score that attributes credit to each clue's marginal contribution. Webenchmark 13 state-of-the-art VLMs with web searching tools on our EarthWhereand report different types of final answer accuracies as well as the calibratedmodel thinking scores.

14, TITLE: Information-Preserving Reformulation of Reasoning Traces for Antidistillation
AUTHORS: Jiayu Ding; Lei Cui; Li Dong; Nanning Zheng; Furu Wei
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To mitigate this risk, proprietarymodel providers often adopt aggressive protection strategies, such as replacingdetailed reasoning with brief summaries, which deprive users of valuableintermediate information. To address this trade-off, we propose PART, aninformation-preserving antidistillation reformulation of reasoning traces.Motivated by the difference between how humans understand reasoning traces andhow LLMs exploit them for supervised fine-tuning, we design a simple buteffective two-step reformulation: removing self-talk behaviors and reorderingsub-conclusions.

15, TITLE: DocReward: A Document Reward Model for Structuring and Stylizing
AUTHORS: Junpeng Liu; Yuzhong Zhao; Bowen Cao; Jiayu Ding; Yilin Jia; Tengchao Lv; Yupan Huang; Shaohan Huang; Nan Yang; Li Dong; Lei Cui; Tao Ge; Xun Wang; Huitian Jiao; Sun Mao; FNU Kartik; Si-Qing Chen; Wai Lam; Furu Wei
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We construct a multi-domain dataset DocPair of 117K paireddocuments, covering 32 domains and 267 document types, each including a high-and low-professionalism document with identical content but different structureand style.

16, TITLE: FML-bench: A Benchmark for Automatic ML Research Agents Highlighting The Importance of Exploration Breadth
AUTHORS: Qiran Zou; Hou Hei Lam; Wenhao Zhao; Yiming Tang; Tingting Chen; Samson Yu; Tianyi Zhang; Chang Liu; Xiangyang Ji; Dianbo Liu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: They also suffer from limited taskdiversity, an overemphasis on application-oriented tasks over fundamentalresearch problems, and limited scalability to realistic research settings. Toaddress these limitations, we introduce FML-bench, a benchmark designed toevaluate automatic machine learning research agents on 8 diverse andfundamental machine learning research problems.

17, TITLE: Simulating Viva Voce Examinations to Evaluate Clinical Reasoning in Large Language Models
AUTHORS: Christopher Chiu; Silviu Pitis; Mihaela van der Schaar
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In contrast, currentmedical benchmarks for large language models (LLMs) primarily assess knowledgerecall through single-turn questions, where complete clinical information isprovided upfront. To address this gap, we introduce VivaBench, a multi-turnbenchmark that evaluates sequential clinical reasoning in LLM agents.

18, TITLE: Beyond Fertility: Analyzing STRR As A Metric for Multilingual Tokenization Evaluation
AUTHORS: Mir Tafseer Nayeem; Sawsan Alqahtani; Md Tahmid Rahman Laskar; Tasnim Mohiuddin; M Saiful Bari
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To address fertility'sblind spots, we propose the Single Token Retention Rate (STRR), which measuresthe proportion of words preserved as single tokens.

19, TITLE: DiffHeads: Differential Analysis and Inference-Time Masking of Bias Heads in Large Language Models
AUTHORS: Tingxu Han; Wei Song; Ziqi Ding; Ziming Li; Chunrong Fang; Yuekang Li; Dongfang Liu; Zhenyu Chen; Zhenting Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, weconduct a systematic investigation LLM unfairness and propose DiffHeads, alightweight debiasing framework for LLMs.

20, TITLE: How Can We Assess Human-agent Interactions? Case Studies in Software Agent Design
AUTHORS: Valerie Chen; Rohit Malhotra; Xingyao Wang; Juan Michelini; Xuhui Zhou; Aditya Bharat Soni; Hoang H. Tran; Calvin Smith; Ameet Talwalkar; Graham Neubig
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we make two major steps towardsthe rigorous assessment of human-agent interactions.

21, TITLE: SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents
AUTHORS: Zonghao Ying; Yangguang Shao; Jianle Gan; Gan Xu; Junjie Shen; Wenxin Zhang; Quanchen Zou; Junzheng Shi; Zhenfei Yin; Mingchuan Zhang; Aishan Liu; Xianglong Liu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Existing benchmarks provide only partialcoverage, typically restricted to narrow scenarios such as user-level promptmanipulation, and thus fail to capture the broad range of agentvulnerabilities. To address this gap, we present \tool{}, the first holisticbenchmark for evaluating the security of LVLM-based web agents.

22, TITLE: Are Large Reasoning Models Interruptible?
AUTHORS: Tsung-Han Wu; Mihran Miroyan; David M. Chan; Trevor Darrell; Narges Norouzi; Joseph E. Gonzalez
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we challenge thefrozen world assumption and evaluate LRM robustness under two realistic dynamicscenarios: interruptions, which test the quality of the model's partial outputson a limited budget, and dynamic context, which tests model adaptation toin-flight changes.

23, TITLE: ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training
AUTHORS: Leonard Bruns; Axel Barroso-Laguna; Tommaso Cavallari; Áron Monszpart; Sowmya Munukutla; Victor Adrian Prisacariu; Eric Brachmann
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose to separatethe coordinate regressor and the map representation into a generic transformerand a scene-specific map code.

24, TITLE: Benchmarking Correctness and Security in Multi-Turn Code Generation
AUTHORS: Ruchit Rawal; Jeffrey Yang Fan Chiang; Chihao Shen; Jeffery Siyuan Tian; Aastha Mahajan; Tom Goldstein; Yizheng Chen
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: We introduce MT-Sec, the first benchmark tosystematically evaluate both correctness and security in multi-turn codingscenarios.

25, TITLE: LLM$ \times$MapReduce-V3: Enabling Interactive In-Depth Survey Generation Through A MCP-Driven Hierarchically Modular Agent System
AUTHORS: Yu Chao; Siyu Lin; xiaorong wang; Zhu Zhang; Zihan Zhou; Haoyu Wang; Shuo Wang; Jie Zhou; Zhiyuan Liu; Maosong Sun
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce LLM x MapReduce-V3, a hierarchically modular agent systemdesigned for long-form survey generation.

26, TITLE: ImCoref-CeS: An Improved Lightweight Pipeline for Coreference Resolution with LLM-based Checker-Splitter Refinement
AUTHORS: Kangyang Luo; Yuzhuo Bai; Shuzheng Si; Cheng Gao; Zhitong Wang; Yingli Shen; Wenhao Li; Zhu Liu; Yufeng Han; Jiayi Wu; Cunliang Kong; Maosong Sun
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To this end, we propose\textbf{ImCoref-CeS}, a novel framework that integrates an enhanced supervisedmodel with LLM-based reasoning.

27, TITLE: Are Video Models Emerging As Zero-Shot Learners and Reasoners in Medical Imaging?
AUTHORS: Yuxiang Lai; Jike Zhong; Ming Li; Yuheng Li; Xiaofeng Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Specifically, we evaluate a large vision model (LVM) in azero-shot setting across four representative tasks: organ segmentation,denoising, super-resolution, and motion prediction.

28, TITLE: ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models
AUTHORS: Yuqi Liu; Liangyu Chen; Jiazhen Liu; Mingkang Zhu; Zhisheng Zhong; Bei Yu; Jiaya Jia
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address these limitations, we proposeViSurf (\textbf{Vi}sual \textbf{Su}pervised-and-\textbf{R}einforcement\textbf{F}ine-Tuning), a unified post-training paradigm that integrates thestrengths of both SFT and RLVR within a single stage. We analyze the derivationof the SFT and RLVR objectives to establish the ViSurf objective, providing aunified perspective on these two paradigms.

29, TITLE: Backdoor Collapse: Eliminating Unknown Threats Via Known Backdoor Aggregation in Language Models
AUTHORS: Liang Lin; Miao Yu; Moayad Aloqaily; Zhenhong Zhou; Kun Wang; Linsey Pang; Prakhar Mehrotra; Qingsong Wen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: Backdoor attacks are a significant threat to large language models (LLMs),often embedded via public checkpoints, yet existing defenses rely onimpractical assumptions about trigger ...

30, TITLE: SR-Scientist: Scientific Equation Discovery With Agentic AI
AUTHORS: Shijie Xia; Yuhan Sun; Pengfei Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Recently, Large Language Models (LLMs) have been applied to scientificequation discovery, leveraging their embedded scientific knowledge forhypothesis generation.

31, TITLE: Agentic Property-Based Testing: Finding Bugs Across The Python Ecosystem
AUTHORS: Muhammad Maaz; Liam DeVoe; Zac Hatfield-Dodds; Nicholas Carlini
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: In this work, we demonstrate an LLM-based agent which analyzes Pythonmodules, infers function-specific and cross-function properties from code anddocumentation, synthesizes and executes PBTs, reflects on outputs of thesetests to confirm true bugs, and finally outputs actionable bug reports for thedeveloper.

32, TITLE: Rethinking RL Evaluation: Can Benchmarks Truly Reveal Failures of RL Methods?
AUTHORS: Zihan Chen; Yiming Zhang; Hengguang Zhou; Zenghui Ding; Yining Sun; Cho-Jui Hsieh
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Current benchmarks are inadequate for evaluating progress in reinforcementlearning (RL) for large language models (LLMs). Despite recent benchmark gainsreported for RL, we find that training on these benchmarks' training setsachieves nearly the same performance as training directly on the test sets,suggesting that the benchmarks cannot reliably separate further progress.Tostudy this phenomenon, we introduce a diagnostic suite and the OraclePerformance Gap (OPG) metric that quantifies the performance difference betweentraining on the train split versus the test split of a benchmark.

33, TITLE: Enabling Doctor-Centric Medical AI with LLMs Through Workflow-Aligned Tasks and Benchmarks
AUTHORS: Wenya Xie; Qingying Xiao; Yu Zheng; Xidong Wang; Junying Chen; Ke Ji; Anningzhe Gao; Prayag Tiwari; Xiang Wan; Feng Jiang; Benyou Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This work contributes avaluable resource and framework for advancing doctor-centered medical LLMdevelopment

34, TITLE: The Geometry of Reasoning: Flowing Logics in Representation Space
AUTHORS: Yufa Zhou; Yixiao Wang; Xunjian Yin; Shuyan Zhou; Anru R. Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We propose a novel geometric framework that models anLLM's reasoning as flows -- embedding trajectories evolving where logic goes.We disentangle logical structure from semantics by employing the same naturaldeduction propositions with varied semantic carriers, allowing us to testwhether LLMs internalize logic beyond surface form.

35, TITLE: Why Do Transformers Fail to Forecast Time Series In-Context?
AUTHORS: Yufa Zhou; Yixiao Wang; Surbhi Goel; Anru R. Zhang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we provide a theoretical analysis ofTransformers' limitations for TSF through the lens of In-Context Learning (ICL)theory.

36, TITLE: Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently By Hybrid Reasoning
AUTHORS: Yujian Zhang; Keyu Chen; Zhifeng Shen; Ruizhi Qiao; Xing Sun
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: (2) A reinforcement learning stagefor optimizing reasoning effort, where we introduce Entropy-guided HybridPolicy Optimization EHPO, an RL training framework employing an entropy-guideddynamic rollout strategy for branching at high-entropy units and adifficulty-aware penalty to balance fast and slow reasoning.

37, TITLE: Representation-Based Exploration for Language Models: From Test-Time to Post-Training
AUTHORS: Jens Tuyls; Dylan J. Foster; Akshay Krishnamurthy; Jordan T. Ash
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Ourmain finding is that exploration with a simple, principled,representation-based bonus derived from the pre-trained language model's hiddenstates significantly improves diversity and pass@k rates -- both forpost-training, and in a novel inference-time scaling setting we introduce.

38, TITLE: MedAgentAudit: Diagnosing and Quantifying Collaborative Failure Modes in Medical Multi-Agent Systems
AUTHORS: Lei Gu; Yinghao Zhu; Haoran Sang; Zixiang Wang; Dehao Sui; Wen Tang; Ewen Harrison; Junyi Gao; Lequan Yu; Liantao Ma
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This practice treats their internal collaborativeprocesses as opaque "black boxes" and overlooks a critical question: is adiagnostic conclusion reached through a sound and verifiable reasoning pathway?The inscrutable nature of these systems poses a significant risk in high-stakesmedical applications, potentially leading to flawed or untrustworthyconclusions. To address this, we conduct a large-scale empirical study of 3,600cases from six medical datasets and six representative multi-agent frameworks.Through a rigorous, mixed-methods approach combining qualitative analysis withquantitative auditing, we develop a comprehensive taxonomy of collaborativefailure modes.

39, TITLE: SAFER: Risk-Constrained Sample-then-Filter in Large Language Models
AUTHORS: Qingni Wang; Yue Fan; Xin Eric Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Existing selectiveconformal prediction (SCP) methods provide statistical guarantees byconstructing prediction sets with a constrained miscoverage rate for correctanswers.

40, TITLE: CodePlot-CoT: Mathematical Visual Reasoning By Thinking with Code-Driven Images
AUTHORS: Chengqi Duan; Kaiyue Sun; Rongyao Fang; Manyuan Zhang; Yan Feng; Ying Luo; Yufang Liu; Ke Wang; Peng Pei; Xunliang Cai; Hongsheng Li; Yi Ma; Xihui Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our approach leverages the VLM to generate textreasoning as well as executable plotting code, which is then rendered intoimages as "visual thought", to solve mathematical problems. To achieve this, wefirst construct Math-VR, the first large-scale, bilingual dataset and benchmarkfor Mathematics problems with Visual Reasoning, comprising 178K samples.Second, to create high-quality training data, we develop a state-of-the-artimage-to-code converter specialized for parsing complex mathematical figuresinto codes.

41, TITLE: VCB Bench: An Evaluation Benchmark for Audio-Grounded Large Language Model Conversational Agents
AUTHORS: Jiliang Hu; Wenfu Wang; Zuchao Li; Chenxing Li; Yiyang Zhao; Hanzhao Li; Liqiang Zhang; Meng Yu; Dong Yu
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: However, existing benchmarks remain limited-- they are mainly English-centric, rely on synthetic speech, and lackcomprehensive, discriminative evaluation across multiple dimensions. To addressthese gaps, we present Voice Chat Bot Bench (VCB Bench) -- a high-qualityChinese benchmark built entirely on real human speech.

42, TITLE: Analyzing and Internalizing Complex Policy Documents for LLM Agents
AUTHORS: Jiateng Liu; Zhenhailong Wang; Xiaojiang Huang; Yingjie Li; Xing Fan; Xiang Li; Chenlei Guo; Ruhi Sarikaya; Heng Ji
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We introduceCC-Gen, an agentic benchmark generator with Controllable Complexity across fourlevels, enabling systematic evaluation of agents' ability to handle complexityand offering a unified framework for assessing policy internalization.

43, TITLE: Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models
AUTHORS: Nianyi Lin; Jiajie Zhang; Lei Hou; Juanzi Li
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: A key challenge in applying reinforcement learning (RL) to diffusion largelanguage models (dLLMs) lies in the intractability of their likelihoodfunctions, which are essential for ...

44, TITLE: $How^{2}$: How to Learn from Procedural How-to Questions
AUTHORS: Gautier Dagan; Frank Keller; Alex Lascarides
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: range from executable actions to high-level descriptions of X'ssub-goals, makes them challenging for AI agents to ask, and for AI experts toanswer, in ways that support efficient planning. We introduce $How^{2}$, amemory agent framework that enables agents to ask how-to questions, store theanswers, and reuse them for lifelong learning in interactive environments.

45, TITLE: Building A Foundational Guardrail for General Agentic Systems Via Synthetic Data
AUTHORS: Yue Huang; Hang Hua; Yujun Zhou; Pengcheng Jing; Manish Nagireddy; Inkit Padhi; Greta Dolcetti; Zhangchen Xu; Subhajit Chaudhury; Ambrish Rawat; Liubov Nedoshivina; Pin-Yu Chen; Prasanna Sattigeri; Xiangliang Zhang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To close the guardian model gap, we propose afoundational guardrail Safiron, combining a cross-planner adapter with acompact guardian model.

46, TITLE: MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps
AUTHORS: Jiahui Lei; Kyle Genova; George Kopanas; Noah Snavely; Leonidas Guibas
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose anovel pixel-aligned Motion Map (MoMap) representation for 3D scene motion,which can be generated from existing generative image models to facilitateefficient and effective motion prediction.

47, TITLE: Evaluating Language Models' Evaluations of Games
AUTHORS: Katherine M. Collins; Cedegao E. Zhang; Graham Todd; Lance Ying; Mauricio Barba da Costa; Ryan Liu; Prafull Sharma; Adrian Weller; Ionatan Kuperwajs; Lionel Wong; Joshua B. Tenenbaum; Thomas L. Griffiths
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we advocate for a newparadigm that assesses AI systems' evaluation of games.

48, TITLE: People Use Fast, Flat Goal-directed Simulation to Reason About Novel Problems
AUTHORS: Katherine M. Collins; Cedegao E. Zhang; Lionel Wong; Mauricio Barba da Costa; Graham Todd; Adrian Weller; Samuel J. Cheyette; Thomas L. Griffiths; Joshua B. Tenenbaum
CATEGORY: arxiv-q-bio.NC [NC]
HIGHLIGHT: We explain thesecapacities via a computational cognitive model that we call the "IntuitiveGamer".

49, TITLE: IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment
AUTHORS: Yinan Chen; Jiangning Zhang; Teng Hu; Yuxiang Zeng; Zhucun Xue; Qingdong He; Chengjie Wang; Yong Liu; Xiaobin Hu; Shuicheng Yan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address the abovelimitations, we introduce IVEBench, a modern benchmark suite specificallydesigned for instruction-guided video editing assessment.

50, TITLE: Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection
AUTHORS: Shizhen Zhao; Jiahui Liu; Xin Wen; Haoru Tan; Xiaojuan Qi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To mitigate this,we propose the Mixture of Feature Experts (MoFE) module, which partitionsfeatures into subspaces, effectively capturing complex data distributions andrefining decision boundaries.

51, TITLE: MC#: Mixture Compressor for Mixture-of-Experts Large Models
AUTHORS: Wei Huang; Yue Liao; Yukang Chen; Jianhui Liu; Haoru Tan; Si Liu; Shiming Zhang; Shuicheng Yan; Xiaojuan Qi
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To addressthis, we propose MC# (Mixture-Compressor-sharp), a framework that combinesstatic quantization and dynamic expert pruning by leveraging the significanceof experts and tokens for aggressive compression of MoE-LLMs/VLMs.

52, TITLE: SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation
AUTHORS: Zhenjie Mao; Yuhuan Yang; Chaofan Ma; Dongsheng Jiang; Jiangchao Yao; Ya Zhang; Yanfeng Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we identify two challengingreal-world scenarios: object-distracting expressions, which involve multipleentities with contextual cues, and category-implicit expressions, where theobject class is not explicitly stated.

53, TITLE: Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning
AUTHORS: Sanchit Sinha; Oana Frunza; Kashif Rasul; Yuriy Nevmyvaka; Aidong Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present Chart-RVR, a general framework that fine-tunes LVLMsto be more robust and explainable for chart reasoning by coupling GroupRelative Policy Optimization (GRPO) with automatically verifiable rewards.

54, TITLE: COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models
AUTHORS: Sanchit Sinha; Guangzhi Xiong; Aidong Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Inthis paper, we present 'COCO-Tree' - a novel approach that augments VLM outputswith carefully designed neurosymbolic concept trees learned from LLMs toimprove VLM's linguistic reasoning.

55, TITLE: Prepared for The Unknown: Adapting AIOps Capacity Forecasting Models to Data Changes
AUTHORS: Lorena Poenaru-Olaru; Wouter van 't Hof; Adrian Stando; Arkadiusz P. Trawinski; Eileen Kapel; Jan S. Rellermeyer; Luis Cruz; Arie van Deursen
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: In this work, we investigate the effects of retrainingcapacity forecasting models for time series based on detected changes in thedata compared to periodic retraining.

56, TITLE: Reproducibility: The New Frontier in AI Governance
AUTHORS: Israel Mason-Williams; Gabryel Mason-Williams
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Our paper outlines how AI research could adoptstricter reproducibility guidelines to assist governance endeavours and improveconsensus on the AI risk landscape.

57, TITLE: Multi Class Parkinsons Disease Detection Based on Finger Tapping Using Attention-Enhanced CNN BiLSTM
AUTHORS: Abu Saleh Musa Miah; Najmul Hassan; Md Maruf Al Hossain; Yuichi Okuyama; Jungpil Shin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this study, we propose a multi-class ParkinsonDisease detection system based on finger tapping using an attention-enhancedCNN BiLSTM.

58, TITLE: ACT: Automatically Generating Compiler Backends from Tensor Accelerator ISA Descriptions
AUTHORS: Devansh Jain; Akash Pardeshi; Marco Frigo; Krut Patel; Kaustubh Khulbe; Jai Arora; Charith Mendis
CATEGORY: arxiv-cs.PL [PL]
HIGHLIGHT: Therefore, to increase adoption and enable faster softwaredevelopment cycles for novel tensor accelerator designs, we need to make thecompiler backend construction process more agile. To address this gap, we introduce ACT, a compiler backend generator thatautomatically generates compiler backends for tensor accelerators, given justthe instruction set architecture (ISA) descriptions.

59, TITLE: ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling
AUTHORS: Rolandos Alexandros Potamias; Stathis Galanakis; Jiankang Deng; Athanasios Papaioannou; Stefanos Zafeiriou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Following theadvent of deep implicit functions, we propose imHead, a novel implicit 3DMMthat not only models expressive 3D head avatars but also facilitates localizedediting of the facial features.

60, TITLE: PhysHSI: Towards A Real-World Generalizable and Natural Humanoid-Scene Interaction System
AUTHORS: Huayi Wang; Wentao Zhang; Runyi Yu; Tao Huang; Junli Ren; Feiyu Jia; Zirui Wang; Xiaojie Niu; Xiao Chen; Jiahe Chen; Qifeng Chen; Jingbo Wang; Jiangmiao Pang
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this work, we present a physical-world humanoid-scene interactionsystem, PhysHSI, that enables humanoids to autonomously perform diverseinteraction tasks while maintaining natural and lifelike behaviors.

61, TITLE: Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective
AUTHORS: Zhezheng Hao; Hong Wang; Haoyang Liu; Jian Luo; Jiarui Yu; Hande Dong; Qiang Lin; Can Wang; Jiawei Chen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, weconduct a quantitative analysis to reveal token-level entropy changes and howexisting entropy intervention methods help avoid entropy collapse.

62, TITLE: BabyBabelLM: A Multilingual Benchmark of Developmentally Plausible Training Data
AUTHORS: Jaap Jumelet; Abdellah Fourtassi; Akari Haga; Bastian Bunzeck; Bhargav Shandilya; Diana Galvan-Sosa; Faiz Ghifari Haznitrama; Francesca Padovani; Francois Meyer; Hai Hu; Julen Etxaniz; Laurent Prévot; Linyang He; María Grandury; Mila Marcheva; Negar Foroutan; Nikitas Theodoropoulos; Pouya Sadeghi; Siyuan Song; Suchir Salhan; Susana Zhou; Yurii Paniv; Ziyin Zhang; Arianna Bisazza; Alex Warstadt; Leshem Choshen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present BabyBabelLM, a multilingual collection of datasets modeling thelanguage a person observes from birth until they acquire a native language.

63, TITLE: Revisiting Model Interpolation for Efficient Reasoning
AUTHORS: Taiqiang Wu; Runming Yang; Tao Liu; Jiahao Wang; Ngai Wong
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, wesystematically revisit the simplest merging method that interpolates twoweights directly.

64, TITLE: RePro: Training Language Models to Faithfully Recycle The Web for Pretraining
AUTHORS: Zichun Yu; Chenyan Xiong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, weintroduce RePro, a novel web recycling method that trains a relatively small LMwith reinforcement learning to generate effective and faithful rephrasings ofpretraining data.

65, TITLE: High-resolution Photo Enhancement in Real-time: A Laplacian Pyramid Network
AUTHORS: Feng Zhang; Haoyou Deng; Zhiqiang Li; Lida Li; Bin Xu; Qingbo Lu; Zisheng Cao; Minchen Wei; Changxin Gao; Nong Sang; Xiang Bai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To this end, this paper introduces apyramid network called LLF-LUT++, which integrates global and local operatorsthrough closed-form Laplacian pyramid decomposition and reconstruction.

66, TITLE: FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model
AUTHORS: Chunyu Xie; Bin Wang; Fanjing Kong; Jincheng Li; Dawei Liang; Ji Ao; Dawei Leng; Yuhui Yin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: While models like CLIPperform well on global alignment, they often struggle to capture fine-graineddetails in object attributes, spatial relations, and linguistic expressions,with limited support for bilingual comprehension. To address these challenges,we introduce FG-CLIP 2, a bilingual vision-language model designed to advancefine-grained alignment for both English and Chinese.

67, TITLE: DITTO: A Spoofing Attack Framework on Watermarked LLMs Via Knowledge Distillation
AUTHORS: Hyeseon Ahn; Shinwoo Park; Yo-Sub Han
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: We introduce the threat of watermarkspoofing, a sophisticated attack that allows a malicious model to generate textcontaining the authentic-looking watermark of a trusted, victim model.

68, TITLE: Survey Response Generation: Generating Closed-Ended Survey Responses In-Silico with Large Language Models
AUTHORS: Georg Ahnert; Anna-Carolina Haensch; Barbara Plank; Markus Strohmaier
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In thispaper, we systematically investigate the impact that various Survey ResponseGeneration Methods have on predicted survey responses.

69, TITLE: Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on Sexism, Racism, and Morality
AUTHORS: Jana Jung; Marlene Lutz; Indira Sen; Markus Strohmaier
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this study, we systematically evaluate the reliability andvalidity of human psychometric tests for three constructs: sexism, racism, andmorality.

70, TITLE: A$^2$FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning
AUTHORS: Qianben Chen; Jingyi Cao; Jiayu Zhang; Tianrui Qin; Xiaowan Li; King Zhu; Dingfeng Shi; He Zhu; Minghao Liu; Xiaobo Liang; Xin Gui; Ge Zhang; Jian Yang; Yuchen Eleanor Jiang; Wangchunshu Zhou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Inthis work, we present Adaptive Agent Foundation Model (A$^2$FM), a unifiedframework that follows a route-then-align principle: the model first learnstask-aware routing and then aligns mode-specific trajectories under a sharedbackbone.

71, TITLE: ACADREASON: Exploring The Limits of Reasoning Models with Academic Research Problems
AUTHORS: Xin Gui; King Zhu; JinCheng Ren; Qianben Chen; Zekun Moore Wang; Yizhi LI; Xinpeng Liu; Xiaowan Li; Wenli Ren; Linyu Miao; Tianrui Qin; Ziqi Shu; He Zhu; Xiangru Tang; Dingfeng Shi; Jiaheng Liu; Yuchen Eleanor Jiang; Minghao Liu; Ge Zhang; Wangchunshu Zhou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, existing evaluationsfocus mainly on math/code contests or general tasks, while existingmulti-domain academic benchmarks lack sufficient reasoning depth, leaving thefield without a rigorous benchmark for high-level reasoning. To fill this gap,we introduce the Acadreason benchmark, designed to evaluate the ability of LLMsand agents to acquire and reason over academic knowledge.

72, TITLE: Video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits Via Memory
AUTHORS: Guangzhi Sun; Yixuan Li; Xiaodong Wu; Yudong Yang; Wei Li; Zejun Ma; Chao Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our model introduces(i) a test-time-training (TTT) memory module that continually updates tokenrepresentations to capture long-range dependencies by replacing token merging,and (ii) a prompt-dependent memory reader that selectively retrievescontext-relevant content from fixed-size memory.

73, TITLE: Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics
AUTHORS: Sheng Jin; Haoming Wang; Zhiqi Gao; Yongbo Yang; Bao Chunjia; Chengliang Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: Large language models (LLMs) based Agents are increasingly pivotal insimulating and understanding complex human systems and interactions. We proposethe AI-Agent School (AAS) ...

74, TITLE: AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes
AUTHORS: Yu Li; Menghan Xia; Gongye Liu; Jianhong Bai; Xintao Wang; Conglang Zhang; Yuxuan Lin; Ruihang Chu; Pengfei Wan; Yujiu Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To this end, we propose a two-stage paradigm to adaptpre-trained T2V models for viewpoint prediction, in a compatible manner.

75, TITLE: Point Prompting: Counterfactual Tracking with Video Diffusion Models
AUTHORS: Ayush Shrivastava; Sanyam Mehta; Daniel Geng; Andrew Owens
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Trackers and video generators solve closely related problems: the formeranalyze motion, while the latter synthesize it. We show that this connectionenables pretrained video diffusion models to perform zero-shot point trackingby simply prompting them to visually mark points as they move over time.

76, TITLE: Demystifying Reinforcement Learning in Agentic Reasoning
AUTHORS: Zhaochen Yu; Ling Yang; Jiaru Zou; Shuicheng Yan; Mengdi Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we conduct acomprehensive and systematic investigation to demystify reinforcement learningin agentic reasoning from three key perspectives: data, algorithm, andreasoning mode.

77, TITLE: ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers
AUTHORS: Shivam Patel; Neharika Jali; Ankur Mallick; Gauri Joshi
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose ProxRouter, which applies anexponentially tilted aggregation mechanism to balance bias and variance innonparametric routers, improving their robustness to outliers.

78, TITLE: Understanding Sampler Stochasticity in Training Diffusion Models for RLHF
AUTHORS: Jiayuan Sheng; Hanyang Zhao; Haoxian Chen; David D. Yao; Wenpin Tang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we theoretically characterize thisreward gap and provide non-vacuous bounds for general diffusion models, alongwith sharper convergence rates for Variance Exploding (VE) and VariancePreserving (VP) Gaussian models.

79, TITLE: BILLY: Steering Large Language Models Via Merging Persona Vectors for Creative Generation
AUTHORS: Tsung-Min Pai; Jui-I Wang; Li-Chun Lu; Shao-Hua Sun; Hung-Yi Lee; Kai-Wei Chang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To address theselimitations, we propose BILLY (BlendIng persona vectors for Large Languagemodel creativitY), a training-free framework that captures the benefits ofmulti-LLM collaboration, i.e. inducing diverse perspectives and specializedexpertise, within a single model.

80, TITLE: Head-wise Adaptive Rotary Positional Encoding for Fine-Grained Image Generation
AUTHORS: Jiaye Li; Baoyou Chen; Hui Li; Zilong Dong; Jingdong Wang; Siyu Zhu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper identifies keylimitations of standard multi-dimensional RoPE-rigid frequency allocation,axis-wise independence, and uniform head treatment-in capturing the complexstructural biases required for fine-grained image generation.

81, TITLE: ImmerIris: A Large-Scale Dataset and Benchmark for Immersive Iris Recognition in Open Scenes
AUTHORS: Yuxi Mi; Qiuyang Yuan; Zhizhou Zhong; Xuan Zhao; Jiaogen Zhou; Fubao Zhu; Jihong Guan; Shuigeng Zhou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: In egocentric applications such as augmented and virtual reality, immersiveiris recognition is emerging as an accurate and seamless way to identifypersons. While classic systems ...

82, TITLE: Unified Open-World Segmentation with Multi-Modal Prompts
AUTHORS: Yang Liu; Yufei Yin; Chenchen Jing; Muzhi Zhu; Hao Chen; Yuling Xi; Bo Feng; Hao Wang; Shiyu Li; Chunhua Shen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we present COSINE, a unified open-world segmentation model thatconsolidates open-vocabulary segmentation and in-context segmentation withmulti-modal prompts (e.g., text and image).

83, TITLE: Judge Before Answer: Can MLLM Discern The False Premise in Question?
AUTHORS: Jidong Li; Lingyong Fang; Haodong Zhao; Sufeng Duan; Gongshen Liu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Our method systematically categorizes the premises intothree main types and thirteen subtypes according to the abilities required toidentify the premises, resulting in the JBA dataset.Results show current MLLMsstill struggle with false premise recognition. Building upon this benchmark, wefurther propose a recognition enhancement framework tailored to strengthen therobustness of MLLMs to detect false premises.

84, TITLE: X-VLA: Soft-Prompted Transformer As Scalable Cross-Embodiment Vision-Language-Action Model
AUTHORS: Jinliang Zheng; Jianxiong Li; Zhihao Wang; Dongxiu Liu; Xirui Kang; Yuchun Feng; Yinan Zheng; Jiayin Zou; Yilun Chen; Jia Zeng; Ya-Qin Zhang; Jiangmiao Pang; Jingjing Liu; Tai Wang; Xianyuan Zhan
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: To facilitate and leverage the heterogeneity in rich,diverse robotic data sources, we propose a novel Soft Prompt approach withminimally added parameters, by infusing prompt learning concepts intocross-embodiment robot learning and introducing separate sets of learnableembeddings for each distinct data source.

85, TITLE: REACT3D: Recovering Articulations for Interactive Physical 3D Scenes
AUTHORS: Zhao Huang; Boyang Sun; Alexandros Delitzas; Jiaqi Chen; Marc Pollefeys
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our contributions include: (i)openable-object detection and segmentation to extract candidate movable partsfrom static scenes, (ii) articulation estimation that infers joint types andmotion parameters, (iii) hidden-geometry completion followed by interactiveobject assembly, and (iv) interactive scene integration in widely supportedformats to ensure compatibility with standard simulation platforms.

86, TITLE: Massive Activations Are The Key to Local Detail Synthesis in Diffusion Transformers
AUTHORS: Chaofan Gan; Zicheng Zhao; Yuanpeng Tu; Xi Chen; Ziran Qin; Tieyuan Chen; Mehrtash Harandi; Weiyao Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Recent observations reveal \emph{Massive Activations}(MAs) in their internal feature maps, yet their function remains poorlyunderstood. In this work, we systematically investigate these activations toelucidate their role in visual generation.

87, TITLE: Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos
AUTHORS: Xuankai Zhang; Junjin Xiao; Qing Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper presents a unified framework that allows high-quality dynamicGaussian Splatting from both defocused and motion-blurred monocular videos.

88, TITLE: Skill-Targeted Adaptive Training
AUTHORS: Yinghui He; Abhishek Panigrahi; Yong Lin; Sanjeev Arora
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Language models often show little to no improvement (i.e., "saturation") whentrained via vanilla supervised fine-tuning (SFT) on data similar to what theysaw in their training set (e.g., MATH). We introduce a new fine-tuningstrategy, STAT, to train such a student model by using the metacognitionability of a stronger large language model (LLM) as the teacher.

89, TITLE: WorldMirror: Universal 3D World Reconstruction with Any-Prior Prompting
AUTHORS: Yifan Liu; Zhiyuan Min; Zhenwei Wang; Junta Wu; Tengfei Wang; Yixuan Yuan; Yawei Luo; Chunchao Guo
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present WorldMirror, an all-in-one, feed-forward model for versatile 3Dgeometric prediction tasks.

90, TITLE: Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation
AUTHORS: Maggie Wang; Stephen Tian; Aiden Swann; Ola Shorinwa; Jiajun Wu; Mac Schwager
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: While reinforcement learning (RL) policiestrained in simulation present a scalable alternative, effective sim-to-realtransfer remains challenging, particularly for tasks that require precisedynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RLpipeline that combines vision-language model (VLM)-inferred physical parameterestimates with interactive adaptation through uncertainty-aware fusion.

91, TITLE: VR-Thinker: Boosting Video Reward Models Through Thinking-with-Image Reasoning
AUTHORS: Qunzhong Wang; Jie Liu; Jiajun Liang; Yilei Jiang; Yuanxing Zhang; Jinyuan Chen; Yaozhi Zheng; Xintao Wang; Pengfei Wan; Xiangyu Yue; Jiaheng Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Recent advancements in multimodal reward models (RMs) have substantiallyimproved post-training for visual generative models. However, current RMs faceinherent limitations: (1) ...

92, TITLE: CardRewriter: Leveraging Knowledge Cards for Long-Tail Query Rewriting on Short-Video Platforms
AUTHORS: Peiyuan Gong; Feiran Zhu; Yaqi Yin; Chenglei Dai; Chao Zhang; Kai Zheng; Wentian Bao; Jiaxin Mao; Yi Zhang
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: While large language models(LLMs) have shown success in long-tail query rewriting within e-commerce, theystruggle on short-video platforms, where proprietary content such as shortvideos, live streams, micro dramas, and user social networks falls outsidetheir training distribution. To address this challenge, we introduce\textbf{CardRewriter}, an LLM-based framework that incorporates domain-specificknowledge to enhance long-tail query rewriting.

93, TITLE: Event-Aware Prompt Learning for Dynamic Graphs
AUTHORS: Xingtong Yu; Ruijuan Liang; Xinming Zhang; Yuan Fang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Inthis paper, we propose EVP, an event-aware dynamic graph prompt learningframework that can serve as a plug-in to existing methods, enhancing theirability to leverage historical events knowledge.

94, TITLE: LSZone: A Lightweight Spatial Information Modeling Architecture for Real-time In-car Multi-zone Speech Separation
AUTHORS: Jun Chen; Shichao Hu; Jiuxin Lin; Wenjie Li; Zihan Zhang; Xingchen Li; JinJiang Liu; Longshuai Xiao; Chao Weng; Lei Xie; Zhiyong Wu
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: We design a spatial informationextraction-compression (SpaIEC) module that combines Mel spectrogram andInteraural Phase Difference (IPD) to reduce computational burden whilemaintaining performance.

95, TITLE: Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model
AUTHORS: Yisen Gao; Jiaxin Bai; Yi Huang; Xingcheng Fu; Qingyun Sun; Yangqiu Song
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Despitetheir clear synergistic potential, where deduction can validate hypotheses andabduction can uncover deeper logical patterns, existing methods address them inisolation. To bridge this gap, we propose DARK, a unified framework forDeductive and Abductive Reasoning in Knowledge graphs.

96, TITLE: DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay
AUTHORS: Yunxiang Mo; Tianshi Zheng; Qing Zong; Jiayu Liu; Baixuan Xu; Yauwai Yim; Chunkit Chan; Jiaxin Bai; Yangqiu Song
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: Multimodal abductive reasoning--the generation and selection of explanatoryhypotheses from partial observations--is a cornerstone of intelligence. Currentevaluations of this ...

97, TITLE: TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models
AUTHORS: Zonghuan Xu; Xiang Zheng; Xingjun Ma; Yu-Gang Jiang
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: In this paper, we study targeted backdoorattacks on VLA models and introduce TabVLA, a novel framework that enables suchattacks via black-box fine-tuning.

98, TITLE: PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents
AUTHORS: SHengjie Ma; Chenlong Deng; Jiaxin Mao; Jiadeng Huang; Teng Wang; Junjie Wu; Changwang Zhang; Jun wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: This results in (i) mode collapse intorepetitive reliance on a single source and (ii) spurious grounding, whereanswers are only weakly supported by cited content. To address this, we propose Proof-of-Use (PoU), an evidence-grounded RLframework that enforces verifiable causal links between retrieved evidence,reasoning traces, and final answers.

99, TITLE: P-4DGS: Predictive 4D Gaussian Splatting with 90$\times$ Compression
AUTHORS: Henan Wang; Hanxin Zhu; Xinliang Gong; Tianyu He; Xin Li; Zhibo Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address this,we propose P-4DGS, a novel dynamic 3DGS representation for compact 4D scenemodeling.

100, TITLE: ParaCook: On Time-Efficient Planning for Multi-Agent Systems
AUTHORS: Shiqi Zhang; Xinbei Ma; Yunqing Xu; Zouying Cao; Pengrui Lu; Haobo Yuan; Tiancheng Shen; Zhuosheng Zhang; Hai Zhao; Ming-Hsuan Yang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Large Language Models (LLMs) exhibit strong reasoning abilities for planninglong-horizon, real-world tasks, yet existing agent benchmarks focus on taskcompletion while neglecting time efficiency in parallel and asynchronousoperations. To address this, we present ParaCook, a benchmark fortime-efficient collaborative planning.

101, TITLE: HeadsUp! High-Fidelity Portrait Image Super-Resolution
AUTHORS: Renjie Li; Zihao Zhu; Xiaoyu Wang; Zhengzhong Tu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, these blending approaches inevitablyintroduce blending or boundary artifacts around the facial regions due todifferent model training recipes, while human perception is particularlysensitive to facial fidelity. To overcome these limitations, we study theportrait image supersolution (PortraitISR) problem, and propose HeadsUp, asingle-step diffusion model that is capable of seamlessly restoring andupscaling portrait images in an end-to-end manner.

102, TITLE: PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities
AUTHORS: Zicheng Liu; Lige Huang; Jie Zhang; Dongrui Liu; Yuan Tian; Jing Shao
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: To handle thesecomplex challenges, we propose PACEagent, a novel agent that emulates humanpenetration testers by supporting multi-phase reconnaissance, analysis, andexploitation.

103, TITLE: LLM-Friendly Knowledge Representation for Customer Support
AUTHORS: Hanchen Su; Wei Luo; Wei Han; Yu Elaine Liu; Yufeng Wayne Zhang; Cen Mia Zhao; Ying Joy Zhang; Yashar Mehdad
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We propose a practical approach by integrating Large Language Models (LLMs)with a framework designed to navigate the complexities of Airbnb customersupport operations.

104, TITLE: OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment
AUTHORS: Yiting Lu; Fengbin Guan; Yixin Gao; Yan Zhong; Xinge Peng; Jiakang Yuan; Yihao Liu; Bo Zhang; Xin Li; Zhibo Chen; Weisi Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Inspired by subjectiveexperiments, where participants are given task-specific instructions outliningdistinct assessment principles prior to evaluation, we propose OmniQuality-R, astructured reward modeling framework that transforms multi-dimensionalreasoning into continuous and interpretable reward signals.

105, TITLE: MRI Brain Tumor Detection with Computer Vision
AUTHORS: Jack Krolik; Jake Lynn; John Henry Rudden; Dmytro Vremenko
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This study explores the application of deep learning techniques in theautomated detection and segmentation of brain tumors from MRI scans.

106, TITLE: Reconstructing 12-Lead ECG from 3-Lead ECG Using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices
AUTHORS: Xinyan Guan; Yongfan Lai; Jiarui Jin; Jun Li; Haoyu Wang; Qinghao Zhao; Deyun Zhang; Shijia Geng; Shenda Hong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Three-lead ECGsystems are widely used in wearable devices due to their simplicity andmobility, but they often fail to capture pathologies in unmeasured regions. Toaddress this, we propose WearECG, a Variational Autoencoder (VAE) method thatreconstructs twelve-lead ECGs from three leads: II, V1, and V5.

107, TITLE: Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning
AUTHORS: Ganlin Yang; Tianyi Zhang; Haoran Hao; Weiyun Wang; Yibin Liu; Dehui Wang; Guanzhou Chen; Zijian Cai; Junting Chen; Weijie Su; Wengang Zhou; Yu Qiao; Jifeng Dai; Jiangmiao Pang; Gen Luo; Wenhai Wang; Yao Mu; Zhi Hou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we take an initial steptoward bridging embodied reasoning with VLA policy learning by introducingVlaser - a Vision-Language-Action Model with synergistic embodied reasoningcapability, which is a foundational vision-language model designed to integratehigh-level reasoning with low-level control for embodied agents.

108, TITLE: Audio-Maestro: Enhancing Large Audio-Language Models with Tool-Augmented Reasoning
AUTHORS: Kuan-Yi Lee; Tsung-En Lin; Hung-Yi Lee
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: In this work, wepresent Audio-Maestro -- a tool-augmented audio reasoning framework thatenables audio-language models to autonomously call external tools and integratetheir timestamped outputs into the reasoning process.

109, TITLE: Gold Panning: Turning Positional Bias Into Signal for Multi-Document LLM Reasoning
AUTHORS: Adam Byerly; Daniel Khashabi
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Weframe the problem of choosing reorderings as a bipartite matching problem.While an optimal assignment can be computed at each iteration with theHungarian algorithm in $O(N^3)$ time, we propose a greedy $O(N \log N)$strategy that achieves comparable performance by prioritizing the placement ofthe most uncertain documents in the most informative positions.

110, TITLE: Demystifying Numerosity in Diffusion Models -- Limitations and Remedies
AUTHORS: Yaqi Zhao; Xiaochen Wang; Li Dong; Wentao Zhang; Yuhui Yuan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we aim to study a fundamental yetoften overlooked question: Can diffusion models inherently generate the correctnumber of objects specified by a textual prompt simply by scaling up thedataset and model size?

111, TITLE: Collaborative Text-to-Image Generation Via Multi-Agent Reinforcement Learning and Semantic Fusion
AUTHORS: Jiabao Shi; Minfeng Qi; Lefeng Zhang; Di Wang; Yingjie Zhao; Ziying Li; Yalong Xing; Ningran Li
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We propose a multi-agent reinforcement learning framework thatcoordinates domain-specialized agents (e.g., focused on architecture,portraiture, and landscape imagery) within two coupled subsystems: a textenhancement module and an image generation module, each augmented withmultimodal integration components.

112, TITLE: DreamMakeup: Face Makeup Customization Using Latent Diffusion Models
AUTHORS: Geon Yeong Park; Inhwa Han; Serin Yang; Yeobin Hong; Seongmin Jeong; Heechan Jeon; Myeongjin Goh; Sung Won Yi; Jin Nam; Jong Chul Ye
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Addressing thesechallenges, we introduce DreamMakup - a novel training-free Diffusion modelbased Makeup Customization method, leveraging the inherent advantages ofdiffusion models for superior controllability and precise real-image editing.DreamMakeup employs early-stopped DDIM inversion to preserve the facialstructure and identity while enabling extensive customization through variousconditioning inputs such as reference images, specific RGB colors, and textualdescriptions.

113, TITLE: Reasoning-Enhanced Large Language Models for Molecular Property Prediction
AUTHORS: Jiaxi Zhuang; Yaorui Shi; Jue Hou; Yunong He; Mingwei Ye; Mingjun Xu; Yuming Su; Linfeng Zhang; Ying Qian; Linfeng Zhang; Guolin Ke; Hengxing Cai
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Molecular property prediction is crucial for drug discovery and materialsscience, yet existing approaches suffer from limited interpretability, poorcross-task generalization, and lack of chemical reasoning capabilities.Traditional machine learning models struggle with task transferability, whilespecialized molecular language models provide little insight into theirdecision-making processes. To address these limitations, we propose\textbf{MPPReasoner}, a multimodal large language model that incorporateschemical reasoning for molecular property prediction.

114, TITLE: GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving
AUTHORS: Ruida Wang; Jiarui Yao; Rui Pan; Shizhe Diao; Tong Zhang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, these approaches relyon fixed problem sets, which causes inefficient training and limits the modelto tackle complex problems. To overcome these limitations, we propose GAR:Generative Adversarial Reinforcement learning, a comprehensive RL trainingframework that jointly trains the problem composer and solver in an adversarialloop.

115, TITLE: XQuant: Achieving Ultra-Low Bit KV Cache Quantization with Cross-Layer Compression
AUTHORS: Haoqi Yang; Yao Yao; Zuchao Li; Baoyuan Qi; Guoming Liu; Hai Zhao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Quantization has emerged as a promisingsolution to reduce memory consumption while preserving historical information.We propose XQuant, a training-free and plug-and-play framework that achievesultra-low equivalent bit-width KV cache quantization.

116, TITLE: BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models
AUTHORS: Bryan Chen Zhengyu Tan; Zheng Weihua; Zhengyuan Liu; Nancy F. Chen; Hwaran Lee; Kenny Tsu Wei Choo; Roy Ka-Wei Lee
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: As vision-language models (VLMs) are deployed globally, their ability tounderstand culturally situated knowledge becomes essential. Yet, existingevaluations largely assess static ...

117, TITLE: The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs
AUTHORS: Xi Fang; Weijie Xu; Yuchong Zhang; Stephanie Eckman; Scott Nickleach; Chandan K. Reddy
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We find that identical scenarios paired with different user profilesproduce systematically divergent emotional interpretations.

118, TITLE: From to : Multidimensional Supervision of Reasoning Process for LLM Optimization
AUTHORS: Beining Wang; Weihang Su; Hongtao Tian; Tao Yang; Yujia Zhou; Ting Yao; Qingyao Ai; Yiqun Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To this end, we propose theDimension-level Reward Model (DRM), a new supervision framework that bridgesthe gap between these two approaches.

119, TITLE: When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents
AUTHORS: Lingfei Qian; Xueqing Peng; Yan Wang; Vincent Jim Zhang; Huan He; Hanley Smith; Yi Han; Yueru He; Haohang Li; Yupeng Cao; Yangyang Yu; Alejandro Lopez-Lira; Peng Lu; Jian-Yun Nie; Guojun Xiong; Jimin Huang; Sophia Ananiadou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: Although Large Language Model (LLM)-based agents are increasingly used infinancial trading, it remains unclear whether they can reason and adapt in livemarkets, as most studies ...

120, TITLE: InfiniHuman: Infinite 3D Human Creation with Precise Control
AUTHORS: Yuxuan Xue; Xianghui Xie; Margaret Kostyrko; Gerard Pons-Moll
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose InfiniHumanData, a fully automatic pipeline thatleverages vision-language and image generation models to create a large-scalemulti-modal dataset.

121, TITLE: PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from A Single Image
AUTHORS: Pradyumna Yalandur Muralidhar; Yuxuan Xue; Xianghui Xie; Margaret Kostyrko; Gerard Pons-Moll
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, existing methods struggle with depth ambiguity,occlusions, and physically inconsistent contacts. To address these challenges,we introduce PhySIC, a framework for physically plausible Human-SceneInteraction and Contact reconstruction.

122, TITLE: Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues
AUTHORS: Chenyu Zhang; Sharifa Alghowinem; Cynthia Breazeal
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This work introduces the first ensemble-LLMframework for large-scale affect sensing in tutoring dialogues, advancing theconversation on responsible pathways for integrating generative AI intoeducation by attending to learners' evolving affective states.

123, TITLE: Tracing The Traces: Latent Temporal Signals for Efficient and Accurate Reasoning
AUTHORS: Martina G. Vilas; Safoora Yousefi; Besmira Nushi; Eric Horvitz; Vidhisha Balachandran
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We introduce Latent-Trajectory signals thatcharacterize the temporal evolution of a model's internal representationsduring the generation of intermediate reasoning tokens.

124, TITLE: GapDNER: A Gap-Aware Grid Tagging Model for Discontinuous Named Entity Recognition
AUTHORS: Yawen Yang; Fukun Ma; Shiao Meng; Aiwei Liu; Lijie Wen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Previous methods recognizediscontinuous entities by connecting entity fragments or internal tokens, whichface challenges of error propagation and decoding ambiguity due to the widevariety of span or word combinations. To address these issues, we deeplyexplore discontinuous entity structures and propose an effective Gap-aware gridtagging model for Discontinuous Named Entity Recognition, named GapDNER.

125, TITLE: GenCNER: A Generative Framework for Continual Named Entity Recognition
AUTHORS: Yawen Yang; Fukun Ma; Shiao Meng; Aiwei Liu; Lijie Wen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, existing continual learning (CL) methods for NERface challenges of catastrophic forgetting and semantic shift of non-entitytype. In this paper, we propose GenCNER, a simple but effective Generativeframework for CNER to mitigate the above drawbacks.

126, TITLE: AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs
AUTHORS: Gunho Park; Jeongin Bae; Beomseok Kwon; Byeongwook Kim; Se Jung Kwon; Dongsoo Lee
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we presentAnyBCQ, a hardware-friendly multi-precision extension of Binary-CodedQuantization (BCQ) that supports direct bit-plane operations.

127, TITLE: UniCoD: Enhancing Robot Policy Via Unified Continuous and Discrete Representation Learning
AUTHORS: Jianke Zhang; Yucheng Hu; Yanjiang Guo; Xiaoyu Chen; Yichen Liu; Wenna Chen; Chaochao Lu; Jianyu Chen
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: We posit thatrobotic policy learning can likewise benefit from the combined strengths ofunderstanding, planning and continuous future representation learning. Buildingon this insight, we introduce UniCoD, which acquires the ability to dynamicallymodel high-dimensional visual features through pretraining on over 1Minternet-scale instructional manipulation videos.

128, TITLE: Rethinking Agentic Workflows: Evaluating Inference-Based Test-Time Scaling Strategies in Text2SQL Tasks
AUTHORS: Jiajing Guo; Kenil Patel; Jorge Piazentin Ono; Wenbin He; Liu Ren
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we benchmark sixlightweight, industry-oriented test-time scaling strategies and four LLMs,including two reasoning models, evaluating their performance on the BIRDMini-Dev benchmark.

129, TITLE: MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference
AUTHORS: Wenyuan Zhang; Jimin Tang; Weiqi Zhang; Yi Fang; Yu-Shen Liu; Zhizhong Han
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, werevisit the problem from a multi-view perspective and show that multi-viewconsistent material inference with more physically-based environment modelingis key to learning accurate reflections with Gaussian Splatting.

130, TITLE: Steering Embedding Models with Geometric Rotation: Mapping Semantic Relationships Across Languages and Models
AUTHORS: Michael Freenor; Lauren Alvarez
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We evaluate RISE across three embeddingmodels, three datasets, and seven morphologically diverse languages in fivemajor language groups.

131, TITLE: Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models
AUTHORS: Minbin Huang; Runhui Huang; Chuanyang Zheng; Jingyao Li; Guoxuan Chen; Han Shi; Hong Cheng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To this end, we propose Answer-Consistent Reinforcement Learning(ACRE) that modifies the GRPO algorithm with an auxiliary consistency check.After the model generates a chain of thought and an initial answer for a givenquestion, we shuffle the answer options and prompt the model again with thesame reasoning trace to predict a second answer.

132, TITLE: ALLOY: Generating Reusable Agent Workflows from User Demonstration
AUTHORS: Jiawen Li; Zheng Ning; Yuan Tian; Toby Jia-jun Li
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: Additionally, a ''successful'' prompt for one taskmay not be reusable or generalizable across similar tasks. We present ALLOY, asystem inspired by classical HCI theories on Programming by Demonstration(PBD), but extended to enhance adaptability in creating LLM-based web agents.ALLOY enables users to express procedural preferences through naturaldemonstrations rather than prompts, while making these procedures transparentand editable through visualized workflows that can be generalized across taskvariations.

133, TITLE: MATH-Beyond: A Benchmark for RL to Expand Beyond The Base Model
AUTHORS: Prasanna Mayilvahanan; Ricardo Dominguez-Olmedo; Thaddäus Wiedemer; Wieland Brendel
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL)methods has emerged that seem to unlock stronger mathematical reasoning.However, a closer look at the ...

134, TITLE: PatentVision: A Multimodal Method for Drafting Patent Applications
AUTHORS: Ruo Yang; Sai Krishna Reddy Mudhiganti; Manali Sharma
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Although Large VisionLanguage Models (LVLMs) show promise across various tasks, their application inautomating patent writing remains underexplored. In this paper, we presentPatentVision, a multimodal framework that integrates textual and visual inputssuch as patent claims and drawings to generate complete patent specifications.Built on advanced LVLMs, PatentVision enhances accuracy by combining fine tunedvision language models with domain specific training tailored to patents.Experiments reveal it surpasses text only methods, producing outputs withgreater fidelity and alignment with human written standards.

135, TITLE: Patentformer: A Demonstration of AI-assisted Automated Patent Drafting
AUTHORS: Sai Krishna Reddy Mudhiganti; Juanyan Wang; Ruo Yang; Manali Sharma
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This paper presents ademonstration of Patentformer, an AI-powered automated patent drafting platformdesigned to support patent attorneys by rapidly producing high-quality patentapplications adhering to legal writing standards.

136, TITLE: Causality $\neq$ Decodability, and Vice Versa: Lessons from Interpreting Counting ViTs
AUTHORS: Lianghuan Huang; Yingshan Chang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we investigate their relationshipin vision transformers (ViTs) fine-tuned for object counting.

137, TITLE: LLMs Are All You Need? Improving Fuzz Testing for MOJO with Large Language Models
AUTHORS: Linghan Huang; Peizhou Zhao; Huaming Chen
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: Ourexperimental results demonstrate that MOJOFuzzer significantly enhances testvalidity, API coverage, and bug detection performance, outperformingtraditional fuzz testing and state-of-the-art LLM-based fuzzing approaches.Using MOJOFuzzer, we have conducted a first large-scale fuzz testing evaluationof MOJO, uncorvering 13 previous unknown bugs.

138, TITLE: Harnessing Consistency for Robust Test-Time LLM Ensemble
AUTHORS: Zhichen Zeng; Qi Yu; Xiao Lin; Ruizhong Qiu; Xuying Ning; Tianxin Wei; Yuchen Yan; Jingrui He; Hanghang Tong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Our analysis shows that ensemble failurestypically arise from both the token level and the model level: the formerreflects severe disagreement in token predictions, while the latter involveslow confidence and pronounced disparities among models.

139, TITLE: DynaSpec: Context-aware Dynamic Speculative Sampling for Large-Vocabulary Language Models
AUTHORS: Jinbin Zhang; Nasib Ullah; Erik Schultheis; Rohit Babbar
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We propose DynaSpec, acontext-dependent dynamic shortlisting mechanism that is robust, speeds updrafting, and generalizes across diverse tasks.

140, TITLE: Hierarchical LoRA MoE for Efficient CTR Model Scaling
AUTHORS: Zhichen Zeng; Mengyue Hang; Xiaolong Liu; Xiaoyi Liu; Xiao Lin; Ruizhong Qiu; Tianxin Wei; Zhining Liu; Siyang Yuan; Chaofei Yang; Yiqun Liu; Hang Yin; Jiyan Yang; Hanghang Tong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Deep models have driven significant advances in click-through rate (CTR)prediction.

141, TITLE: ELMO: Efficiency Via Low-precision and Peak Memory Optimization in Large Output Spaces
AUTHORS: Jinbin Zhang; Nasib Ullah; Erik Schultheis; Rohit Babbar
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we proposeELMO, a pure low-precision training framework for XMC models using BFloat16 andFloat8 data types.

142, TITLE: Pharmacist: Safety Alignment Data Curation for Large Language Models Against Harmful Fine-tuning
AUTHORS: Guozhi Liu; Qi Mu; Tiansheng Huang; Xinhua Wang; Li Shen; Weiwei Lin; Zhang Li
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: We observe that their defense performance and computational efficiencyremain constrained by the quality and composition of the alignment dataset. Toaddress this limitation, we propose Pharmacist, a safety alignment datacuration solution that enhances defense against harmful fine-tuning byselecting a high-quality and safety-critical core subset from the originalalignment data.

143, TITLE: VLM-Guided Adaptive Negative Prompting for Creative Generation
AUTHORS: Shelly Golan; Yotam Nitzan; Zongze Wu; Or Patashnik
CATEGORY: arxiv-cs.GR [GR]
HIGHLIGHT: We propose VLM-Guided Adaptive Negative-Prompting, atraining-free, inference-time method that promotes creative image generationwhile preserving the validity of the generated object.

144, TITLE: LONGQAEVAL: Designing Reliable Evaluations of Long-Form Clinical QA Under Resource Constraints
AUTHORS: Federica Bologna; Tiffany Pan; Matthew Wilkens; Yue Guo; Lucy Lu Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce LongQAEval, an evaluation framework and set ofevaluation recommendations for limited-resource and high-expertise settings.Based on physician annotations of 300 real patient questions answered byphysicians and LLMs, we compare coarse answer-level versus fine-grainedsentence-level evaluation over the dimensions of correctness, relevance, andsafety.

145, TITLE: RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models
AUTHORS: Aashiq Muhamed; Leonardo F. R. Ribeiro; Markus Dreyer; Virginia Smith; Mona T. Diab
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: The ability of language models in RAG systems to selectively refuse to answerbased on flawed context is critical for safety, yet remains a significantfailure point. Our large-scale study reveals that even frontier models strugglein this setting, with refusal accuracy dropping below 50% on multi-documenttasks, while exhibiting either dangerous overconfidence or overcaution.

146, TITLE: Concise Reasoning in The Lens of Lagrangian Optimization
AUTHORS: Chengqian Gao; Haonan Li; Taylor W. Killian; Jianshu She; Renxi Wang; Liqun Ma; Zhoujun Cheng; Shibo Hao; Zhiqiang Xu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Most proposed approaches hinge on carefullyhand-crafted heuristics, struggling to balance concision with performance,often failing to adapt across domains and model scales. In this work, weaddress these challenges by introducing a principled and pragmatic strategy,performance-aware length updating (PALU).

147, TITLE: FACE: Faithful Automatic Concept Extraction
AUTHORS: Dipkamal Bhusal; Michael Clifford; Sara Rampazzi; Nidhi Rastogi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we propose FACE(Faithful Automatic Concept Extraction), a novel framework that augmentsNon-negative Matrix Factorization (NMF) with a Kullback-Leibler (KL) divergenceregularization term to ensure alignment between the model's original andconcept-based predictions.

148, TITLE: What Makes Looped Transformers Perform Better Than Non-Recursive Ones (Provably)
AUTHORS: Zixuan Gong; Jiaye Teng; Yong Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: While looped transformers (termed as Looped-Attn) often outperform standardtransformers (termed as Single-Attn) on complex reasoning tasks, thetheoretical basis for this advantage remains underexplored. In this paper, weexplain this phenomenon through the lens of loss landscape geometry, inspiredby empirical observations of their distinct dynamics at both sample and Hessianlevels.

149, TITLE: Cross-Sensor Touch Generation
AUTHORS: Samanta Rodriguez; Yiming Dou; Miquel Oller; Andrew Owens; Nima Fazeli
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: The second methodbuilds an intermediate depth representation and does not require paired data(T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specificmodels across multiple sensors via the cross-sensor touch generation process.Together, these models offer flexible solutions for sensor translation,depending on data availability and application needs.

150, TITLE: Multiview Manifold Evidential Fusion for PolSAR Image Classification
AUTHORS: Junfei Shi; Haojia Zhang; Haiyan Jin; Junhuai Li; Xiaogang Song; Yuanfan Guo; Haonan Su; Weisi Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Existingfusion methods also overlook the varying importance of different views andignore uncertainty, often leading to unreliable predictions. To address theseissues, we propose a Multiview Manifold Evidential Fusion (MMEFnet) method toeffectively fuse these two views.

151, TITLE: Task-Aware Resolution Optimization for Visual Large Language Models
AUTHORS: Weiqing Luo; Zhen Tan; Yifan Li; Xinyu Zhao; Kwonjoon Lee; Behzad Dariush; Tianlong Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address this problem, we first conduct a comprehensiveand pioneering investigation into the resolution preferences of differentvision-language tasks, revealing a correlation between resolution preferenceswith image complexity, and uncertainty variance of the VLLM at different imageinput resolutions. Building on this insight, we propose an empirical formula todetermine the optimal resolution for a given vision-language task, combiningthese two factors.

152, TITLE: EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection
AUTHORS: Huaizhi Qu; Ruichen Zhang; Shuqing Luo; Luchao Qi; Zhihao Zhang; Xiaoming Liu; Roni Sengupta; Tianlong Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, their heavy computational demands and therestrictions and costs of closed-source APIs make plugging these models intoexisting iterative editing strategies impractical. To address this limitation,we propose EditCast3D, a pipeline that employs video generation foundationmodels to propagate edits from a single first frame across the entire datasetprior to reconstruction.

153, TITLE: VA-GS: Enhancing The Geometric Representation of Gaussian Splatting Via View Alignment
AUTHORS: Qing Li; Huifang Feng; Xun Gong; Yu-Shen Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Due to the discrete andunstructured nature of Gaussians, supervision based solely on image renderingloss often leads to inaccurate geometry and inconsistent multi-view alignment.In this work, we propose a novel method that enhances the geometricrepresentation of 3D Gaussians through view alignment (VA).

154, TITLE: A Unified Frequency Domain Decomposition Framework for Interpretable and Robust Time Series Forecasting
AUTHORS: Cheng He; Xijie Liang; Zengrong Zheng; Patrick P. C. Lee; Xu Huang; Zhaoyi Li; Hong Xie; Defu Lian; Enhong Chen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose FIRE, a unifiedfrequency domain decomposition framework that provides a mathematicalabstraction for diverse types of time series, so as to achieve interpretableand robust time series forecasting.

155, TITLE: Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework
AUTHORS: Shanzhi Yin; Bolin Chen; Xinju Wu; Ru-Ling Liao; Jie Chen; Shiqi Wang; Yan Ye
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: This paper proposes an efficient 3D avatar coding framework that leveragescompact human priors and canonical-to-target transformation to enablehigh-quality 3D human avatar video compression at ultra-low bit rates.

156, TITLE: Detecting Hallucinations in Authentic LLM-Human Interactions
AUTHORS: Yujie Ren; Niklas Gruhlke; Anne Lauscher
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: As large language models (LLMs) are increasingly applied in sensitive domainssuch as medicine and law, hallucination detection has become a critical task.Although numerous benchmarks have been proposed to advance research in thisarea, most of them are artificially constructed--either through deliberatehallucination induction or simulated interactions--rather than derived fromgenuine LLM-human dialogues. Consequently, these benchmarks fail to fullycapture the characteristics of hallucinations that occur in real-world usage.To address this limitation, we introduce AuthenHallu, the first hallucinationdetection benchmark built entirely from authentic LLM-human interactions.

157, TITLE: AVoCaDO: An Audiovisual Video Captioner Driven By Temporal Orchestration
AUTHORS: Xinlong Chen; Yue Ding; Weihong Lin; Jingyun Hua; Linli Yao; Yang Shi; Bozhou Li; Yuanxing Zhang; Qiang Liu; Pengfei Wan; Liang Wang; Tieniu Tan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we present AVoCaDO, apowerful audiovisual video captioner driven by the temporal orchestrationbetween audio and visual modalities.

158, TITLE: DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety
AUTHORS: Wei-Chieh Huang; Henry Peng Zou; Yaozu Wu; Dongyuan Li; Yankai Chen; Weizhi Zhang; Yangning Li; Angelo Zangari; Jizhou Guo; Chunyu Miao; Liancheng Fang; Langzhou He; Renhe Jiang; Philip S. Yu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This oversight mayresult in hazardous or malicious sources being integrated into the finalreport. To address these issues, we introduce DEEPRESEARCHGUARD, acomprehensive framework featuring four-stage safeguards with open-domainevaluation of references and reports.

159, TITLE: DRIFT: Decompose, Retrieve, Illustrate, Then Formalize Theorems
AUTHORS: Meiru Zhang; Philipp Borchert; Milan Gritta; Gerasimos Lampouras
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Currentretrieval-augmented autoformalization methods query external libraries usingthe informal statement directly, but overlook a fundamental limitation:informal mathematical statements are often complex and offer limited context onthe underlying math concepts. To address this, we introduce DRIFT, a novelframework that enables LLMs to decompose informal mathematical statements intosmaller, more tractable ''sub-components''.

160, TITLE: Scaling Language-Centric Omnimodal Representation Learning
AUTHORS: Chenghao Xiao; Hou Pong Chan; Hao Zhang; Weiwen Xu; Mahani Aljunied; Yu Rong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Throughanalysis of anisotropy and kernel similarity structure, we empirically confirmthat latent alignment emerges within MLLM representations, allowing CL to serveas a lightweight refinement stage. Leveraging this insight, we propose aLanguage-Centric Omnimodal Embedding framework, termed LCO-Emb.

161, TITLE: Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics
AUTHORS: Lianhao Zhou; Hongyi Ling; Cong Fu; Yepeng Huang; Michael Sun; Wendi Yu; Xiaoxuan Wang; Xiner Li; Xingyu Su; Junkai Zhang; Xiusi Chen; Chenxing Liang; Xiaofeng Qian; Heng Ji; Wei Wang; Marinka Zitnik; Shuiwang Ji
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Recently,a paradigm shift has emerged with the rise of large language models (LLMs),introducing autonomous systems, referred to as agents, that acceleratediscovery across varying levels of autonomy. These language agents provide aflexible and versatile framework that orchestrates interactions with humanscientists, natural language, computer language and code, and physics.

162, TITLE: Project-Level C-to-Rust Translation Via Synergistic Integration of Knowledge Graphs and Large Language Models
AUTHORS: Zhiqiang Yuan; Wenjun Mao; Zhuo Chen; Xiyue Shang; Chong Wang; Yiling Lou; Xin Peng
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: However, this bottom-up,unit-by-unit paradigm often fails to translate pointers due to the lack of aglobal perspective on their usage. To address this problem, we propose a novelC-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph withtwo types of pointer semantics: (i) pointer-usage information which recordglobal behaviors such as points-to flows and map lower-level struct usage tohigher-level units; and (ii) Rust-oriented annotations which encode ownership,mutability, nullability, and lifetime.

163, TITLE: Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models
AUTHORS: Youngrok Park; Hojung Jung; Sangmin Bae; Se-Young Yun
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we propose a general solution to addressthe off-manifold phenomenon observed in diffusion models.

164, TITLE: Artificial Intelligence – Numerical Study of A 3D Model of Latent Heat Thermal Energy Storage with Sine-shaped Fins
AUTHORS: Obai Younis; Jana Shafi; Saeed Tiari; Mohammad Ghalambaz
CATEGORY: Journal of Energy Storage [JOURNAL OF ENERGY STORAGE]
HIGHLIGHT: 

165, TITLE: $Δ\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves Both OOD Detection and OOD Generalization
AUTHORS: Lin Zhu; Yifeng Yang; Xinbing Wang; Qinying Gu; Nanyang Ye
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Inthis paper, inspired by the substantial energy change observed in closed-setdata when re-aligning vision-language modalities (specifically by directlyreducing the maximum cosine similarity to a low value), we introduce a novelOOD score, named {\Delta}Energy.

166, TITLE: Bag of Tricks for Subverting Reasoning-based Safety Guardrails
AUTHORS: Shuo Chen; Zhen Han; Haokun Chen; Bailan He; Shengyun Si; Jingpei Wu; Philip Torr; Volker Tresp; Jindong Gu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: By leveraging LRMs' reasoning ability, these guardrails help themodels to assess the safety of user inputs before generating final responses.The powerful reasoning ability can analyze the intention of the input query andwill refuse to assist once it detects the harmful intent hidden by thejailbreak methods. Such guardrails have shown a significant boost in defense,such as the near-perfect refusal rates on the open-source gpt-oss series.Unfortunately, we find that these powerful reasoning-based guardrails can beextremely vulnerable to subtle manipulation of the input prompts, and oncehijacked, can lead to even more harmful results.

167, TITLE: Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products
AUTHORS: Komal Gupta; Aditya Shrivastava
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work, we explore zero data retention policiesfor the Enterprise apps of large language models (LLMs).

168, TITLE: RLFR: Extending Reinforcement Learning for LLMs with Flow Environment
AUTHORS: Jinghao Zhang; Naishan Zheng; Ruilin Li; Dongzhou Cheng; Zheming Liang; Feng Zhao; Jiaqi Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we offer anovel perspective on shaping RLVR with flow rewards derived from latent space,and propose RLFR, where the flow fields of model latents are constructed fromeither off-policy high-quality data and on-policy rejection sampling data, andthe velocity deviations of policy latents within it are quantified to serve asa reward signal.

169, TITLE: Deliberative Dynamics and Value Alignment in LLM Debates
AUTHORS: Pratik S. Sachdeva; Tom van Nuenen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Most evaluations study this sociotechnical alignmentthrough single-turn prompts, but it is unclear if these findings extend tomulti-turn settings where values emerge through dialogue, revision, andconsensus. We address this gap using LLM debate to examine deliberativedynamics and value alignment in multi-turn settings by prompting subsets ofthree models (GPT-4.1, Claude 3.7 Sonnet, and Gemini 2.0 Flash) to collectivelyassign blame in 1,000 everyday dilemmas from Reddit's "Am I the Asshole"community.

170, TITLE: Are Large Language Models Effective Knowledge Graph Constructors?
AUTHORS: Ruirui Chen; Weifeng Jiang; Chengwei Qin; Bo Xiong; Fiona Liausvia; Dongkyu Choi; Boon Kiat Quek
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We propose a hierarchical extraction frameworkthat organizes information at multiple levels, enabling the creation ofsemantically rich and well-structured KGs.

171, TITLE: EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling
AUTHORS: Daniel Scalena; Leonidas Zotos; Elisabetta Fersini; Malvina Nissim; Ahmet Üstün
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Grounded on theassumption that different prompts carry different degrees of complexity, andthus different computation needs, we propose EAGer, a training-free generationmethod that leverages model uncertainty through token-wise entropy distributionto reduce redundant computation and concurrently improve overall performance.EAGer allows branching to multiple reasoning paths only in the presence ofhigh-entropy tokens, and then reallocates the saved compute budget to theinstances where exploration of alternative paths is most needed.

172, TITLE: Neural Networks for Neurocomputing Circuits: A Computational Study of Tolerance to Noise and Activation Function Non-uniformity When Machine Learning Materials Properties
AUTHORS: Ye min Thant; Methawee Nukunudompanich; Chu-Chen Chueh; Manabu Ihara; Sergei Manzhos
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: We present acomputational study of the impact of circuit noise and NAF inhomogeneity infunction of NN architecture and training regimes.

173, TITLE: JND-Guided Light-Weight Neural Pre-Filter for Perceptual Image Coding
AUTHORS: Chenlong He; Zhijian Hao; Leilei Huang; Xiaoyang Zeng; Yibo Fan
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: However,existing methods are often computationally expensive, and the field lacksstandardized benchmarks for fair comparison. To address these challenges, thispaper introduces a twofold contribution. First, we develop and open-sourceFJNDF-Pytorch, a unified benchmark for frequency-domain JND-Guided pre-filters.

174, TITLE: LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach
AUTHORS: Renxuan Tan; Rongpeng Li; Fei Wang; Chenghui Peng; Shaoyun Wu; Zhifeng Zhao; Honggang Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: While deep reinforcement learning (DRL)-basedprotocols enhance task-specified network performance, they suffer from poorgeneralizability and resilience, demanding costly retraining to adapt todynamic environments. To overcome this limitation, we introduce agame-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which theuplink transmission between a base station and a varying number of userequipments is modeled as a dynamic multi-follower Stackelberg game (MFSG),capturing the network's natural hierarchical structure.

175, TITLE: A Vision for Access Control in LLM-based Agent Systems
AUTHORS: Xinfeng Li; Dong Huang; Jie Li; Hongyi Cai; Zhenhong Zhou; Wei Dong; XiaoFeng Wang; Yang Liu
CATEGORY: arxiv-cs.MA [MA]
HIGHLIGHT: Abstract: The autonomy and contextual complexity of LLM-based agents render traditionalaccess control (AC) mechanisms insufficient. Static, rule-based systemsdesigned for predictable ...

176, TITLE: Revisiting The UID Hypothesis in LLM Reasoning Traces
AUTHORS: Minju Gwak; Guijin Son; Jaehyung Kim
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Inspired by the Uniform Information Density(UID) hypothesis in psycholinguistics -- which posits that humans communicateby maintaining a stable flow of information -- we introduce entropy-basedmetrics to analyze the information flow within reasoning traces.

177, TITLE: Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization
AUTHORS: Zihan Wang; Zhiyong Ma; Zhongkui Ma; Shuofeng Liu; Akide Liu; Derui Wang; Minhui Xue; Guangdong Bai
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose non-transferableexamples (NEs), a training-free and data-agnostic input-side usage-controlmechanism.

178, TITLE: A Simple and Better Baseline for Visual Grounding
AUTHORS: Jingchao Wang; Wenlong Zhang; Dingjiang Huang; Hong Wang; Yefeng Zheng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To facilitate the implementation, in this paper, we propose afeature selection-based simple yet effective baseline for visual grounding,called FSVG.

179, TITLE: Cooperative Pseudo Labeling for Unsupervised Federated Classification
AUTHORS: Kuangpu Guo; Lijun Sheng; Yongcan Yu; Jian Liang; Zilei Wang; Ran He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we extend UFL tothe classification problem with CLIP for the first time and propose a novelmethod, \underline{\textbf{Fed}}erated \underline{\textbf{Co}}operative\underline{\textbf{P}}seudo \underline{\textbf{L}}abeling (\textbf{FedCoPL}).

180, TITLE: ADMIT: Few-shot Knowledge Poisoning Attacks on RAG-based Fact Checking
AUTHORS: Yutao Wu; Xiao Liu; Yinghui Li; Yifeng Gao; Yifan Ding; Jiale Ding; Xiang Zheng; Xingjun Ma
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We propose \textbf{ADMIT}(\textbf{AD}versarial \textbf{M}ulti-\textbf{I}njection \textbf{T}echnique), afew-shot, semantically aligned poisoning attack that flips fact-checkingdecisions and induces deceptive justifications, all without access to thetarget LLMs, retrievers, or token-level control.

181, TITLE: Sample-Efficient Online Learning in LM Agents Via Hindsight Trajectory Rewriting
AUTHORS: Michael Y. Hu; Benjamin Van Durme; Jacob Andreas; Harsh Jhamtani
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce ECHO (Experience Consolidation viaHindsight Optimization), a prompting framework that adapts hindsight experiencereplay from reinforcement learning for language model agents.

182, TITLE: ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios
AUTHORS: Mahika Phutane; Hayoung Jung; Matthew Kim; Tanushree Mitra; Aditya Vashistha
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We conduct a comprehensive audit of six LLMs across 2,820 hiringscenarios spanning diverse disability, gender, nationality, and caste profiles.To capture subtle intersectional harms and biases, we introduce ABLEIST(Ableism, Inspiration, Superhumanization, and Tokenism), a set of fiveableism-specific and three intersectional harm metrics grounded in disabilitystudies literature.

183, TITLE: NG-Router: Graph-Supervised Multi-Agent Collaboration for Nutrition Question Answering
AUTHORS: Kaiwen Shi; Zheyuan Zhang; Zhengqing Yuan; Keerthiram Murugesan; Vincent Galass; Chuxu Zhang; Yanfang Ye
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To further address contextual overload, we propose agradient-based subgraph retrieval mechanism that identifies salient evidenceduring training, thereby enhancing multi-hop and relational reasoning.Extensive experiments across multiple benchmarks and backbone modelsdemonstrate that NG-Router consistently outperforms both single-agent andensemble baselines, offering a principled approach to domain-aware multi-agentreasoning for complex nutritional health tasks.

184, TITLE: Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use
AUTHORS: Yiyang Li; Zehong Wang; Zhengqing Yuan; Zheyuan Zhang; Keerthiram Murugesan; Chuxu Zhang; Yanfang Ye
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To address thislimitation, we propose LAMI (LAtent relation Mining with bi-modalInterpretability), a novel joint graph-language modeling framework fordetecting illicit drug use and interpreting behavioral risk factors among TYAs.LAMI represents individual responses as relational graphs, learns latentconnections through a specialized graph structure learning layer, andintegrates a large language model to generate natural language explanationsgrounded in both graph structures and survey semantics.

185, TITLE: Controllable Graph Generation with Diffusion Models Via Inference-Time Tree Search Guidance
AUTHORS: Jiachi Zhao; Zehong Wang; Yamei Liao; Chuxu Zhang; Yanfang Ye
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Inference-time guidance methodsmitigate these issues by adjusting the sampling process without retraining, butthey remain inherently local, heuristic, and limited in controllability. Toovercome these limitations, we propose TreeDiff, a Monte Carlo Tree Search(MCTS) guided dual-space diffusion framework for controllable graph generation.TreeDiff is a plug-and-play inference-time method that expands the search spacewhile keeping computation tractable.

186, TITLE: Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks Via LLM-Enhanced Optimization
AUTHORS: Yang Li; Ruichen Zhang; Yinqiu Liu; Guangyuan Liu; Dusit Niyato; Abbas Jamalipour; Xianbin Wang; Dong In Kim
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Based on this model, we formulate amixed-integer non-convex optimization problem to minimize task latency andpower consumption under user-specific accuracy constraints.

187, TITLE: Think Twice to See More: Iterative Visual Reasoning in Medical VLMs
AUTHORS: Kaitao Chen; Shaohao Rui; Yankai Jiang; Jiamin Wu; Qihao Zheng; Chunfeng Song; Xiaosong Wang; Mu Zhou; Mianxin Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Medical vision-language models (VLMs) excel at image-text understanding buttypically rely on a single-pass reasoning that neglects localized visual cues.In clinical practice, however, human experts iteratively scan, focus, andrefine the regions of interest before reaching a final diagnosis. To narrowthis machine-human perception gap, we introduce ViTAR, a novel VLM frameworkthat emulates the iterative reasoning process of human experts through acognitive chain of "think-act-rethink-answer".

188, TITLE: Injecting Frame-Event Complementary Fusion Into Diffusion for Optical Flow in Challenging Scenes
AUTHORS: Haonan Wang; Hanyu Zhou; Haoyue Liu; Luxin Yan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: So we introducediffusion models that learn the mapping from noising flow to clear flow, whichis not affected by the deteriorated visual features. Therefore, we propose anovel optical flow estimation framework Diff-ABFlow based on diffusion modelswith frame-event appearance-boundary fusion.

189, TITLE: Path Drift in Large Reasoning Models:How First-Person Commitments Override Safety
AUTHORS: Yuyi Huang; Runzhe Zhan; Lidia S. Chao; Ailin Tao; Derek F. Wong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Through empirical analysis, we uncover three behavioraltriggers of Path Drift: (1) first-person commitments that induce goal-drivenreasoning that delays refusal signals; (2) ethical evaporation, wheresurface-level disclaimers bypass alignment checkpoints; (3) condition chainescalation, where layered cues progressively steer models toward unsafecompletions. Building on these insights, we introduce a three-stage Path DriftInduction Framework comprising cognitive load amplification, self-role priming,and condition chain hijacking.

190, TITLE: Bounds on Eventually Universal Quantum Gate Sets
AUTHORS: Chaitanya Karamchedu; Matthew Fox; Daniel Gottesman
CATEGORY: arxiv-quant-ph [ARXIV-QUANT-PH]
HIGHLIGHT: Say a collection of $n$-qu$d$it gates $\Gamma$ is eventually universal if andonly if there exists $N_0 \geq n$ such that for all $N \geq N_0$, one canapproximate any $N$-qu$d$it unitary to arbitrary precision by a circuit over$\Gamma$. In this work, we improve the best known upper bound on the smallest$N_0$ with the above property.

191, TITLE: Perspective-aware 3D Gaussian Inpainting with Multi-view Consistency
AUTHORS: Yuxin Cheng; Binxiao Huang; Taiqiang Wu; Wenyong Zhou; Chenchen Ding; Zhengwu Liu; Graziano Chesi; Ngai Wong
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work,we present PAInpainter, a novel approach designed to advance 3D Gaussianinpainting by leveraging perspective-aware content propagation and consistencyverification across multi-view inpainted images.

192, TITLE: Find Your Optimal Teacher: Personalized Data Synthesis Via Router-Guided Multi-Teacher Distillation
AUTHORS: Hengyuan Zhang; Shiping Yang; Xiao Liang; Chenming Shang; Yuxuan Jiang; Chaofan Tao; Jing Xiong; Hayden Kwok-Hay So; Ruobing Xie; Angel X. Chang; Ngai Wong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, recentstudies show that stronger models are not always optimal teachers, revealing amismatch between teacher outputs and student learnability. To address thisissue, we propose PerSyn (Personalized data Synthesis), a novel synthesisstrategy that operates under a new ``Route then Generate'' paradigm to createdata tailored to each student model, enabling it to learn more effectively.Specifically, PerSyn first assigns each prompt to its optimal teacher via aquery-level router that jointly considers student learnability and teacherresponse quality.

193, TITLE: IBERT: Interpretable Style Embeddings Via Sense Decomposition
AUTHORS: Vishal Anand; Milad Alshomary; Kathleen McKeown
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present iBERT (interpretable-BERT), an encoder to produce inherentlyinterpretable and controllable embeddings - designed to modularize and exposethe discriminative cues present in language, such as stylistic and semanticstructure.

194, TITLE: OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs
AUTHORS: Caorui Li; Yu Chen; Yiyan Ji; Jin Xu; Zhenyu Cui; Shihao Li; Yuanxing Zhang; Jiafu Tang; Zhenghao Song; Dingling Zhang; Ying He; Haoxiang Liu; Yuxuan Wang; Qiufeng Wang; Zhenhe Wu; Jiehui Luo; Zhiyu Pan; Weihao Xie; Chenchen Zhang; Zhaohui Wang; Jiayi Tian; Yanghai Wang; Zhe Cao; Minxin Dai; Ke Wang; Runzhe Wen; Yinghao Ma; Yaning Pan; Sungkyun Chang; Termeh Taheri; Haiwen Xia; Christos Plachouras; Emmanouil Benetos; Yizhi Li; Ge Zhang; Jian Yang; Tianhao Peng; Zili Wang; Minghao Liu; Junran Peng; Zhaoxiang Zhang; Jiaheng Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: Recent advances in multimodal large language models (MLLMs) have demonstratedsubstantial potential in video understanding. However, existing benchmarks failto comprehensively ...

195, TITLE: LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation
AUTHORS: Chang Liu; Henghui Ding; Kaining Ying; Lingyi Hong; Ning Xu; Linjie Yang; Yuchen Fan; Mingqi Gao; Jingkun Chen; Yunqi Miao; Gengshen Wu; Zhijin Qin; Jungong Han; Zhixiong Zhang; Shuangrui Ding; Xiaoyi Dong; Yuhang Zang; Yuhang Cao; Jiaqi Wang; Chang Soo Lim; Joonyoung Moon; Donghyeon Cho; Tingmin Li; Yixuan Li; Yang Yang; An Yan; Leilei Cao; Feng Lu; Ran Hong; Youhai Jiang; Fengjie Zhu; Yujie Xie; Hongyang Zhang; Zhihui Liu; Shihai Ruan; Quanzhu Niu; Dengxian Gong; Shihao Chen; Tao Zhang; Yikang Zhou; Haobo Yuan; Lu Qi; Xiangtai Li; Shunping Ji; Ran Hong; Feng Lu; Leilei Cao; An Yan; Alexey Nekrasov; Ali Athar; Daan de Geus; Alexander Hermans; Bastian Leibe
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This report presents an overview of the 7th Large-scale Video ObjectSegmentation (LSVOS) Challenge held in conjunction with ICCV 2025.

196, TITLE: Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph
AUTHORS: Wentao Wang; Heqing Zou; Tianze Luo; Rui Huang; Yutian Zhao; Zhuochen Wang; Hansheng Zhang; Chengwei Qin; Yan Wang; Lin Zhao; Huaijian Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Such limitations restrict theuse of MLLMs in downstream applications that demand high precision, includingembodied intelligence and VR. To address this issue, we present Video-STR, anovel graph-based reinforcement method for precise Video Spatio-TemporalReasoning.

197, TITLE: Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation
AUTHORS: Kai Han; Siqi Ma; Chengxuan Qian; Jun Chen; Chongwen Lyu; Yuqing Song; Zhe Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Although foundationmodels generally perform well in segmentation tasks, they often struggle tofocus on foreground areas in complex, low-contrast backgrounds, where somemalignant tumors closely resemble normal organs, complicating contextualdifferentiation. To address these challenges, we propose the Foreground-AwareSpectrum Segmentation (FASS) framework.

198, TITLE: ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?
AUTHORS: Liu Yang; Huiyu Duan; Ran Tao; Juntao Cheng; Sijing Wu; Yunhao Li; Jing Liu; Xiongkuo Min; Guangtao Zhai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Omnidirectional images (ODIs) provide full 360x180 view which are widelyadopted in VR, AR and embodied intelligence applications. While multi-modallarge language models (MLLMs) ...

199, TITLE: Large Language Model Sourcing: A Survey
AUTHORS: Liang Pang; Kangxi Wu; Sunhao Dai; Zihao Wei; Zenghao Duan; Jia Gu; Xiang Li; Zhiyi Yin; Jun Xu; Huawei Shen; Xueqi Cheng
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This survey presents a systematic investigation into provenance tracking forcontent generated by LLMs, organized around four interrelated dimensions thattogether capture both model- and data-centric perspectives.

200, TITLE: LLM-Specific Utility: A New Perspective for Retrieval-Augmented Generation
AUTHORS: Hengran Zhang; Keping Bi; Jiafeng Guo; Jiaming Zhang; Shuaiqiang Wang; Dawei Yin; Xueqi Cheng
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we introduce and systematically investigate the notionof LLM-specific utility.

201, TITLE: SNAP: Towards Segmenting Anything in Any Point Cloud
AUTHORS: Aniket Gupta; Hanhui Wang; Charles Saunders; Aruni RoyChowdhury; Hanumant Singh; Huaizu Jiang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address theselimitations, we present \textbf{SNAP} (\textbf{S}egment a\textbf{N}ything in\textbf{A}ny \textbf{P}oint cloud), a unified model for interactive 3Dsegmentation that supports both point-based and text-based prompts acrossdiverse domains.

202, TITLE: Scaling Laws and Symmetry, Evidence from Neural Force Fields
AUTHORS: Khang Ngo; Siamak Ravanbakhsh
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We present an empirical study in the geometric task of learning interatomicpotentials, which shows equivariance matters even more at larger scales; weshow a clear power-law scaling behaviour with respect to data, parameters andcompute with ``architecture-dependent exponents''.

203, TITLE: FlareX: A Physics-Informed Dataset for Lens Flare Removal Via 2D Synthesis and 3D Rendering
AUTHORS: Lishen Qu; Zhihao Liu; Jinshan Pan; Shihao Zhou; Jinglei Shi; Duosheng Chen; Jufeng Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, the lack of flare diversity in templates and theneglect of physical principles in the synthesis process hinder models trainedon these datasets from generalizing well to real-world scenarios. To addressthese challenges, we propose a new physics-informed method for flare datageneration, which consists of three stages: parameterized template creation,the laws of illumination-aware 2D synthesis, and physical engine-based 3Drendering, which finally gives us a mixed flare dataset that incorporates both2D and 3D perspectives, namely FlareX.

204, TITLE: BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes
AUTHORS: Lishen Qu; Zhihao Liu; Shihao Zhou; Yaqi Luo; Jie Liang; Hui Zeng; Lei Zhang; Jufeng Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Despite the prevalence offlicker, the lack of a large-scale, realistic dataset has been a significantbarrier to advancing research in flicker removal.

205, TITLE: A Machine Learning Perspective on Automated Driving Corner Cases
AUTHORS: Sebastian Schmidt; Julius Körner; Stephan Günnemann
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Based on our novelperspective, we present a framework for effective corner case recognition forperception on individual samples.

206, TITLE: From Material-derived to Artificial Intelligence-empowered Intelligent Hydrogels
AUTHORS: Shiwei Zheng; Zhiwei Zhu; Da-Wen Sun
CATEGORY: Coordination Chemistry Reviews [COORDINATION CHEMISTRY REVIEWS]
HIGHLIGHT: 

207, TITLE: The Curious Case of Factual (Mis)Alignment Between LLMs' Short- and Long-Form Answers
AUTHORS: Saad Obaid ul Islam; Anne Lauscher; Goran Glavaš
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work,we introduce Short-Long Form Alignment for Factual Question Answering (SLAQ), acontrolled evaluation framework that compares LLMs' answers to the same factualquestions asked (a) in isolation (short) vs. (b) integrated into complexqueries (long).

208, TITLE: Discursive Circuits: How Do Language Models Understand Discourse Relations?
AUTHORS: Yisong Miao; Min-Yen Kan
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Unlikesimpler tasks, discourse relations involve longer spans and complex reasoning.To make circuit discovery feasible, we introduce a task called Completion underDiscourse Relation (CuDR), where a model completes a discourse given aspecified relation.

209, TITLE: Bhasha-Rupantarika: Algorithm-Hardware Co-design Approach for Multilingual Neural Machine Translation
AUTHORS: Mukul Lokhande; Tanushree Dewangan; Mohd Sharik Mansoori; Tejas Chaudhari; Akarsh J.; Damayanti Lokhande; Adam Teman; Santosh Kumar Vishvakarma
CATEGORY: arxiv-cs.AR [AR]
HIGHLIGHT: This paper introduces Bhasha-Rupantarika, a light and efficient multilingualtranslation system tailored through algorithm-hardware codesign forresource-limited settings.

210, TITLE: How AI Companionship Develops: Evidence from A Longitudinal Study
AUTHORS: Angel Hsing-Chi Hwang; Fiona Li; Jacy Reese Anthis; Hayoun Noh
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: In Study 1, wesurveyed AI companion users (N = 303) to map the psychological pathway fromusers' mental models of the agent to parasocial experiences, socialinteraction, and the psychological impact of AI companions.

211, TITLE: Latent Retrieval Augmented Generation of Cross-Domain Protein Binders
AUTHORS: Zishen Zhang; Xiangzhe Kong; Wenbing Huang; Yang Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we propose Retrieval-Augmented Diffusion forAligned interface (RADiAnce), a new framework that leverages known interfacesto guide the design of novel binders.

212, TITLE: Beyond The Crowd: LLM-Augmented Community Notes for Governing Health Misinformation
AUTHORS: Jiaying Wu; Zihang Fu; Haonan Wang; Fanxiao Li; Min-Yen Kan
CATEGORY: arxiv-cs.SI [SI]
HIGHLIGHT: To improveresponsiveness during real-world misinformation surges, we propose CrowdNotes+,a unified framework that leverages large language models (LLMs) to augmentCommunity Notes for faster and more reliable health misinformation governance.CrowdNotes+ integrates two complementary modes: (1) evidence-grounded noteaugmentation and (2) utility-guided note automation, along with a hierarchicalthree-step evaluation that progressively assesses relevance, correctness, andhelpfulness.

213, TITLE: EA4LLM: A Gradient-Free Approach to Large Language Model Optimization Via Evolutionary Algorithms
AUTHORS: WenTao Liu; Siyu Song; Hao Hao; Aimin Zhou
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Moreover, theyrequire all neural network operations to be differentiable, thereby excludingmany promising non-differentiable architectures from practical use. To addressthese limitations, we propose EA4LLM, an evolutionary algorithm for optimizingLLMs, and, for the first time, empirically verify full-parameter optimizationfrom the pretraining stage across model sizes ranging from 0.5B to 32B.

214, TITLE: Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation
AUTHORS: Yuchen Yan; Zhihua Liu; Hao Wang; Weiming Li; Xiaoshuai Hao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Under the multi-hop settings, existing methods often struggle to fullyunderstand the questions with complex semantic structures and are susceptibleto irrelevant noise during the retrieval of multiple information targets. Toaddress these limitations, we propose a novel graph representation learningframework for multi-hop question retrieval.

215, TITLE: Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model
AUTHORS: Ruiping Liu; Junwei Zheng; Yufan Chen; Zirui Wang; Kunyu Peng; Kailun Yang; Jiaming Zhang; Marc Pollefeys; Rainer Stiefelhagen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Physical environments and circumstances are fundamentally dynamic, yetcurrent 3D datasets and evaluation benchmarks tend to concentrate on eitherdynamic scenarios or dynamic situations in isolation, resulting in incompletecomprehension. To overcome these constraints, we introduce Situat3DChange, anextensive dataset supporting three situation-aware change understanding tasksfollowing the perception-action model: 121K question-answer pairs, 36K changedescriptions for perception tasks, and 17K rearrangement instructions for theaction task.

216, TITLE: Aligning Deep Implicit Preferences By Learning to Reason Defensively
AUTHORS: Peiming Li; Zhiyuan Hu; Yang Tang; Shiyu Li; Xi Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Thiscognitive gap leads to responses that are superficial, brittle andshort-sighted. To address this, we propose Critique-Driven Reasoning Alignment(CDRA), which reframes alignment from a scalar reward-matching task into astructured reasoning process.

217, TITLE: On The Entity-Level Alignment in Crosslingual Consistency
AUTHORS: Yihong Liu; Mingyang Wang; François Yvon; Hinrich Schütze
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, the factors that give rise tosuch crosslingual consistency -- and its frequent failure -- remain poorlyunderstood. In this work, we hypothesize that these inconsistencies may arisefrom failures in entity alignment, the process of mapping subject and objectentities into a shared conceptual space across languages.

218, TITLE: Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection
AUTHORS: Gaojian Wang; Feng Lin; Tong Wu; Zhisheng Yan; Kui Ren
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce three learning objectives, namely 3C, that synergizemasked image modeling (MIM) and instance discrimination (ID), empowering FS-VFMto encode both local patterns and global semantics of real faces.

219, TITLE: Rethinking LLM Evaluation: Can We Evaluate LLMs with 200x Less Data?
AUTHORS: Shaobo Wang; Cong Wang; Wenjie Fu; Yue Min; Mingquan Feng; Isabel Guan; Xuming Hu; Conghui He; Cunxiang Wang; Kexin Yang; Xingzhang Ren; Fei Huang; Dayiheng Liu; Linfeng Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Besides, we frame benchmark compression as an optimization problemwith the aim of score reconstruction.

220, TITLE: Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning
AUTHORS: Can Xie; Ruotong Pan; Xiangyu Wu; Yunfei Zhang; Jiayi Fu; Tingting Gao; Guorui Zhou
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However, prevailing algorithms like GRPO broadcast a uniform advantagesignal across all tokens in a sequence. This coarse-grained approach overlooksthe pivotal role of uncertain, high-stakes decisions during reasoning, leadingto inefficient exploration and the well-documented problem of entropy collapse.To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), amodel-free method that refines credit assignment by leveraging the model'sinternal uncertainty signals.

221, TITLE: Hierarchical Qubit-Merging Transformer for Quantum Error Correction
AUTHORS: Seong-Joon Park; Hee-Youl Kwak; Yongjune Kim
CATEGORY: arxiv-quant-ph [ARXIV-QUANT-PH]
HIGHLIGHT: We propose the Hierarchical Qubit-Merging Transformer (HQMT), a novel andgeneral decoding framework that explicitly leverages the structural graph ofstabilizer codes to learn error correlations across multiple scales.

222, TITLE: Self-Supervised Multi-Scale Transformer with Attention-Guided Fusion for Efficient Crack Detection
AUTHORS: Blessing Agyei Kyem; Joshua Kofi Asamoah; Eugene Denteh; Andrews Danyo; Armstrong Aboah
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This work advances self-supervisedlearning and motivates pavement cracks detection research.

223, TITLE: Complementary and Contrastive Learning for Audio-Visual Segmentation
AUTHORS: Sitong Gong; Yunzhi Zhuge; Lu Zhang; Pingping Zhang; Huchuan Lu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Morerecently, Transformer-based methods treat auditory cues as queries, utilizingattention mechanisms to enhance audio-visual cooperation within frames.Nevertheless, they typically struggle to extract multimodal coefficients andtemporal dynamics adequately. To overcome these limitations, we present theComplementary and Contrastive Transformer (CCFormer), a novel framework adeptat processing both local and global information and capturing spatial-temporalcontext comprehensively.

224, TITLE: Taming A Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs
AUTHORS: Suyang Xi; Chenxi Yang; Hong Ding; Yiqing Ni; Catherine C. Liu; Yunhao Liu; Chengqi Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Specifically, it focuses only on global-level imageinformation but lacks local detail and limits reasoning about fine-grainedinteractions. To overcome this limitation, we present Human-LikeRetrieval-Augmented Generation (HuLiRAG), a framework that stages multimodalreasoning as a ``what--where--reweight'' cascade.

225, TITLE: Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from A Single View
AUTHORS: Jinyu Zhang; Haitao Lin; Jiashu Hou; Xiangyang Xue; Yanwei Fu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Inthis work, we propose a unified, category-agnostic framework thatsimultaneously predicts 6D pose, size, and dense shape from a single RGB-Dimage, without requiring templates, CAD models, or category labels at testtime.

226, TITLE: AI-Driven Anemia Diagnosis: A Review of Advanced Models and Techniques
AUTHORS: Abdullah Al Mahmud; Prangon Chowdhury; Mohammed Borhan Uddin; Khaled Eabne Delowar; Tausifur Rahman Talha; Bijoy Dewanjee
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In recent years, there has been a growing interest inthe use of artificial intelligence techniques, i.e., machine learning (ML) anddeep learning (DL) for the detection, classification, and diagnosis of anemia.This paper provides a systematic review of the recent advancements in thisfield, with a focus on various models applied to anemia detection.

227, TITLE: FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks
AUTHORS: Sabrina McCallum; Amit Parekh; Alessandro Suglia
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This work explores how agents trained withimitation learning can learn robust representations from both optimal andsuboptimal demonstrations when given access to constructive language feedbackas a means to contextualise different modes of behaviour.

228, TITLE: Culturally-Aware Conversations: A Framework & Benchmark for LLMs
AUTHORS: Shreya Havaldar; Sunny Rai; Young-Min Cho; Lyle Ungar
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we introduce the first frameworkand benchmark designed to evaluate LLMs in realistic, multiculturalconversational settings.

229, TITLE: DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis
AUTHORS: Peiyin Chen; Zhuowei Yang; Hui Feng; Sheng Jiang; Rui Yan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose DEMO, aflow-matching generative framework for audio-driven talking-portrait videosynthesis that delivers disentangled, high-fidelity control of lip motion, headpose, and eye gaze.

230, TITLE: A Dynamic Framework of Solar Based Electric Vehicle Charging Station with Artificial Neural Network and Genetic Algorithm Techniques
AUTHORS: Abhinav Saxena; Mohd. Majid; Rajat Kumar; Mohammed Amir; Majed A. Alotaibi; Hasmat Malik; Taha Selim Ustun; Asyraf Afthanorhan
CATEGORY: International Journal of Mathematical, Engineering and ... [INTERNATIONAL JOURNAL OF MATHEMATICAL, ENGINEERING AND ...]
HIGHLIGHT: In this paper, electric vehicle charging has been assessed at various voltage levels.

231, TITLE: You Only Need 4 Extra Tokens: Synergistic Test-time Adaptation for LLMs
AUTHORS: Yijie Xu; Huizai Yao; Zhiyu Guo; Weiyu Guo; Pengteng Li; Aiwei Liu; Xuming Hu; Hui Xiong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We studylabel-free test-time adaptation for language models and present SyTTA, aninference-time framework that adapts models on-the-fly without additionalsupervision.

232, TITLE: Diffusion-Link: Diffusion Probabilistic Model for Bridging The Audio-Text Modality Gap
AUTHORS: KiHyun Nam; Jongmin Choi; Hyeongkeun Lee; Jungwoo Heo; Joon Son Chung
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: The module istrained at the output embedding from the frozen multimodal encoder andimplemented as a lightweight network with three residual MLP blocks. To assessthe effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate onAutomatic Audio Captioning (AAC); to our knowledge, this is the firstapplication of diffusion-based modality bridging to AAC.

233, TITLE: Offline Reinforcement Learning with Generative Trajectory Policies
AUTHORS: Xinsong Feng; Leshu Tang; Chenan Wang; Haipeng Chen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we demonstrate that it is possible to bridge thisgap.

234, TITLE: EvoCAD: Evolutionary CAD Code Generation with Vision Language Models
AUTHORS: Tobias Preintner; Weixuan Yuan; Adrian König; Thomas Bäck; Elena Raponi; Niki van Stein
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we present EvoCAD, a method for generatingcomputer-aided design (CAD) objects through their symbolic representationsusing vision language models and evolutionary optimization.

235, TITLE: A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation
AUTHORS: Denis Zavadski; Damjan Kalšan; Tim Küchler; Haebom Lee; Stefan Roth; Carsten Rother
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To addressthis, we present a new framework that adapts an off-the-shelf diffusion modelto a target domain using only imperfect pseudo-labels.

236, TITLE: Trustworthy Retrosynthesis: Eliminating Hallucinations with A Diverse Ensemble of Reaction Scorers
AUTHORS: Michal Sadowski; Tadija Radusinović; Maria Wyrzykowska; Lukasz Sztukiewicz; Jan Rzymkowski; Paweł Włodarczyk-Pruszyński; Mikołaj Sacha; Piotr Kozakowski; Ruard van Workum; Stanislaw Kamil Jastrzebski
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, wepresent RetroTrim, a retrosynthesis system that successfully avoids nonsensicalplans on a set of challenging drug-like targets.

237, TITLE: YOLOv11-Litchi: Efficient Litchi Fruit Detection Based on UAV-Captured Agricultural Imagery in Complex Orchard Environments
AUTHORS: Hongxing Peng; Haopei Xie; Weijia Lia; Huanai Liuc; Ximing Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper introduces YOLOv11-Litchi, alightweight and robust detection model specifically designed for UAV-basedlitchi detection.

238, TITLE: ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer
AUTHORS: Yuan Tian; Min Zhou; Yitong Chen; Fang Li; Lingzi Qi; Shuo Wang; Xieyang Xu; Yu Yu; Shiqiong Xu; Chaoyu Lei; Yankai Jiang; Rongzhao Zhang; Jia Tan; Li Wu; Hong Chen; Xiaowei Liu; Wei Lu; Lin Li; Huifang Zhou; Xuefei Song; Guangtao Zhai; Xianqun Fan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Here, we introduce ROFI, a deeplearning-based privacy protection framework for ophthalmology.

239, TITLE: Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes
AUTHORS: Zhao-Yang Wang; Jieneng Chen; Jiang Liu; Yuxiang Guo; Rama Chellappa
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Multi-modalapproaches that incorporate 3D body shape information offer improved robustnessbut are computationally expensive, limiting their feasibility for real-timeapplications. To address these challenges, we introduce Mesh-Gait, a novelend-to-end multi-modal gait recognition framework that directly reconstructs 3Drepresentations from 2D silhouettes, effectively combining the strengths ofboth modalities.

240, TITLE: Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis
AUTHORS: Zhao-Yang Wang; Zhimin Shao; Jieneng Chen; Rama Chellappa
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we propose a multi-modaland multi-task framework that combines 2D temporal silhouettes with 3D SMPLfeatures for robust gait analysis.

241, TITLE: From Craft to Constitution: A Governance-First Paradigm for Principled Agent Engineering
AUTHORS: Qiang Xu; Xiangyu Wen; Changran Xu; Zeju Li; Jianyuan Zhong
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: This paper argues this crisisstems from a fundamental paradigm mismatch -- attempting to command inherentlyprobabilistic processors with the deterministic mental models of traditionalsoftware engineering. To solve this crisis, we introduce a governance-firstparadigm for principled agent engineering, embodied in a formal architecture wecall ArbiterOS.

242, TITLE: Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation
AUTHORS: Zixi Wang; Yushe Cao; Yubo Huang; Jinzhu Wei; Jingzehua Xu; Shuai Zhang; Xin Lai
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we propose a new method called Self-Training with DynamicWeighting (STDW), which aims to enhance robustness in Gradual Domain Adaptation(GDA) by addressing the challenge of smooth knowledge migration from the sourceto the target domain.

243, TITLE: Accelerated Stochastic First-order Method for Convex Optimization Under Heavy-tailed Noise
AUTHORS: Chuan He; Zhaosong Lu
CATEGORY: arxiv-math.OC [OC]
HIGHLIGHT: Existing work oftenemploys gradient clipping or normalization techniques in stochastic first-ordermethods to address heavy-tailed noise. In this paper, we demonstrate that avanilla stochastic algorithm -- without additional modifications such asclipping or normalization -- can achieve optimal complexity for these problems.In particular, we establish that an accelerated stochastic proximal subgradientmethod achieves a first-order oracle complexity that is universally optimal forsmooth, weakly smooth, and nonsmooth convex optimization, as well as forstochastic convex optimization under heavy-tailed noise.

244, TITLE: SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation
AUTHORS: Zeyu Ling; Xiaodong Gu; Jiangnan Tang; Changqing Zou
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We introduce SyncLipMAE, a self-supervised pretraining framework fortalking-face video that learns synchronization-aware and transferable facialdynamics from unlabeled audio-visual streams.

245, TITLE: Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers
AUTHORS: Sarthak Mittal; Divyat Mahajan; Guillaume Lajoie; Mohammad Pezeshki
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: While motivated by similar goals, these approaches differ in how theyencode and leverage task-specific information, often provided as in-contextexamples. In this work, we propose a unified framework which describes how suchmethods differ primarily in the aspects of learning they amortize - such asinitializations, learned updates, or predictive mappings - and how theyincorporate task data at inference.

246, TITLE: ADVICE: Answer-Dependent Verbalized Confidence Estimation
AUTHORS: Ki Jung Seo; Sehun Lim; Taeuk Kim
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Recent progress in large language models (LLMs) has enabled them to expresstheir confidence in natural language, enhancing transparency and reliability.However, their confidence often exhibits overconfidence, the cause of whichremains poorly understood. In this work, we conduct a detailed analysis of thedynamics underlying verbalized confidence and identify answer-independence as akey factor, defined as the model's failure to condition confidence on its ownanswer.

247, TITLE: Extended Triangular Method: A Generalized Algorithm for Contradiction Separation Based Automated Deduction
AUTHORS: Yang Xu; Shuwei Chen; Jun Liu; Feng Cao; Xingxing He
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: TheContradiction Separation Extension (CSE) framework, introduced in 2018,proposed a dynamic multi-clause reasoning theory that redefined logicalinference as a process of contradiction separation rather than sequentialresolution.

248, TITLE: From Programs to Poses: Factored Real-World Scene Generation Via Learned Program Libraries
AUTHORS: Joy Hsu; Emily Jin; Jiajun Wu; Niloy J. Mitra
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we proposeFactoredScenes, a framework that synthesizes realistic 3D scenes by leveragingthe underlying structure of rooms while learning the variation of object posesfrom lived-in scenes.

249, TITLE: SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams
AUTHORS: Zhuoheng Gao; Jiyao Zhang; Zhiyong Xie; Hao Dong; Zhaofei Yu; Rongmei Chen; Guozhang Chen; Tiejun Huang
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: This paper explores a fundamentally different, neuro-inspiredparadigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework thatmimics the biological visuomotor pathway, processing raw, asynchronous eventsfrom stereo spike cameras, similarly to retinas, to directly infer grasp poses.Our model fuses these stereo spike streams and uses a recurrent spiking neuralnetwork, analogous to high-level visual processing, to iteratively refine grasphypotheses without ever reconstructing a point cloud.

250, TITLE: Do LLMs "Feel"? Emotion Circuits Discovery and Control
AUTHORS: Chenxi Wang; Yixuan Zhang; Ruiji Yu; Yufei Zheng; Lang Gao; Zirui Song; Zixiang Xu; Gus Xia; Huishuai Zhang; Dongyan Zhao; Xiuying Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We identify neurons and attention heads that locallyimplement emotional computation through analytical decomposition and causalanalysis, and validate their causal roles via ablation and enhancementinterventions.

