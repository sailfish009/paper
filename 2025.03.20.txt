1, TITLE: BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?
AUTHORS: Pierre Chambon ; Baptiste Roziere ; Benoit Sagot ; Gabriel Synnaeve
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CC]
HIGHLIGHT: We introduce BigO(Bench), a novel coding benchmark designed to evaluate the capabilities of generative language models in understanding and generating code with specified time and space complexities.

2, TITLE: Learning 4D Panoptic Scene Graph Generation from Rich 2D Visual Scene
AUTHORS: SHENGQIONG WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Most importantly, we propose a 2D-to-4D visual scene transfer learning framework, where a spatial-temporal scene transcending strategy effectively transfers dimension-invariant features from abundant 2D SG annotations to 4D scenes, effectively compensating for data scarcity in 4D-PSG.

3, TITLE: Universal Scene Graph Generation
AUTHORS: Shengqiong Wu ; Hao Fei ; Tat-Seng Chua
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we introduce Universal SG (USG), a novel representation capable of fully characterizing comprehensive semantic scenes from any given combination of modality inputs, encompassing modality-invariant and modality-specific scenes.

4, TITLE: Inside-Out: Hidden Factual Knowledge in LLMs
AUTHORS: ZORIK GEKHMAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work presents a framework for assessing whether large language models (LLMs) encode more factual knowledge in their parameters than what they express in their outputs.

5, TITLE: Value Profiles for Encoding Human Variation
AUTHORS: TAYLOR SORENSEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.HC, cs.LG]
HIGHLIGHT: We propose representing individuals using value profiles -- natural language descriptions of underlying values compressed from in-context demonstrations -- along with a steerable decoder model to estimate ratings conditioned on a value profile or other rater information.

6, TITLE: TULIP: Towards Unified Language-Image Pretraining
AUTHORS: ZINENG TANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this work, we introduce TULIP, an open-source, drop-in replacement for existing CLIP-like models.

7, TITLE: MMDT: Decoding The Trustworthiness and Safety of Multimodal Foundation Models
AUTHORS: CHEJIAN XU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR]
HIGHLIGHT: In this paper, we present the first unified platform, MMDT (Multimodal DecodingTrust), designed to provide a comprehensive safety and trustworthiness evaluation for MMFMs.

8, TITLE: FACTS&EVIDENCE: An Interactive Tool for Transparent Fine-Grained Factual Verification of Machine-Generated Text
AUTHORS: VARICH BOONSANONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We develop Facts&Evidence - an interactive and transparent tool for user-driven verification of complex text.

9, TITLE: What Makes A Reward Model A Good Teacher? An Optimization Perspective
AUTHORS: NOAM RAZIN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, stat.ML]
HIGHLIGHT: While this quality is primarily evaluated through accuracy, it remains unclear whether accuracy fully captures what makes a reward model an effective teacher. We address this question from an optimization perspective.

10, TITLE: EfficientLLaVA:Generalizable Auto-Pruning for Large Vision-language Models
AUTHORS: Yinan Liang ; Ziwei Wang ; Xiuwei Xu ; Jie Zhou ; Jiwen Lu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose an automatic pruning method for large vision-language models to enhance the efficiency of multimodal reasoning.

11, TITLE: Learn Your Scales: Towards Scale-Consistent Generative Novel View Synthesis
AUTHORS: Fereshteh Forghani ; Jason J. Yu ; Tristan Aumentado-Armstrong ; Konstantinos G. Derpanis ; Marcus A. Brubaker
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we seek to understand and address the effect of scale ambiguity when used to train generative novel view synthesis methods (GNVS).

12, TITLE: POSTA: A Go-to Framework for Customized Artistic Poster Generation
AUTHORS: HAOYU CHEN et. al.
CATEGORY: cs.GR [cs.GR, cs.AI, cs.CV]
HIGHLIGHT: Prior work has explored automatic poster design using deep learning techniques, but these approaches lack text accuracy, user customization, and aesthetic appeal, limiting their applicability in artistic domains such as movies and exhibitions, where both clear content delivery and visual impact are essential. To address these limitations, we present POSTA: a modular framework powered by diffusion models and multimodal large language models (MLLMs) for customized artistic poster generation.

13, TITLE: MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration
AUTHORS: David Wan ; Justin Chih-Yao Chen ; Elias Stengel-Eskin ; Mohit Bansal
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We investigate how iterative collaboration among multiple instances and types of large language models (LLMs) enhances subtasks in the refinement process, such as error detection, critiquing unfaithful sentences, and making corrections based on critiques.

14, TITLE: Mitigating Object Hallucinations in MLLMs Via Multi-Frequency Perturbations
AUTHORS: SHUO LI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we introduce Multi-Frequency Perturbations (MFP), a simple, cost-effective, and pluggable method that leverages both low-frequency and high-frequency features of images to perturb visual feature representations and explicitly suppress redundant frequency-domain features during inference, thereby mitigating hallucinations.

15, TITLE: World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like A Child
AUTHORS: Javier Del Ser ; Jesus L. Lobo ; Heimo M�ller ; Andreas Holzinger
CATEGORY: cs.AI [cs.AI, cs.CV, cs.ET, cs.LG, 68T05]
HIGHLIGHT: We highlight six key research areas -- physics-informed learning, neurosymbolic learning, continual learning, causal inference, human-in-the-loop AI, and responsible AI -- as essential for enabling true reasoning in AI.

16, TITLE: Di$\mathtt{[M]}$O: Distilling Masked Diffusion Models Into One-step Generator
AUTHORS: Yuanzhi Zhu ; Xi Wang ; St�phane Lathuili�re ; Vicky Kalogeiton
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we propose Di$\mathtt{[M]}$O, a novel approach that distills masked diffusion models into a one-step generator.

17, TITLE: LogLLaMA: Transformer-based Log Anomaly Detection with LLaMA
AUTHORS: Zhuoyi Yang ; Ian G. Harris
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we propose LogLLaMA, a novel framework that leverages LLaMA2.

18, TITLE: MASS: Mathematical Data Selection Via Skill Graphs for Pretraining Large Language Models
AUTHORS: JIAZHENG LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce MASS, a \textbf{MA}thematical data \textbf{S}election framework using the \textbf{S}kill graph for pretraining LLMs in the mathematical reasoning domain.

19, TITLE: SketchSplat: 3D Edge Reconstruction Via Differentiable Multi-view Sketch Splatting
AUTHORS: Haiyang Ying ; Matthias Zwicker
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we study parametric 3D edge reconstruction from calibrated multi-view images.

20, TITLE: Visual Persona: Foundation Model for Full-Body Human Customization
AUTHORS: JISU NAM et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce Visual Persona, a foundation model for text-to-image full-body human customization that, given a single in-the-wild human image, generates diverse images of the individual guided by text descriptions.

21, TITLE: Visual Position Prompt for MLLM Based Visual Grounding
AUTHORS: Wei Tang ; Yanpeng Sun ; Qinying Gu ; Zechao Li
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address this issue, we introduce VPP-LLaVA, an MLLM equipped with Visual Position Prompt (VPP) to improve its grounding capability.

22, TITLE: Unlocking The Capabilities of Vision-Language Models for Generalizable and Explainable Deepfake Detection
AUTHORS: PEIPENG YU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we present a novel paradigm that unlocks VLMs' potential capabilities through three components: (1) A knowledge-guided forgery adaptation module that aligns VLM's semantic space with forensic features through contrastive learning with external manipulation knowledge; (2) A multi-modal prompt tuning framework that jointly optimizes visual-textual embeddings for both localization and explainability; (3) An iterative refinement strategy enabling multi-turn dialog for evidence-based reasoning.

23, TITLE: Forensics-Bench: A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models
AUTHORS: JIN WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, it still lacks a comprehensive benchmark designed to comprehensively assess LVLMs' discerning capabilities on forgery media. To fill this gap, we present Forensics-Bench, a new forgery detection evaluation benchmark suite to assess LVLMs across massive forgery detection tasks, requiring comprehensive recognition, location and reasoning capabilities on diverse forgeries.

24, TITLE: GR00T N1: An Open Foundation Model for Generalist Humanoid Robots
AUTHORS: JOHAN BJORCK et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: To this end, we introduce GR00T N1, an open foundation model for humanoid robots.

25, TITLE: Towards Understanding The Safety Boundaries of DeepSeek Models: Evaluation and Findings
AUTHORS: ZONGHAO YING et. al.
CATEGORY: cs.CR [cs.CR, cs.AI, cs.CL]
HIGHLIGHT: This study presents the first comprehensive safety evaluation of the DeepSeek models, focusing on evaluating the safety risks associated with their generated content.

26, TITLE: Shushing! Let's Imagine An Authentic Speech from The Silent Video
AUTHORS: Jiaxin Ye ; Hongming Shan
CATEGORY: cs.CV [cs.CV, cs.AI, cs.SD, eess.AS]
HIGHLIGHT: To tackle emerging challenges, we introduce ImaginTalk, a novel cross-modal diffusion framework that generates faithful speech using only visual input, operating within a discrete space.

27, TITLE: Learning to Play Piano in The Real World
AUTHORS: Yves-Simon Zeulner ; Sandeep Selvaraj ; Roberto Calandra
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we develop the first piano playing robotic system that makes use of learning approaches while also being deployed on a real world dexterous robot.

28, TITLE: Boosting HDR Image Reconstruction Via Semantic Knowledge Transfer
AUTHORS: Qingsen Yan ; Tao Hu ; Genggeng Chen ; Wei Dong ; Yanning Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, these priors are typically extracted from sRGB Standard Dynamic Range (SDR) images, the domain/format gap poses a significant challenge when applying it to HDR imaging. To address this issue, we propose a general framework that transfers semantic knowledge derived from SDR domain via self-distillation to boost existing HDR reconstruction.

29, TITLE: Decompositional Neural Scene Reconstruction with Generative Diffusion Prior
AUTHORS: JUNFENG NI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose DP-Recon, which employs diffusion priors in the form of Score Distillation Sampling (SDS) to optimize the neural representation of each individual object under novel views.

30, TITLE: StyleLoco: Generative Adversarial Distillation for Natural Humanoid Robot Locomotion
AUTHORS: LE MA et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Integrating these approaches proves challenging due to the inherent heterogeneity between expert policies and human motion datasets. To address this, we introduce StyleLoco, a novel two-stage framework that bridges this gap through a Generative Adversarial Distillation (GAD) process.

31, TITLE: LEGION: Learning to Ground and Explain for Synthetic Image Detection
AUTHORS: HENGRUI KANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce SynthScars, a high-quality and diverse dataset consisting of 12,236 fully synthetic images with human-expert annotations.

32, TITLE: RAT: Boosting Misclassification Detection Ability Without Extra Data
AUTHORS: Ge Yan ; Tsui-Wei Weng
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this work, we investigate the detection of misclassified inputs for image classification models from the lens of adversarial perturbation: we propose to use robust radius (a.k.a. input-space margin) as a confidence metric and design two efficient estimation algorithms, RR-BS and RR-Fast, for misclassification detection.

33, TITLE: Right Answer, Wrong Score: Uncovering The Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering
AUTHORS: FRANCESCO MARIA MOLFESE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we shed light on the inconsistencies of MCQA evaluation strategies, which can lead to inaccurate and misleading model comparisons.

34, TITLE: RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving
AUTHORS: WENQI JIANG et. al.
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CL, cs.DC]
HIGHLIGHT: In this paper, we make three fundamental contributions to advancing RAG serving.

35, TITLE: The CLEF-2025 CheckThat! Lab: Subjectivity, Fact-Checking, Claim Normalization, and Retrieval
AUTHORS: FIROJ ALAM et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, 68T50, I.2; I.2.7]
HIGHLIGHT: lab aims to advance the development of innovative technologies designed to identify and counteract online disinformation and manipulation efforts across various languages and platforms.

36, TITLE: Exploring The Limits of KV Cache Compression in Visual Autoregressive Transformers
AUTHORS: BO CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: In this work, we take the first step in formally defining the KV-cache compression problem for Visual Autoregressive transformers.

37, TITLE: Image Captioning Evaluation in The Age of Multimodal LLMs: Challenges and Future Perspectives
AUTHORS: Sara Sarto ; Marcella Cornia ; Rita Cucchiara
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: This survey provides a comprehensive overview of advancements in image captioning evaluation, analyzing the evolution, strengths, and limitations of existing metrics. We assess these metrics across multiple dimensions, including correlation with human judgment, ranking accuracy, and sensitivity to hallucinations.

38, TITLE: LLM Alignment for The Arabs: A Homogenous Culture or Diverse Ones?
AUTHORS: Amr Keleg
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Yet, Arabs are sometimes assumed to share the same culture. In this position paper, I discuss the limitations of this assumption and provide preliminary thoughts for how to build systems that can better represent the cultural diversity within the Arab world.

39, TITLE: UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation
AUTHORS: QIHUI ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Although automated MLLM-as-judge approaches attempt to reduce the human workload through automatic evaluations, they often introduce biases. To address these problems, we propose an Unsupervised Peer review MLLM Evaluation framework.

40, TITLE: DeepMesh: Auto-Regressive Artist-mesh Creation with Reinforcement Learning
AUTHORS: RUOWEN ZHAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While auto-regressive methods generate structured meshes by predicting discrete vertex tokens, they are often constrained by limited face counts and mesh incompleteness. To address these challenges, we propose DeepMesh, a framework that optimizes mesh generation through two key innovations: (1) an efficient pre-training strategy incorporating a novel tokenization algorithm, along with improvements in data curation and processing, and (2) the introduction of Reinforcement Learning (RL) into 3D mesh generation to achieve human preference alignment via Direct Preference Optimization (DPO).

41, TITLE: Generating Medically-Informed Explanations for Depression Detection Using LLMs
AUTHORS: Xiangyong Chen ; Xiaochuan Lin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose LLM-MTD (Large Language Model for Multi-Task Depression Detection), a novel approach that leverages a pre-trained large language model to simultaneously classify social media posts for depression and generate textual explanations grounded in medical diagnostic criteria.

42, TITLE: Temporal-Consistent Video Restoration with Pre-trained Diffusion Models
AUTHORS: HENGKANG WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we advocate viewing the reverse process in DMs as a function and present a novel Maximum a Posterior (MAP) framework that directly parameterizes video frames in the seed space of DMs, eliminating approximation errors.

43, TITLE: Reasoning Effort and Problem Complexity: A Scaling Analysis in LLMs
AUTHORS: Benjamin Estermann ; Roger Wattenhofer
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Large Language Models (LLMs) have demonstrated remarkable text generation capabilities, and recent advances in training paradigms have led to breakthroughs in their reasoning performance. In this work, we investigate how the reasoning effort of such models scales with problem complexity.

44, TITLE: Recover and Match: Open-Vocabulary Multi-Label Recognition Through Knowledge-Constrained Optimal Transport
AUTHORS: HAO TAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: (2) The matching property between image regions and candidate labels has been neglected, relying instead on naive feature aggregation such as average pooling, which leads to spurious predictions from irrelevant regions. In this paper, we present RAM (Recover And Match), a novel framework that effectively addresses the above issues.

45, TITLE: Unique Hard Attention: A Tale of Two Sides
AUTHORS: Selim Jerad ; Anej Svete ; Jiaoda Li ; Ryan Cotterell
CATEGORY: cs.LG [cs.LG, cs.CC, cs.CL, cs.FL]
HIGHLIGHT: When multiple positions achieve the maximum score, either the rightmost or the leftmost of those is chosen. In this paper, we highlight the importance of this seeming triviality.

46, TITLE: Evaluating Bias in Retrieval-Augmented Medical Question-Answering Systems
AUTHORS: Yuelyu Ji ; Hang Zhang ; Yanshan Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Using datasets like MMLU and MedMCQA, we analyze retrieval overlap and correctness disparities.

47, TITLE: 3D Occupancy Prediction with Low-Resolution Queries Via Prototype-aware View Transformation
AUTHORS: GYEONGROK OH et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To this end, we introduce ProtoOcc, a novel occupancy network that leverages prototypes of clustered image segments in view transformation to enhance low-resolution context.

48, TITLE: TROVE: A Challenge for Fine-Grained Text Provenance Via Source Sentence Tracing and Relationship Classification
AUTHORS: JUNNAN ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In high-stakes domains such as healthcare, law, and news, it is crucial to understand where and how the content is created. To address this, we introduce the Text pROVEnance (TROVE) challenge, designed to trace each sentence of a target text back to specific source sentences within potentially lengthy or multi-document inputs.

49, TITLE: LipShiFT: A Certifiably Robust Shift-based Vision Transformer
AUTHORS: Rohan Menon ; Nicola Franco ; Stephan G�nnemann
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: Focusing on a Lipschitz continuous variant of the ShiftViT model, we address significant training challenges for transformer-based architectures under norm-constrained input setting.

50, TITLE: MMAIF: Multi-task and Multi-degradation All-in-One for Image Fusion with Language Guidance
AUTHORS: Zihan Cao ; Yu Zhong ; Ziqi Wang ; Liang-Jian Deng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing methods face several significant limitations: 1) requiring task- or dataset-specific models; 2) neglecting real-world image degradations (\textit{e.g.}, noise), which causes failure when processing degraded inputs; 3) operating in pixel space, where attention mechanisms are computationally expensive; and 4) lacking user interaction capabilities. To address these challenges, we propose a unified framework for multi-task, multi-degradation, and language-guided image fusion.

51, TITLE: Taming Flow Matching with Unbalanced Optimal Transport Into Fast Pansharpening
AUTHORS: Zihan Cao ; Yu Zhong ; Liang-Jian Deng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose the Optimal Transport Flow Matching (OTFM) framework, which integrates the dual formulation of unbalanced optimal transport (UOT) to achieve one-step, high-quality pansharpening.

52, TITLE: Reinforcement Learning-based Motion Imitation for Physiologically Plausible Musculoskeletal Motor Control
AUTHORS: Merkourios Simos ; Alberto Silvio Chiappa ; Alexander Mathis
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG, q-bio.NC]
HIGHLIGHT: In this work, we present a model-free motion imitation framework (KINESIS) to advance the understanding of muscle-based motor control.

53, TITLE: V2X-DG: Domain Generalization for Vehicle-to-Everything Cooperative Perception
AUTHORS: BAOLU LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose Cooperative Mixup Augmentation based Generalization (CMAG) to improve the model generalization capability by simulating the unseen cooperation, which is designed compactly for the domain gaps in cooperative perception.

54, TITLE: HandSplat: Embedding-Driven Gaussian Splatting for High-Fidelity Hand Rendering
AUTHORS: YILAN DONG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: These limitations lead to geometric detail loss, temporal instability, and inefficient point distribution. To address these issues, we propose HandSplat, a novel Gaussian Splatting-based framework that enhances both fidelity and stability for hand rendering.

55, TITLE: Single-Step Bidirectional Unpaired Image Translation Using Implicit Bridge Consistency Distillation
AUTHORS: Suhyeon Lee ; Kwanyoung Kim ; Jong Chul Ye
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, methods based on diffusion models or Schr\"odinger bridges have yet to be widely adopted in real-world applications due to their iterative sampling nature. To address this challenge, we propose a novel framework, Implicit Bridge Consistency Distillation (IBCD), which enables single-step bidirectional unpaired translation without using adversarial loss.

56, TITLE: LIFT: Latent Implicit Functions for Task- and Data-Agnostic Encoding
AUTHORS: Amirhossein Kazerouni ; Soroush Mehraban ; Michael Brudno ; Babak Taati
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: However, existing INR frameworks frequently rely on global latent vectors or exhibit computational inefficiencies that limit their broader applicability. We introduce LIFT, a novel, high-performance framework that addresses these challenges by capturing multiscale information through meta-learning.

57, TITLE: From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment
AUTHORS: Jia-Nan Li ; Jian Guan ; Songhao Wu ; Wei Wu ; Rui Yan
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper introduces a comprehensive framework for scalable personalized alignment of LLMs.

58, TITLE: Increasing The Robustness of The Fine-tuned Multilingual Machine-Generated Text Detectors
AUTHORS: Dominik Macko ; Robert Moro ; Ivan Srba
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This work addresses the problem by proposing a robust fine-tuning process of LLMs for the detection task, making the detectors more robust against obfuscation and more generalizable to out-of-distribution data.

59, TITLE: Derm1M: A Million-scale Vision-Language Dataset Aligned with Clinical Ontology Knowledge for Dermatology
AUTHORS: SIYUAN YAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing dermatological datasets are limited in both scale and depth, offering only single-label annotations across a narrow range of diseases instead of rich textual descriptions, and lacking the crucial clinical context needed for real-world applications. To address these limitations, we present Derm1M, the first large-scale vision-language dataset for dermatology, comprising 1,029,761 image-text pairs.

60, TITLE: CoE: Chain-of-Explanation Via Automatic Visual Concept Circuit Description and Polysemanticity Quantification
AUTHORS: Wenlong Yu ; Qilong Wang ; Chuang Liu ; Dong Li ; Qinghua Hu
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Particularly, the intrinsic polysemanticity in semantic Visual Concepts (VCs) impedes the interpretability of concepts and DVMs, which is underestimated severely. In this paper, we propose a Chain-of-Explanation (CoE) approach to address these issues.

61, TITLE: Language-based Image Colorization: A Benchmark and Beyond
AUTHORS: Yifan Li ; Shuai Yang ; Jiaying Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Based on the analyzed limitations of existing language-based methods, we propose a simple yet effective method based on distilled diffusion model.

62, TITLE: Dynamic Bi-Elman Attention Networks (DBEAN): Dual-Directional Context-Aware Representation Learning for Enhanced Text Classification
AUTHORS: ZhengLin Lai ; MengYao Liao ; Dong Xu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper proposes the Dynamic Bidirectional Elman with Attention Network (DBEAN), which integrates bidirectional temporal modelling with self-attention mechanisms.

63, TITLE: Optimal Transport Adapter Tuning for Bridging Modality Gaps in Few-Shot Remote Sensing Scene Classification
AUTHORS: ZHONG JI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing methods typically emphasize single-modal feature learning, neglecting the potential benefits of optimizing multi-modal representations. To address this limitation, we propose a novel Optimal Transport Adapter Tuning (OTAT) framework aimed at constructing an ideal Platonic representational space through optimal transport (OT) theory.

64, TITLE: DPFlow: Adaptive Optical Flow Estimation with A Dual-Pyramid Framework
AUTHORS: Henrique Morimitsu ; Xiaobin Zhu ; Roberto M. Cesar Jr. ; Xiangyang Ji ; Xu-Cheng Yin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose DPFlow, an adaptive optical flow architecture capable of generalizing up to 8K resolution inputs while trained with only low-resolution samples.

65, TITLE: SceneEval: Evaluating Semantic Coherence in Text-Conditioned 3D Indoor Scene Synthesis
AUTHORS: Hou In Ivan Tam ; Hou In Derek Pun ; Austin T. Wang ; Angel X. Chang ; Manolis Savva
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: Existing metrics primarily assess the realism of generated scenes by comparing them to a set of ground-truth scenes, often overlooking alignment with the input text - a critical factor in determining how effectively a method meets user requirements. We present SceneEval, an evaluation framework designed to address this limitation.

66, TITLE: Towards Efficient Keyword Spotting Using Spike-based Time Difference Encoders
AUTHORS: Alejandro Peque�o-Zurro ; Lyes Khacef ; Stefano Panzeri ; Elisabetta Chicca
CATEGORY: cs.NE [cs.NE, cs.AI, cs.CV, cs.ET]
HIGHLIGHT: Here, we explore the Temporal Difference Encoder (TDE) performance in keyword spotting.

67, TITLE: Dynamic Accumulated Attention Map for Interpreting Evolution of Decision-Making in Vision Transformer
AUTHORS: Yi Liao ; Yongsheng Gao ; Weichuan Zhang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The contribution of this work focuses on visualizing the evolution dynamic of the decision-making attention for any intermediate block inside a ViT model by proposing a novel decomposition module and dimension-wise importance weights.

68, TITLE: Prototype Perturbation for Relaxing Alignment Constraints in Backward-Compatible Learning
AUTHORS: Zikun Zhou ; Yushuai Sun ; Wenjie Pei ; Xin Li ; Yaowei Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Nevertheless, such strong alignment constraints would compromise the discriminative ability of the new model, particularly when different classes are closely clustered and hard to distinguish in the old feature space. To address this issue, we propose to relax the constraints by introducing perturbations to the old feature prototypes.

69, TITLE: ShapeShift: Towards Text-to-Shape Arrangement Synthesis with Content-Aware Geometric Constraints
AUTHORS: Vihaan Misra ; Peter Schaldenbrand ; Jean Oh
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To preserve arrangement clarity, we introduce a content-aware collision resolution mechanism that applies minimal semantically coherent adjustments when overlaps occur, ensuring smooth convergence toward physically valid configurations.

70, TITLE: Long Context Modeling with Ranked Memory-Augmented Retrieval
AUTHORS: GHADIR ALSELWI et. al.
CATEGORY: cs.IR [cs.IR, cs.AI, cs.LG]
HIGHLIGHT: We introduce a novel framework that dynamically ranks memory entries based on relevance.

71, TITLE: Generating Multimodal Driving Scenes Via Next-Scene Prediction
AUTHORS: YANHAO WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a multimodal generation framework that incorporates four major data modalities, including a novel addition of map modality.

72, TITLE: VideoGen-of-Thought: Step-by-step Generating Multi-shot Video with Minimal Manual Intervention
AUTHORS: MINGZHE ZHENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce VideoGen-of-Thought (VGoT), a step-by-step framework that automates multi-shot video synthesis from a single sentence by systematically addressing three core challenges: (1) Narrative Fragmentation: Existing methods lack structured storytelling.

73, TITLE: Temporal Regularization Makes Your Video Generator Stronger
AUTHORS: HAROLD HAODONG CHEN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we explore temporal augmentation in video generation for the first time, and introduce FluxFlow for initial investigation, a strategy designed to enhance temporal quality.

74, TITLE: Optimizing Decomposition for Optimal Claim Verification
AUTHORS: Yining Lu ; Noah Ziems ; Hy Dang ; Meng Jiang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We formulate finding the optimal decomposition policy for optimal verification as a bilevel optimization problem. To approximate a solution for this strongly NP-hard problem, we propose dynamic decomposition, a reinforcement learning framework that leverages verifier feedback to learn a policy for dynamically decomposing claims to verifier-preferred atomicity.

75, TITLE: ML-Triton, A Multi-Level Compilation and Language Extension to Triton GPU Programming
AUTHORS: DEWEI WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: FlashAttention2 advocates explicit data partition between warps to make a performance boost. In this context, we propose ML-Triton which features multi-level compilation flow and programming interface.

76, TITLE: Exploring Model Editing for LLM-based Aspect-Based Sentiment Classification
AUTHORS: Shichen Li ; Zhongqing Wang ; Zheyu Zhao ; Yue Zhang ; Peifeng Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate model editing to serve an efficient method for adapting LLMs to solve aspect-based sentiment classification.

77, TITLE: SplatVoxel: History-Aware Novel View Streaming Without Temporal Training
AUTHORS: YIMING WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a hybrid splat-voxel feed-forward scene reconstruction approach that combines Gaussian Splatting to propagate information over time, with a hierarchical voxel grid for temporal fusion.

78, TITLE: DiST-4D: Disentangled Spatiotemporal Diffusion with Metric Depth for 4D Driving Scene Generation
AUTHORS: JIAZHE GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A key challenge lies in finding an efficient and generalizable geometric representation that seamlessly connects temporal and spatial synthesis. To address this, we propose DiST-4D, the first disentangled spatiotemporal diffusion framework for 4D driving scene generation, which leverages metric depth as the core geometric representation.

79, TITLE: PointSFDA: Source-free Domain Adaptation for Point Cloud Completion
AUTHORS: XING HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose an effective yet simple source-free domain adaptation framework for point cloud completion, termed \textbf{PointSFDA}.

80, TITLE: Entity-aware Cross-lingual Claim Detection for Automated Fact-checking
AUTHORS: Rrubaa Panchendrarajan ; Arkaitz Zubiaga
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce \textit{EX-Claim}, an entity-aware cross-lingual claim detection model that generalizes well to handle claims written in any language.

81, TITLE: Evaluating ASR Confidence Scores for Automated Error Detection in User-Assisted Correction Interfaces
AUTHORS: Korbinian Kuhn ; Verena Kersken ; Gottfried Zimmermann
CATEGORY: cs.HC [cs.HC, cs.CL, cs.SD, eess.AS, I.2.7]
HIGHLIGHT: This study evaluates the reliability of confidence scores for error detection through a comprehensive analysis of end-to-end ASR models and a user study with 36 participants.

82, TITLE: Solla: Towards A Speech-Oriented LLM That Hears Acoustic Context
AUTHORS: JUNYI AO et. al.
CATEGORY: eess.AS [eess.AS, cs.CL, cs.SD]
HIGHLIGHT: However, most existing models primarily focus on analyzing input signals using text instructions, overlooking scenarios in which speech instructions and audio are mixed and serve as inputs to the model. To address these challenges, we introduce Solla, a novel framework designed to understand speech-based questions and hear the acoustic context concurrently.

83, TITLE: When The Future Becomes The Past: Taming Temporal Correspondence for Self-supervised Video Representation Learning
AUTHORS: Yang Liu ; Qianqian Xu ; Peisong Wen ; Siran Dai ; Qingming Huang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: 2) Previous MVM methods primarily recover the masked patches in the pixel space, leading to insufficient information compression for downstream tasks. To address these challenges jointly, we propose a self-supervised framework that leverages Temporal Correspondence for video Representation learning (T-CoRe).

84, TITLE: Aligning Information Capacity Between Vision and Language Via Dense-to-Sparse Feature Distillation for Image-Text Matching
AUTHORS: Yang Liu ; Wentao Feng ; Zhuoyao Liu ; Shudong Huang ; Jiancheng Lv
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Enabling Visual Semantic Models to effectively handle multi-view description matching has been a longstanding challenge.

85, TITLE: An Extensive Simulation Study Evaluating The Interaction of Resampling Techniques Across Multiple Causal Discovery Contexts
AUTHORS: Ritwick Banerjee ; Bryan Andrews ; Erich Kummerfeld
CATEGORY: stat.ME [stat.ME, cs.AI]
HIGHLIGHT: We present theoretical results proving that certain resampling methods closely emulate the assignment of specific values to algorithm tuning parameters.

86, TITLE: VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning
AUTHORS: YANG TAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, q-bio.QM]
HIGHLIGHT: This work presents VenusFactory, a versatile engine that integrates biological data retrieval, standardized task benchmarking, and modular fine-tuning of PLMs.

87, TITLE: EgoDTM: Towards 3D-Aware Egocentric Video-Language Pretraining
AUTHORS: Boshen Xu ; Yuting Mei ; Xinbi Liu ; Sipeng Zheng ; Qin Jin
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, most previous works learn from 1D text or 2D visual cues, such as bounding boxes, which inherently lack 3D understanding. To bridge this gap, we introduce EgoDTM, an Egocentric Depth- and Text-aware Model, jointly trained through large-scale 3D-aware video pretraining and video-text contrastive learning.

88, TITLE: Behaviour Discovery and Attribution for Explainable Reinforcement Learning
AUTHORS: Rishav Rishav ; Somjit Nath ; Vincent Michalski ; Samira Ebrahimi Kahou
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we propose a framework for behavior discovery and action attribution to behaviors in offline RL trajectories.

89, TITLE: Language Independent Named Entity Recognition Via Orthogonal Transformation of Word Vectors
AUTHORS: Omar E. Rakha ; Hazem M. Abbas
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, a model is proposed based on using Bidirectional LSTM/CRF with word embeddings to perform named entity recognition for any language.

90, TITLE: Robust Distribution Alignment for Industrial Anomaly Detection Under Distribution Shift
AUTHORS: JINGYI LIAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing methods attempt to address domain shifts by training generalizable models but often rely on prior knowledge of target distributions and can hardly generalise to backbones designed for other data modalities. To overcome these limitations, we build upon memory-bank-based anomaly detection methods, optimizing a robust Sinkhorn distance on limited target training data to enhance generalization to unseen target domains.

91, TITLE: Challenges and Trends in Egocentric Vision: A Survey
AUTHORS: XIANG LI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: By summarizing the latest advancements, we anticipate the broad applications of egocentric vision technologies in fields such as augmented reality, virtual reality, and embodied intelligence, and propose future research directions based on the latest developments in the field.

92, TITLE: When Domain Generalization Meets Generalized Category Discovery: An Adaptive Task-Arithmetic Driven Approach
AUTHORS: VAIBHAV RATHORE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Current methods often falter with distribution shifts and typically require access to target data during training, which can sometimes be impractical. To address this issue, we introduce the novel paradigm of Domain Generalization in GCD (DG-GCD), where only source data is available for training, while the target domain, with a distinct data distribution, remains unseen until inference.

93, TITLE: Degradation Alchemy: Self-Supervised Unknown-to-Known Transformation for Blind Hyperspectral Image Fusion
AUTHORS: He Huang ; Yong Chen ; Yujun Guo ; Wei He
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: To unleash the potential and generalization ability of SLMs, we propose a novel self-supervised unknown-to-known degradation transformation framework (U2K) for blind HSI fusion, which adaptively transforms unknown degradation into the same type of degradation as those handled by pre-trained SLMs.

94, TITLE: Strategic Resource Allocation in Memory Encoding: An Efficiency Principle Shaping Language Processing
AUTHORS: Weijie Xu ; Richard Futrell
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate strategic resource allocation as an efficiency principle for memory encoding in sentence processing.

95, TITLE: Improving Adversarial Transferability on Vision Transformers Via Forward Propagation Refinement
AUTHORS: YUCHEN REN et. al.
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: In this work, we instead focus on Forward Propagation Refinement (FPR) and specifically refine two key modules of ViTs: attention maps and token embeddings.

96, TITLE: FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding
AUTHORS: CHONGJUN TU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To comprehensively assess the motion understanding ability of existing MLLMs, we introduce FAVOR-Bench, comprising 1,776 videos with structured manual annotations of various motions.

97, TITLE: MetaLadder: Ascending Mathematical Solution Quality Via Analogical-Problem Reasoning Transfer
AUTHORS: HONGLIN LIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Humans often solve problems by recalling analogous cases and leveraging their solutions to reason about the current task. Inspired by this cognitive process, we propose \textbf{MetaLadder}, a novel framework that explicitly prompts LLMs to recall and reflect on meta-problems, those structurally or semantically analogous problems, alongside their CoT solutions before addressing the target problem.

98, TITLE: Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence
AUTHORS: Sophia Hager ; David Mueller ; Kevin Duh ; Nicholas Andrews
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose a simple procedure, uncertainty distillation, to teach an LLM to verbalize calibrated semantic confidences.

99, TITLE: Distilling 3D Distinctive Local Descriptors for 6D Pose Estimation
AUTHORS: Amir Hamza ; Andrea Caraffa ; Davide Boscaini ; Fabio Poiesi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: \textit{Can we retain GeDi's effectiveness while significantly improving its efficiency?} In this paper, we explore this question by introducing a knowledge distillation framework that trains an efficient student model to regress local descriptors from a GeDi teacher.

100, TITLE: RETHINED: A New Benchmark and Baseline for Real-Time High-Resolution Image Inpainting On Edge Devices
AUTHORS: Marcelo Sanchez ; Gil Triginer ; Ignacio Sarasua ; Lara Raad ; Coloma Ballester
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, most of these algorithms fail at high resolutions and require powerful hardware, limiting their deployment on edge devices. Motivated by this, we propose the first baseline for REal-Time High-resolution image INpainting on Edge Devices (RETHINED) that is able to inpaint at ultra-high-resolution and can run in real-time ($\leq$ 30ms) in a wide variety of mobile devices.

101, TITLE: A Unified Framework for Real-Time Failure Handling in Robotics Using Vision-Language Models, Reactive Planner and Behavior Trees
AUTHORS: Faseeh Ahmad ; Hashim Ismail ; Jonathan Styrud ; Maj Stenmark ; Volker Krueger
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: This paper presents a unified failure recovery framework that combines Vision-Language Models (VLMs), a reactive planner, and Behavior Trees (BTs) to enable real-time failure handling.

102, TITLE: VisNumBench: Evaluating Number Sense of Multimodal Large Language Models
AUTHORS: Tengjin Weng ; Jingyi Wang ; Wenhao Jiang ; Zhong Ming
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Can Multimodal Large Language Models (MLLMs) develop an intuitive number sense similar to humans? Targeting this problem, we introduce Visual Number Benchmark (VisNumBench) to evaluate the number sense abilities of MLLMs across a wide range of visual numerical tasks.

103, TITLE: VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making
AUTHORS: MOHAMED SALIM AISSI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.RO]
HIGHLIGHT: In this paper, we introduce VIPER, a novel framework for multimodal instruction-based planning that integrates VLM-based perception with LLM-based reasoning.

104, TITLE: DRoPE: Directional Rotary Position Embedding for Efficient Agent Interaction Modeling
AUTHORS: JIANBO ZHAO et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: Existing methods, scene-centric, agent-centric, and query-centric frameworks, each present distinct advantages and drawbacks, creating an impossible triangle among accuracy, computational time, and memory efficiency. To break this limitation, we propose Directional Rotary Position Embedding (DRoPE), a novel adaptation of Rotary Position Embedding (RoPE), originally developed in natural language processing.

105, TITLE: Exploiting Diffusion Prior for Real-World Image Dehazing with Unpaired Training
AUTHORS: YUNWEI LAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Inspired by the strong generative capabilities of diffusion models in producing both hazy and clear images, we exploit diffusion prior for real-world image dehazing, and propose an unpaired framework named Diff-Dehazer.

106, TITLE: GenM$^3$: Generative Pretrained Multi-path Motion Model for Text Conditional Human Motion Generation
AUTHORS: JUNYU SHI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, training on large-scale multi-source datasets introduces data heterogeneity challenges due to variations in motion content. To address this, we propose Generative Pretrained Multi-path Motion Model (GenM$^3$), a comprehensive framework designed to learn unified motion representations.

107, TITLE: These Magic Moments: Differentiable Uncertainty Quantification of Radiance Field Models
AUTHORS: PARKER EWEN et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This paper introduces a novel approach to uncertainty quantification for radiance fields by leveraging higher-order moments of the rendering equation.

108, TITLE: 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities
AUTHORS: Kevin Wang ; Ishaan Javali ; Micha? Bortkiewicz ; Tomasz Trzci?ski ; Benjamin Eysenbach
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor.

109, TITLE: GO-N3RDet: Geometry Optimized NeRF-enhanced 3D Object Detector
AUTHORS: ZECHUAN LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose GO-N3RDet, a scene-geometry optimized multi-view 3D object detector enhanced by neural radiance fields.

110, TITLE: XMOD: Cross-Modal Distillation for 2D/3D Multi-Object Discovery from 2D Motion
AUTHORS: SAAD LAHLALI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, despite this growing interest, it remains under-explored in 3D data, where approaches rely exclusively on 3D motion, despite its several challenges. In this paper, we present a novel framework that leverages advances in 2D object discovery which are based on 2D motion to exploit the advantages of such motion cues being more flexible and generalizable and to bridge the gap between 2D and 3D modalities.

111, TITLE: Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control
AUTHORS: Stelios Zarifis ; Ioannis Kordonis ; Petros Maragos
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SY, eess.SY, I.2.6; I.5.1]
HIGHLIGHT: We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic framework for uncertainty-aware prediction and decision-making in partially observable stochastic systems by integrating diffusion-based time series forecasting models in Model Predictive Control algorithms.

112, TITLE: DCA: Dividing and Conquering Amnesia in Incremental Object Detection
AUTHORS: AOTING ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we dive into the cause of forgetting and discover forgetting imbalance between localization and recognition in transformer-based IOD, which means that localization is less-forgetting and can generalize to future classes, whereas catastrophic forgetting occurs primarily on recognition.

113, TITLE: An Explainable Framework for Misinformation Identification Via Critical Question Answering
AUTHORS: Ramon Ruiz-Dolz ; John Lawrence
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a new explainable framework for both factual and rational misinformation detection based on the theory of Argumentation Schemes and Critical Questions.

114, TITLE: FedSCA: Federated Tuning with Similarity-guided Collaborative Aggregation for Heterogeneous Medical Image Segmentation
AUTHORS: YUMIN ZHANG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we propose a novel FLFM fine-tuning framework, \underline{\textbf{Fed}}erated tuning with \underline{\textbf{S}}imilarity-guided \underline{\textbf{C}}ollaborative \underline{\textbf{A}}ggregation (FedSCA), encompassing all phases of the FL process.

115, TITLE: Exploring Large Language Models for Word Games:Who Is The Spy?
AUTHORS: Chentian Wei ; Jiewei Chen ; Jinzhu Xu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study explores how large language models (LLMs) can be effectively involved in word games and proposes a training-free framework.

116, TITLE: Global Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery
AUTHORS: CALEB ROBINSON et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: We present a comprehensive global temporal dataset of commercial solar photovoltaic (PV) farms and onshore wind turbines, derived from high-resolution satellite imagery analyzed quarterly from the fourth quarter of 2017 to the second quarter of 2024.

117, TITLE: GIVEPose: Gradual Intra-class Variation Elimination for RGB-based Category-Level Object Pose Estimation
AUTHORS: ZINQIN HUANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: By leveraging the complementary strengths of the NOCS map and the IVFC map, we introduce GIVEPose, a framework that implements Gradual Intra-class Variation Elimination for category-level object pose estimation.

118, TITLE: UltraFlwr -- An Efficient Federated Medical and Surgical Object Detection Framework
AUTHORS: YANG LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce UltraFlwr, a framework for federated medical and surgical object detection.

119, TITLE: Detect-and-Guide: Self-regulation of Diffusion Models for Safe Text-to-Image Generation Via Guideline Token Optimization
AUTHORS: Feifei Li ; Mi Zhang ; Yiming Sun ; Min Yang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose the safe generation framework Detect-and-Guide (DAG), leveraging the internal knowledge of diffusion models to perform self-diagnosis and fine-grained self-regulation during the sampling process.

120, TITLE: HAD-Gen: Human-like and Diverse Driving Behavior Modeling for Controllable Scenario Generation
AUTHORS: Cheng Wang ; Lingxin Kong ; Massimiliano Tamborski ; Stefano V. Albrecht
CATEGORY: cs.RO [cs.RO, cs.AI, cs.MA]
HIGHLIGHT: However, contemporary methodologies, such as deterministic and imitation learning-based driver models, struggle to capture the variability of human-like driving behavior. Given these challenges, we propose HAD-Gen, a general framework for realistic traffic scenario generation that simulates diverse human-like driving behaviors.

121, TITLE: Deep Contrastive Unlearning for Language Models
AUTHORS: Estrid He ; Tabinda Sarwar ; Ibrahim Khalil ; Xun Yi ; Ke Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Most existing studies focus on mitigating the impact of those forgot samples upon a model's outputs, and do not explicitly consider the geometric distributions of samples in the latent space of a model. To address this issue, we propose a machine unlearning framework, named Deep Contrastive Unlearning for fine-Tuning (DeepCUT) language models.

122, TITLE: DEPT: Deep Extreme Point Tracing for Ultrasound Image Segmentation
AUTHORS: Lei Shi ; Xi Fang ; Naiyu Wang ; Junxing Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce Deep Extreme Point Tracing (DEPT) integrated with Feature-Guided Extreme Point Masking (FGEPM) algorithm for ultrasound image segmentation.

123, TITLE: Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis
AUTHORS: Imanol G. Estepa ; Jes�s M. Rodr�guez-de-Vera ; Ignacio Saras�a ; Bhalaji Nagarajan ; Petia Radeva
CATEGORY: cs.CV [cs.CV, cs.AI, I.5.4; I.5.1; I.2.10]
HIGHLIGHT: In this work, we introduce Sorcen, a novel unified SSL framework, incorporating a synergic Contrastive-Reconstruction objective.

124, TITLE: EmoGRACE: Aspect-based Emotion Analysis for Social Media Data
AUTHORS: Christina Zorenb�hmer ; Sebastian Schmidt ; Bernd Resch
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While sentiment analysis has advanced from sentence to aspect-level, i.e., the identification of concrete terms related to a sentiment, the equivalent field of Aspect-based Emotion Analysis (ABEA) is faced with dataset bottlenecks and the increased complexity of emotion classes in contrast to binary sentiments. This paper addresses these gaps, by generating a first ABEA training dataset, consisting of 2,621 English Tweets, and fine-tuning a BERT-based model for the ABEA sub-tasks of Aspect Term Extraction (ATE) and Aspect Emotion Classification (AEC).

125, TITLE: CCDP: Composition of Conditional Diffusion Policies with Guided Sampling
AUTHORS: Amirreza Razmjoo ; Sylvain Calinon ; Michael Gienger ; Fan Zhang
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this work, we propose an enhanced sampling strategy that refines the sampling distribution to avoid previously unsuccessful actions.

126, TITLE: Automated Processing of EXplainable Artificial Intelligence Outputs in Deep Learning Models for Fault Diagnostics of Large Infrastructures
AUTHORS: Giovanni Floreale ; Piero Baraldi ; Enrico Zio ; Olga Fink
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: eXplainable Artificial Intelligence (XAI) can address these issues but manually analyzing explanations generated by XAI techniques is time-consuming and prone to errors. This work proposes a novel framework that combines post-hoc explanations with semi-supervised learning to automatically identify anomalous explanations that deviate from those of correctly classified images and may therefore indicate model abnormal behaviors.

127, TITLE: DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis
AUTHORS: Chen Gong ; Kecen Li ; Zinan Lin ; Tianhao Wang
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: To address the issue, this paper introduces DPImageBench for DP image synthesis, with thoughtful design across several dimensions: (1) Methods.

128, TITLE: A Language Vision Model Approach for Automated Tumor Contouring in Radiation Oncology
AUTHORS: YI LUO et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, physics.med-ph]
HIGHLIGHT: Conclusions: OCC represents a significant advance in oncology care, particularly through the use of the latest LVMs to improve contouring results by (1) streamlining oncology treatment workflows by optimizing tumor delineation, reducing manual processes; (2) offering a scalable and intuitive framework to reduce false positives in radiotherapy planning using LVMs; (3) introducing novel medical language vision prompt techniques to minimize LVMs hallucinations with ablation study, and (4) conducting a comparative analysis of LVMs, highlighting their potential in addressing medical language vision challenges.

129, TITLE: MotionStreamer: Streaming Motion Generation Via Diffusion-based Autoregressive Model in Causal Latent Space
AUTHORS: LIXING XIAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing methods struggle to achieve streaming motion generation, e.g., diffusion models are constrained by pre-defined motion lengths, while GPT-based methods suffer from delayed response and error accumulation problem due to discretized non-causal tokenization. To solve these problems, we propose MotionStreamer, a novel framework that incorporates a continuous causal latent space into a probabilistic autoregressive model.

130, TITLE: TF-TI2I: Training-Free Text-and-Image-to-Image Generation Via Multi-Modal Implicit-Context Learning in Text-to-Image Models
AUTHORS: Teng-Fang Hsiao ; Bo-Kai Ruan ; Yi-Lun Wu ; Tzu-Ling Lin ; Hong-Han Shuai
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing methods often partially utilize image inputs, focusing on specific elements like objects or styles, or they experience a decline in generation quality with complex, multi-image instructions. To overcome these challenges, we introduce Training-Free Text-and-Image-to-Image (TF-TI2I), which adapts cutting-edge T2I models such as SD3 without the need for additional training.

131, TITLE: Body-Hand Modality Expertized Networks with Cross-attention for Fine-grained Skeleton Action Recognition
AUTHORS: Seungyeon Cho ; Tae-Kyun Kim
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose BHaRNet (Body-Hand action Recognition Network), a novel framework that augments a typical body-expert model with a hand-expert model.

132, TITLE: Semi-KAN: KAN Provides An Effective Representation for Semi-Supervised Learning in Medical Image Segmentation
AUTHORS: ZANTING YE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Inspired by Kolmogorov-Arnold Networks (KANs), we propose Semi-KAN, which leverages the untapped potential of KANs to enhance backbone architectures for representation learning in SSMIS.

133, TITLE: SkyLadder: Better and Faster Pretraining Via Context Window Scheduling
AUTHORS: TONGYAO ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we propose SkyLadder, a simple yet effective approach that implements a short-to-long context window transition.

134, TITLE: ClimateGS: Real-Time Climate Simulation with 3D Gaussian Style Transfer
AUTHORS: Yuezhen Xie ; Meiying Zhang ; Qi Hao
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: This paper presents ClimateGS, a novel framework integrating 3D Gaussian representations with physical simulation to enable real-time climate effects rendering.

135, TITLE: One-Shot Medical Video Object Segmentation Via Temporal Contrastive Memory Networks
AUTHORS: YAXIONG CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce the task of one-shot medical video object segmentation, which requires separating foreground and background pixels throughout a video given only the mask annotation of the first frame. To address this problem, we propose a temporal contrastive memory network comprising image and mask encoders to learn feature representations, a temporal contrastive memory bank that aligns embeddings from adjacent frames while pushing apart distant ones to explicitly model inter-frame relationships and stores these features, and a decoder that fuses encoded image features and memory readouts for segmentation.

136, TITLE: Test-Time Backdoor Detection for Object Detection Models
AUTHORS: HANGTAO ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we design TRAnsformation Consistency Evaluation (TRACE), a brand-new method for detecting poisoned samples at test time in object detection.

137, TITLE: Core-Periphery Principle Guided State Space Model for Functional Connectome Classification
AUTHORS: MINHENG CHEN et. al.
CATEGORY: q-bio.NC [q-bio.NC, cs.AI, cs.CV, eess.IV]
HIGHLIGHT: However, traditional machine learning approaches struggle to capture the complex relationships between brain regions, while deep learning methods, particularly Transformer-based models, face computational challenges due to their quadratic complexity in long-sequence modeling. To address these limitations, we propose a Core-Periphery State-Space Model (CP-SSM), an innovative framework for functional connectome classification.

138, TITLE: Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection
AUTHORS: Matt Franchi ; Nikhil Garg ; Wendy Ju ; Emma Pierson
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: However, a major challenge in using these datasets is their lack of reliable labels: there are myriad types of incidents, many types occur rarely, and ground-truth measures of where incidents occur are lacking. Here, we propose BayFlood, a two-stage approach which circumvents this difficulty.

139, TITLE: H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection
AUTHORS: Yuhang Liu ; Wenjie Zhao ; Yunhui Guo
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Continually detecting OOD samples presents several challenges for current OOD detection methods: reliance on model outputs leads to excessive dependence on model performance, selecting suitable thresholds is difficult, hindering real-world deployment, and binary ID/OOD classification fails to provide task-level identification. To address these issues, we propose a novel continual OOD detection method called the Hierarchical Two-sample Tests (H2ST).

140, TITLE: Covering Cracks in Content Moderation: Delexicalized Distant Supervision for Illicit Drug Jargon Detection
AUTHORS: Minkyoo Song ; Eugene Jang ; Jaehan Kim ; Seungwon Shin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present JEDIS, a framework for detecting illicit drug jargon terms by analyzing their contexts.

141, TITLE: Intelligent Spatial Perception By Building Hierarchical 3D Scene Graphs for Indoor Scenarios with The Help of LLMs
AUTHORS: YAO CHENG et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: This paper addresses the high demand in advanced intelligent robot navigation for a more holistic understanding of spatial environments, by introducing a novel system that harnesses the capabilities of Large Language Models (LLMs) to construct hierarchical 3D Scene Graphs (3DSGs) for indoor scenarios.

142, TITLE: SPADE: Systematic Prompt Framework for Automated Dialogue Expansion in Machine-Generated Text Detection
AUTHORS: Haoyi Li ; Angela Yifei Yuan ; Soyeon Caren Han ; Christopher Leckie
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these detectors face significant challenges due to the lack of systematically generated, high-quality datasets for training. To address this issue, we propose five novel data augmentation frameworks for synthetic user dialogue generation through a structured prompting approach, reducing the costs associated with traditional data collection methods.

143, TITLE: Spot The Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation
AUTHORS: SIWEI WEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite the effectiveness of existing methods in evaluating image authenticity and locating forgeries, these approaches often lack human interpretability and do not fully address the growing complexity of synthetic data. To tackle these challenges, we introduce FakeVLM, a specialized large multimodal model designed for both general synthetic image and DeepFake detection tasks.

144, TITLE: Beacon2Science: Enhancing STEREO/HI Beacon Data1 with Machine Learning for Efficient CME Tracking
AUTHORS: Justin Le Lou�dec ; Maike Bauer ; Tanja Amerstorfer ; Jackie A. Davies
CATEGORY: physics.space-ph [physics.space-ph, cs.CV, cs.LG]
HIGHLIGHT: We present our novel pipeline entitled ''Beacon2Science'', bridging the gap between beacon and science data to improve CME tracking.

145, TITLE: Do Chains-of-Thoughts of Large Language Models Suffer from Hallucinations, Cognitive Biases, or Phobias in Bayesian Reasoning?
AUTHORS: Roberto Araya
CATEGORY: cs.AI [cs.AI, I.2.0]
HIGHLIGHT: This is unfortunate, as these strategies help humans avoid critical mistakes and have proven pedagogical value in Bayesian reasoning. In order to overcome these biases and aid understanding and learning, we included prompts that induce LLMs to use these strategies.

146, TITLE: Model Hubs and Beyond: Analyzing Model Popularity, Performance, and Documentation
AUTHORS: PRITAM KADASI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: With the massive surge in ML models on platforms like Hugging Face, users often lose track and struggle to choose the best model for their downstream tasks, frequently relying on model popularity indicated by download counts, likes, or recency.

147, TITLE: Neuro Symbolic Knowledge Reasoning for Procedural Video Question Answering
AUTHORS: THANH-SON NGUYEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces a new video question-answering (VQA) dataset that challenges models to leverage procedural knowledge for complex reasoning.

148, TITLE: Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability
AUTHORS: Zihao Liu ; Xing Liu ; Yizhai Zhang ; Zhengxiong Liu ; Panfeng Huang
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: Specifically, imitation policy based on neural network may generate hallucinations, leading to inaccurate behaviors that impact the safety of real-world applications. To address this issue, this paper proposes the Curiosity-Diffuser, aimed at guiding the conditional diffusion model to generate trajectories with lower curiosity, thereby improving the reliability of policy.

149, TITLE: PAPI-Reg: Patch-to-Pixel Solution for Efficient Cross-Modal Registration Between LiDAR Point Cloud and Camera Image
AUTHORS: Yuanchao Yue ; Zhengxin Li ; Wei Zhang ; Hui Yuan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, due to the domain gap between the point cloud and the image, existing methods rarely achieve satisfactory registration accuracy while maintaining real-time performance. To address this issue, we propose a framework that projects point clouds into several 2D representations for matching with camera images, which not only leverages the geometric characteristic of LiDAR point clouds more effectively but also bridge the domain gap between the point cloud and image.

150, TITLE: FetalFlex: Anatomy-Guided Diffusion Model for Flexible Control on Fetal Ultrasound Image Synthesis
AUTHORS: YAOFEI DUAN et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This poses difficulties in training novice radiologists and developing robust AI models, especially for detecting abnormal fetuses. In this study, we introduce a Flexible Fetal US image generation framework (FetalFlex) to address these challenges, which leverages anatomical structures and multimodal information to enable controllable synthesis of fetal US images across diverse planes.

151, TITLE: A Semantic and Clean-label Backdoor Attack Against Graph Convolutional Networks
AUTHORS: Jiazhu Dai ; Haoyu Sun
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: The semantic and clean-label backdoor attack is not fully explored in GCNs. In this paper, we propose a semantic and clean-label backdoor attack against GCNs under the context of graph classification to reveal the existence of this security vulnerability in GCNs.

152, TITLE: ChatStitch: Visualizing Through Structures Via Surround-View Unsupervised Deep Image Stitching with Collaborative LLM-Agents
AUTHORS: Hao Liang ; Zhipeng Dong ; Yi Yang ; Mengyin Fu
CATEGORY: cs.CV [cs.CV, cs.HC]
HIGHLIGHT: However, existing collaborative perception systems are limited by inefficiencies in user interaction and the challenge of multi-camera photorealistic visualization. To address these challenges, this paper introduces ChatStitch, the first collaborative perception system capable of unveiling obscured blind spot information through natural language commands integrated with external digital assets.

153, TITLE: Euclid Quick Data Release (Q1). Active Galactic Nuclei Identification Using Diffusion-based Inpainting of Euclid VIS Images
AUTHORS: EUCLID COLLABORATION et. al.
CATEGORY: astro-ph.GA [astro-ph.GA, cs.CV]
HIGHLIGHT: This paper introduces a novel approach to identify AGN and QSO from a single image.

154, TITLE: Semantic Segmentation of Transparent and Opaque Drinking Glasses with The Help of Zero-shot Learning
AUTHORS: ANNALENA BL�NSDORF et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work we propose TransCaGNet, a modified version of the zero-shot model CaGNet.

155, TITLE: Federated Continual 3D Segmentation With Single-round Communication
AUTHORS: CAN PENG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this paper, we propose a federated continual learning strategy that employs a one-time model aggregation at the server through multi-model distillation.

156, TITLE: Efficient Personalization of Quantized Diffusion Model Without Backpropagation
AUTHORS: Hoigi Seo ; Wongi Jeong ; Kyungryeol Lee ; Se Young Chun
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, memory-efficient fine-tuning is particularly desirable for applications such as personalization that often must be run on edge devices like mobile phones with private data. In this work, we address this challenge by quantizing a diffusion model with personalization via Textual Inversion and by leveraging a zeroth-order optimization on personalization tokens without dequantization so that it does not require gradient and activation storage for backpropagation that consumes considerable memory.

157, TITLE: Comparing Llama3 and DeepSeekR1 on Biomedical Text Classification Tasks
AUTHORS: Yuting Guo ; Abeed Sarker
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study compares the performance of two open-source large language models (LLMs)-Llama3-70B and DeepSeekR1-distill-Llama3-70B-on six biomedical text classification tasks.

158, TITLE: Fine-Grained Open-Vocabulary Object Detection with Fined-Grained Prompts: Task, Dataset and Benchmark
AUTHORS: Ying Liu ; Yijing Hua ; Haojiang Chai ; Yanbo Wang ; TengQi Ye
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces 3F-OVD, a novel task that extends supervised fine-grained object detection to the open-vocabulary setting.

159, TITLE: 3D Engine-ready Photorealistic Avatars Via Dynamic Textures
AUTHORS: Yifan Wang ; Ivan Molodetskikh ; Ondrej Texler ; Dimitar Dinev
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose an end-to-end pipeline that builds explicitly-represented photorealistic 3D avatars using standard 3D assets.

160, TITLE: Can Large Vision Language Models Read Maps Like A Human?
AUTHORS: SHUO XING et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce MapBench-the first dataset specifically designed for human-readable, pixel-based map-based outdoor navigation, curated from complex path finding scenarios.

161, TITLE: Construction Site Scaffolding Completeness Detection Based on Mask R-CNN and Hough Transform
AUTHORS: Pei-Hsin Lin ; Jacob J. Lin ; Shang-Hsien Hsieh
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The inspection process includes ensuring all the components are in the right place since workers often compromise safety for convenience and disassemble parts such as cross braces. This paper proposes a deep learning-based approach to detect the scaffolding and its cross braces using computer vision.

162, TITLE: Texture-Aware StarGAN for CT Data Harmonisation
AUTHORS: Francesco Di Feola ; Ludovica Pompilio ; Cecilia Assolito ; Valerio Guarrasi ; Paolo Soda
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: In this work, we propose a novel texture-aware StarGAN for CT data harmonization, enabling one-to-many translations across different reconstruction kernels.

163, TITLE: Inspecting The Representation Manifold of Differentially-Private Text
AUTHORS: Stefan Arnold
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Differential Privacy (DP) for text has recently taken the form of text paraphrasing using language models and temperature sampling to better balance privacy and utility.

164, TITLE: Second Language Korean Universal Dependency Treebank V1.2: Focus on Data Augmentation and Annotation Scheme Refinement
AUTHORS: Hakyung Sung ; Gyu-Ho Shin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The annotation guidelines are also revised to better align with the UD framework. Using this enhanced treebank, we fine-tune three Korean language models and evaluate their performance on in-domain and out-of-domain L2-Korean datasets.

165, TITLE: Text-Derived Relational Graph-Enhanced Network for Skeleton-Based Action Segmentation
AUTHORS: HAOYU JI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, these methods overlook the intrinsic correlations among joints and actions within skeletal features, leading to a limited understanding of human movements. To address this, we propose a Text-Derived Relational Graph-Enhanced Network (TRG-Net) that leverages prior graphs generated by Large Language Models (LLM) to enhance both modeling and supervision.

166, TITLE: SPILL: Domain-Adaptive Intent Clustering Based on Selection and Pooling with Large Language Models
AUTHORS: I-Fan Lin ; Faegheh Hasibi ; Suzan Verberne
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose Selection and Pooling with Large Language Models (SPILL), an intuitive and domain-adaptive method for intent clustering without fine-tuning.

167, TITLE: Reducing Annotation Burden: Exploiting Image Knowledge for Few-Shot Medical Video Object Segmentation Via Spatiotemporal Consistency Relearning
AUTHORS: ZIXUAN ZHENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Subsequently, to improve performance without full supervision, we introduce a spatiotemporal consistency relearning approach on medical videos that enforces consistency between consecutive frames.

168, TITLE: Elevating Visual Question Answering Through Implicitly Learned Reasoning Pathways in LVLMs
AUTHORS: Liu Jing ; Amirul Rahman
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Large Vision-Language Models (LVLMs) have shown remarkable progress in various multimodal tasks, yet they often struggle with complex visual reasoning that requires multi-step inference. To address this limitation, we propose MF-SQ-LLaVA, a novel approach that enhances LVLMs by enabling implicit self-questioning through end-to-end training.

169, TITLE: Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code Generation By Large Language Models
AUTHORS: Man Fai Wong ; Chee Wei Tan
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance text-to-code generation.

170, TITLE: Benchmarking Large Language Models for Handwritten Text Recognition
AUTHORS: Giorgia Crosilla ; Lukas Klic ; Giovanni Colavizza
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: The study benchmarks various proprietary and open-source LLMs against Transkribus models, evaluating their performance on both modern and historical datasets written in English, French, German, and Italian.

171, TITLE: Volumetric Reconstruction From Partial Views for Task-Oriented Grasping
AUTHORS: Fujian Yan ; Hui Li ; Hongsheng He
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: This paper presents an approach for inferring suitable grasping strategies from limited partial views of an object.

172, TITLE: SemanticFlow: A Self-Supervised Framework for Joint Scene Flow Prediction and Instance Segmentation in Dynamic Environments
AUTHORS: Yinqi Chen ; Meiying Zhang ; Qi Hao ; Guang Zhou
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This paper proposes a multi-task SemanticFlow framework to simultaneously predict scene flow and instance segmentation of full-resolution point clouds.

173, TITLE: FP4DiT: Towards Effective Floating Point Quantization for Diffusion Transformers
AUTHORS: Ruichen Chen ; Keith G. Mills ; Di Niu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In response, we introduce FP4DiT, a PTQ method that leverages FPQ to achieve W4A6 quantization.

174, TITLE: Probing The Topology of The Space of Tokens with Structured Prompts
AUTHORS: Michael Robinson ; Sourya Dey ; Taisa Kushner
CATEGORY: math.DG [math.DG, cs.AI, 53Z50, 58Z05, I.2.7]
HIGHLIGHT: This article presents a general and flexible method for prompting a large language model (LLM) to reveal its (hidden) token input embedding up to homeomorphism.

175, TITLE: ConQuer: A Framework for Concept-Based Quiz Generation
AUTHORS: Yicheng Fu ; Zikui Wang ; Liuxin Yang ; Meiqing Huo ; Zhongdongming Dai
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Although LLMs have greatly enhanced the efficiency of quiz generation, concerns remain regarding the quality of these AI-generated quizzes and their educational impact on students. To address these issues, we introduce ConQuer, a concept-based quiz generation framework that leverages external knowledge sources.

176, TITLE: ARC: Anchored Representation Clouds for High-Resolution INR Classification
AUTHORS: Joost Luijmes ; Alexander Gielisse ; Roman Knyazhitskiy ; Jan van Gemert
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose ARC: Anchored Representation Clouds, a novel INR architecture that explicitly anchors latent vectors locally in image-space.

177, TITLE: Low-Complexity Patch-based No-Reference Point Cloud Quality Metric Exploiting Weighted Structure and Texture Features
AUTHORS: Michael Neri ; Federica Battisti
CATEGORY: cs.CV [cs.CV, cs.MM, eess.IV]
HIGHLIGHT: This study introduces PST-PCQA, a no-reference point cloud quality metric based on a low-complexity, learning-based framework.

178, TITLE: Bridging The Gap: Fusing CNNs and Transformers to Decode The Elegance of Handwritten Arabic Script
AUTHORS: Chaouki Boufenar ; Mehdi Ayoub Rabiai ; Boualem Nadjib Zahaf ; Khelil Rafik Ouaras
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Handwritten Arabic script recognition is a challenging task due to the script's dynamic letter forms and contextual variations. This paper proposes a hybrid approach combining convolutional neural networks (CNNs) and Transformer-based architectures to address these complexities.

179, TITLE: Ultrasound Image-to-Video Synthesis Via Latent Dynamic Diffusion Models
AUTHORS: TINGXIU CHEN et. al.
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: To this end, we introduce a latent dynamic diffusion model (LDDM) to efficiently translate static images to dynamic sequences with realistic video characteristics.

180, TITLE: TGV: Tabular Data-Guided Learning of Visual Cardiac Representations
AUTHORS: Marta Hasny ; Maxime Di Folco ; Keno Bressem ; Julia Schnabel
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose harnessing clinically relevant tabular data to identify distinct patient phenotypes and form more meaningful pairs in a contrastive learning framework.

181, TITLE: Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving
AUTHORS: Priscylla Silva ; Evandro Costa
CATEGORY: cs.SE [cs.SE, cs.AI, cs.LG]
HIGHLIGHT: We assessed the models' capacity to provide accurate and insightful feedback, particularly in identifying reasoning mistakes.

182, TITLE: A Foundational Theory for Decentralized Sensory Learning
AUTHORS: Linus M�rtensson ; Jonas M. D. Enander ; Udaya B. Rongala ; Henrik J�rntell
CATEGORY: q-bio.NC [q-bio.NC, cs.AI]
HIGHLIGHT: Available evidence shows that the evolution of the nervous system likely was an adaptation to more effectively communicate intercellular signals to support such division of labour. We therefore propose that the same learning principle that evolved already in the earliest unicellular life forms, i.e. negative feedback control of externally and internally generated sensor signals, has simply been scaled up to become a fundament of the learning we see in biological brains today.

183, TITLE: A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection
AUTHORS: Aamir Mehmood ; Yue Hu ; Saddam Hussain Khan
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: This study introduces a novel hybrid framework, CB-Res-RBCMT, combining customized residual CNNs and new ViT components for detailed BUSI cancer analysis.

184, TITLE: GraspCorrect: Robotic Grasp Correction Via Vision-Language Model-Guided Feedback
AUTHORS: Sungjae Lee ; Yeonjoo Hong ; Kwang In Kim
CATEGORY: cs.AI [cs.AI, cs.RO]
HIGHLIGHT: Our analysis reveals that even state-of-the-art policy models frequently exhibit unstable grasping behaviors, leading to failure cases that create bottlenecks in real-world robotic applications. To address these challenges, we introduce GraspCorrect, a plug-and-play module designed to enhance grasp performance through vision-language model-guided feedback.

185, TITLE: Real-world Validation of A Multimodal LLM-powered Pipeline for High-Accuracy Clinical Trial Patient Matching Leveraging EHR Data
AUTHORS: Anatole Callies ; Quentin Bodinier ; Philippe Ravaud ; Kourosh Davarpanah
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Methods: We introduce a broadly applicable, integration-free, LLM-powered pipeline that automates patient-trial matching using unprocessed documents extracted from EHRs.

186, TITLE: Command R7B Arabic: A Small, Enterprise Focused, Multilingual, and Culturally Aware Arabic LLM
AUTHORS: YAZEED ALNUMAY et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Building high-quality large language models (LLMs) for enterprise Arabic applications remains challenging due to the limited availability of digitized Arabic data. In this work, we present a data synthesis and refinement strategy to help address this problem, namely, by leveraging synthetic data generation and human-in-the-loop annotation to expand our Arabic training corpus.

187, TITLE: SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation
AUTHORS: THOMAS PICKARD et. al.
CATEGORY: cs.CL [cs.CL, cs.CV, I.2.7; I.4.m]
HIGHLIGHT: We present datasets and tasks for SemEval-2025 Task 1: AdMiRe (Advancing Multimodal Idiomaticity Representation), which challenges the community to assess and improve models' ability to interpret idiomatic expressions in multimodal contexts and in multiple languages.

188, TITLE: A Data-driven Investigation of Euphemistic Language: Comparing The Usage of "slave" and "servant" in 19th Century US Newspapers
AUTHORS: Jaihyun Park ; Ryan Cordell
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study investigates the usage of "slave" and "servant" in the 19th century US newspapers using computational methods.

189, TITLE: ELTEX: A Framework for Domain-Driven Synthetic Data Generation
AUTHORS: Arina Razmyslovich ; Kseniia Murasheva ; Sofia Sedlova ; Julien Capitaine ; Eugene Dmitriev
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework for generating high-quality synthetic training data in specialized domains.

190, TITLE: Retrieval-Augmented Simulacra: Generative Agents for Up-to-date and Knowledge-Adaptive Simulations
AUTHORS: Hikaru Shimadzu ; Takehito Utsuro ; Daisuke Kitayama
CATEGORY: cs.CL [cs.CL, cs.SI]
HIGHLIGHT: In this paper, we evaluate the impact of the search extension generation mechanism used to create posts and replies in a virtual SNS environment using a simulation system on the ability to generate posts and replies.

191, TITLE: Object-Centric Pretraining Via Target Encoder Bootstrapping
AUTHORS: Nikola ?uki? ; Tim Lebailly ; Tinne Tuytelaars
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Attempts to update the target encoder by bootstrapping result in large performance drops, which can be attributed to its lack of object-centric inductive biases, causing the object-centric model's encoder to drift away from representations useful as reconstruction targets. To address these limitations, we propose Object-CEntric Pretraining by Target Encoder BOotstrapping, a self-distillation setup for training object-centric models from scratch, on real-world data, for the first time ever.

192, TITLE: SUM Parts: Benchmarking Part-Level Semantic Segmentation of Urban Meshes
AUTHORS: Weixiao Gao ; Liangliang Nan ; Hugo Ledoux
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces SUM Parts, the first large-scale dataset for urban textured meshes with part-level semantic labels, covering about 2.5 km2 with 21 classes.

193, TITLE: TruthLens:A Training-Free Paradigm for DeepFake Detection
AUTHORS: Ritabrata Chakraborty ; Rajatsubhra Chakraborty ; Ali Khaleghi Rahimian ; Thomas MacDougall
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Current fake image detection methods predominantly rely on binary classification models that focus on accuracy while often neglecting interpretability, leaving users without clear insights into why an image is deemed real or fake. To bridge this gap, we introduce TruthLens, a novel training-free framework that reimagines deepfake detection as a visual question-answering (VQA) task.

194, TITLE: Deep Polycuboid Fitting for Compact 3D Representation of Indoor Scenes
AUTHORS: Gahye Lee ; Hyejeong Yoon ; Jungeon Kim ; Seungyong Lee
CATEGORY: cs.CV [cs.CV, I.4.8; I.3.5]
HIGHLIGHT: This paper presents a novel framework for compactly representing a 3D indoor scene using a set of polycuboids through a deep learning-based fitting method.

195, TITLE: Machine Unlearning in Hyperbolic Vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU
AUTHORS: �lex Pujol Vidal ; Sergio Escalera ; Kamal Nasrollahi ; Thomas B. Moeslund
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG, cs.MM]
HIGHLIGHT: Our approach introduces hyperbolic-specific components including entailment calibration and norm regularization that leverage the unique properties of hyperbolic space.

196, TITLE: An Investigation of Beam Density on LiDAR Object Detection Performance
AUTHORS: Christoph Griesbacher ; Christian Fruhwirth-Reisinger
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To gain better understanding of the impact of beam density on domain gaps, we conduct a comprehensive investigation that includes an evaluation of different object detection architectures.

197, TITLE: MultiBARF: Integrating Imagery of Different Wavelength Regions By Using Neural Radiance Fields
AUTHORS: Kana Kurata ; Hitoshi Niigaki ; Xiaojun Wu ; Ryuichi Tanida
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To make data preparation easier for users unfamiliar with sensing and image processing, we have developed MultiBARF.

198, TITLE: EdgeRegNet: Edge Feature-based Multimodal Registration Network Between Images and LiDAR Point Clouds
AUTHORS: YUANCHAO YUE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Additionally, high-dimensional features extracted using different feature extractors from various modalities require specific techniques to mitigate cross-modal differences for effective matching. To address these challenges, we propose a method that uses edge information from the original point clouds and images for cross-modal registration.

199, TITLE: A Simple Combination of Diffusion Models for Better Quality Trade-Offs in Image Denoising
AUTHORS: Jonas Dornbusch ; Emanuel Pfarr ; Florin-Alexandru Vasluianu ; Frank Werner ; Radu Timofte
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A Simple Combination of Diffusion Models for Better Quality Trade-Offs in Image Denoising

200, TITLE: DVHGNN: Multi-Scale Dilated Vision HGNN for Efficient Vision Recognition
AUTHORS: Caoshuo Li ; Tanzhe Li ; Xiaobin Hu ; Donghao Luo ; Taisong Jin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the aforementioned challenges, we propose a novel vision architecture, termed Dilated Vision HyperGraph Neural Network (DVHGNN), which is designed to leverage multi-scale hypergraph to efficiently capture high-order correlations among objects.

201, TITLE: Validation of Human Pose Estimation and Human Mesh Recovery for Extracting Clinically Relevant Motion Data from Videos
AUTHORS: Kai Armstrong ; Alexander Rodrigues ; Alexander P. Willmott ; Lei Zhang ; Xujiong Ye
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work aims to discuss the current landscape of kinematic analysis tools, ranging from the state-of-the-art in sports biomechanics such as inertial measurement units (IMUs) and retroreflective marker-based optical motion capture (MoCap) to more novel approaches from the field of computing such as human pose estimation and human mesh recovery.

202, TITLE: Revisiting Image Fusion for Multi-Illuminant White-Balance Correction
AUTHORS: DAVID SERRANO-LOZANO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Additionally, existing fusion-based methods rely on sRGB WB datasets lacking dedicated multi-illuminant images, limiting both training and evaluation. To address these challenges, we introduce two key contributions. First, we propose an efficient transformer-based model that effectively captures spatial dependencies across sRGB WB presets, substantially improving upon linear fusion techniques.

203, TITLE: Cube: A Roblox View of 3D Intelligence
AUTHORS: FOUNDATION AI TEAM et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Foundation models trained on vast amounts of data have demonstrated remarkable reasoning and generation capabilities in the domains of text, images, audio and video. Our goal at Roblox is to build such a foundation model for 3D intelligence, a model that can support developers in producing all aspects of a Roblox experience, from generating 3D objects and scenes to rigging characters for animation to producing programmatic scripts describing object behaviors.

204, TITLE: Toward Task-driven Satellite Image Super-resolution
AUTHORS: Maciej Ziaja ; Pawel Kowaleczko ; Daniel Kostrzewa ; Nicolas Long�p� ; Michal Kawulok
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, it often remains unclear whether the reconstructed details are close to the actual ground-truth information and whether they constitute a more valuable source for image analysis algorithms. In the reported work, we address the latter problem, and we present our efforts toward learning super-resolution algorithms in a task-driven way to make them suitable for generating high-resolution images that can be exploited for automated image analysis.

205, TITLE: Manifold Learning for Hyperspectral Images
AUTHORS: Fethi Harkat ; Tiphaine Deuberet ; Guillaume Gey ; Val�rie Perrier ; K�vin Polisano
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Traditional feature extraction and projection techniques, such as Principal Component Analysis, struggle to adequately represent X-Ray Transmission (XRT) Multi-Energy (ME) images, limiting the performance of neural networks in decision-making processes. To address this issue, we propose a method that approximates the dataset topology by constructing adjacency graphs using the Uniform Manifold Approximation and Projection.

206, TITLE: Depth-Aware Range Image-Based Model for Point Cloud Segmentation
AUTHORS: Bike Chen ; Antti Tikanm�ki ; Juha R�ning
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose Depth-Aware Module (DAM) and Fast FMVNet V3.

207, TITLE: Disentangling Modes and Interference in The Spectrogram of Multicomponent Signals
AUTHORS: K�vin Polisano ; Sylvain Meignen ; Nils Laurent ; Hubert Leterme
CATEGORY: cs.CV [cs.CV, eess.SP]
HIGHLIGHT: In this paper, we investigate how the spectrogram of multicomponent signals can be decomposed into a mode part and an interference part.

208, TITLE: USAM-Net: A U-Net-based Network for Improved Stereo Correspondence and Scene Depth Estimation Using Features from A Pre-trained Image Segmentation Network
AUTHORS: Joseph Emmanuel DL Dayo ; Prospero C. Naval Jr
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The increasing demand for high-accuracy depth estimation in autonomous driving and augmented reality applications necessitates advanced neural architectures capable of effectively leveraging multiple data modalities. In this context, we introduce the Unified Segmentation Attention Mechanism Network (USAM-Net), a novel convolutional neural network that integrates stereo image inputs with semantic segmentation maps and attention to enhance depth estimation performance.

209, TITLE: Foundation Models May Exhibit Staged Progression in Novel CBRN Threat Disclosure
AUTHORS: Kevin M Esvelt
CATEGORY: cs.CY [cs.CY, cs.AI, q-bio.OT]
HIGHLIGHT: The extent to which foundation models can disclose novel chemical, biological, radiation, and nuclear (CBRN) threats to expert users is unclear due to a lack of test cases.

210, TITLE: A Personalized Data-Driven Generative Model of Human Motion
AUTHORS: Angelo Di Porzio ; Marco Coraggio
CATEGORY: cs.GR [cs.GR, cs.AI, cs.LG, cs.SY, eess.SY]
HIGHLIGHT: In this work, we propose a fully data-driven approach, based on Long Short-Term Memory neural networks, to generate original motion that captures the unique characteristics of specific individuals.

211, TITLE: When Pigs Get Sick: Multi-Agent AI for Swine Disease Detection
AUTHORS: Tittaya Mairittha ; Tanakon Sawanglok ; Panuwit Raden ; Sorrawit Treesuk
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CL, cs.IR, cs.MA]
HIGHLIGHT: Swine disease surveillance is critical to the sustainability of global agriculture, yet its effectiveness is frequently undermined by limited veterinary resources, delayed identification of cases, and variability in diagnostic accuracy. To overcome these barriers, we introduce a novel AI-powered, multi-agent diagnostic system that leverages Retrieval-Augmented Generation (RAG) to deliver timely, evidence-based disease detection and clinical guidance.

212, TITLE: A Review on Large Language Models for Visual Analytics
AUTHORS: Navya Sonal Agarwal ; Sanjay Kumar Sonbhadra
CATEGORY: cs.HC [cs.HC, cs.CL, cs.CV]
HIGHLIGHT: This paper provides a comprehensive review of the integration of Large Language Models (LLMs) with visual analytics, addressing their foundational concepts, capabilities, and wide-ranging applications.

213, TITLE: Envisioning An AI-Enhanced Mental Health Ecosystem
AUTHORS: Kellie Yu Hui Sim ; Kenny Tsu Wei Choo
CATEGORY: cs.HC [cs.HC, cs.AI, H.5.0]
HIGHLIGHT: We propose a hybrid ecosystem where where AI assists but does not replace human providers, emphasising responsible deployment and evaluation.

214, TITLE: On The Robustness Tradeoff in Fine-Tuning
AUTHORS: KUNYANG LI et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we characterize the robustness-accuracy trade-off in fine-tuning.

215, TITLE: Learning with Expert Abstractions for Efficient Multi-Task Continuous Control
AUTHORS: Jeff Jewett ; Sandhya Saisubramanian
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Existing hierarchical approaches often target discrete settings and do not generalize across tasks. We propose a hierarchical reinforcement learning approach that addresses these limitations by dynamically planning over the expert-specified abstraction to generate subgoals to learn a goal-conditioned policy.

216, TITLE: Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems
AUTHORS: George Stamatelis ; Angelos-Nikolaos Kanatas ; George C. Alexandropoulos
CATEGORY: cs.LG [cs.LG, cs.AI, cs.NI]
HIGHLIGHT: However, deploying deep learning models on resource-constrained edge devices remains challenging due to their high computational cost. To address this challenge, in this paper, we present a novel sparse recurrent MARL framework integrating gradual neural network pruning into the independent actor global critic paradigm.

217, TITLE: Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer
AUTHORS: Abhi Kamboj ; Minh N. Do
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, eess.SP]
HIGHLIGHT: Multimodal alignment aims to construct a joint latent vector space where two modalities representing the same concept map to the same vector. We formulate this as an inverse problem and show that under certain conditions perfect alignment can be achieved.

218, TITLE: Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach
AUTHORS: GRACE FUNMILAYO FARAYOLA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents a machine learning approach to reduce false VT alarms using the VTaC dataset, a benchmark dataset of annotated VT alarms from ICU monitors.

219, TITLE: Application of Linear Regression Method to The Deep Reinforcement Learning in Continuous Action Cases
AUTHORS: Hisato Komatsu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, the LS-DQN method assumes that the actions are discrete. In this study, we propose the Double Least Squares Deep Deterministic Policy Gradient (DLS-DDPG) method to address this limitation.

220, TITLE: Project Jenkins: Turning Monkey Neural Data Into Robotic Arm Movement, and Back
AUTHORS: Andrii Zahorodnii ; Dima Yanovsky
CATEGORY: cs.RO [cs.RO, cs.AI, eess.SP, q-bio.NC]
HIGHLIGHT: Using real neural data recorded from motor and premotor cortex areas of a macaque monkey named Jenkins, we develop models for decoding (converting brain signals into robotic arm movements) and encoding (simulating brain activity corresponding to a given movement).

221, TITLE: ARC-Calib: Autonomous Markerless Camera-to-Robot Calibration Via Exploratory Robot Motions
AUTHORS: Podshara Chanrungmaneekul ; Yiting Chen ; Joshua T. Grace ; Aaron M. Dollar ; Kaiyu Hang
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: Furthermore, existing autonomous markerless calibration methods typically rely on pre-trained robot tracking models that impede their application on edge devices and require fine-tuning for novel robot embodiments. To address these limitations, this paper proposes a model-based markerless camera-to-robot calibration framework, ARC-Calib, that is fully autonomous and generalizable across diverse robots and scenarios without requiring extensive data collection or learning.

222, TITLE: ViVa-SAFELAND: A New Freeware for Safe Validation of Vision-based Navigation in Aerial Vehicles
AUTHORS: Miguel S. Soriano-Garc�a ; Diego A. Mercado-Ravell
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: ViVa-SAFELAND provides a new, safe, simple and fair comparison baseline to evaluate and compare different visual navigation solutions under the same conditions, and to randomize variables along several trials.

223, TITLE: Automated Non-Functional Requirements Generation in Software Engineering with Large Language Models: A Comparative Study
AUTHORS: Jomar Thomas Almonte ; Santhosh Anitha Boominathan ; Nathalia Nascimento
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: To support requirements engineers in eliciting NFRs, we developed a framework that leverages Large Language Models (LLMs) to derive quality-driven NFRs from functional requirements (FRs).

224, TITLE: Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution
AUTHORS: Akram Khatami-Rizi ; Ahmad Mahmoudi-Aznaveh
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: We propose the Involution & BSConv Multi-Depth Distillation Network (IBMDN), combining Involution & BSConv Multi-Depth Distillation Block (IBMDB) and the Contrast and High-Frequency Attention Block (CHFAB).
