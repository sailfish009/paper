1, TITLE: Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data Using Large Language Models
AUTHORS: FREDERIKE Lï¿½BECK et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: We developed AdaCVD, an adaptable CVD risk prediction framework built on large language models extensively fine-tuned on over half a million participants from the UK Biobank.

2, TITLE: Black-box Adversarial Attacks on CNN-based SLAM Algorithms
AUTHORS: MARIA RAFAELA GKEKA et. al.
CATEGORY: cs.RO [cs.RO, cs.CV, 68T40, 68T45, 68M25,]
HIGHLIGHT: Our work introduces black-box adversarial perturbations applied to the RGB images fed into the GCN-SLAM algorithm.

3, TITLE: MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR
AUTHORS: Dimitrios Damianos ; Georgios Paraskevopoulos ; Alexandros Potamianos
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this work, we investigate the Meta PL unsupervised domain adaptation framework for Automatic Speech Recognition (ASR).

4, TITLE: Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI
AUTHORS: XINLIU ZHONG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we propose a contrast-augmented segmentation framework that leverages complementary information across multi-echo T2*-weighted MRI to learn robust, contrast-invariant representations.

5, TITLE: Tackling View-Dependent Semantics in 3D Language Gaussian Splatting
AUTHORS: JIAZHONG CEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, most of them simply project 2D semantic features onto 3D Gaussians and overlook a fundamental gap between 2D and 3D understanding: a 3D object may exhibit various semantics from different viewpoints--a phenomenon we term view-dependent semantics. To address this challenge, we propose LaGa (Language Gaussians), which establishes cross-view semantic connections by decomposing the 3D scene into objects.

6, TITLE: SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training
AUTHORS: Yehonathan Refael ; Guy Smorodinsky ; Tom Tirer ; Ofir Lindenbaum
CATEGORY: cs.LG [cs.LG, cs.CL, math.OC]
HIGHLIGHT: In this paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an optimizer that employs exact singular value decomposition (SVD) for moment orthogonalization within a dynamically adapted low-dimensional subspace, enabling norm-inducing steepest descent optimization steps.

7, TITLE: Don't Reinvent The Wheel: Efficient Instruction-Following Text Embedding Based on Guided Space Transformation
AUTHORS: YINGCHAOJIE FENG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: In this work, we investigate an important task named instruction-following text embedding, which generates dynamic text embeddings that adapt to user instructions, highlighting specific attributes of text.

8, TITLE: LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews
AUTHORS: Christian Jaumann ; Andreas Wiedholz ; Annemarie Friedrich
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To date, abstract screening methods using large language models (LLMs) focus on binary classification settings; existing question answering (QA) based ranking approaches suffer from error propagation.

9, TITLE: Unsupervised Evolutionary Cell Type Matching Via Entropy-Minimized Optimal Transport
AUTHORS: Mu Qiao
CATEGORY: q-bio.QM [q-bio.QM, cs.AI, cs.LG]
HIGHLIGHT: Here, we present OT-MESH, an unsupervised computational framework leveraging entropy-regularized optimal transport (OT) to systematically determine cross-species cell type homologies.

10, TITLE: REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards
AUTHORS: ZAFIR STOJANOVSKI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We introduce Reasoning Gym (RG), a library of reasoning environments for reinforcement learning with verifiable rewards.

11, TITLE: Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications
AUTHORS: Srikanth Thudumu ; Jason Fisher ; Hung Du
CATEGORY: quant-ph [quant-ph, cs.AI]
HIGHLIGHT: Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications

12, TITLE: A Survey of Using EHR As Real-world Evidence for Discovering and Validating New Drug Indications
AUTHORS: Nabasmita Talukdar ; Xiaodan Zhang ; Shreya Paithankar ; Hui Wang ; Bin Chen
CATEGORY: stat.AP [stat.AP, cs.AI]
HIGHLIGHT: It discusses study designs and statistical frameworks for evaluating drug efficacy.

13, TITLE: From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning
AUTHORS: Haoyu Li ; Xuhong Li ; Yiming Dong ; Kun Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In the experimental evaluation, we construct fixed-size datasets (e.g., 10,000 samples each) from a corpus of 117,000 open-source SFT samples, incorporating six distinct diversity-control strategies spanning macro-, meso-, and microscopic levels applied to both instructions and responses.

14, TITLE: Scaling Up The Think-aloud Method
AUTHORS: DANIEL WURGAFT et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Here, we develop methods to automate the transcription and annotation of verbal reports of reasoning using natural language processing tools, allowing for large-scale analysis of think-aloud data.

15, TITLE: Multi-Domain ABSA Conversation Dataset Generation Via LLMs for Real-World Evaluation and Model Comparison
AUTHORS: Tejul Pandit ; Meet Raval ; Dhvani Upadhyay
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Aspect-Based Sentiment Analysis (ABSA) offers granular insights into opinions but often suffers from the scarcity of diverse, labeled datasets that reflect real-world conversational nuances. This paper presents an approach for generating synthetic ABSA data using Large Language Models (LLMs) to address this gap.

16, TITLE: Exploring Societal Concerns and Perceptions of AI: A Thematic Analysis Through The Lens of Problem-Seeking
AUTHORS: Naomi Omeonga wa Kayembe
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: This study introduces a novel conceptual framework distinguishing problem-seeking from problem-solving to clarify the unique features of human intelligence in contrast to AI.

17, TITLE: BIRD: Behavior Induction Via Representation-structure Distillation
AUTHORS: Galen Pogoncheff ; Michael Beyeler
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We introduce BIRD (Behavior Induction via Representation-structure Distillation), a flexible framework for transferring aligned behavior by matching the internal representation structure of a student model to that of a teacher.

18, TITLE: PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches
AUTHORS: Dennis Jacob ; Chong Xiang ; Prateek Mittal
CATEGORY: cs.CR [cs.CR, cs.CV, cs.LG]
HIGHLIGHT: In this work, we present PatchDEMUX, a certifiably robust framework for multi-label classifiers against adversarial patches.

19, TITLE: SwingArena: Competitive Programming Arena for Long-context GitHub Issue Solving
AUTHORS: WENDONG XU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present SwingArena, a competitive evaluation framework for Large Language Models (LLMs) that closely mirrors real-world software development workflows.

20, TITLE: RT-X Net: RGB-Thermal Cross Attention Network for Low-Light Image Enhancement
AUTHORS: Raman Jha ; Adithya Lenka ; Mani Ramanagopal ; Aswin Sankaranarayanan ; Kaushik Mitra
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose RT-X Net, a cross-attention network that fuses RGB and thermal images for nighttime image enhancement.

21, TITLE: On Symmetric Losses for Robust Policy Optimization with Noisy Preferences
AUTHORS: Soichiro Nishimori ; Yu-Jie Zhang ; Thanawat Lodkaew ; Masashi Sugiyama
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We propose a principled framework for robust policy optimization under noisy preferences, viewing reward modeling as a classification problem.

22, TITLE: Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting
AUTHORS: WEI CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: However, these pre-trained models are prone to lack reasoning abilities and are difficult to adapt to new environments, further hindering their application to complex real-world tasks. To address these challenges, inspired by the human cognitive process, we propose Causal-aware LLMs, which integrate the structural causal model (SCM) into the decision-making process to model, update, and utilize structured knowledge of the environment in a ``learning-adapting-acting" paradigm.

23, TITLE: SG-Blend: Learning An Interpolation Between Improved Swish and GELU for Robust Neural Representations
AUTHORS: Gaurav Sarkar ; Jay Gala ; Subarna Tripathi
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This work introduces SG-Blend, a novel activation function that blends our proposed SSwish, a first-order symmetric variant of Swish and the established GELU through dynamic interpolation.

24, TITLE: HESEIA: A Community-based Dataset for Evaluating Social Biases in Large Language Models, Co-designed in Real School Settings in Latin America
AUTHORS: GUIDO IVETTA et. al.
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: We introduce HESEIA, a dataset of 46,499 sentences created in a professional development course.

25, TITLE: Vision Language Models Are Biased
AUTHORS: AN VO et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we test how the knowledge about popular subjects hurt the accuracy of vision language models (VLMs) on standard, objective visual tasks of counting and identification.

26, TITLE: Retrieval Augmented Generation Based Large Language Models for Causality Mining
AUTHORS: Thushara Manjari Naduvilakandy ; Hyeju Jang ; Mohammad Al Hasan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present several retrieval-augmented generation (RAG) based dynamic prompting schemes to enhance LLM performance in causality detection and extraction tasks.

27, TITLE: FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation
AUTHORS: JUNYU LUO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To advance the development of MLLMs in the finance domain, we introduce FinMME, encompassing more than 11,000 high-quality financial research samples across 18 financial domains and 6 asset classes, featuring 10 major chart types and 21 subtypes.

28, TITLE: Voice Conversion Improves Cross-Domain Robustness for Spoken Arabic Dialect Identification
AUTHORS: Badr M. Abdullah ; Matthew Baas ; Bernd Mï¿½bius ; Dietrich Klakow
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we present an effective approach based on voice conversion for training ADI models that achieves state-of-the-art performance and significantly improves robustness in cross-domain scenarios.

29, TITLE: Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve
AUTHORS: YUANZHE LIU et. al.
CATEGORY: cs.AI [cs.AI, cs.LG, cs.MA, cs.SE]
HIGHLIGHT: We propose a lesson-based collaboration framework, design the lesson solicitation--banking--selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods.

30, TITLE: A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models
AUTHORS: Sriram Balasubramanian ; Samyadeep Basu ; Soheil Feizi
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.10; I.2.7]
HIGHLIGHT: We present the first comprehensive study of CoT faithfulness in large vision-language models (LVLMs), investigating how both text-based and previously unexplored image-based biases affect reasoning and bias articulation.

31, TITLE: Towards Scalable Schema Mapping Using Large Language Models
AUTHORS: Christopher Buss ; Mahdis Safari ; Arash Termehchy ; Stefan Lee ; David Maier
CATEGORY: cs.DB [cs.DB, cs.AI]
HIGHLIGHT: In this paper, we identify three core issues with using LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to input phrasing and structure, which we propose methods to address through sampling and aggregation techniques; (2) the need for more expressive mappings (e.g., GLaV), which strain the limited context windows of LLMs; and (3) the computational cost of repeated LLM calls, which we propose to mitigate through strategies like data type prefiltering.

32, TITLE: CoRet: Improved Retriever for Code Editing
AUTHORS: Fabio Fehr ; Prabhu Teja Sivaprasad ; Luca Franceschi ; Giovanni Zappella
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we introduce CoRet, a dense retrieval model designed for code-editing tasks that integrates code semantics, repository structure, and call graph dependencies.

33, TITLE: Reinforcing Video Reasoning with Focused Thinking
AUTHORS: JISHENG DANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose TW-GRPO, a novel framework that enhances visual reasoning with focused thinking and dense reward granularity.

34, TITLE: Position: The Future of Bayesian Prediction Is Prior-Fitted
AUTHORS: Samuel Mï¿½ller ; Arik Reuter ; Noah Hollmann ; David Rï¿½gamer ; Frank Hutter
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We thus believe they are a fruitful area of research. In this position paper, we explore their potential and directions to address their current limitations.

35, TITLE: TSENOR: Highly-Efficient Algorithm for Finding Transposable N:M Sparse Masks
AUTHORS: Xiang Meng ; Mehdi Makni ; Rahul Mazumder
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We introduce an efficient solver for transposable N:M masks that scales to billion-parameter models.

36, TITLE: InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback
AUTHORS: BOYUAN CHEN et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we present an initial exploration through the InterMT -- the first preference dataset for multi-turn multimodal interaction, grounded in real human feedback.

37, TITLE: Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach
AUTHORS: Melika Sepidband ; Hamed Taherkhani ; Song Wang ; Hadi Hemmati
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: In this paper, as the most straightforward characteristic of code, we investigate the relationship between code complexity and the success of LLM generated code.

38, TITLE: HELM: Hyperbolic Large Language Models Via Mixture-of-Curvature Experts
AUTHORS: NEIL HE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: These findings suggest that shifting to non-Euclidean geometries can better align language models with the underlying geometry of text. We thus propose to operate fully in Hyperbolic space, known for its expansive, scale-free, and low-distortion properties.

39, TITLE: Leveraging Auxiliary Information in Text-to-Video Retrieval: A Review
AUTHORS: Adriano Fragomeni ; Dima Damen ; Michael Wray
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Auxiliary information can include visual attributes, such as objects; temporal and spatial context; and textual descriptions, such as speech and rephrased captions. This survey comprehensively reviews 81 research papers on Text-to-Video retrieval that utilise such auxiliary information.

40, TITLE: Reflect, Retry, Reward: Self-Improving LLMs Via Reinforcement Learning
AUTHORS: SHELLY BENSAL et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We explore a method for improving the performance of large language models through self-reflection and reinforcement learning.

41, TITLE: Guiding Generative Storytelling with Knowledge Graphs
AUTHORS: ZHIJUN PAN et. al.
CATEGORY: cs.CL [cs.CL, cs.HC]
HIGHLIGHT: This paper investigates how knowledge graphs (KGs) can enhance LLM-based storytelling by improving narrative quality and enabling user-driven modifications. We propose a KG-assisted storytelling pipeline and evaluate its effectiveness through a user study with 15 participants.

42, TITLE: AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning
AUTHORS: WEI FU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We present AReaL, a \emph{fully asynchronous} RL system that completely decouples generation from training.

43, TITLE: Interactive Video Generation Via Domain Adaptation
AUTHORS: Ishaan Rawal ; Suryansh Kumar
CATEGORY: cs.CV [cs.CV, cs.AI, cs.MM]
HIGHLIGHT: Recent training-free approaches introduce attention masking to guide trajectory, but this often degrades perceptual quality. We identify two key failure modes in these methods, both of which we interpret as domain shift problems, and propose solutions inspired by domain adaptation.

44, TITLE: RealDrive: Retrieval-Augmented Driving with Diffusion Models
AUTHORS: WENHAO DING et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Nonetheless, data-driven approaches often struggle with rare, safety-critical scenarios and offer limited controllability over the generated trajectories. To address these challenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG) framework that initializes a diffusion-based planning policy by retrieving the most relevant expert demonstrations from the training dataset.

45, TITLE: A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming
AUTHORS: Yizhong Ding
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Existing malicious-code generation methods, which primarily rely on prompt engineering, often suffer from limited diversity and high redundancy in the payloads they produce. To address these limitations, we propose \textbf{RAWG}, a \textbf{R}eward-driven \textbf{A}utomated \textbf{W}ebshell Malicious-code \textbf{G}enerator designed for red-teaming applications.

46, TITLE: Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games
AUTHORS: Neemesh Yadav ; Palakorn Achananuparp ; Jing Jiang ; Ee-Peng Lim
CATEGORY: cs.CL [cs.CL, cs.AI, cs.HC]
HIGHLIGHT: In this study, we investigate the role of ToM reasoning in aligning agentic behaviors with human norms in negotiation tasks, using the ultimatum game as a controlled environment.

47, TITLE: Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames
AUTHORS: Sahithya Ravi ; Gabriel Sarch ; Vibhav Vineet ; Andrew D. Wilson ; Balasaravanan Thoravi Kumaravel
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: An embodied AI assistant operating on egocentric video must integrate spatial cues across time - for instance, determining where an object A, glimpsed a few moments ago lies relative to an object B encountered later. We introduce Disjoint-3DQA , a generative QA benchmark that evaluates this ability of VLMs by posing questions about object pairs that are not co-visible in the same frame.

48, TITLE: FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation
AUTHORS: Vishal Pallagani ; Nitin Gupta ; John Aydin ; Biplav Srivastava
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We introduce FABLE, an extensible benchmark designed to assess LLMs' understanding of data flow using structured, procedural text.

49, TITLE: Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy
AUTHORS: NIKITA BALAGANSKY et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We introduce a novel training objective, \emph{HierarchicalTopK}, which trains a single SAE to optimise reconstructions across multiple sparsity levels simultaneously.

50, TITLE: Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models
AUTHORS: MINGYI HE et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: The advent of generative artificial intelligence (GenAI) offers transformative potential by improving the efficiency of design generation and facilitating the communication of design ideas.

51, TITLE: VietMix: A Naturally Occurring Vietnamese-English Code-Mixed Corpus with Iterative Augmentation for Machine Translation
AUTHORS: HIEU TRAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Machine translation systems fail when processing code-mixed inputs for low-resource languages. We address this challenge by curating VietMix, a parallel corpus of naturally occurring code-mixed Vietnamese text paired with expert English translations.

52, TITLE: SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds
AUTHORS: CHENG ZENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To compensate for the limitations of deep learning features when the training set size is limited, we incorporate multidimensional handcrafted features into the model.

53, TITLE: Evaluating Gemini in An Arena for Learning
AUTHORS: LEARNLM TEAM et. al.
CATEGORY: cs.CY [cs.CY, cs.AI, cs.LG]
HIGHLIGHT: Artificial intelligence (AI) is poised to transform education, but the research community lacks a robust, general benchmark to evaluate AI models for learning.

54, TITLE: Period-LLM: Extending The Periodic Capability of Multimodal Large Language Model
AUTHORS: YUTING ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces Period-LLM, a multimodal large language model designed to enhance the performance of periodic tasks across various modalities, and constructs a benchmark of various difficulty for evaluating the cross-modal periodic capabilities of large models.

55, TITLE: Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation
AUTHORS: Sania Nayab ; Marco Simoni ; Giulio Rossolini
CATEGORY: cs.AI [cs.AI, cs.CL, cs.SI]
HIGHLIGHT: In this paper, we propose a novel approach that leverages knowledge graphs (KGs) as structured semantic resources to systematically generate fake triplets.

56, TITLE: Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations
AUTHORS: Xin Quan ; Marco Valentino ; Louise A. Dennis ; Andrï¿½ Freitas
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To mitigate issues related to faithfulness and robustness, this paper investigates strategies to (1) alleviate semantic loss during autoformalisation, (2) efficiently identify and correct syntactic errors in logical representations, (3) explicitly use logical expressions to guide LLMs in generating structured proof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback for iterative refinement.

57, TITLE: Simulating Training Data Leakage in Multiple-Choice Benchmarks for LLM Evaluation
AUTHORS: Naila Shafirni Hidayat ; Muhammad Dehan Al Kautsar ; Alfan Farizki Wicaksono ; Fajri Koto
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Leveraging the best-performing method, we create cleaned versions of MMLU and HellaSwag, and re-evaluate several LLMs.

58, TITLE: Cora: Correspondence-aware Image Editing Using Few Step Diffusion
AUTHORS: AMIRHOSSEIN ALMOHAMMADI et. al.
CATEGORY: cs.CV [cs.CV, I.4.10; I.3.7; I.2.10]
HIGHLIGHT: Existing few step editing approaches produce artifacts such as irrelevant texture or struggle to preserve key attributes of the source image (e.g., pose). We introduce Cora, a novel editing framework that addresses these limitations by introducing correspondence-aware noise correction and interpolated attention maps.

59, TITLE: Optimizing The Interface Between Knowledge Graphs and LLMs for Complex Reasoning
AUTHORS: Vasilije Markovic ; Lazar Obradovic ; Laszlo Hajdu ; Jovan Pavlovic
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: While such systems are increasingly common in retrieval-augmented generation, the role of systematic hyperparameter optimization remains underexplored. In this paper, we study this problem in the context of Cognee, a modular framework for end-to-end KG construction and retrieval.

60, TITLE: One Task Vector Is Not Enough: A Large-Scale Study for In-Context Learning
AUTHORS: Pavel Tikhonov ; Ivan Oseledets ; Elena Tutubalina
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce QuiteAFew, a novel dataset of 3,096 diverse few-shot tasks, each with 30 input-output pairs derived from the Alpaca dataset.

61, TITLE: Towards Effective Code-Integrated Reasoning
AUTHORS: FEI BAI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we investigate code-integrated reasoning, where models generate code when necessary and integrate feedback by executing it through a code interpreter.

62, TITLE: INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization
AUTHORS: Aleksandr Algazinov ; Joydeep Chandra ; Matt Laing
CATEGORY: cs.NI [cs.NI, cs.AI]
HIGHLIGHT: This paper provides a comprehensive analysis of optimizing in-network computation for AI, exploring the evolution of programmable network architectures, such as Software-Defined Networking (SDN) and Programmable Data Planes (PDPs), and their convergence with AI.

63, TITLE: ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation
AUTHORS: JING HUANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While many recent works aim to improve this framework by designing more powerful encoders and decoders, employing advanced convolutional neural networks (CNNs) for local feature extraction, Transformers or state space models (SSMs) such as Mamba for global context modeling, or hybrid combinations of both, these methods often struggle to fully utilize pretrained vision backbones (e.g., ResNet, ViT, VMamba) due to structural mismatches. To bridge this gap, we introduce ACM-UNet, a general-purpose segmentation framework that retains a simple UNet-like design while effectively incorporating pretrained CNNs and Mamba models through a lightweight adapter mechanism.

64, TITLE: Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation
AUTHORS: Caiqi Zhang ; Xiaochen Zhu ; Chengzu Li ; Nigel Collier ; Andreas Vlachos
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose LoVeC (Long-form Verbalized Confidence), an on-the-fly verbalized confidence estimation method for long-form generation.

65, TITLE: Probing Association Biases in LLM Moderation Over-Sensitivity
AUTHORS: Yuxin Wang ; Botao Yu ; Ivory Yang ; Saeed Hassanpour ; Soroush Vosoughi
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Inspired by cognitive psychology's implicit association tests, we introduce Topic Association Analysis, a semantic-level approach to quantify how LLMs associate certain topics with toxicity.

66, TITLE: How Much Backtracking Is Enough? Exploring The Interplay of SFT and RL in Enhancing LLM Reasoning
AUTHORS: Hongyi James Cai ; Junlin Wang ; Xiaoyin Chen ; Bhuwan Dhingra
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we systematically investigate the dynamics between SFT and RL on eight reasoning tasks: Countdown, Sudoku, Arc 1D, Geometry, Color Cube Rotation, List Functions, Zebra Puzzles, and Self Reference.

67, TITLE: Representational Difference Explanations
AUTHORS: Neehar Kondapaneni ; Oisin Mac Aodha ; Pietro Perona
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, q-bio.NC]
HIGHLIGHT: We propose a method for discovering and visualizing the differences between two learned representations, enabling more direct and interpretable model comparisons.

68, TITLE: DGIQA: Depth-guided Feature Attention and Refinement for Generalizable Image Quality Assessment
AUTHORS: Vaishnav Ramesh ; Junliang Liu ; Haining Wang ; Md Jahidul Islam
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A long-held challenge in no-reference image quality assessment (NR-IQA) learning from human subjective perception is the lack of objective generalization to unseen natural distortions. To address this, we integrate a novel Depth-Guided cross-attention and refinement (Depth-CAR) mechanism, which distills scene depth and spatial features into a structure-aware representation for improved NR-IQA.

69, TITLE: Estimating Head Motion in Structural MRI Using A Deep Neural Network Trained on Synthetic Artifacts
AUTHORS: Charles Bricout ; Samira Ebrahimi Kahou ; Sylvain Bouix
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Here, we train a 3D convolutional neural network to estimate motion severity using only synthetically corrupted volumes.

70, TITLE: Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection
AUTHORS: FALIH GOZI FEBRINANTO et. al.
CATEGORY: cs.SD [cs.SD, cs.AI, cs.CR, cs.LG, eess.AS]
HIGHLIGHT: However, existing rehearsal techniques don't effectively capture the diversity of audio characteristics, introducing bias and increasing the risk of forgetting. To address this challenge, we propose Rehearsal with Auxiliary-Informed Sampling (RAIS), a rehearsal-based CL approach for audio deepfake detection.

71, TITLE: Multi-output Classification Using A Cross-talk Architecture for Compound Fault Diagnosis of Motors in Partially Labeled Condition
AUTHORS: Wonjun Yi ; Wonho Jung ; Kangmin Jang ; Yong-Hwa Park
CATEGORY: eess.SP [eess.SP, cs.AI]
HIGHLIGHT: Furthermore, we explore various single-task and multi-task architectures applicable to the MOC formulation-including shared trunk and cross-talk-based designs-for compound fault diagnosis under PL conditions. Based on this investigation, we propose a novel cross-talk layer structure that enables selective information sharing across diagnostic tasks, effectively enhancing classification performance in compound fault scenarios.

72, TITLE: Redefining Research Crowdsourcing: Incorporating Human Feedback with LLM-Powered Digital Twins
AUTHORS: AMANDA CHAN et. al.
CATEGORY: cs.HC [cs.HC, cs.CL, cs.CY]
HIGHLIGHT: Researchers face compromised data validity as AI responses replace authentic human behavior, while workers risk diminished roles as AI automates tasks. To address this, we propose a hybrid framework using digital twins, personalized AI models that emulate workers' behaviors and preferences while keeping humans in the loop.

73, TITLE: Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting
AUTHORS: CHENGAO SHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, as we identified in this work, applying LVMs to LTSF poses an inductive bias towards "forecasting periods". To harness this bias, we propose DMMV, a novel decomposition-based multi-modal view framework that leverages trend-seasonal decomposition and a novel backcast residual based adaptive decomposition to integrate MMVs for LTSF.

74, TITLE: Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification
AUTHORS: Maciej Wielgosz ; Simon Berg ; Heikki Korpunen ; Stephan Hoffmann
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents a deep learning-based framework for classifying forestry operations from dashcam video footage.

75, TITLE: Mastering Massive Multi-Task Reinforcement Learning Via Mixture-of-Expert Decision Transformer
AUTHORS: YILUN KONG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we first revisit the key impact of task numbers on current MTRL method, and further reveal that naively expanding the parameters proves insufficient to counteract the performance degradation as the number of tasks escalates. Building upon these insights, we propose M3DT, a novel mixture-of-experts (MoE) framework that tackles task scalability by further unlocking the model's parameter scalability.

76, TITLE: LLM Inference Enhanced By External Knowledge: A Survey
AUTHORS: YU-HSUAN LIN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study offers a systematic exploration of strategies for using external knowledge to enhance LLMs, beginning with a taxonomy that categorizes external knowledge into unstructured and structured data.

77, TITLE: Deformable Attention Mechanisms Applied to Object Detection, Case of Remote Sensing
AUTHORS: Anasse Boutayeb ; Iyad Lahsen-cherif ; Ahmed El Khadimi
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Thus, the present work proposes an application of Deformable-DETR model, a specific architecture using deformable attention mechanisms, on remote sensing images in two different modes, especially optical and Synthetic Aperture Radar (SAR).

78, TITLE: Breaking The Gold Standard: Extracting Forgotten Data Under Exact Unlearning in Large Language Models
AUTHORS: Xiaoyu Wu ; Yifei Pang ; Terrance Liu ; Zhiwei Steven Wu
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.CR]
HIGHLIGHT: Of these, exact unlearning -- which retrains the model from scratch without the target data -- is widely regarded the gold standard, believed to be robust against privacy-related attacks. In this paper, we challenge this assumption by introducing a novel data extraction attack that compromises even exact unlearning.

79, TITLE: Preemptive Hallucination Reduction: An Input-Level Approach for Multimodal Language Model
AUTHORS: Nokimul Hasan Arif ; Shadman Rabby ; Md Hefzul Hossain Papon ; Sabbir Ahmed
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This study presents a novel ensemble-based preprocessing framework that adaptively selects the most appropriate filtering approach -- noise reduced (NR), edge enhanced (EE), or unaltered input (org) based on the type of question posed, resulting into reduced hallucination without requiring any modifications to the underlying model architecture or training pipeline.

80, TITLE: SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification
AUTHORS: Zheng Wang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: These factors collectively make it difficult for traditional methods to stably extract discriminative features, thereby limiting the generalizability and interpretability of models in real-world applications. To address these challenges, this paper proposes a fine-grained bird classification framework based on strip-aware spatial perception, which aims to capture long-range spatial dependencies across entire rows or columns in bird images, thereby enhancing the model's robustness and interpretability.

81, TITLE: Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws
AUTHORS: HIDETAKA KAMIGAITO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Experiments on multiple semantic-understanding tasks with various LLMs empirically confirm the theoretical properties derived in this study.

82, TITLE: MELT: Towards Automated Multimodal Emotion Data Annotation By Leveraging LLM Embedded Knowledge
AUTHORS: Xin Jing ; Jiadong Wang ; Iosif Tsangko ; Andreas Triantafyllopoulos ; Bjï¿½rn W. Schuller
CATEGORY: cs.AI [cs.AI, cs.SD, eess.AS]
HIGHLIGHT: By crafting structured text prompts, our methodology capitalizes on the knowledge GPT-4o has accumulated during its training, showcasing that it can generate accurate and contextually relevant annotations without direct access to multimodal inputs. Therefore, we propose MELT, a multimodal emotion dataset fully annotated by GPT-4o.

83, TITLE: Object Centric Concept Bottlenecks
AUTHORS: David Steinmann ; Wolfgang Stammer ; Antonia Wï¿½st ; Kristian Kersting
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, their reliance on holistic image encodings limits their expressiveness in object-centric real-world settings and thus hinders their ability to solve complex vision tasks beyond single-label classification. To tackle these challenges, we introduce Object-Centric Concept Bottlenecks (OCB), a framework that combines the strengths of CBMs and pre-trained object-centric foundation models, boosting performance and interpretability.

84, TITLE: PCIE_Pose Solution for EgoExo4D Pose and Proficiency Estimation Challenge
AUTHORS: FENG CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This report introduces our team's (PCIE_EgoPose) solutions for the EgoExo4D Pose and Proficiency Estimation Challenges at CVPR2025.

85, TITLE: Leadership Assessment in Pediatric Intensive Care Unit Team Training
AUTHORS: LIANGYANG OUYANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To automate data processing, we propose a method leveraging REMoDNaV, SAM, YOLO, and ChatGPT for fixation object detection, eye contact detection, and conversation classification.

86, TITLE: ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation
AUTHORS: HAO CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, existing RAG systems frequently underutilize the retrieved documents, failing to extract and integrate the key clues needed to support faithful and interpretable reasoning, especially in cases where relevant evidence is implicit, scattered, or obscured by noise. To address this issue, we propose ClueAnchor, a novel framework for enhancing RAG via clue-anchored reasoning exploration and optimization.

87, TITLE: Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation
AUTHORS: Andreas Spilz ; Heiko Oppel ; Michael Munz
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we present a novel data augmentation method that generates realistic IMU data using musculoskeletal simulations integrated with systematic modifications of movement trajectories.

88, TITLE: EasyText: Controllable Diffusion Transformer for Multilingual Text Rendering
AUTHORS: Runnan Lu ; Yuxuan Zhang ; Jailing Liu ; Haifa Wang ; Yiren Song
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces EasyText, a text rendering framework based on DiT (Diffusion Transformer), which connects denoising latents with multilingual character tokens encoded as character tokens.

89, TITLE: Binary Cumulative Encoding Meets Time Series Forecasting
AUTHORS: Andrei Chernov ; Vitaliy Pozdnyakov ; Ilya Makarov
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors.

90, TITLE: Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction
AUTHORS: Shuai Liu ; Ning Cao ; Yile Chen ; Yue Jiang ; Gao Cong
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, existing approaches face two core limitations: (1) they fall short in capturing the complex, multi-functional semantics of real-world locations; and (2) they lack the capacity to model heterogeneous behavioral dynamics across diverse user groups. To tackle these challenges, we introduce NextLocMoE, a novel framework built upon large language models (LLMs) and structured around a dual-level Mixture-of-Experts (MoE) design.

91, TITLE: Three Kinds of Negation in Knowledge and Their Mathematical Foundations
AUTHORS: Zhenghua Pan ; Yong Wang
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we examine and analyze the understanding and characteristics of negation in various fields such as philosophy, logic, and linguistics etc.

92, TITLE: PyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation
AUTHORS: ABDUL-MOJEED OLABISI ILYAS et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Traditional augmentation uses a single pipeline for all transformations, disregarding the unique traits of each augmentation and struggling with large data volumes. To address these challenges, we propose a Multi-encoder Augmentation-Aware Learning (MEAL) framework that leverages four distinct augmentation variants processed through dedicated encoders.

93, TITLE: Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning
AUTHORS: Amit Peleg ; Naman Deep Singh ; Matthias Hein
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we introduce CLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a novel training technique combining multiple images and their associated captions.

94, TITLE: MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs
AUTHORS: ZHIWEI LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce MMAFFBen, the first extensive open-source benchmark for multilingual multimodal affective analysis.

95, TITLE: Pangu DeepDiver: Adaptive Search Intensity Scaling Via Open-Web Reinforcement Learning
AUTHORS: WENXUAN SHI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: WebPuzzle consists of 24K training instances and 275 test questions spanning both wiki-based and open-web queries. Building on this dataset, we propose DeepDiver, a Reinforcement Learning (RL) framework that promotes SIS by encouraging adaptive search policies through exploration under a real-world open-web environment.

96, TITLE: Context-Aware Sentiment Forecasting Via LLM-based Multi-Perspective Role-Playing Agents
AUTHORS: FANHANG MAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we address the problem of \textbf{sentiment forecasting} on social media to predict the user's future sentiment in response to the development of the event.

97, TITLE: P: A Universal Measure of Predictive Intelligence
AUTHORS: David Gamez
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper sets out a new universal measure of intelligence that is based on the hypothesis that prediction is the most important component of intelligence.

98, TITLE: KairosAD: A SAM-Based Model for Industrial Anomaly Detection on Embedded Devices
AUTHORS: Uzair Khan ; Franco Fummi ; Luigi Capogrosso
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, while many existing models show promising performance, they are often too large, computationally demanding, and impractical to deploy on resource-constrained embedded devices that can be easily installed on the production lines of Small and Medium Enterprises (SMEs). To bridge this gap, we present KairosAD, a novel supervised approach that uses the power of the Mobile Segment Anything Model (MobileSAM) for image-based anomaly detection.

99, TITLE: Model Unlearning Via Sparse Autoencoder Subspace Guided Projections
AUTHORS: Xu Wang ; Zihao Li ; Benyou Wang ; Yan Hu ; Difan Zou
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose SAE-Guided Subspace Projection Unlearning (SSPU), a novel framework that leverages SAE features to drive targeted updates in the model's parameter space, enabling precise, interpretable, and robust unlearning.

100, TITLE: When Humans Growl and Birds Speak: High-Fidelity Voice Conversion from Human to Animal and Designed Sounds
AUTHORS: Minsu Kang ; Seolhee Lee ; Choonghyeon Lee ; Namhyun Cho
CATEGORY: eess.AS [eess.AS, cs.AI, cs.LG, cs.SD, eess.SP]
HIGHLIGHT: To accomodate generation of diverse non-speech sounds and 44.1kHz high-quality audio transformation, we introduce a preprocessing pipeline and an improved CVAE-based H2NH-VC model, both optimized for human and non-human voices.

101, TITLE: The State of Multilingual LLM Safety Research: From Measuring The Language Gap to Mitigating It
AUTHORS: Zheng-Xin Yong ; Beyza Ermis ; Marzieh Fadaee ; Stephen H. Bach ; Julia Kreutzer
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents a comprehensive analysis of the linguistic diversity of LLM safety research, highlighting the English-centric nature of the field.

102, TITLE: Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts
AUTHORS: Christopher Bagdon ; Aidan Combs ; Carina Silberer ; Roman Klinger
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, it is unclear if and how study-created content may differ from genuine content, and how differences may impact models. We collect study-created and genuine multimodal social media posts labeled for emotion and compare them on several dimensions, including model performance.

103, TITLE: Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on The Canary Current Upwelling System
AUTHORS: Giovanny C-Londoï¿½o ; Javier Sï¿½nchez ; ï¿½ngel Rodrï¿½guez-Santana
CATEGORY: physics.ao-ph [physics.ao-ph, cs.AI, cs.LG]
HIGHLIGHT: This work aims to adapt a graph neural network initially developed for global weather forecasting to improve subregional ocean prediction, specifically focusing on the Canary Current upwelling system.

104, TITLE: CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs
AUTHORS: AI JIAN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Current multimodal benchmarks predominantly evaluate generic image comprehension or text-driven reasoning, lacking authentic scientific contexts that require domain-specific knowledge integration with visual evidence analysis. To fill this gap, we present CSVQA, a diagnostic multimodal benchmark specifically designed for evaluating scientific reasoning through domain-grounded visual question answering.Our benchmark features 1,378 carefully constructed question-answer pairs spanning diverse STEM disciplines, each demanding domain knowledge, integration of visual evidence, and higher-order reasoning.

105, TITLE: Bridging 3D Anomaly Localization and Repair Via High-Quality Continuous Geometric Representation
AUTHORS: BOZHONG ZHENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce Pose-Aware Signed Distance Field (PASDF), a novel framework that integrates 3D anomaly detection and repair by learning a continuous, pose-invariant shape representation.

106, TITLE: Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings
AUTHORS: SHUJIAN YANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: In this paper, we highlight the multimodal nature of Chinese language as a key challenge for deploying LLMs in toxic Chinese detection.

107, TITLE: Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields
AUTHORS: Md Shahriar Rahim Siddiqui ; Moshe Eliasof ; Eldad Haber
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: However, this pointwise approach may overlook correlations between points along the generation trajectory that could enhance velocity predictions, thereby improving downstream generation quality. To address this, we propose Graph Flow Matching (GFM), a lightweight enhancement that decomposes the learned velocity into a reaction term -- any standard flow matching network -- and a diffusion term that aggregates neighbor information via a graph neural module.

108, TITLE: DEEPQUESTION: Systematic Generation of Real-World Challenges for Evaluating LLMs Performance
AUTHORS: ALI KHORAMFAR et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce DeepQuestion, a scalable automated framework that augments existing datasets based on Bloom's taxonomy and creates novel questions that trace original solution paths to probe evaluative and creative skills.

109, TITLE: RMoA: Optimizing Mixture-of-Agents Through Diversity Maximization and Residual Compensation
AUTHORS: ZHENTAO XIE et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Inspired by ResNet's residual learning, we propose Residual Mixture-of-Agents (RMoA), integrating residual connections to optimize efficiency and reliability.

110, TITLE: SORCE: Small Object Retrieval in Complex Environments
AUTHORS: CHUNXU LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Thus, we introduce SORCE (Small Object Retrieval in Complex Environments), a new subfield of T2IR, focusing on retrieving small objects in complex images with textual queries.

111, TITLE: Directional Non-Commutative Monoidal Structures with Interchange Law Via Commutative Generators
AUTHORS: Mahesh Godavarti
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SC, 20-XX, 08A02, F.4.1; I.2]
HIGHLIGHT: We introduce a novel framework consisting of a class of algebraic structures that generalize one-dimensional monoidal systems into higher dimensions by defining per-axis composition operators subject to non-commutativity and a global interchange law.

112, TITLE: Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers
AUTHORS: Heejo Kong ; Sung-Jin Kim ; Gunho Jung ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: The outliers are treated as noise, considerably degrading the performance of SSL models. To address this drawback, we propose a novel framework, Diversify and Conquer (DAC), to enhance SSL robustness in the context of open-set semi-supervised learning.

113, TITLE: CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control
AUTHORS: Chaohui Xu ; Qi Cui ; Chip-Hong Chang
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Unfortunately, neither watermarking nor passport-based methods provide a holistic protection with robust ownership proof, high fidelity, active usage authorization and user traceability for offline access distributed models and multi-user Machine-Learning as a Service (MLaaS) cloud model. In this paper, we propose a Chameleon Hash-based Irreversible Passport (CHIP) protection framework that utilizes the cryptographic chameleon hash function to achieve all these goals.

114, TITLE: Beyond Linear Steering: Unified Multi-Attribute Control for Language Models
AUTHORS: Narmeen Oozeer ; Luke Marks ; Fazl Barez ; Amirali Abdullah
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We introduce K-Steering, a unified and flexible approach that trains a single non-linear multi-label classifier on hidden activations and computes intervention directions via gradients at inference time.

115, TITLE: Learning Safety Constraints for Large Language Models
AUTHORS: Xin Chen ; Yarden As ; Andreas Krause
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Large language models (LLMs) have emerged as powerful tools but pose significant safety risks through harmful outputs and vulnerability to adversarial attacks.

116, TITLE: Don't Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections
AUTHORS: Orfeas Menis Mastromichalakis ; Jason Liartis ; Kristina Rose ; Antoine Isaac ; Giorgos Stamou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: CH Institutions (CHIs) face significant challenges in curating these data due to the vast scale and complexity of the task. To address this, we develop an AI-powered tool that detects offensive terms in CH metadata and provides contextual insights into their historical background and contemporary perception.

117, TITLE: Exploring The Impact of Occupational Personas on Domain-Specific QA
AUTHORS: Eojin Kang ; Jaehyuk Yu ; Juae Kim
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study analyzes whether personas enhance specialized QA performance by introducing two types of persona: Profession-Based Personas (PBPs) (e.g., scientist), which directly relate to domain expertise, and Occupational Personality-Based Personas (OPBPs) (e.g., scientific person), which reflect cognitive tendencies rather than explicit expertise.

118, TITLE: Localizing Persona Representations in LLMs
AUTHORS: Celia Cintas ; Miriam Rateike ; Erik Miehling ; Elizabeth Daly ; Skyler Speakman
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present a study on how and where personas -- defined by distinct sets of human characteristics, values, and beliefs -- are encoded in the representation space of large language models (LLMs).

119, TITLE: When Large Multimodal Models Confront Evolving Knowledge:Challenges and Pathways
AUTHORS: KAILIN JIANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Previous work focused on constructing textual knowledge datasets and exploring knowledge injection in LLMs, lacking exploration of multimodal evolving knowledge injection in LMMs. To address this, we propose the EVOKE benchmark to evaluate LMMs' ability to inject multimodal evolving knowledge in real-world scenarios.

120, TITLE: Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts
AUTHORS: Xin He ; Xumeng Han ; Longhui Wei ; Lingxi Xie ; Qi Tian
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we introduce Mixpert, an efficient mixture-of-vision-experts architecture that inherits the joint learning advantages from a single vision encoder while being restructured into a multi-expert paradigm for task-specific fine-tuning across different visual tasks.

121, TITLE: Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning
AUTHORS: SHUYAO XU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, I.2.6; I.2.7]
HIGHLIGHT: To this end, We propose Reinforcement Distillation (REDI), a two-stage framework.

122, TITLE: DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation
AUTHORS: ZHAO MANDI et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: We focus on long-horizon, bimanual tasks with articulated objects, which is challenging due to large action space, spatiotemporal discontinuities, and embodiment gap between human and robot hands. We propose DexMachina, a novel curriculum-based algorithm: the key idea is to use virtual object controllers with decaying strength: an object is first driven automatically towards its target states, such that the policy can gradually learn to take over under motion and contact guidance.

123, TITLE: Cross-Attention Speculative Decoding
AUTHORS: WEI ZHONG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present Budget EAGLE (Beagle), the first, to our knowledge, cross-attention-based Transformer decoder SD model that achieves performance on par with leading self-attention SD models (EAGLE-v2) while eliminating the need for pooling or auxiliary components, simplifying the architecture, improving training efficiency, and maintaining stable memory usage during training-time simulation. To enable effective training of this novel architecture, we propose Two-Stage Block-Attention Training, a new method that achieves training stability and convergence efficiency in block-level attention scenarios.

124, TITLE: Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization
AUTHORS: Joschka Braun ; Carsten Eickhoff ; Seyed Ali Bahrainian
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We find that steering effectively controls the targeted summary properties, but high steering strengths consistently degrade both intrinsic and extrinsic text quality.

125, TITLE: A*-Thought: Efficient Reasoning Via Bidirectional Compression for Low-Resource Settings
AUTHORS: XIAOANG XU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Most of the existing methods are stuck in the assumption of overthinking and attempt to reason efficiently by compressing the Chain-of-Thought, but this often leads to performance degradation. To address this problem, we introduce A*-Thought, an efficient tree search-based unified framework designed to identify and isolate the most essential thoughts from the extensive reasoning chains produced by these models.

126, TITLE: MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs
AUTHORS: GABRIELLE KAILI-MAY LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Our results demonstrate that LLMs largely fail at this task, and that existing interventions are insufficient: standard prompt approaches provide only marginal gains, and existing, factuality-based calibration techniques can even harm faithful calibration. To address this critical gap, we introduce MetaFaith, a novel prompt-based calibration approach inspired by human metacognition.

127, TITLE: ViStoryBench: Comprehensive Benchmark Suite for Story Visualization
AUTHORS: CAILIN ZHUANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To further enhance the performance of story visualization frameworks in real-world scenarios, we introduce a comprehensive evaluation benchmark, ViStoryBench.

128, TITLE: Bench4KE: Benchmarking Automated Competency Question Generation
AUTHORS: Anna Sofia Lippolis ; Minh Davide Ragagni ; Paolo Ciancarini ; Andrea Giovanni Nuzzolese ; Valentina Presutti
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This undermines the methodological rigour and hinders the replication and comparison of results. To address this gap, we introduce Bench4KE, an extensible API-based benchmarking system for KE automation.

129, TITLE: CREFT: Sequential Multi-Agent LLM for Character Relation Extraction
AUTHORS: Ye Eun Chun ; Taeyoon Hwang ; Seung-won Hwang ; Byung-Hak Kim
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Understanding complex character relations is crucial for narrative analysis and efficient script evaluation, yet existing extraction methods often fail to handle long-form narratives with nuanced interactions. To address this challenge, we present CREFT, a novel sequential framework leveraging specialized Large Language Model (LLM) agents.

130, TITLE: ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models
AUTHORS: MINGJIE LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we challenge prevailing assumptions by demonstrating that prolonged RL (ProRL) training can uncover novel reasoning strategies that are inaccessible to base models, even under extensive sampling.

131, TITLE: AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time
AUTHORS: JUNYU ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents AlphaOne ($\alpha$1), a universal framework for modulating reasoning progress in large reasoning models (LRMs) at test time.

132, TITLE: Optimal Weighted Convolution for Classification and Denosing
AUTHORS: Simone Cammarasana ; Giuseppe Patanï¿½
CATEGORY: cs.CV [cs.CV, 68T05]
HIGHLIGHT: We introduce a novel weighted convolution operator that enhances traditional convolutional neural networks (CNNs) by integrating a spatial density function into the convolution operator.

133, TITLE: TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection
AUTHORS: XINQI XIONG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our benchmark aims to accelerate research towards more robust and generalizable detection models in the face of rapidly evolving generative techniques.

134, TITLE: Improving Language and Modality Transfer in Translation By Character-level Modeling
AUTHORS: Ioannis Tsiamas ; David Dale ; Marta R. Costa-jussï¿½
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we propose a character-based approach to improve adaptability to new languages and modalities.

135, TITLE: Time Blindness: Why Video-Language Models Can't See What Humans Can?
AUTHORS: Ujjwal Upadhyay ; Mukul Ranjan ; Zhiqiang Shen ; Mohamed Elhoseiny
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We introduce $\textbf{SpookyBench}$, a benchmark where information is encoded solely in temporal sequences of noise-like frames, mirroring natural phenomena from biological signaling to covert communication.

136, TITLE: SiLVR: A Simple Language-based Video Reasoning Framework
AUTHORS: Ce Zhang ; Yan-Bo Lin ; Ziyang Wang ; Mohit Bansal ; Gedas Bertasius
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the reasoning capabilities of multimodal LLMs (MLLMs) still significantly lag, especially for complex video-language tasks. To address this issue, we present SiLVR, a Simple Language-based Video Reasoning framework that decomposes complex video understanding into two stages.

137, TITLE: MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning
AUTHORS: YIQING LIANG et. al.
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: We introduce a systematic post-training framework for Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation and benchmark implementation.

138, TITLE: GenSpace: Benchmarking Spatially-Aware Image Generation
AUTHORS: ZEHAN WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Furthermore, standard evaluations using general Vision-Language Models (VLMs) frequently fail to capture the detailed spatial errors. To handle this challenge, we propose a specialized evaluation pipeline and metric, which reconstructs 3D scene geometry using multiple visual foundation models and provides a more accurate and human-aligned metric of spatial faithfulness.

139, TITLE: MiniMax-Remover: Taming Bad Noise Helps Video Object Removal
AUTHORS: BOJIA ZI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Furthermore, existing methods often rely on computationally expensive sampling procedures and classifier-free guidance (CFG), resulting in slow inference. To address these limitations, we propose MiniMax-Remover, a novel two-stage video object removal approach.

140, TITLE: ProxyThinker: Test-Time Guidance Through Small Visual Reasoners
AUTHORS: ZILIN XIAO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this work, we propose ProxyThinker, an inference-time technique that enables large models to inherit the visual reasoning capabilities from small, slow-thinking visual reasoners without any training.

141, TITLE: Unleashing The Power of Intermediate Domains for Mixed Domain Semi-Supervised Medical Image Segmentation
AUTHORS: QINGHE MA et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the coexistence of limited annotation and domain shift is quite common, which motivates us to introduce a novel and challenging scenario: Mixed Domain Semi-supervised medical image Segmentation (MiDSS), where limited labeled data from a single domain and a large amount of unlabeled data from multiple domains. To tackle this issue, we propose the UST-RUN framework, which fully leverages intermediate domain information to facilitate knowledge transfer.

142, TITLE: ReasonGen-R1: CoT for Autoregressive Image Generation Models Through SFT and RL
AUTHORS: YU ZHANG et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Although chain-of-thought reasoning and reinforcement learning (RL) have driven breakthroughs in NLP, their integration into generative vision models remains underexplored. We introduce ReasonGen-R1, a two-stage framework that first imbues an autoregressive image generator with explicit text-based "thinking" skills via supervised fine-tuning on a newly generated reasoning dataset of written rationales, and then refines its outputs using Group Relative Policy Optimization.

143, TITLE: TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence
AUTHORS: GUIYANG HOU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Recognizing that the social world follows a distinct timeline and requires a richer blend of cognitive modes (from intuitive reactions (System 1) and surface-level thinking to deliberate thinking (System 2)) than mathematics, which primarily relies on System 2 cognition (careful, step-by-step reasoning), we introduce Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL) for enhancing LLMs' social intelligence.

144, TITLE: Online Fair Division with Additional Information
AUTHORS: Tzeh Yuan Neoh ; Jannik Peters ; Nicholas Teh
CATEGORY: cs.GT [cs.GT, cs.AI]
HIGHLIGHT: Given normalization information, we propose an algorithm that achieves stronger fairness guarantees than previously known results.

145, TITLE: Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting
AUTHORS: Jiahao Wang ; Mingyue Cheng ; Qi Liu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This motivates a key question: can slow-thinking LLMs effectively reason over temporal patterns to support time series forecasting, even in zero-shot manner? To investigate this, in this paper, we propose TimeReasoner, an extensive empirical study that formulates TSF as a conditional reasoning task.

146, TITLE: Digital Twins Enable Full-reference Quality Assessment of Photoacoustic Image Reconstructions
AUTHORS: JANEK GRï¿½HL et. al.
CATEGORY: physics.med-ph [physics.med-ph, cs.CV, eess.SP]
HIGHLIGHT: While the ground truth is known in simulations, it is unknown in vivo, or in phantom studies, as the reference depends on both the phantom properties and the imaging system. We tackle this problem by using numerical digital twins of tissue-mimicking phantoms and the imaging system to perform a quantitative calibration to reduce the simulation gap.

147, TITLE: Airborne Neural Network
AUTHORS: Paritosh Ranjan ; Surajit Majumder ; Prodip Roy
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: This paper proposes a novel concept: the Airborne Neural Network a distributed architecture where multiple airborne devices each host a subset of neural network neurons.

148, TITLE: Un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability Via Inverting UnCLIP
AUTHORS: YINQI LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We find that a specific type of generative models, unCLIP, provides a suitable framework for achieving our goal.

149, TITLE: AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders
AUTHORS: Yuqi Zhang ; Yuchun Miao ; Zuchao Li ; Liang Ding
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: We introduce AMIA, a lightweight, inference-only defense for Large Vision-Language Models (LVLMs) that (1) Automatically Masks a small set of text-irrelevant image patches to disrupt adversarial perturbations, and (2) conducts joint Intention Analysis to uncover and mitigate hidden harmful intents before response generation.

150, TITLE: UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation
AUTHORS: YANG-TIAN SUN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we demonstrate that, through appropriate design and fine-tuning, the intrinsic consistency of video generation models can be effectively harnessed for consistent geometric estimation.

151, TITLE: Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors
AUTHORS: ANDREA PEDROTTI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we present a pipeline to test the resilience of state-of-the-art MGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed adversarial attacks.

152, TITLE: Limited-Resource Adapters Are Regularizers, Not Linguists
AUTHORS: MARCELL FEKETE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate an adapter souping method combined with cross-attention fine-tuning of a pre-trained MT model to leverage language transfer for three low-resource Creole languages, which exhibit relatedness to different language groups across distinct linguistic dimensions.

153, TITLE: Optimal Density Functions for Weighted Convolution in Learning Models
AUTHORS: Simone Cammarasana ; Giuseppe Patanï¿½
CATEGORY: cs.CV [cs.CV, cs.LG, 42A85]
HIGHLIGHT: The paper introduces the weighted convolution, a novel approach to the convolution for signals defined on regular grids (e.g., 2D images) through the application of an optimal density function to scale the contribution of neighbouring pixels based on their distance from the central pixel.

154, TITLE: Geospatial Foundation Models to Enable Progress on Sustainable Development Goals
AUTHORS: PEDRAM GHAMISI et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We introduce SustainFM, a comprehensive benchmarking framework grounded in the 17 Sustainable Development Goals with extremely diverse tasks ranging from asset wealth prediction to environmental hazard detection.

155, TITLE: Attractor Learning for Spatiotemporally Chaotic Dynamical Systems Using Echo State Networks with Transfer Learning
AUTHORS: Mohammad Shah Alam ; William Ott ; Ilya Timofeyev
CATEGORY: math.DS [math.DS, cs.AI, cs.LG, nlin.CD, stat.ML, 37N99, 68T30]
HIGHLIGHT: In this paper, we explore the predictive capabilities of echo state networks (ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal nonlinear PDE that exhibits spatiotemporal chaos.

156, TITLE: HardTests: Synthesizing High-Quality Test Cases for LLM Coding
AUTHORS: ZHONGMOU HE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, reliable verifiers are hard to get for difficult coding problems, because a well-disguised wrong solution may only be detected by carefully human-written edge cases that are difficult to synthesize. To address this issue, we propose HARDTESTGEN, a pipeline for high-quality test synthesis using LLMs.

157, TITLE: Bridging Source and Target Domains Via Link Prediction for Unsupervised Domain Adaptation on Graphs
AUTHORS: Yilong Wang ; Tianxiang Zhao ; Zongyu Wu ; Suhang Wang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have ``in-distribution'' neighborhoods with the source domain.

158, TITLE: LLM-powered Query Expansion for Enhancing Boundary Prediction in Language-driven Action Localization
AUTHORS: Zirui Shang ; Xinxiao Wu ; Shuo Yang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, on one hand, we propose to expand the original query by generating textual descriptions of the action start and end boundaries through LLMs, which can provide more detailed boundary cues for localization and thus reduce the impact of boundary uncertainty.

159, TITLE: EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding
AUTHORS: EGE ï¿½ZSOY et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce EgoExOR, the first OR dataset and accompanying benchmark to fuse first-person and third-person perspectives.

160, TITLE: Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion
AUTHORS: KAIDI WANG et. al.
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: In this work, we propose Discl-VC, a novel voice conversion framework that disentangles content and prosody information from self-supervised speech representations and synthesizes the target speaker's voice through in-context learning with a flow matching transformer.

161, TITLE: Large Language Models Are Locally Linear Mappings
AUTHORS: James R. Golden
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We demonstrate that the inference operations of several open-weight large language models (LLMs) can be mapped to an exactly equivalent linear system for an input sequence without modifying the model weights or altering output predictions.

162, TITLE: Mind The Quote: Enabling Quotation-Aware Dialogue in LLMs Via Plug-and-Play Modules
AUTHORS: YUEQI ZHANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: To meet the benchmark's zero-overhead and parameter-efficiency requirements, we propose QuAda, a lightweight training-based method that attaches two bottleneck projections to every attention head, dynamically amplifying or suppressing attention to quoted spans at inference time while leaving the prompt unchanged and updating < 2.8% of backbone weights.

163, TITLE: Conformal Prediction for Zero-Shot Models
AUTHORS: Julio Silva-Rodrï¿½guez ; Ismail Ben Ayed ; Jose Dolz
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we investigate the capabilities of CLIP models under the split conformal prediction paradigm, which provides theoretical guarantees to black-box models based on a small, labeled calibration set.

164, TITLE: Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?
AUTHORS: JIWAN CHUNG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Any-to-any generative models aim to enable seamless interpretation and generation across multiple modalities within a unified framework, yet their ability to preserve relationships across modalities remains uncertain.

165, TITLE: STORK: Improving The Fidelity of Mid-NFE Sampling for Diffusion and Flow Matching Models
AUTHORS: Zheng Tan ; Weizhen Wang ; Andrea L. Bertozzi ; Ernest K. Ryu
CATEGORY: cs.CV [cs.CV, cs.NA, math.NA]
HIGHLIGHT: In this work, we propose a novel, training-free, and structure-independent DM ODE solver called the Stabilized Taylor Orthogonal Runge--Kutta (STORK) method, based on a class of stiff ODE solvers with a Taylor expansion adaptation.

166, TITLE: Benchmarking Foundation Models for Zero-Shot Biometric Tasks
AUTHORS: Redwan Sony ; Parisa Farmanifard ; Hamzeh Alzwairy ; Nitish Shukla ; Arun Ross
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes).

167, TITLE: Semi-structured LLM Reasoners Can Be Rigorously Audited
AUTHORS: Jixuan Leng ; Cassandra A. Cohen ; Zhixian Zhang ; Chenyan Xiong ; William W. Cohen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: As Large Language Models (LLMs) become increasingly capable at reasoning, the problem of "faithfulness" persists: LLM "reasoning traces" can contain errors and omissions that are difficult to detect, and may obscure biases in model outputs. To address these limitations, we introduce Semi-Structured Reasoning Models (SSRMs), which internalize a semi-structured Chain-of-Thought (CoT) reasoning format within the model.

168, TITLE: Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation
AUTHORS: PRASANNA REDDY PULAKURTHI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A new augmentation technique, Shuffle PatchMix (SPM), and a novel reweighting strategy are introduced to enhance performance.

169, TITLE: ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation
AUTHORS: Lam Thanh Do ; Aaditya Bodke ; Pritom Saha Akash ; Kevin Chen-Chuan Chang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In addition, they lack consideration for time efficiency. To solve these problems, we propose ERU-KG, an unsupervised keyphrase generation (UKG) model that consists of an informativeness and a phraseness module.

170, TITLE: GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models
AUTHORS: GILLES QUENTIN HACHEME et. al.
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG, I.2.10; I.2.7; I.4.8; I.5.3]
HIGHLIGHT: We introduce GeoVision Labeler (GVL), a strictly zero-shot classification framework: a vision Large Language Model (vLLM) generates rich, human-readable image descriptions, which are then mapped to user-defined classes by a conventional Large Language Model (LLM).

171, TITLE: Unleashing High-Quality Image Generation in Diffusion Sampling Using Second-Order Levenberg-Marquardt-Langevin
AUTHORS: FANGYIKANG WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce a novel Levenberg-Marquardt-Langevin (LML) method that approximates the diffusion Hessian geometry in a training-free manner, drawing inspiration from the celebrated Levenberg-Marquardt optimization algorithm.

172, TITLE: KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval
AUTHORS: FANHANG MAN et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Finally, existing approaches lack structured affective knowledge to resolve ambiguity and ensure consistent emotional reasoning across diverse visual domains. To address these limitations, we propose \textbf{K-EVER\textsuperscript{2}}, a knowledge-enhanced framework for emotion reasoning and retrieval.

173, TITLE: Automated Structured Radiology Report Generation
AUTHORS: JEAN-BENOIT DELBROUCK et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This variability poses challenges for both generation and evaluation: existing models struggle to produce consistent, clinically meaningful reports, and standard evaluation metrics fail to capture the nuances of radiological interpretation. To address this, we introduce Structured Radiology Report Generation (SRRG), a new task that reformulates free-text radiology reports into a standardized format, ensuring clarity, consistency, and structured clinical reporting.

174, TITLE: E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness
AUTHORS: Yibo Zhao ; Jiapeng Zhu ; Ye Guo ; Kangkang He ; Xiang Li
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we propose E^2GraphRAG, a streamlined graph-based RAG framework that improves both Efficiency and Effectiveness.

175, TITLE: Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction
AUTHORS: YANGUI FANG et. al.
CATEGORY: cs.CL [cs.CL, eess.AS]
HIGHLIGHT: However, directly using LLMs will encounter hallucinations problem, which may lead to the modification of the correct text. To address this problem, we propose the Reliable LLM Correction Framework (RLLM-CF), which consists of three stages: (1) error pre-detection, (2) chain-of-thought sub-tasks iterative correction, and (3) reasoning process verification.

176, TITLE: Reasoning Can Hurt The Inductive Abilities of Large Language Models
AUTHORS: Haibo Jin ; Peiyan Zhang ; Man Luo ; Haohan Wang
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: We find that CoT reasoning can degrade inductive performance, with LRMs often underperforming their non-reasoning counterparts. To explain this, we present a theoretical framework that reveals how reasoning steps can amplify error through three failure modes: incorrect sub-task decomposition, incorrect sub-task solving, and incorrect final answer summarization.

177, TITLE: VUDG: A Dataset for Video Understanding Domain Generalization
AUTHORS: ZIYI WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a multi-expert progressive annotation framework to annotate each video with both multiple-choice and open-ended question-answer pairs.

178, TITLE: Light As Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models
AUTHORS: YING YANG et. al.
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: Existing methods, primarily designed for classification tasks, struggle when adapted to VLP models due to their restricted optimization spaces, leading to ineffective attacks or unnatural artifacts. To address this, we propose \textbf{LightD}, a novel framework that generates natural adversarial samples for VLP models via semantically guided relighting.

179, TITLE: Dynamic Context-Aware Streaming Pretrained Language Model For Inverse Text Normalization
AUTHORS: LUONG HO et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we introduce a streaming pretrained language model for ITN, leveraging pretrained linguistic representations for improved robustness.

180, TITLE: Dynamic Malware Classification of Windows PE Files Using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion
AUTHORS: Md Shahnawaz ; Bishwajit Prasad Gond ; Durga Prasad Mohapatra
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: In this paper, we present a dynamic malware categorization framework that extracts API argument calls at the runtime execution of Windows Portable Executable (PE) files.

181, TITLE: ProofNet++: A Neuro-Symbolic System for Formal Proof Verification with Self-Correction
AUTHORS: Murari Ambati
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We propose ProofNet++, a neuro-symbolic framework that enhances automated theorem proving by combining large language models (LLMs) with formal proof verification and self-correction mechanisms.

182, TITLE: A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization
AUTHORS: PENG QI et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This is a challenging process as it requires registration of images from different geometrical modalities (2D -> 3D and vice versa), with variations in contrast and noise levels. In this paper, we propose a novel multimodal coronary artery image registration method based on a swarm optimization algorithm, which effectively addresses challenges such as large deformations, low contrast, and noise across these imaging modalities.

183, TITLE: Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research
AUTHORS: QIANQIAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, developing robust agents presents significant challenges: substantial engineering overhead, lack of standardized components, and insufficient evaluation frameworks for fair comparison. We introduce Agent Graph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and extensible framework that addresses these challenges through three key contributions: (1) a modular architecture with a graph-based workflow engine, efficient memory management, and clean component abstraction; (2) a comprehensive suite of reusable agent algorithms implementing state-of-the-art reasoning approaches; and (3) a rigorous evaluation framework enabling systematic comparison across multiple dimensions.

184, TITLE: From Hallucinations to Jailbreaks: Rethinking The Vulnerability of Large Foundation Models
AUTHORS: Haibo Jin ; Peiyan Zhang ; Peiran Wang ; Man Luo ; Haohan Wang
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: We propose a unified theoretical framework that models jailbreaks as token-level optimization and hallucinations as attention-level optimization.

185, TITLE: Multilingual Gloss-free Sign Language Translation: Towards Building A Sign Language Foundation Model
AUTHORS: Sihan Tan ; Taro Miyazaki ; Kazuhiro Nakadai
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, multilingual SLT (MLSLT) remains unexplored due to language conflicts and alignment difficulties across SLs and spoken languages. To address these challenges, we propose a multilingual gloss-free model with dual CTC objectives for token-level SL identification and spoken text generation.

186, TITLE: ReCalKV: Low-Rank KV Cache Compression Via Head Reordering and Offline Calibration
AUTHORS: XIANGLONG YAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Recent methods have explored reducing the hidden dimensions of the KV cache, but many introduce additional computation through projection layers or suffer from significant performance degradation under high compression ratios. To address these challenges, we propose ReCalKV, a post-training KV cache compression method that reduces the hidden dimensions of the KV cache.

187, TITLE: An Adversary-Resistant Multi-Agent LLM System Via Credibility Scoring
AUTHORS: Sana Ebrahimi ; Mohsen Dehghankar ; Abolfazl Asudeh
CATEGORY: cs.MA [cs.MA, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: While multi-agent LLM systems show strong capabilities in various domains, they are highly vulnerable to adversarial and low-performing agents. To resolve this issue, in this paper, we introduce a general and adversary-resistant multi-agent LLM framework based on credibility scoring.

188, TITLE: Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation
AUTHORS: Roger Ferrod ; Cï¿½ssio F. Dantas ; Luigi Di Caro ; Dino Ienco
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, these approaches face challenges in teacher architecture choices and distillation process selection, thus limiting their adoption in real-world scenarios. To overcome these issues, we introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook on Knowledge Distillation), a novel cross-modal knowledge distillation framework for RGBD semantic segmentation.

189, TITLE: MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM
AUTHORS: BOWEN DONG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Our analysis reveals that (1) the model scale, data scale, and training stages significantly affect the degree of logical, fabrication, and factual hallucinations; (2) current MLLMs show no effective improvement on spatial hallucinations caused by misinterpreted spatial relationships, indicating their limited visual reasoning capabilities; and (3) question types correlate with distinct hallucination patterns, highlighting targeted challenges and potential mitigation strategies. To address these challenges, we propose {\method}, a method that combines curriculum reinforcement fine-tuning to encourage models to generate logic-consistent reasoning chains by stepwise reducing learning difficulty, and collaborative hint inference to reduce reasoning complexity.

190, TITLE: Advantageous Parameter Expansion Training Makes Better Large Language Models
AUTHORS: NAIBIN GU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose Advantageous Parameter EXpansion Training (APEX), a method that progressively expands advantageous parameters into the space of disadvantageous ones, thereby increasing their proportion and enhancing training effectiveness.

191, TITLE: Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion
AUTHORS: Anum Afzal ; Florian Matthes ; Gal Chechik ; Yftah Ziser
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We investigate whether the success of a zero-shot Chain-of-Thought (CoT) process can be predicted before completion.

192, TITLE: Mamba Knockout for Unraveling Factual Information Flow
AUTHORS: NIR ENDY et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper investigates the flow of factual information in Mamba State-Space Model (SSM)-based language models.

193, TITLE: LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework
AUTHORS: XIN KANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We present LTM3D, a Latent Token space Modeling framework for conditional 3D shape generation that integrates the strengths of diffusion and auto-regressive (AR) models.

194, TITLE: Adversarial Preference Learning for Robust LLM Alignment
AUTHORS: YUANFU WANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, they remain vulnerable to adversarial attacks due to three key limitations: (1) the inefficiency and high cost of human annotation, (2) the vast diversity of potential adversarial attacks, and (3) the risk of feedback bias and reward hacking. To address these challenges, we introduce Adversarial Preference Learning (APL), an iterative adversarial training method incorporating three key innovations.

195, TITLE: 50 Years of Automated Face Recognition
AUTHORS: Minchul Kim ; Anil Jain ; Xiaoming Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We outline critical challenges and promising directions for future face recognition research, including scalability, multi-modal fusion, synthetic identity generation, and explainable systems.

196, TITLE: Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization
AUTHORS: Qingyao Tian ; Huai Liao ; Xinyan Huang ; Bingyu Yang ; Hongbin Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing methods struggle with 1) limited generalization across patient cases due to scarce labeled data, and 2) poor robustness under visual degradation, as bronchoscopy procedures frequently involve artifacts such as occlusions and motion blur that impair visual information. To address these challenges, we propose PANSv2, a generalizable and robust bronchoscopy localization framework.

197, TITLE: Proactive Guidance of Multi-Turn Conversation in Industrial Search
AUTHORS: XIAOYU LI et. al.
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In the Baidu Search AI assistant, an industrial-scale multi-turn search system, we propose a novel two-phase framework to provide proactive guidance.

198, TITLE: D2AF: A Dual-Driven Annotation and Filtering Framework for Visual Grounding
AUTHORS: Yichi Zhang ; Gongwei Chen ; Jun Zhu ; Jia Wan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the degree of improvement depends on how well the pseudo labels broaden the original data distribution. Based on these insights, we propose a consistency and distribution aware filtering method to further improve data quality by effectively removing erroneous and redundant data.

199, TITLE: Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering
AUTHORS: MD INTISAR CHOWDHURY et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a Grid-based Local and Global Area Transcription (Grid-LoGAT) system for Video Question Answering (VideoQA).

200, TITLE: Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?
AUTHORS: Jiayu Liu ; Qing Zong ; Weiqi Wang ; Yangqiu Song
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: As large language models (LLMs) are increasingly used in high-stakes domains, accurately assessing their confidence is crucial.

201, TITLE: Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV
AUTHORS: Karim Abou-Moustafa
CATEGORY: stat.ML [stat.ML, cs.CE, cs.CV, cs.LG, eess.SP, I.2.0; I.2.6]
HIGHLIGHT: In particular, we propose to estimate an optimal shrinkage coefficient by setting $\alpha$ as the solution to a suitably chosen objective function; namely the leave-one-out cross-validated (LOOCV) log-likelihood loss.

202, TITLE: AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion
AUTHORS: Yangyi Huang ; Ye Yuan ; Xueting Li ; Jan Kautz ; Umar Iqbal
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce AdaHuman, a novel framework that generates high-fidelity animatable 3D avatars from a single in-the-wild image.

203, TITLE: Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks
AUTHORS: TAJAMUL ASHRAF et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: However, existing benchmarks typically evaluate agents with fully synthetic, single-turn queries, limited visual modalities, and lack a framework to assess reasoning quality over multiple steps as required in real-world settings. To address this, we introduce Agent-X, a large-scale benchmark for evaluating vision-centric agents multi-step and deep reasoning capabilities in real-world, multimodal settings.

204, TITLE: Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents
AUTHORS: YAXIN LUO et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CV, cs.LG]
HIGHLIGHT: While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, multi-step reasoning challenges like CAPTCHAs is largely untested. To address this gap, we introduce Open CaptchaWorld, the first web-based benchmark and platform specifically designed to evaluate the visual reasoning and interaction capabilities of MLLM-powered agents through diverse and dynamic CAPTCHA puzzles.

205, TITLE: EXP-Bench: Can AI Conduct AI Research Experiments?
AUTHORS: PATRICK TSER JERN KON et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We introduce EXP-Bench, a novel benchmark designed to systematically evaluate AI agents on complete research experiments sourced from influential AI publications.

206, TITLE: Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing
AUTHORS: Mika Feng ; Koichi Ito ; Takafumi Aoki ; Tetsushi Ohki ; Masakatsu Nishigaki
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a spoofing attack detection method based on Vision Transformer (ViT) to detect minute differences between live and spoofed face images.

207, TITLE: Category-aware EEG Image Generation Based on Wavelet Transform and Contrast Semantic Loss
AUTHORS: Enshang Zhang ; Zhicheng Zhang ; Takashi Hanakawa
CATEGORY: cs.CV [cs.CV, cs.HC]
HIGHLIGHT: In this paper, we propose a transformer-based EEG signal encoder integrating the Discrete Wavelet Transform (DWT) and the gating mechanism.

208, TITLE: S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification
AUTHORS: XIANHENG MA et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we leverage the advantages of event cameras to resist harsh lighting conditions, reduce background interference, achieve high time resolution, and protect facial information to study the long-sequence event-based person re-identification (Re-ID) task.

209, TITLE: PCIE_Interaction Solution for Ego4D Social Interaction Challenge
AUTHORS: KANOKPHAN LERTNIPHONPHAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This report presents our team's PCIE_Interaction solution for the Ego4D Social Interaction Challenge at CVPR 2025, addressing both Looking At Me (LAM) and Talking To Me (TTM) tasks.

210, TITLE: AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models
AUTHORS: CONOR HEINS et. al.
CATEGORY: cs.AI [cs.AI, cs.LG, stat.ML]
HIGHLIGHT: However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes.

211, TITLE: IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models
AUTHORS: HANTING WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address this challenge, we propose a transition equation that bridges two diffusion processes with the same endpoint distribution. Based on this, we introduce the IRBridge framework, which enables the direct utilization of generative models within image restoration bridges, offering a more flexible and adaptable approach to image restoration.

212, TITLE: Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation
AUTHORS: Yucheng Zhou ; Jiahao Yuan ; Qianning Wang
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Beyond benchmarking, we propose an agent framework (Plan2Gen) that facilitates complex instruction-driven image generation without requiring additional model training.

213, TITLE: ScienceMeter: Tracking Scientific Knowledge Updates in Language Models
AUTHORS: Yike Wang ; Shangbin Feng ; Yulia Tsvetkov ; Hannaneh Hajishirzi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce ScienceMeter, a new framework for evaluating scientific knowledge update methods over scientific knowledge spanning the past, present, and future.

214, TITLE: DiG-Net: Enhancing Quality of Life Through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics
AUTHORS: Eran Bamani Beeri ; Eden Nissinman ; Avishai Sintov
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV]
HIGHLIGHT: In this paper, we introduce a novel approach designed specifically for assistive robotics, enabling dynamic gesture recognition at extended distances of up to 30 meters, thereby significantly improving accessibility and quality of life.

215, TITLE: Efficient RAW Image Deblurring with Adaptive Frequency Modulation
AUTHORS: Wenlong Jiao ; Binglong Li ; Wei Shang ; Ping Wang ; Dongwei Ren
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Deblurring RAW images presents unique challenges, particularly in handling frequency-dependent blur while maintaining computational efficiency. To address these issues, we propose Frequency Enhanced Network (FrENet), a framework specifically designed for RAW-to-RAW deblurring that operates directly in the frequency domain.

216, TITLE: LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer Via Language and Thought Theory
AUTHORS: Eojin Kang ; Juae Kim
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose the Language-to-Thought (L2T) prompting strategy, which analyzes the relationship between input language, internal cognitive processes, and knowledge.

217, TITLE: SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping
AUTHORS: MINGXU ZHANG et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: While several 3D reconstruction and depth completion approaches address these challenges, they suffer from setup complexity or limited observation information utilization. To address this, leveraging the power of single view 3D object reconstruction approaches, we propose a training free framework SR3D that enables robotic grasping of transparent and specular objects from a single view observation.

218, TITLE: Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation
AUTHORS: Henry Conklin
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We lack methods to reliably describe how their representations are structured, how that structure emerges over training, and what kinds of structures are desirable. This thesis introduces quantitative methods for identifying systematic structure in a mapping between spaces, and leverages them to understand how deep-learning models learn to represent information, what representational structures drive generalisation, and how design decisions condition the structures that emerge.

219, TITLE: Drop Dropout on Single-Epoch Language Model Pretraining
AUTHORS: Houjun Liu ; John Bauer ; Christopher D. Manning
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We further investigate the models' editability, and find that models trained without dropout are more successful in gradient-based model editing (MEND) and equivalent in representation-based model editing (ReFT). Therefore, we advocate to drop dropout during single-epoch pretraining.

220, TITLE: MangoLeafViT: Leveraging Lightweight Vision Transformer with Runtime Augmentation for Efficient Mango Leaf Disease Classification
AUTHORS: Rafi Hassan Chowdhury ; Sabbir Ahmed
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a lightweight Vision Transformer-based pipeline with a self-attention mechanism to classify mango leaf diseases, achieving state-of-the-art performance with minimal computational overhead.

221, TITLE: GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments
AUTHORS: KECHEN LI et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, most existing studies focus on LLMs' independent reasoning capabilities and overlook the potential synergy between LLMs and traditional algorithms. To fill this gap, we propose a comprehensive evaluation benchmark GridRoute to assess how LLMs can take advantage of traditional algorithms.

222, TITLE: Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification
AUTHORS: Xinliu Zhong ; Leo Hwa Liang ; Angela S. Koh ; Yeo Si Yong
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: These images, typically derived from video frames, often exhibit similar patterns, posing challenges in discrimination. To overcome these challenges, we propose a novel Deep Learning network built on a Few-Shot Learning architecture, which includes a tailored feature extractor, task interpolation, relational embedding, and a bi-level routing attention mechanism.

223, TITLE: FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression
AUTHORS: JIAYI TIAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose FLAT-LLM, a fast and accurate, training-free structural compression method based on fine-grained low-rank transformations in the activation space.

224, TITLE: Inference Acceleration of Autoregressive Normalizing Flows By Selective Jacobi Decoding
AUTHORS: Jiaru Zhang ; Juanwu Lu ; Ziran Wang ; Ruqi Zhang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Moreover, the models tend to exhibit low dependency redundancy in the initial layer and higher redundancy in subsequent layers. Leveraging these observations, we propose a selective Jacobi decoding (SeJD) strategy that accelerates autoregressive inference through parallel iterative optimization.

225, TITLE: Progressive Class-level Distillation
AUTHORS: Jiayan Li ; Jun Li ; Zhourui Zhang ; Jianhua Xu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Since high-confidence object classes usually dominate the distillation process, low-probability classes which also contain discriminating information are downplayed in conventional methods, leading to insufficient knowledge transfer. To address this issue, we propose a simple yet effective LD method termed Progressive Class-level Distillation (PCD).

226, TITLE: Confidential Guardian: Cryptographically Prohibiting The Abuse of Model Abstention
AUTHORS: STEPHAN RABANSER et. al.
CATEGORY: cs.CR [cs.CR, cs.AI, cs.CY, cs.LG, stat.ML]
HIGHLIGHT: Cautious predictions -- where a machine learning model abstains when uncertain -- are crucial for limiting harmful errors in safety-critical applications. In this work, we identify a novel threat: a dishonest institution can exploit these mechanisms to discriminate or unjustly deny services under the guise of uncertainty.

227, TITLE: TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores
AUTHORS: ZIMU LIAO et. al.
CATEGORY: cs.GR [cs.GR, cs.CV, cs.DC, I.3.6; I.3.2; D.1.3]
HIGHLIGHT: This paper proposes TC-GS, an algorithm-independent universal module that expands Tensor Core (TCU) applicability for 3DGS, leading to substantial speedups and seamless integration into existing 3DGS optimization frameworks.

228, TITLE: CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning
AUTHORS: Jiangpeng He ; Zhihao Duan ; Fengqing Zhu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose ContinuaL Low-Rank Adaptation (CL-LoRA), which introduces a novel dual-adapter architecture combining \textbf{task-shared adapters} to learn cross-task knowledge and \textbf{task-specific adapters} to capture unique features of each new task.

229, TITLE: Bi-Manual Joint Camera Calibration and Scene Representation
AUTHORS: Haozhan Tang ; Tianyi Zhang ; Matthew Johnson-Roberson ; Weiming Zhi
CATEGORY: cs.RO [cs.RO, cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce the Bi-Manual Joint Calibration and Representation Framework (Bi-JCR).

230, TITLE: InteractAnything: Zero-shot Human Object Interaction Synthesis Via LLM Feedback and Object Affordance Parsing
AUTHORS: JINLU ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a novel zero-shot 3D HOI generation framework without training on specific datasets, leveraging the knowledge from large-scale pre-trained models.

231, TITLE: Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images
AUTHORS: ADITYA RETNANTO et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Its pixel footprint is too large to capture small features like houses, streets, or hedge rows. To address this, we present SEN4X, a hybrid super-resolution architecture that combines the advantages of single-image and multi-image techniques.

232, TITLE: HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification
AUTHORS: Yuntao Shi ; Yi Luo ; Yeyun Gong ; Chen Lin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, when handling long-form text modification tasks, they still face two major problems: (1) producing undesired modifications by inappropriately altering or summarizing irrelevant content, and (2) missing necessary modifications to implicitly related passages that are crucial for maintaining document coherence. To address these issues, we propose HiCaM, a Hierarchical-Causal Modification framework that operates through a hierarchical summary tree and a causal graph.

233, TITLE: Exploring Domain Wall Pinning in Ferroelectrics Via Automated High Throughput AFM
AUTHORS: Kamyar Barakati ; Yu Liu ; Hiroshi Funakubo ; Sergei V. Kalinin
CATEGORY: cond-mat.mtrl-sci [cond-mat.mtrl-sci, cs.CV, cs.LG, physics.app-ph]
HIGHLIGHT: Domain-wall dynamics in ferroelectric materials are strongly position-dependent since each polar interface is locked into a unique local microstructure. This necessitates spatially resolved studies of the wall-pinning using scanning-probe microscopy techniques.

234, TITLE: Segmenting France Across Four Centuries
AUTHORS: Marta Lï¿½pez-Rauhut ; Hongyu Zhou ; Mathieu Aubry ; Loic Landrieu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a new dataset of historical maps tailored for analyzing large-scale, long-term land use and land cover evolution with limited annotations.

235, TITLE: VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL
AUTHORS: YICHEN FENG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: To tackle the challenge of image synthesis with grounding answers, we propose a rule-to-image synthesis pipeline, which extracts and expands puzzle rules from seed questions and generates the code of grounding synthesis image synthesis for puzzle sample assembly.

236, TITLE: TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional Chinese Medicine
AUTHORS: JIACHENG XIE et. al.
CATEGORY: cs.CL [cs.CL, cs.DB]
HIGHLIGHT: However, existing evaluation datasets are limited in scope and primarily text-based, lacking a unified and standardized multimodal question-answering (QA) benchmark. To address this issue, we introduce TCM-Ladder, the first multimodal QA dataset specifically designed for evaluating large TCM language models.

237, TITLE: PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models
AUTHORS: Yinggan Xu ; Yue Liu ; Zhiqiang Gao ; Changnan Peng ; Di Luo
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: This discrepancy highlights a crucial gap in their ability to apply core physical principles for efficient and interpretable problem solving. To systematically investigate this limitation, we introduce PhySense, a novel principle-based physics reasoning benchmark designed to be easily solvable by experts using guiding principles, yet deceptively difficult for LLMs without principle-first reasoning.

238, TITLE: SwiftEval: Developing A Language-Specific Benchmark for LLM-generated Code Evaluation
AUTHORS: Ivan Petrukha ; Yana Kurliak ; Nataliia Stulova
CATEGORY: cs.LG [cs.LG, cs.CL, cs.PL, cs.SE]
HIGHLIGHT: We present SwiftEval, the first Swift-oriented benchmark consisting of 28 carefully hand-crafted problems, and evaluate 44 popular Code LLMs on it.

239, TITLE: STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising
AUTHORS: Jingjing Liu ; Jiashun Jin ; Xianchao Xiu ; Jianhua Zhang ; Wanquan Liu
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Different from conventional iterative optimization, we develop an alternating direction method of multipliers (ADMM)-guided deep unrolling network, in which all regularization parameters can be automatically learned, thus inheriting the advantages of both model-based and deep learning-based approaches and successfully addressing the above-mentioned shortcomings.

240, TITLE: LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text
AUTHORS: Li yunhan ; Wu gengshen
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: As large language models (LLMs) are increasingly used in legal applications, current evaluation benchmarks tend to focus mainly on factual accuracy while largely neglecting important linguistic quality aspects such as clarity, coherence, and terminology.

241, TITLE: How to Verify That A Small Device Is Quantum, Unconditionally
AUTHORS: Giulio Malavolta ; Tamer Mour
CATEGORY: quant-ph [quant-ph, cs.CC]
HIGHLIGHT: A proof of quantumness (PoQ) allows a classical verifier to efficiently test if a quantum machine is performing a computation that is infeasible for any classical machine. In this work, we propose a new approach for constructing PoQ protocols where soundness holds unconditionally assuming a bound on the memory of the prover, but otherwise no restrictions on its runtime.

242, TITLE: DSR-Bench: Evaluating The Structural Reasoning Abilities of LLMs Via Data Structures
AUTHORS: Yu He ; Yingxi Li ; Colin White ; Ellen Vitercik
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, existing benchmarks primarily focus on high-level, application-driven evaluations without isolating this fundamental capability. To address this gap, we introduce DSR-Bench, a novel benchmark evaluating LLMs' structural reasoning capabilities through data structures, which provide interpretable representations of data relationships.

243, TITLE: DisTime: Distribution-based Time Representation for Video Large Language Models
AUTHORS: YINGSEN ZENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing methods for temporal expression either conflate time with text-based numerical values, add a series of dedicated temporal tokens, or regress time using specialized temporal grounding heads. To address these issues, we introduce DisTime, a lightweight framework designed to enhance temporal comprehension in Video-LLMs.

244, TITLE: Circuit Stability Characterizes Language Model Generalization
AUTHORS: Alan Sun
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Inspired by the recent developments in mechanistic interpretability, we introduce circuit stability as a new way to assess model performance.

245, TITLE: MRAG: Elucidating The Design Space of Multi-modal Retrieval-Augmented Generation
AUTHORS: Chan-Wei Hu ; Yueqi Wang ; Shuo Xing ; Chia-Ju Chen ; Zhengzhong Tu
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Large Vision-Language Models (LVLMs) have made remarkable strides in multimodal tasks such as visual question answering, visual grounding, and complex reasoning.

246, TITLE: DeepTopoNet: A Framework for Subglacial Topography Estimation on The Greenland Ice Sheets
AUTHORS: BAYU ADHI TAMA et. al.
CATEGORY: cs.CV [cs.CV, cs.LG, eess.IV]
HIGHLIGHT: This study introduces a deep learning framework, which we call as DeepTopoNet, that integrates radar-derived ice thickness observations and BedMachine Greenland data through a novel dynamic loss-balancing mechanism.

247, TITLE: MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge
AUTHORS: JERRY JUNYANG CHEUNG et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Despite recent advances in large language models (LLMs) for materials science, there is a lack of benchmarks for evaluating their domain-specific knowledge and complex reasoning abilities. To bridge this gap, we introduce MSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials science questions in two formats: detailed explanatory responses and binary True/False assessments.

248, TITLE: DreamDance: Animating Character Art Via Inpainting Stable Gaussian Worlds
AUTHORS: JIAXU ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents DreamDance, a novel character art animation framework capable of producing stable, consistent character and scene motion conditioned on precise camera trajectories.

249, TITLE: "Dyadosyncrasy", Idiosyncrasy and Demographic Factors in Turn-Taking
AUTHORS: Julio Cesar Cavalcanti ; Gabriel Skantze
CATEGORY: eess.AS [eess.AS, cs.CL]
HIGHLIGHT: This study examines how demographic (sex, age, education) and individual factors shape turn-taking using a large dataset of US English conversations (Fisher).

250, TITLE: SIM: A Mapping Framework for Built Environment Auditing Based on Street View Imagery
AUTHORS: Huan Ning ; Zhenlong Li ; Manzhu Yu ; Wenpeng Yin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we introduced an open source street view mapping framework, providing three pipelines to map and measure: 1) width measurement for ground objects, such as roads; 2) 3D localization for objects with a known dimension (e.g., doors and stop signs); and 3) diameter measurements (e.g., street trees).

251, TITLE: Improving Reliability and Explainability of Medical Question Answering Through Atomic Fact Checking in Retrieval-Augmented LLMs
AUTHORS: JURAJ VLADIKA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we introduce a novel atomic fact-checking framework designed to enhance the reliability and explainability of LLMs used in medical long-form question answering.

252, TITLE: How Much Do Language Models Memorize?
AUTHORS: JOHN X. MORRIS et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a new method for estimating how much a model ``knows'' about a datapoint and use it to measure the capacity of modern language models.

253, TITLE: ComposeAnything: Composite Object Priors for Text-to-Image Generation
AUTHORS: Zeeshan Khan ; Shizhe Chen ; Cordelia Schmid
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce ComposeAnything, a novel framework for improving compositional image generation without retraining existing T2I models.

254, TITLE: Multilinguality Does Not Make Sense: Investigating Factors Behind Zero-Shot Transfer in Sense-Aware Tasks
AUTHORS: Roksana Goworek ; Haim Dubossarsky
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Cross-lingual transfer allows models to perform tasks in languages unseen during training and is often assumed to benefit from increased multilinguality. In this work, we challenge this assumption in the context of two underexplored, sense-aware tasks: polysemy disambiguation and lexical semantic change.

255, TITLE: Large Language Models for Controllable Multi-property Multi-objective Molecule Optimization
AUTHORS: Vishal Dey ; Xiao Hu ; Xia Ning
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, q-bio.BM]
HIGHLIGHT: However, existing computational approaches and instruction-tuned LLMs fail to capture such nuanced property-specific objectives, limiting their practical applicability. To address this, we introduce C-MuMOInstruct, the first instruction-tuning dataset focused on multi-property optimization with explicit, property-specific objectives.

256, TITLE: Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models Without Forgetting
AUTHORS: CHEN HUANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: We propose a novel regularization method Proxy-FDA that explicitly preserves the structural knowledge in feature space.

257, TITLE: Zero-Shot Chinese Character Recognition with Hierarchical Multi-Granularity Image-Text Aligning
AUTHORS: YINGLIAN ZHU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a Hierarchical Multi-Granularity Image-Text Aligning (Hi-GITA) framework based on a contrastive paradigm.

258, TITLE: Searching Clinical Data Using Generative AI
AUTHORS: KARAN HANSWADKAR et. al.
CATEGORY: cs.DB [cs.DB, cs.AI]
HIGHLIGHT: In this paper, we present a generative AI approach, coined SearchAI, to enhance the accuracy and efficiency of searching clinical data.

259, TITLE: VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software
AUTHORS: Brandon Man ; Ghadi Nehme ; Md Ferdous Alam ; Faez Ahmed
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we introduce VideoCAD, the first attempt at engineering UI interaction learning for precision tasks.

260, TITLE: Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding
AUTHORS: MINGYANG MAO et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: As robots and intelligent agents become more integrated into human life, there is a growing opportunity-and need-to offload the cognitive burden on humans to these systems, particularly in dynamic, information-rich scenarios. To fill this critical need, we present Multi-RAG, a multimodal retrieval-augmented generation system designed to provide adaptive assistance to humans in information-intensive circumstances.

261, TITLE: Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are The Bottleneck
AUTHORS: Yuwen Tan ; Yuan Qing ; Boqing Gong
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: This paper reveals that many state-of-the-art large language models (LLMs) lack hierarchical knowledge about our visual world, unaware of even well-established biology taxonomies.

262, TITLE: Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning
AUTHORS: Wanyun Xie ; Francesco Tonin ; Volkan Cevher
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: To this end, we introduce a flexible and efficient data mixing framework, Chameleon, that employs leverage scores to quantify domain importance within a learned embedding space.

263, TITLE: Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem
AUTHORS: Katherine Tieu ; Dongqi Fu ; Jun Wu ; Jingrui He
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: With the Information Bottleneck (IB) method, we propose an error-bounded Invariant Link Selector that can distinguish invariant components and variant components during the training process to make the deep learning model generalizable for different testing scenarios.

264, TITLE: Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs
AUTHORS: YINONG OLIVER WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Conventional fairness metrics, which focus on discrete accuracy-based evaluations (i.e., prediction correctness), fail to capture the implicit impact of model uncertainty (e.g., higher model confidence about one group over another despite similar accuracy). To address this limitation, we propose an uncertainty-aware fairness metric, UCerF, to enable a fine-grained evaluation of model fairness that is more reflective of the internal bias in model decisions compared to conventional fairness measures.

265, TITLE: Large Language Model Meets Constraint Propagation
AUTHORS: Alexandre Bonlarron ; Florian Rï¿½gin ; Elisabetta De Maria ; Jean-Charles Rï¿½gin
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we improve GenCP by integrating Masked Language Models (MLMs) for domain generation, which allows bidirectional constraint propagation that leverages both past and future tokens.

266, TITLE: SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling
AUTHORS: Xiaodong Ji ; Hailin Zhang ; Fangcheng Fu ; Bin Cui
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose SALE, a fine-grained sparse attention method that accelerates the long-context prefilling stage of LLM with negligible loss in model accuracy.

267, TITLE: SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning Via Flow Chain-of-Thought
AUTHORS: GUANGHAO LI et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Flow CoT frames each iteration as a distinct cognitive stage deepening reasoning across iterations without relying on manual supervision. To realize this, we propose SCOUT (Stepwise Cognitive Optimization Using Teachers), a lightweight fine tuning framework that enables Flow CoT style reasoning without the need for pretraining.

268, TITLE: Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation
AUTHORS: Ximing Xing ; Yandong Guan ; Jing Zhang ; Dong Xu ; Qian Yu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce Reason-SVG, a novel framework designed to enhance LLM reasoning for SVG generation.

269, TITLE: MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning
AUTHORS: JINGYAN SHEN et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this work, we introduce MiCRo, a two-stage framework that enhances personalized preference learning by leveraging large-scale binary preference datasets without requiring explicit fine-grained annotations.

270, TITLE: CodeV-R1: Reasoning-Enhanced Verilog Generation
AUTHORS: YAOYU ZHU et. al.
CATEGORY: cs.LG [cs.LG, cs.AR, cs.PL]
HIGHLIGHT: To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs.

271, TITLE: Seeing Is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT
AUTHORS: ZHUOBAI DONG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To ensure fine-grained evaluation, we introduce a graph-based CoT consistency metric that verifies whether the reasoning path of model adheres to valid physical logic.

272, TITLE: Towards Unified Modeling in Federated Multi-Task Learning Via Subspace Decoupling
AUTHORS: Yipan Wei ; Yuchen Zou ; Yapeng Li ; Bo Du
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: As a result, in real-world scenarios where task objectives, label spaces, and optimization paths vary significantly, conventional FMTL methods struggle to achieve effective joint training. To address this challenge, we propose FedDEA (Federated Decoupled Aggregation), an update-structure-aware aggregation method specifically designed for multi-task model integration.

273, TITLE: Beyond Exponential Decay: Rethinking Error Accumulation in Large Language Models
AUTHORS: Mikhail L. Arbuzov ; Alexey A. Shvets ; Sisong Beir
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We thus propose a framework for next-generation systems centered on selective preservation of semantically vital tokens, dynamic computational allocation at uncertain decision boundaries, multi-path exploration at ambiguities, and architectures aligned with natural semantic domains.

274, TITLE: Reading Recognition in The Wild
AUTHORS: CHARIG YANG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we introduce a new task of reading recognition to determine when the user is reading.

275, TITLE: BeaverTalk: Oregon State University's IWSLT 2025 Simultaneous Speech Translation System
AUTHORS: Matthew Raffel ; Victor Agostinelli ; Lizhong Chen
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper discusses the construction, fine-tuning, and deployment of BeaverTalk, a cascaded system for speech-to-text translation as part of the IWSLT 2025 simultaneous translation task.

276, TITLE: LLM Agents Should Employ Security Principles
AUTHORS: KAIYUAN ZHANG et. al.
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Design principles such as defense-in-depth, least privilege, complete mediation, and psychological acceptability have helped guide the design of mechanisms for securing information systems over the last five decades, and we argue that their explicit and conscientious adoption will help secure agentic systems. To illustrate this approach, we introduce AgentSandbox, a conceptual framework embedding these security principles to provide safeguards throughout an agent's life-cycle.

277, TITLE: ScaleLong: A Multi-Timescale Benchmark for Long Video Understanding
AUTHORS: DAVID MA et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Although long-video understanding demands that models capture hierarchical temporal information -- from clip (seconds) and shot (tens of seconds) to event (minutes) and story (hours) -- existing benchmarks either neglect this multi-scale design or scatter scale-specific questions across different videos, preventing direct comparison of model performance across timescales on the same content. To address this, we introduce ScaleLong, the first benchmark to disentangle these factors by embedding questions targeting four hierarchical timescales -- clip (seconds), shot (tens of seconds), event (minutes), and story (hours) -- all within the same video content.

278, TITLE: Fine-Tune An SLM or Prompt An LLM? The Case of Generating Low-Code Workflows
AUTHORS: Orlando Marquez Ayala ; Patrice Bechard ; Emily Chen ; Maggie Baird ; Jingfei Chen
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this work, we present evidence that, for domain-specific tasks that require structured outputs, SLMs still have a quality advantage.

279, TITLE: Provably Improving Generalization of Few-Shot Models with Synthetic Data
AUTHORS: LAN-CUONG NGUYEN et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Building upon this framework, we propose a novel theoretical-based algorithm that integrates prototype learning to optimize both data partitioning and model training, effectively bridging the gap between real few-shot data and synthetic data.

280, TITLE: ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents
AUTHORS: FEITENG FANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, traditional reward models often struggle with scalability and adapting to subjective conversational preferences. We propose ChARM, a Character-based Act-adaptive Reward Model, addressing these challenges through two innovations: (1) an act-adaptive margin that significantly enhances learning efficiency and generalizability, and (2) a self-evolution mechanism leveraging large-scale unlabeled data to improve training coverage.

281, TITLE: Multi-Group Proportional Representation for Text-to-Image Models
AUTHORS: SANGWON JUNG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper introduces a novel framework to measure the representation of intersectional groups in images generated by T2I models by applying the Multi-Group Proportional Representation (MPR) metric.

282, TITLE: Point-MoE: Towards Cross-Domain Generalization in 3D Semantic Segmentation Via Mixture-of-Experts
AUTHORS: Xuweiyi Chen ; Wentao Zhou ; Aruni RoyChowdhury ; Zezhou Cheng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose Point-MoE, a Mixture-of-Experts architecture designed to enable large-scale, cross-domain generalization in 3D perception.

283, TITLE: MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking
AUTHORS: Numair Nadeem ; Muhammad Hamza Asad ; Saeed Anwar ; Abdul Bais
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Unsupervised Domain Adaptation (UDA) addresses this by enabling adaptation without target-domain labels, but current UDA methods struggle with occlusions and visual blending between crops and weeds, leading to misclassifications in real-world conditions. To overcome these limitations, we introduce MaskAdapt, a novel approach that enhances segmentation accuracy through multimodal contextual learning by integrating RGB images with features derived from depth data.

284, TITLE: DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models
AUTHORS: Chenbin Pan ; Wenbin He ; Zhengzhong Tu ; Liu Ren
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, such reasoning abilities remain underexplored and notably absent in vision foundation models, including representation models like the DINO series. In this work, we propose \textbf{DINO-R1}, the first such attempt to incentivize visual in-context reasoning capabilities of vision foundation models using reinforcement learning.

285, TITLE: Hidden Persuasion: Detecting Manipulative Narratives on Social Media During The 2022 Russian Invasion of Ukraine
AUTHORS: Kateryna Akhynko ; Oleksandr Kosovan ; Mykola Trokhymovych
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents one of the top-performing solutions to the UNLP 2025 Shared Task on Detecting Manipulation in Social Media.

286, TITLE: CLaSp: In-Context Layer Skip for Self-Speculative Decoding
AUTHORS: LONGZE CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose CLaSp, an in-context layer-skipping strategy for self-speculative decoding.

287, TITLE: WikiGap: Promoting Epistemic Equity By Surfacing Knowledge Gaps Between English Wikipedia and Other Language Editions
AUTHORS: ZINING WANG et. al.
CATEGORY: cs.HC [cs.HC, cs.CL]
HIGHLIGHT: We present WikiGap, a system that surfaces complementary facts sourced from other Wikipedias within the English Wikipedia interface.

288, TITLE: Decoupled Competitive Framework for Semi-supervised Medical Image Segmentation
AUTHORS: Jiahe Chen ; Jiahe Ying ; Shen Wang ; Jianwei Zheng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, to date, these approaches face a performance bottleneck due to two inherent limitations, \textit{e.g.}, the over-coupling problem within MT structure owing to the employment of exponential moving average (EMA) mechanism, as well as the severe cognitive bias between two students of DS structure, both of which potentially lead to reduced efficacy, or even model collapse eventually. To mitigate these issues, a Decoupled Competitive Framework (DCF) is elaborated in this work, which utilizes a straightforward competition mechanism for the update of EMA, effectively decoupling students and teachers in a dynamical manner.

289, TITLE: 6D Pose Estimation on Point Cloud Data Through Prior Knowledge Integration: A Case Study in Autonomous Disassembly
AUTHORS: CHENGZHI WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, employing the task of bolt detection within the scope of our project as a pertinent use case, we introduce a meticulously devised pipeline.

290, TITLE: Multiple LLM Agents Debate for Equitable Cultural Alignment
AUTHORS: Dayeon Ki ; Rachel Rudinger ; Tianyi Zhou ; Marine Carpuat
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce a Multi-Agent Debate framework, where two LLM-based agents debate over a cultural scenario and collaboratively reach a final decision.

291, TITLE: From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?
AUTHORS: ZIMING ZHAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis.

292, TITLE: Learning API Functionality from Demonstrations for Tool-based Agents
AUTHORS: Bhrij Patel ; Ashish Jagmohan ; Aditya Vempaty
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we propose learning API functionality directly from demonstrations as a new paradigm applicable in scenarios without documentation.

293, TITLE: The Surprising Soupability of Documents in State Space Models
AUTHORS: Yasaman Jafari ; Zixian Wang ; Leon Bergen ; Taylor Berg-Kirkpatrick
CATEGORY: cs.CL [cs.CL, cs.CE, cs.LG]
HIGHLIGHT: Inspired by model souping, we propose a strategy where documents are encoded independently and their representations are pooled -- via simple operations like averaging -- into a single context state.

294, TITLE: Intuitionistic Fuzzy Sets for Large Language Model Data Annotation: A Novel Approach to Side-by-Side Preference Labeling
AUTHORS: Yimin Du
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a novel framework based on intuitionistic fuzzy sets (IFS) for modeling and aggregating human preferences in LLM data annotation tasks.

295, TITLE: LlamaRL: A Distributed Asynchronous Reinforcement Learning Framework for Efficient Large-scale LLM Trainin
AUTHORS: BO WU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we present LlamaRL, a fully distributed, asynchronous RL framework optimized for efficient training of large-scale LLMs with various model sizes (8B, 70B, and 405B parameters) on GPU clusters ranging from a handful to thousands of devices.

296, TITLE: A Mathematical Perspective On Contrastive Learning
AUTHORS: Ricardo Baptista ; Andrew M. Stuart ; Son Tran
CATEGORY: stat.ML [stat.ML, cs.CV, cs.LG]
HIGHLIGHT: In this work, we focus on the bimodal setting and interpret contrastive learning as the optimization of (parameterized) encoders that define conditional probability distributions, for each modality conditioned on the other, consistent with the available data.

297, TITLE: Leave It to The Specialist: Repair Sparse LLMs with Sparse Fine-Tuning Via Sparsity Evolution
AUTHORS: QIAO XIAO et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we propose Sparsity Evolution Fine-Tuning (SEFT), a novel method designed specifically for sparse LLMs.

298, TITLE: R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration
AUTHORS: ZEFAN CAI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While chain-of-thought inference significantly improves performance on complex reasoning tasks, it can also lead to reasoning failures when deployed with existing KV cache compression approaches. To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models.

299, TITLE: GenIC: An LLM-Based Framework for Instance Completion in Knowledge Graphs
AUTHORS: Amel Gader ; Alsayed Algergawy
CATEGORY: cs.AI [cs.AI, cs.IR]
HIGHLIGHT: Notably, modern knowledge bases often contain entity descriptions and types, which can provide valuable context for inferring missing facts. By leveraging these textual descriptions and the ability of large language models to extract facts from them and recognize patterns within the knowledge graph schema, we propose an LLM-powered, end-to-end instance completion approach.

300, TITLE: Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction
AUTHORS: Ya?ar Utku Alï¿½alar ; Mehmet Akï¿½akaya
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV, cs.LG, physics.med-ph]
HIGHLIGHT: However, its application at high acceleration rates frequently introduces artifacts, compromising image fidelity. To mitigate this shortcoming, we propose a novel way to train PD-DL networks via carefully-designed perturbations.

301, TITLE: AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits
AUTHORS: YICHEN SHI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, current research typically evaluates MLLMs on isolated tasks within the domain, lacking a comprehensive benchmark that systematically assesses model capabilities across diverse AMS-related challenges. To address this gap, we introduce AMSbench, a benchmark suite designed to evaluate MLLM performance across critical tasks including circuit schematic perception, circuit analysis, and circuit design.

302, TITLE: TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis
AUTHORS: XIAORUI WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Most existing datasets focus primarily on lexical diversity while neglecting other critical dimensions. To address this limitation, we propose a novel analysis framework to systematically measure the risk coverage of alignment datasets across three essential dimensions: Lexical Diversity, Malicious Intent, and Jailbreak Tactics.

303, TITLE: Beyond FACS: Data-driven Facial Expression Dictionaries, with Application to Predicting Autism
AUTHORS: EVANGELOS SARIYANIDI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Instead of creating automated tools that mimic FACS experts, we propose to use a new coding system that mimics the key properties of FACS.

304, TITLE: A Simple Linear Patch Revives Layer-Pruned Large Language Models
AUTHORS: XINRUI CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We identify that this degradation stems from the mismatch of activation magnitudes across layers and tokens at the pruning interface. To address this, we propose LinearPatch, a simple plug-and-play technique to revive the layer-pruned LLMs.

305, TITLE: Conformal Object Detection By Sequential Risk Control
AUTHORS: Lï¿½o Andï¿½ol ; Luca Mossina ; Adrien Mazoyer ; Sï¿½bastien Gerchinovitz
CATEGORY: stat.ML [stat.ML, cs.CV, cs.LG]
HIGHLIGHT: Finally, we present a conformal toolkit, enabling replication and further exploration of our methods. Using this toolkit, we perform extensive experiments, yielding a benchmark that validates the investigated methods and emphasizes trade-offs and other practical consequences.

306, TITLE: MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering
AUTHORS: YUEXING HAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we introduce the MedPAIR (Medical Dataset Comparing Physicians and AI Relevance Estimation and Question Answering) dataset to evaluate how physician trainees and LLMs prioritize relevant information when answering QA questions.

307, TITLE: S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation
AUTHORS: YICHEN XIE et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To this end, we propose S4-Driver, a scalable self-supervised motion planning algorithm with spatio-temporal visual representation, based on the popular PaLI multimodal large language model.

308, TITLE: The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models
AUTHORS: JIASHUAI LIU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Specifically, we introduce the principle of \textit{local perturbation with global impact} and propose a label-free attack framework that operates without requiring access to downstream task labels.

309, TITLE: CrossICL: Cross-Task In-Context Learning Via Unsupervised Demonstration Transfer
AUTHORS: Jinglong Gao ; Xiao Ding ; Lingxiao Zou ; Bing Qin ; Ting Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Based on it, we conduct comprehensive exploration of CrossICL, with 875 NLP tasks from the Super-NI benchmark and six types of LLMs, including GPT-4o.

310, TITLE: Rationales Are Not Silver Bullets: Measuring The Impact of Rationales on Model Performance and Reliability
AUTHORS: CHIWEI ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Training language models with rationales augmentation has been shown to be beneficial in many existing works. In this paper, we identify that such a prevailing view does not hold consistently.

311, TITLE: Generative Knowledge Production Pipeline Driven By Academic Influencers
AUTHORS: Katalin Feher ; Marton Demeter
CATEGORY: cs.CY [cs.CY, cs.AI, cs.HC, cs.SI, 1.2, J.4, K.4]
HIGHLIGHT: Accordingly, the study proposes a generative publication production pipeline and a policy framework for co-intelligence adaptation and reinforcing credibility-centered standards in AI-powered research.

312, TITLE: Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs
AUTHORS: Zihao Chen ; Yu Xiang ; Wenyong Wang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we focus on exploring the implicit inductive bias that drive disentanglement in VAEs with factorization priors.

313, TITLE: Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC
AUTHORS: Qingzheng Wang ; Jiancheng Sun ; Yifan Peng ; Shinji Watanabe
CATEGORY: cs.SD [cs.SD, cs.CL, eess.AS]
HIGHLIGHT: This paper enhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple strategies for adapting SFMs, including frozen upstream training, partial fine-tuning, and low-rank adaptation.

314, TITLE: Should I Share This Translation? Evaluating Quality Feedback for User Reliance on Machine Translation
AUTHORS: Dayeon Ki ; Kevin Duh ; Marine Carpuat
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We compare four types of quality feedback: explicit feedback that directly give users an assessment of translation quality using 1) error highlights and 2) LLM explanations, and implicit feedback that helps users compare MT inputs and outputs through 3) backtranslation and 4) question-answer (QA) tables.

315, TITLE: SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems
AUTHORS: Xu He ; Di Wu ; Yan Zhai ; Kun Sun
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we present a system-level anomaly detection framework tailored for MAS, integrating structural modeling with runtime behavioral oversight.

316, TITLE: Soft Reasoning: Navigating Solution Spaces in Large Language Models Through Controlled Embedding Exploration
AUTHORS: QINGLIN ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose Soft Reasoning, an embedding-based search framework that optimises the embedding of the first token to guide generation.

317, TITLE: 3DGEER: Exact and Efficient Volumetric Rendering with 3D Gaussians
AUTHORS: Zixun Huang ; Cho-Ying Wu ; Yuliang Guo ; Xinyu Huang ; Liu Ren
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: In this work, we introduce 3DGEER, an Exact and Efficient Volumetric Gaussian Rendering method.

318, TITLE: RCCDA: Adaptive Model Updates in The Presence of Concept Drift Under A Constrained Resource Budget
AUTHORS: Adam Piaseczny ; Md Kamran Chowdhury Shisher ; Shiqiang Wang ; Christopher G. Brinton
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Existing solutions often depend on drift-detection methods that produce high computational overhead for resource-constrained environments, and fail to provide strict guarantees on resource usage or theoretical performance assurances. To address these shortcomings, we propose RCCDA: a dynamic model update policy that optimizes ML training dynamics while ensuring strict compliance to predefined resource constraints, utilizing only past loss information and a tunable drift threshold.

319, TITLE: LPASS: Linear Probes As Stepping Stones for Vulnerability Detection Using Compressed LLMs
AUTHORS: Luis Ibanez-Lissen ; Lorena Gonzalez-Manzano ; Jose Maria de Fuentes ; Nicolas Anciaux
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Large Language Models (LLMs) are being extensively used for cybersecurity purposes.

320, TITLE: Domain Pre-training Impact on Representations
AUTHORS: Cesar Gonzalez-Gutierrez ; Ariadna Quattoni
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This empirical study analyzes the effects of the pre-training corpus on the quality of learned transformer representations.

321, TITLE: Towards A Generalizable Bimanual Foundation Policy Via Flow-based Video Prediction
AUTHORS: CHENYOU FAN et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: In this paper, we propose a novel bimanual foundation policy by fine-tuning the leading text-to-video models to predict robot trajectories and training a lightweight diffusion policy for action generation.

322, TITLE: CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation
AUTHORS: EMILIO VILLA-CUEVA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate whether images can act as cultural context in multimodal translation.

323, TITLE: Threading Keyframe with Narratives: MLLMs As Strong Long Video Comprehenders
AUTHORS: Bo Fang ; Wenhao Wu ; Qiangqiang Wu ; Yuxin Song ; Antoni B. Chan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose threading keyframes with narratives (Nar-KFC), a plug-and-play module to facilitate effective and efficient long video perception.

324, TITLE: TumorGen: Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching
AUTHORS: SHENGYUAN LIU et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We present TumorGen, a novel Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching for efficient 3D tumor synthesis with three key components: a Boundary-Aware Pseudo Mask Generation module that replaces strict binary masks with flexible bounding boxes; a Spatial-Constraint Vector Field Estimator that simultaneously synthesizes tumor latents and masks using rectified flow matching to ensure computational efficiency; and a VAE-guided mask refiner that enhances boundary realism.

325, TITLE: BPE Stays on SCRIPT: Structured Encoding for Robust Multilingual Pretokenization
AUTHORS: Sander Land ; Catherine Arnett
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose SCRIPT (Script Category Representation in PreTokenization), a novel encoding scheme that bypasses UTF-8 byte conversion by using initial tokens based on Unicode script and category properties.

326, TITLE: Bootstrapping LLM Robustness for VLM Safety Via Reducing The Pretraining Modality Gap
AUTHORS: Wenhan Yang ; Spencer Stice ; Ali Payani ; Baharan Mirzasoleiman
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we show that the amount of modality gap is highly inversely correlated with VLMs' safety.

327, TITLE: Boosting All-in-One Image Restoration Via Self-Improved Privilege Learning
AUTHORS: Gang Wu ; Junjun Jiang ; Kui Jiang ; Xianming Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Unified image restoration models for diverse and mixed degradations often suffer from unstable optimization dynamics and inter-task conflicts. This paper introduces Self-Improved Privilege Learning (SIPL), a novel paradigm that overcomes these limitations by innovatively extending the utility of privileged information (PI) beyond training into the inference stage.

328, TITLE: Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios
AUTHORS: Gerard I. Gï¿½llego ; Oriol Pareras ; Martï¿½ Cortada Garcia ; Lucas Takanori ; Javier Hernando
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: We propose a Speech-to-Text Translation (S2TT) approach that integrates phoneme representations into a Chain-of-Thought (CoT) framework to improve translation in low-resource and zero-resource settings.

329, TITLE: Learning Reusable Concepts Across Different Egocentric Video Understanding Tasks
AUTHORS: Simone Alberto Peirone ; Francesca Pistilli ; Antonio Alliegro ; Tatiana Tommasi ; Giuseppe Averta
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce Hier-EgoPack, a unified framework able to create a collection of task perspectives that can be carried across downstream tasks and used as a potential source of additional insights, as a backpack of skills that a robot can carry around and use when needed.

330, TITLE: SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors
AUTHORS: TIANLONG YU et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: The dataset supports research in detecting AR-driven SE attacks, designing defensive frameworks, and understanding multimodal adversarial manipulation.

331, TITLE: Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents
AUTHORS: Seungjoon Lee ; Suhwan Kim ; Minhyeon Oh ; Youngsik Yoon ; Jungseul Ok
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Moreover, efficiency is crucial for practicality as learning can demand prohibitive exploration. In response, we introduce Robust and Efficient Planning for Open-world Agents (REPOA), a novel framework designed to tackle these issues.

332, TITLE: Proxy Target: Bridging The Gap Between Discrete Spiking Neural Networks and Continuous Control
AUTHORS: Zijie Xu ; Tong Bu ; Zecheng Hao ; Jianhao Ding ; Zhaofei Yu
CATEGORY: cs.NE [cs.NE, cs.LG]
HIGHLIGHT: We identify that this mismatch destabilizes SNN training in continuous control tasks. To bridge this gap between discrete SNN and continuous control, we propose a novel proxy target framework.

333, TITLE: Beyond The LUMIR Challenge: The Pathway to Foundational Registration Models
AUTHORS: JUNYU CHEN et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Image registration, a foundational task in neuroimaging pipelines, has similarly benefited from the Learn2Reg initiative. Building on this foundation, we introduce the Large-scale Unsupervised Brain MRI Image Registration (LUMIR) challenge, a next-generation benchmark designed to assess and advance unsupervised brain MRI registration.

334, TITLE: LKD-KGC: Domain-Specific KG Construction Via LLM-driven Knowledge Dependency Parsing
AUTHORS: JIAQI SUN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, these methods are constrained by their reliance on manually defined schema, single-document processing, and public-domain references, making them less effective for domain-specific corpora that exhibit complex knowledge dependencies and specificity, as well as limited reference knowledge. To address these challenges, we propose LKD-KGC, a novel framework for unsupervised domain-specific KG construction.

335, TITLE: Training-free Zero-shot 3D Symmetry Detection with Visual Features Back-projected to Geometry
AUTHORS: Isaac Aguirre ; Ivan Sipiran
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present a simple yet effective training-free approach for zero-shot 3D symmetry detection that leverages visual features from foundation vision models such as DINOv2.

336, TITLE: SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking
AUTHORS: YINGJIA XU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address this, we introduce SCENEPERSON-13W, a large-scale dataset featuring over 100,000 scenes with rich annotations covering both pedestrian appearance and environmental cues. Based on this, we propose SA-Person, a two-stage retrieval framework.

337, TITLE: Tag-Evol: Achieving Efficient Instruction Evolving Via Tag Injection
AUTHORS: Yixuan Wang ; Shiqi Zhou ; Chuanzhe Guo ; Qingfu Zhu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In addition, iterative evolution also makes the acquisition of hard samples expensive. In view of this, we propose the Tag-Evol framework, a more diverse and efficient instruction evolving method.

338, TITLE: Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models
AUTHORS: SHILIN XU et. al.
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: There are no works that can leverage multi-source MLLM tasks for stable reinforcement learning. In this work, we present a unified perspective to solve this problem.

339, TITLE: Pretraining Deformable Image Registration Networks with Random Images
AUTHORS: Junyu Chen ; Shuwen Wei ; Yihao Liu ; Aaron Carass ; Yong Du
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Previous work showed that DNNs trained on randomly generated images with carefully designed noise and contrast properties can still generalize well to unseen medical data. Building on this insight, we propose using registration between random images as a proxy task for pretraining a foundation model for image registration.

340, TITLE: When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation
AUTHORS: Daniela Occhipinti ; Marco Guerini ; Malvina Nissim
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While much focus has been placed on aligning dialogues with provided personas, the adaptation to the interlocutor's profile remains largely underexplored. In this work, we investigate three key aspects: (1) a model's ability to align responses with both the provided persona and the interlocutor's; (2) its robustness when dealing with familiar versus unfamiliar interlocutors and topics, and (3) the impact of additional fine-tuning on specific persona-based dialogues.

341, TITLE: Harnessing Large Language Models for Scientific Novelty Detection
AUTHORS: Yan Liu ; Zonglin Yang ; Soujanya Poria ; Thanh-Son Nguyen ; Erik Cambria
CATEGORY: cs.CL [cs.CL, H.4.0]
HIGHLIGHT: In this paper, we propose to harness large language models (LLMs) for scientific novelty detection (ND), associated with two new datasets in marketing and NLP domains.

342, TITLE: Eye of Judgement: Dissecting The Evaluation of Russian-speaking LLMs with POLLUX
AUTHORS: NIKITA MARTYNOV et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce POLLUX, a comprehensive open-source benchmark designed to evaluate the generative capabilities of large language models (LLMs) in Russian.

343, TITLE: Interpretable Phenotyping of Heart Failure Patients with Dutch Discharge Letters
AUTHORS: VITTORIO TORRI et. al.
CATEGORY: cs.CL [cs.CL, cs.LG, 68T50, I.2.7; J.3]
HIGHLIGHT: This study evaluates models for phenotyping HF patients based on left ventricular ejection fraction (LVEF) classes, using structured and unstructured data, assessing performance and interpretability.

344, TITLE: Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation
AUTHORS: Ryota Miyano ; Yuki Arase
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This study proposes a simple yet effective LoRA merge method to achieve LLM adaptation for low-resource language generation tasks.

345, TITLE: DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?
AUTHORS: TIANHONG ZHOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing benchmarks do not systematically evaluate whether these models truly reason like human clinicians or merely imitate superficial patterns. To address this gap, we propose DrVD-Bench, the first multimodal benchmark for clinical visual reasoning.

346, TITLE: Identifying Primary Stress Across Related Languages and Dialects with Transformer-based Speech Encoder Models
AUTHORS: Nikola Ljube?i? ; Ivan Porupski ; Peter Rupnik
CATEGORY: eess.AS [eess.AS, cs.CL, cs.SD]
HIGHLIGHT: In this paper, we investigate the approach of fine-tuning a pre-trained transformer model with an audio frame classification head.

347, TITLE: Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success
AUTHORS: Ben Griffin ; Joseph Ternasky ; Fuat Alican ; Yigit Ihlamur
CATEGORY: cs.AI [cs.AI, cs.LG, I.2.7]
HIGHLIGHT: We present a lightweight ensemble framework that combines YES/NO questions generated by large language models (LLMs), forming a transparent decision-making system.

348, TITLE: Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization
AUTHORS: Utsav Maskey ; Chencheng Zhu ; Usman Naseem
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce a novel benchmark dataset comprising diverse plain texts spanning various domains, lengths, writing styles, and topics paired with their encrypted versions.

349, TITLE: Hyperbolic Dataset Distillation
AUTHORS: Wenyuan Li ; Guang Li ; Keisuke Maeda ; Takahiro Ogawa ; Miki Haseyama
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: However, existing DM methods, constrained to Euclidean space, treat data as independent and identically distributed points, overlooking complex geometric and hierarchical relationships. To overcome this limitation, we propose a novel hyperbolic dataset distillation method, termed HDD.

350, TITLE: Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors
AUTHORS: Duo Zheng ; Shijia Huang ; Yanyang Li ; Liwei Wang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose a novel and efficient method, the Video-3D Geometry Large Language Model (VG LLM).

351, TITLE: NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization
AUTHORS: Hyuntak Kim ; Byung-Hak Kim
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce NexusSum, a multi-agent LLM framework for narrative summarization that processes long-form text through a structured, sequential pipeline--without requiring fine-tuning.

352, TITLE: GATE: General Arabic Text Embedding for Enhanced Semantic Textual Similarity with Matryoshka Representation Learning and Hybrid Loss Training
AUTHORS: OMER NACAR et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces General Arabic Text Embedding (GATE) models that achieve state-of-the-art performance on the Semantic Textual Similarity task within the MTEB benchmark.

353, TITLE: The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models
AUTHORS: Junyi Li ; Hwee Tou Ng
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We theoretically analyze the RL training dynamics, identifying high-variance gradient, entropy-induced randomness, and susceptibility to spurious local optima as key factors leading to hallucinations. To address this drawback, we propose Factuality-aware Step-wise Policy Optimization (FSPO), an innovative RL fine-tuning algorithm incorporating explicit factuality verification at each reasoning step.

354, TITLE: Disentangling Language and Culture for Evaluating Multilingual Large Language Models
AUTHORS: JIAHAO YING et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a Dual Evaluation Framework to comprehensively assess the multilingual capabilities of LLMs.

355, TITLE: NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation
AUTHORS: Xuzhi Wang ; Wei Feng ; Lingdong Kong ; Liang Wan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: (2) it does not well handle the unbalanced point distribution of LiDAR point cloud. In this paper, we propose a non-uniform cylindrical partition network named NUC-Net to tackle the above challenges.

356, TITLE: Category-Level 6D Object Pose Estimation in Agricultural Settings Using A Lattice-Deformation Framework and Diffusion-Augmented Synthetic Data
AUTHORS: Marios Glytsos ; Panagiotis P. Filntisis ; George Retsinas ; Petros Maragos
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce PLANTPose, a novel framework for category-level 6D pose estimation that operates purely on RGB input.

357, TITLE: Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models
AUTHORS: Zahid Hassan Tushar ; Adeleke Ademakinwa ; Jianwu Wang ; Zhibo Zhang ; Sanjay Purushotham
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: These models also introduce substantial errors in COT estimation under different solar and viewing zenith angles. To address these challenges, we propose a novel angle-invariant, attention-based deep model called Cloud-Attention-Net with Angle Coding (CAAC).

358, TITLE: Efficient Text Encoders for Labor Market Analysis
AUTHORS: Jens-Joris Decorte ; Jeroen Van Hautte ; Chris Develder ; Thomas Demeester
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose \textbf{ConTeXT-match}, a novel contrastive learning approach with token-level attention that is well-suited for the extreme multi-label classification task of skill classification.

359, TITLE: AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams
AUTHORS: Sakhinana Sagar Srinivas ; Shivam Gupta ; Venkataramana Runkana
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IR]
HIGHLIGHT: We present a closed loop, physics aware framework for the automated generation of industrially viable PFDs and PIDs.

360, TITLE: Weakly-Supervised Affordance Grounding Guided By Part-Level Semantic Priors
AUTHORS: Peiran Xu ; Yadong Mu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels.

361, TITLE: Training LLMs for EHR-Based Reasoning Tasks Via Reinforcement Learning
AUTHORS: Jiacheng Lin ; Zhenbang Wu ; Jimeng Sun
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present EHRMIND, a practical recipe for adapting large language models (LLMs) to complex clinical reasoning tasks using reinforcement learning with verifiable rewards (RLVR).

362, TITLE: A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning
AUTHORS: Chengzhi Wu ; Qianliang Huang ; Kun Jin ; Julius Pfrommer ; Jï¿½rgen Beyerer
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, for point cloud unsupervised learning without the use of extra training data, we propose a Contrastive Cross-branch Attention-based framework for Point cloud data (termed PoCCA), to learn rich 3D point cloud representations.

363, TITLE: Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching
AUTHORS: JUAN WISZNIA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce a novel framework for analyzing sorting algorithms in pairwise ranking prompting (PRP), re-centering the cost model around LLM inferences rather than traditional pairwise comparisons.

364, TITLE: PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder
AUTHORS: Yiqun Sun ; Qiang Huang ; Anthony K. H. Tung ; Jun Yu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While existing embedding models excel at capturing general meaning, they often overlook ideological nuances, limiting their effectiveness in tasks that require an understanding of political bias. To address this gap, we introduce PRISM, the first framework designed to Produce inteRpretable polItical biaS eMbeddings.

365, TITLE: BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models
AUTHORS: Huu-Thien Tran ; Thanh-Dat Truong ; Khoa Luu
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a new Bijective Maximum Likelihood Learning (BIMA) approach to hallucination mitigation using normalizing flow theories.

366, TITLE: SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition
AUTHORS: Omer Nacar ; Yasser Al-Habashi ; Serry Sibaee ; Adel Ammar ; Wadii Boulila
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing Arabic OCR datasets often focus on isolated words or lines or are limited in scale, typographic variety, or structural complexity found in books. To address this significant gap, we introduce SARD (Large-Scale Synthetic Arabic OCR Dataset).

367, TITLE: Federated Foundation Model for GI Endoscopy Images
AUTHORS: ALINA DEVKOTA et. al.
CATEGORY: cs.CV [cs.CV, cs.LG, I.2.10; I.4; I.5]
HIGHLIGHT: In this work, we propose a FL framework for training foundation models for gastroendoscopy imaging, enabling data to remain within local hospital environments while contributing to a shared model.

368, TITLE: A Flat Minima Perspective on Understanding Augmentations and Model Robustness
AUTHORS: Weebum Yoo ; Sung Whan Yoon
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We offer a unified theoretical framework to clarify how augmentations can enhance model robustness through the lens of loss surface flatness and PAC generalization bound.

369, TITLE: Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis
AUTHORS: JUNZHUO LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Existing attribution methods for dense models fail to capture dynamic routing-expert interactions in sparse MoE architectures. To address this issue, we propose a cross-level attribution algorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE, Mixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mixtral-7B).

370, TITLE: Taxonomic Networks: A Representation for Neuro-Symbolic Pairing
AUTHORS: Zekun Wang ; Ethan L. Haarer ; Nicki Barari ; Christopher J. MacLellan
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We introduce the concept of a \textbf{neuro-symbolic pair} -- neural and symbolic approaches that are linked through a common knowledge representation.

371, TITLE: Model-Guided Network with Cluster-Based Operators for Spatio-Spectral Super-Resolution
AUTHORS: Ivan Pereira-Sï¿½nchez ; Julia Navarro ; Ana Belï¿½n Petro ; Joan Duran
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We propose an end-to-end model-driven framework that explicitly decomposes the joint spatio-spectral super-resolution problem into spatial super-resolution, spectral super-resolution and fusion tasks.

372, TITLE: GARLIC: GAussian Representation LearnIng for SpaCe Partitioning
AUTHORS: PANAGIOTIS RIGAS et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce GARLIC (GAussian Representation LearnIng for spaCe partitioning), a novel indexing structure based on \(N\)-dimensional Gaussians for efficiently learning high-dimensional vector spaces.

373, TITLE: Explainable Depression Detection Using Masked Hard Instance Mining
AUTHORS: Patawee Prakrankamanant ; Shinji Watanabe ; Ekapol Chuangsuwanich
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose the use of Masked Hard Instance Mining (MHIM) to enhance the explainability in the depression detection task.
