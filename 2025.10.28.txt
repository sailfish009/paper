1, TITLE: Revisiting Multimodal Positional Encoding in Vision-Language Models
AUTHORS: Jie Huang; Xuejing Liu; Sibo Song; Ruibing Hou; Hong Chang; Junyang Lin; Shuai Bai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Multimodal position encoding is essential for vision-language models, yetthere has been little systematic investigation into multimodal positionencoding. We conduct a comprehensive analysis of multimodal Rotary PositionalEmbedding (RoPE) by examining its two core components: position design andfrequency allocation.

2, TITLE: Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations
AUTHORS: Yujia Zhang; Xiaoyang Wu; Yixing Lao; Chengyao Wang; Zhuotao Tian; Naiyan Wang; Hengshuang Zhao
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Humans learn abstract concepts through multisensory synergy, and once formed,such representations can often be recalled from a single modality. Inspired bythis principle, we introduce Concerto, a minimalist simulation of human conceptlearning for spatial cognition, combining 3D intra-modal self-distillation with2D-3D cross-modal joint embedding.

3, TITLE: VisCoder2: Building Multi-Language Visualization Coding Agents
AUTHORS: Yuansheng Ni; Songcheng Cai; Xiangchao Chen; Jiarong Liang; Zhiheng Lyu; Jiaqi Deng; Kai Zou; Ping Nie; Fei Yuan; Xiang Yue; Wenhu Chen
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: Abstract: Large language models (LLMs) have recently enabled coding agents capable ofgenerating, executing, and revising visualization code. However, existingmodels often fail in practical ...

4, TITLE: Encoder-Decoder Diffusion Language Models for Efficient Training and Inference
AUTHORS: Marianne Arriola; Yair Schiff; Hao Phung; Aaron Gokaslan; Volodymyr Kuleshov
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose an encoder-decoderarchitecture to accelerate discrete diffusion inference, which relies on anencoder to represent clean tokens and a lightweight decoder to iterativelyrefine a noised sequence.

5, TITLE: Performance Trade-offs of Optimizing Small Language Models for E-Commerce
AUTHORS: Josip Tomo Licardo; Nikola Tankovic
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We present a methodology for optimizing aone-billion-parameter Llama 3.2 model for multilingual e-commerce intentrecognition.

6, TITLE: Scalable Supervising Software Agents with Patch Reasoner
AUTHORS: Junjielong Xu; Boyin Tan; Xiaoyuan Liu; Chao Peng; Pengfei Gao; Pinjia He
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose R4P, a patch verifier model to providescalable rewards for training and testing SWE agents via reasoning.

7, TITLE: Transitive RL: Value Learning Via Divide and Conquer
AUTHORS: Seohong Park; Aditya Oberai; Pranav Atreya; Sergey Levine
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we present Transitive Reinforcement Learning (TRL), a new valuelearning algorithm based on a divide-and-conquer paradigm.

8, TITLE: PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection
AUTHORS: Yusu Qian; Cheng Wan; Chao Jia; Yinfei Yang; Qingyu Zhao; Zhe Gan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce \textbf{PRISM-Bench}, a benchmark of puzzle-based visualchallenges designed to evaluate not only whether models can solve problems, buthow their reasoning unfolds.

9, TITLE: ESCA: Enabling Seamless Codec Avatar Execution Through Algorithm and Hardware Co-Optimization for Virtual Reality
AUTHORS: Mingzhi Zhu; Ding Shang; Sai Qian Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, these models impose significant computationaldemands, making real-time inference challenging on resource-constrained VRdevices such as head-mounted displays, where latency and power efficiency arecritical. To address this challenge, we propose an efficient post-trainingquantization (PTQ) method tailored for Codec Avatar models, enablinglow-precision execution without compromising output quality.

10, TITLE: Frequentist Validity of Epistemic Uncertainty Estimators
AUTHORS: Anchit Jain; Stephen Bates
CATEGORY: arxiv-stat.ML [ML]
HIGHLIGHT: However, evaluating this measure requires access to the posteriordistribution of the model parameters, which is challenging to compute. In viewof this, we introduce a frequentist measure of epistemic uncertainty based onthe bootstrap.

11, TITLE: Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences
AUTHORS: Zhuoran Jin; Hongbang Yuan; Kejian Zhu; Jiachun Li; Pengfei Cao; Yubo Chen; Kang Liu; Jun Zhao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To address the abovechallenges, we propose Omni-Reward, a step toward generalist omni-modal rewardmodeling with support for free-form preferences, consisting of: (1) Evaluation:We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-formpreferences, covering nine tasks across five modalities including text, image,video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodalpreference dataset comprising 248K general preference pairs and 69Kinstruction-tuning pairs for training generalist omni-modal RMs; (3) Model: Wepropose Omni-RewardModel, which includes both discriminative and generativeRMs, and achieves strong performance on Omni-RewardBench as well as otherwidely used reward modeling benchmarks.

12, TITLE: Code Aesthetics with Agentic Reward Feedback
AUTHORS: Bang Xiao; Lingjie Jiang; Shaohan Huang; Tengchao Lv; Yupan Huang; Xun Wu; Lei Cui; Furu Wei
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we introduce a newpipeline to enhance the aesthetic quality of LLM-generated code.

13, TITLE: Towards Stable and Effective Reinforcement Learning for Mixture-of-Experts
AUTHORS: Di Zhang; Xun Wu; Shaohan Huang; Yaru Hao; Li Dong; Zewen Chi; Zhifang Sui; Furu Wei
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To address the instability commonlyobserved in MoE training, we propose a novel router-aware approach to optimizeimportance sampling (IS) weights in off-policy RL.

14, TITLE: CHOIR: Collaborative Harmonization FOr Inference Robustness
AUTHORS: Xiangjue Dong; Cong Wang; Maria Teleki; Millennium Bismay; James Caverlee
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Persona-assigned Large Language Models (LLMs) can adopt diverse roles,enabling personalized and context-aware reasoning.

15, TITLE: RobotArena $\infty$: Scalable Robot Benchmarking Via Real-to-Sim Translation
AUTHORS: Yash Jangir; Yidi Zhang; Kashu Yamazaki; Chenyu Zhang; Kuan-Hsun Tu; Tsung-Wei Ke; Lei Ke; Yonatan Bisk; Katerina Fragkiadaki
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Existing simulation benchmarks are similarly limited, as they trainand test policies within the same synthetic domains and cannot assess modelstrained from real-world demonstrations or alternative simulation environments.As policies expand in scope and complexity, these barriers only intensify,since defining "success" in robotics often hinges on nuanced human judgments ofexecution quality. In this paper, we introduce a new benchmarking frameworkthat overcomes these challenges by shifting VLA evaluation into large-scalesimulated environments augmented with online human feedback.

16, TITLE: A Survey of AI Scientists: Surveying The Automatic Scientists and Research
AUTHORS: Guiyao Tie; Pan Zhou; Lichao Sun
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: Artificial intelligence is undergoing a profound transition from acomputational instrument to an autonomous originator of scientific knowledge.This emerging paradigm, the AI ...

17, TITLE: BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents
AUTHORS: Litu Ou; Kuan Li; Huifeng Yin; Liwen Zhang; Zhongwang Zhang; Xixi Wu; Rui Ye; Zile Qiao; Yong Jiang; Pengjun Xie; Fei Huang; Jingren Zhou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Experimenting on open-sourceagentic models, we first find that models exhibit much higher task accuracy athigh confidence while having near-zero accuracy when confidence is low. Basedon this observation, we propose Test-Time Scaling (TTS) methods that useconfidence scores to determine answer quality, encourage the model to try againuntil reaching a satisfactory confidence level.

18, TITLE: EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting
AUTHORS: Musleh Alharthi; Kaleel Mahmood; Sarosh Patel; Ausif Mahmood
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: One of the challenges in forecasting is the fact that TSF data favors the more recent past, and is sometimes subject to unpredictable events. Based upon these recent insights in TSF, we propose a strong Mixture of Experts (MoE) framework.

19, TITLE: CoMo: Compositional Motion Customization for Text-to-Video Generation
AUTHORS: Youcan Xu; Zhen Wang; Jiaxin Shi; Kexin Li; Feifei Shao; Jun Xiao; Yi Yang; Jun Yu; Long Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Although methods for single-motion customization have been developedto address this gap, they fail in compositional scenarios due to two primarychallenges: motion-appearance entanglement and ineffective multi-motionblending. This paper introduces CoMo, a novel framework for$\textbf{compositional motion customization}$ in text-to-video generation,enabling the synthesis of multiple, distinct motions within a single video.CoMo addresses these issues through a two-phase approach.

20, TITLE: ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding The Curse of Multilinguality
AUTHORS: Shayne Longpre; Sneha Kudugunta; Niklas Muennighoff; I-Hung Hsu; Isaac Caswell; Alex Pentland; Sercan Arik; Chen-Yu Lee; Sayna Ebrahimi
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Scaling laws research has focused overwhelmingly on English -- yet the mostprominent AI models explicitly serve billions of international users.

21, TITLE: Rethinking The Text-Vision Reasoning Imbalance in MLLMs Through The Lens of Training Recipes
AUTHORS: Guanyu Yao; Qiucheng Wu; Yang Zhang; Zhaowen Wang; Handong Zhao; Shiyu Chang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we analyze the modalitygap through the lens of training recipes.

22, TITLE: AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines
AUTHORS: Abolfazl Younesi; Zahra Najafabadi Samani; Thomas Fahringer
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we present AutoStreamPipe, a novelframework that employs Large Language Models (LLMs) to automate the design,generation, and deployment of stream processing pipelines.

23, TITLE: Robust Decision Making with Partially Calibrated Forecasts
AUTHORS: Shayan Kiyani; Hamed Hassani; George Pappas; Aaron Roth
CATEGORY: arxiv-stat.ML [ML]
HIGHLIGHT: For higher dimensionalprediction problems (e.g. when outcomes are multiclass), weaker forms ofcalibration have been studied that lack these decision theoretic properties. Inthis paper we study how a conservative decision maker should map predictionsendowed with these weaker (``partial'') calibration guarantees to actions, in away that is robust in a minimax sense: i.e. to maximize their expected utilityin the worst case over distributions consistent with the calibrationguarantees.

24, TITLE: LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation
AUTHORS: Zeyu Wang; Zilong Chen; Chenhui Gou; Feng Li; Chaorui Deng; Deyao Zhu; Kunchang Li; Weihao Yu; Haoqin Tu; Haoqi Fan; Cihang Xie
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we showthat competitive performance can be obtained far more efficiently bystrategically fusing publicly available models specialized for eithergeneration or understanding.

25, TITLE: TraceTrans: Translation and Spatial Tracing for Surgical Prediction
AUTHORS: Xiyu Luo; Haodong LI; Xinxing Cheng; He Zhao; Yang Hu; Xuan Song; Tianyang Zhang
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: In this work, we presentTraceTrans, a novel deformable image translation model designed forpost-operative prediction that generates images aligned with the targetdistribution while explicitly revealing spatial correspondences with thepre-operative input.

26, TITLE: DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration Training for Text-to-SQL Model
AUTHORS: Yuanzhen Xie; Liu Ye; Jiqun Chu; Mochi Gao; Hehuan Liu; Yunzhi Tan; Bo Hu; Zang Li
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we systemically design a fully automateddata-centric pipeline for text-to-SQL tasks, including \emph{adaptive datarepair}, which can automatically find and fix errors in the training dataset;and \emph{error data augmentation}, where we specifically diffuse and enhanceerroneous data predicted by the initially trained models.

27, TITLE: How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations
AUTHORS: Zora Zhiruo Wang; Yijia Shao; Omar Shaikh; Daniel Fried; Graham Neubig; Diyi Yang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work, we study how agents do human work bypresenting the first direct comparison of human and agent workers acrossmultiple essential work-related skills: data analysis, engineering,computation, writing, and design.

28, TITLE: A Survey of Data Agents: Emerging Paradigm or Overstated Hype?
AUTHORS: Yizhang Zhu; Liangwei Wang; Chenyu Yang; Xiaotian Lin; Boyan Li; Wei Zhou; Xinyu Liu; Zhangyang Peng; Tianqi Luo; Yu Li; Chengliang Chai; Chong Chen; Shimin Di; Ju Fan; Ji Sun; Nan Tang; Fugee Tsung; Jiannan Wang; Chenglin Wu; Yanwei Xu; Shaolei Zhang; Yong Zhang; Xuanhe Zhou; Guoliang Li; Yuyu Luo
CATEGORY: arxiv-cs.DB [DB]
HIGHLIGHT: This terminological ambiguity fosters mismatched userexpectations, accountability challenges, and barriers to industry growth.Inspired by the SAE J3016 standard for driving automation, this surveyintroduces the first systematic hierarchical taxonomy for data agents,comprising six levels that delineate and trace progressive shifts in autonomy,from manual operations (L0) to a vision of generative, fully autonomous dataagents (L5), thereby clarifying capability boundaries and responsibilityallocation. Through this lens, we offer a structured review of existingresearch arranged by increasing autonomy, encompassing specialized data agentsfor data management, preparation, and analysis, alongside emerging effortstoward versatile, comprehensive systems with enhanced autonomy.

29, TITLE: GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation
AUTHORS: Karim Elmaaroufi; Liheng Lai; Justin Svegliato; Yutong Bai; Sanjit A. Seshia; Matei Zaharia
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present GRAID, built on the keyinsight that qualitative spatial relationships can be reliably determined from2D geometric primitives alone.

30, TITLE: On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner and MAVEN Dataset
AUTHORS: Vishvesh Bhat; Omkar Ghugarkar; Julian McAuley
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Our resultsshow that most current models achieve below 50% accuracy on MAVEN, revealing asignificant generalization gap across tool-use settings. To address this, we present the CoreThink Agentic Reasoner, a framework thataugments LLMs with a lightweight symbolic reasoning layer for structureddecomposition and adaptive tool orchestration.

31, TITLE: Parallel Sampling from Masked Diffusion Models Via Conditional Independence Testing
AUTHORS: Iskander Azangulov; Teodora Pandeva; Niranjani Prasad; Javier Zazo; Sushrut Karmalkar
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: These goals conflict because high-confidence predictions oftencluster and depend on each other, opportunities for parallel updates. We present PUNT, a model-agnostic sampler that reconciles this trade-off.

32, TITLE: Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)
AUTHORS: Liwei Jiang; Yuanjun Chai; Margaret Li; Mickel Liu; Raymond Fok; Nouha Dziri; Yulia Tsvetkov; Maarten Sap; Alon Albalak; Yejin Choi
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce Infinity-Chat, a large-scale dataset of 26K diverse,real-world, open-ended user queries that admit a wide range of plausibleanswers with no single ground truth.

33, TITLE: Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems
AUTHORS: Kaushal Kumar Maurya; Ekaterina Kochmar
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we take a step back from mainstream ITSdevelopment and provide comprehensive state-of-the-art evaluation practices,highlighting associated challenges through real-world case studies from carefuland caring AIED research.

34, TITLE: Can Language Models Compose Skills In-Context?
AUTHORS: Zidong Liu; Zhuoyan Xu; Zhenmei Shi; Yingyu Liang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Thisinspires a method for the probing tasks, whose improved performance providespositive support for our insights.

35, TITLE: IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction
AUTHORS: Hao Li; Zhengyu Zou; Fangfu Liu; Xuanyang Zhang; Fangzhou Hong; Yukang Cao; Yushi Lan; Manyuan Zhang; Gang Yu; Dingwen Zhang; Ziwei Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, most prior approaches prioritizetraining large geometry models for low-level 3D reconstruction and treathigh-level spatial understanding in isolation, overlooking the crucialinterplay between these two fundamental aspects of 3D-scene analysis, therebylimiting generalization and leading to poor performance in downstream 3Dunderstanding tasks. Recent attempts have mitigated this issue by simplyaligning 3D models with specific language models, thus restricting perceptionto the aligned model's capacity and limiting adaptability to downstream tasks.In this paper, we propose InstanceGrounded Geometry Transformer (IGGT), anend-to-end large unified transformer to unify the knowledge for both spatialreconstruction and instance-level contextual understanding.

36, TITLE: Normalization in Attention Dynamics
AUTHORS: Nikita Karagodin; Shu Ge; Yury Polyanskiy; Philippe Rigollet
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Modeling their evolution as interacting particles on the sphere,we show that normalization acts as a form of speed regulation.

37, TITLE: Increasing LLM Coding Capabilities Through Diverse Synthetic Coding Tasks
AUTHORS: Amal Abed; Ivan Lukic; Jörg K. H. Franke; Frank Hutter
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Mostexisting resources pair problems with solutions, but omit the intermediatethought process that guides coding. To close this gap, we present a scalablesynthetic data generation pipeline that produces nearly 800kinstruction-reasoning-code-test quadruplets.

38, TITLE: LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation
AUTHORS: Md Mostafijur Rahman; Radu Marculescu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: U-shaped networks output logits at multiple spatial scales, each capturing adifferent blend of coarse context and fine detail. Yet, training still treatsthese logits in isolation ...

39, TITLE: An Efficient Remote Sensing Super Resolution Method Exploring Diffusion Priors and Multi-Modal Constraints for Crop Type Mapping
AUTHORS: Songxi Yang; Tang Sui; Qunying Huang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Inthis study, we present a efficient LSSR framework for RSSR, supported by a newmultimodal dataset of paired 30 m Landsat 8 and 10 m Sentinel 2 imagery.

40, TITLE: EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT
AUTHORS: Baoqi Pei; Yifei Huang; Jilan Xu; Yuping He; Guo Chen; Fei Wu; Yu Qiao; Jiangmiao Pang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To bridge thisgap, we introduce EgoThinker, a novel framework that endows MLLMs with robustegocentric reasoning capabilities through spatio-temporal chain-of-thoughtsupervision and a two-stage learning curriculum.

41, TITLE: More Than Generation: Unifying Generation and Depth Estimation Via Text-to-Image Diffusion Models
AUTHORS: Hongkai Lin; Dingkang Liang; Mingyang Du; Xin Zhou; Xiang Bai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Specifically, MERGE introduces a play-and-plug framework that enables seamless switching between image generation anddepth estimation modes through simple and pluggable converters.

42, TITLE: Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports
AUTHORS: Alois Thomas; Maya Varma; Jean-Benoit Delbrouck; Curtis P. Langlotz
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Existing hallucination detectionmethods frequently lack the necessary sentence-level granularity or robustgeneralization across different LVLM generators. We introduce a novel approach:a sentence-level Process Reward Model (PRM) adapted for this vision-languagetask.

43, TITLE: Once Upon An Input: Reasoning Via Per-Instance Program Synthesis
AUTHORS: Adam Stein; Neelay Velingker; Mayur Naik; Eric Wong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce Per-Instance Program Synthesis(PIPS), a method that generates and refines programs at the instance-levelusing structural feedback without relying on task-specific guidance or explicittest cases.

44, TITLE: SteerX: Disentangled Steering for LLM Personalization
AUTHORS: Xiaoyan Zhao; Ming Yan; Yilun Qiu; Haoting Ni; Yang Zhang; Fuli Feng; Hong Cheng; Tat-Seng Chua
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However,existing methods rely on all historical data to compute the steering vector,ignoring that not all content reflects true user preferences, which underminesthe personalization signal. To address this, we propose SteerX, a disentangledsteering method that isolates preference-driven components frompreference-agnostic components.

45, TITLE: RoGBot: Relationship-Oblivious Graph-based Neural Network with Contextual Knowledge for Bot Detection
AUTHORS: Ashutosh Anshul; Mohammad Zia Ur Rehman; Sri Akash Kadali; Nagendra Kumar
CATEGORY: arxiv-cs.SI [SI]
HIGHLIGHT: This reliance limits theirapplicability in scenarios where such information is unavailable. To addressthis limitation, we propose a novel multimodal framework that integratesdetailed textual features with enriched user metadata while employinggraph-based reasoning without requiring follower-following data.

46, TITLE: ConMatFormer: A Multi-attention and Transformer Integrated ConvNext Based Deep Learning Model for Enhanced Diabetic Foot Ulcer Classification
AUTHORS: Raihan Ahamed Rifat; Fuyad Hasan Bhoyan; Md Humaion Kabir Mehedi; Md Kaviul Hossain; Md. Jakir Hossen; M. F. Mridha
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Diabetic foot ulcer (DFU) detection is a clinically significant yetchallenging task due to the scarcity and variability of publicly availabledatasets. To solve these problems, we propose ConMatFormer, a new hybrid deeplearning architecture that combines ConvNeXt blocks, multiple attentionmechanisms convolutional block attention module (CBAM) and dual attentionnetwork (DANet), and transformer modules in a way that works together.

47, TITLE: Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics
AUTHORS: Yilin Zhang; Wenda Xu; Zhongtao Liu; Tetsuji Nakagawa; Markus Freitag
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: These inherent length biases risk unfairlypenalizing longer, correct translations and can lead to sub-optimaldecision-making in applications such as QE reranking and QE guidedreinforcement learning. To mitigate this, we propose two strategies: (a)applying length normalization during model training, and (b) incorporatingreference texts during evaluation.

48, TITLE: ReCode: Unify Plan and Action for Universal Granularity Control
AUTHORS: Zhaoyang Yu; Jiayi Zhang; Huixue Su; Yufan Zhao; Yifan Wu; Mingyi Deng; Jinyu Xiang; Yizhang Lin; Lingxiao Tang; Yingchao Li; Yuyu Luo; Bang Liu; Chenglin Wu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Extensive experiments show ReCode significantlysurpasses advanced baselines in inference performance and demonstratesexceptional data efficiency in training, validating our core insight thatunifying planning and action through recursive code generation is a powerfuland effective approach to achieving universal granularity control.

49, TITLE: VOLD: Reasoning Transfer from LLMs to Vision-Language Models Via On-Policy Distillation
AUTHORS: Walid Bousselham; Hilde Kuehne; Cordelia Schmid
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Conversely, text-based reasoning resources are abundant and scalable, butit is still an open question how to leveraging them for VLM reasoning. Toaddress this problem, we propose VOLD, a framework to transfer reasoningcapabilities from text-only teacher models to VLM student models.

50, TITLE: Alita-G: Self-Evolving Generative Agent for Agent Generation
AUTHORS: Jiahao Qiu; Xuan Qi; Hongru Wang; Xinzhe Juan; Yimin Wang; Zelin Zhao; Jiayi Geng; Jiacheng Guo; Peihang Li; Jingzhe Shi; Shilong Liu; Mengdi Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Beyond this,self-evolving agents have emerged, but current work largely limits adaptationto prompt rewriting or failure retries. Therefore, we present ALITA-G, aself-evolution framework that transforms a general-purpose agent into a domainexpert by systematically generating, abstracting, and curating Model ContextProtocol (MCP) tools.

51, TITLE: MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion
AUTHORS: Haoyi Qiu; Yilun Zhou; Pranav Narayanan Venkit; Kung-Hsiang Huang; Jiaxin Zhang; Nanyun Peng; Chien-Sheng Wu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce MMPersuade, aunified framework for systematically studying multimodal persuasion dynamics inLVLMs.

52, TITLE: Sprint: Sparse-Dense Residual Fusion for Efficient Diffusion Transformers
AUTHORS: Dogyun Park; Moayed Haji-Ali; Yanyu Li; Willi Menapace; Sergey Tulyakov; Hyunwoo J. Kim; Aliaksandr Siarohin; Anil Kag
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present SPRINT, Sparse--DenseResidual Fusion for Efficient Diffusion Transformers, a simple method thatenables aggressive token dropping (up to 75%) while preserving quality.

53, TITLE: Combining Deep Learning and Explainable AI for Toxicity Prediction of Chemical Compounds
AUTHORS: Eduard Popescu; Adrian Groza; Andreea Cernat
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This research introduces a novel image-based pipeline based on DenseNet121,which processes 2D graphical representations of chemical structures.Additionally, we employ Grad-CAM visualizations, an explainable AI technique,to interpret the model's predictions and highlight molecular regionscontributing to toxicity classification.

54, TITLE: Agentic Reinforcement Learning for Real-World Code Repair
AUTHORS: Siyu Zhu; Anastasiya Karpovich; Albert Chen; Jessica Koscheka; Shailesh Jannu; Di Wen; Yuqing Zhu; Rohit Jain; Alborz Geramifard
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We tackle the challenge of training reliable code-fixing agents in realrepositories, where complex builds and shifting dependencies make evaluationunstable.

55, TITLE: Online Optimization for Offline Safe Reinforcement Learning
AUTHORS: Yassine Chemingui; Aryan Deshwal; Alan Fern; Thanh Nguyen-Tang; Janardhan Rao Doppa
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose a novel OSRL approach that frames the problem as aminimax objective and solves it by combining offline RL with onlineoptimization algorithms.

56, TITLE: Probing Knowledge Holes in Unlearned LLMs
AUTHORS: Myeongseob Ko; Hoang Anh Just; Charles Fleming; Ming Jin; Ruoxi Jia
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To probe where unlearned models reveal knowledge holes, we proposea test case generation framework that explores both immediate neighbors ofunlearned content and broader areas of potential failures.

57, TITLE: A Comprehensive Dataset for Human Vs. AI Generated Text Detection
AUTHORS: Rajarshi Roy; Nasrin Imanpour; Ashhar Aziz; Shashwat Bajpai; Gurpreet Singh; Shwetangshu Biswas; Kapil Wanaskar; Parth Patwa; Subhankar Ghosh; Shreyas Dixit; Nilesh Ranjan Pal; Vipula Rawte; Ritvik Garimella; Gaytri Jena; Amit Sheth; Vasu Sharma; Aishwarya Naresh Reganti; Vinija Jain; Aman Chadha; Amitava Das
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we present acomprehensive dataset comprising over 58,000 text samples that combineauthentic New York Times articles with synthetic versions generated by multiplestate-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B,Yi-Large, and GPT-4-o.

58, TITLE: Efficient Utility-Preserving Machine Unlearning with Implicit Gradient Surgery
AUTHORS: Shiji Zhou; Tianbai Yu; Zhi Zhang; Heng Chang; Xiao Zhou; Dong Wu; Han Zhao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To resolve theadditional computational cost brought by gradient surgery, we propose animplicit gradient surgery method, which approximates the solution to theaforementioned constrained optimization problem via only one backpropagation,thereby achieving efficient utility-preserving MU.

59, TITLE: PACR: Progressively Ascending Confidence Reward for LLM Reasoning
AUTHORS: Eunseop Yoon; Hee Suk Yoon; Jaehyun Jang; SooHwan Eom; Qi Dai; Chong Luo; Mark A. Hasegawa-Johnson; Chang D. Yoo
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We propose ProgressivelyAscending Confidence Reward (PACR), a dense, model-intrinsic reward computeddirectly from the model's evolving belief in the correct answer.

60, TITLE: Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation
AUTHORS: Junyoung Seo; Rodrigo Mira; Alexandros Haliassos; Stella Bounareli; Honglie Chen; Linh Tran; Seungryong Kim; Zoe Landgraf; Jie Shen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To addressthis, we propose Lookahead Anchoring, which leverages keyframes from futuretimesteps ahead of the current generation window, rather than within it.

61, TITLE: IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering
AUTHORS: Jieyong Kim; Maryam Amirizaniani; Soojin Yoon; Dongha Lee
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Since users do not explicitly state their prioritizedintents, we derive core intents from observable behavior patterns in answerselection, grounded in satisficing theory where users choose answers meetingtheir acceptance thresholds.

62, TITLE: PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming
AUTHORS: Zhaoming Hu; Ruikang Zhong; Xidong Mu; Dengao Li; Yuanwei Liu
CATEGORY: arxiv-eess.SP [SP]
HIGHLIGHT: We formulate a network latencyminimization problem to joint optimize uplink PASS beamforming and taskoffloading.

63, TITLE: GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching Via Regulated Clipping
AUTHORS: Jing Wang; Jiajun Liang; Jie Liu; Henglin Liu; Gongye Liu; Jun Zheng; Wanyuan Pang; Ao Ma; Zhenyu Xie; Xintao Wang; Meng Wang; Pengfei Wan; Xiaodan Liang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our method incorporates ratio normalization, which restores abalanced and step-consistent importance ratio, ensuring that PPO clippingproperly constrains harmful updates across denoising timesteps.

64, TITLE: Personal Care Utility (PCU): Building The Health Infrastructure for Everyday Insight and Guidance
AUTHORS: Mahyar Abbasian; Ramesh Jain
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Building on decades of success in digital infrastructure and biomedicalinnovation, we propose the Personal Care Utility (PCU) - a cybernetic systemfor lifelong health guidance.

65, TITLE: Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMS
AUTHORS: Umberto Cappellazzo; Stavros Petridis; Maja Pantic
CATEGORY: arxiv-eess.AS [AS]
HIGHLIGHT: In natural language processing, recent work hasrevealed attention sinks, tokens that attract disproportionately highattention, and associated massive activations in which some features of sinktokens exhibit huge activation in LLMs. In this work, we are the first to studythese phenomena in multimodal speech recognition.

66, TITLE: M4FC: A Multimodal, Multilingual, Multicultural, Multitask Real-World Fact-Checking Dataset
AUTHORS: Jiahui Geng; Jonathan Tonglet; Iryna Gurevych
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We provide baseline results for all tasks and analyze how combiningintermediate tasks influence downstream verdict prediction performance.

67, TITLE: DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry
AUTHORS: Changti Wu; Shijie Lian; Zihao Liu; Lei Zhang; Laurence Tianruo Yang; Kai Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Constructed through a semi-automatic annotation pipeline, DynaSolidGeocontains 503 expert-curated seed questions that can, in principle, dynamicallygenerate an unbounded number of diverse multimodal text-visual instances.Beyond answer accuracy, we incorporate process evaluation based onexpert-annotated reasoning chains to measure logical validity and causalcoherence.

68, TITLE: Towards Generalisable Foundation Models for 3D Brain MRI
AUTHORS: Moona Mazher; Geoff J. M. Parker; Daniel C. Alexander
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce BrainFound, a self-supervisedfoundation model for brain MRI, built by extending DINO-v2, a visiontransformer originally designed for 2D natural images.

69, TITLE: LooGLE V2: Are LLMs Ready for Real World Long Dependency Challenges?
AUTHORS: Ziyuan He; Yuxuan Wang; Jiaqi Li; Kexin Liang; Muhan Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we introduce LooGLE v2, a novel benchmarkdesigned to evaluate LLMs' long context ability in real-world applications andscenarios.

70, TITLE: AutoBench: Automating LLM Evaluation Through Reciprocal Peer Assessment
AUTHORS: Dario Loi; Elena Maria Muià; Federico Siciliano; Giovanni Trappolini; Vincenzo Crisà; Peter Kruger; Fabrizio Silvestri
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present AutoBench, a fully automated and self-sustaining framework forevaluating Large Language Models (LLMs) through reciprocal peer assessment.This paper provides a rigorous scientific validation of the AutoBenchmethodology, originally developed as an open-source project by eZecute S.R.L..

71, TITLE: Toward Robust Signed Graph Learning Through Joint Input-Target Denoising
AUTHORS: Junran Wu; Beng Chin Ooi; Ke Xu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Different from the basicGIB, we extend the GIB theory with the capability of target space denoising asthe co-existence of noise in both input and target spaces.

72, TITLE: Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents
AUTHORS: Zihao Wang; Xujing Li; Yining Ye; Junjie Fang; Haoming Wang; Longxiang Liu; Shihao Liang; Junting Lu; Zhiyong Wu; Jiazhan Feng; Wanjun Zhong; Zili Li; Yu Wang; Yu Miao; Bo Zhou; Yuanfan Li; Hao Wang; Zhongkai Zhao; Faming Wu; Zhengxuan Jiang; Weihao Tan; Heyuan Yao; Shi Yan; Xiangyang Li; Yitao Liang; Yujia Qin; Guang Shi
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We present Game-TARS, a generalist game agent trained with a unified,scalable action space anchored to human-aligned native keyboard-mouse inputs.Unlike API- or GUI-based approaches, this paradigm enables large-scalecontinual pre-training across heterogeneous domains, including OS, web, andsimulation games.

73, TITLE: VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations
AUTHORS: Yupeng Xie; Zhiyang Zhang; Yifan Wu; Sirong Lu; Jiayi Zhang; Zhaoyang Yu; Jinlin Wang; Sirui Hong; Bang Liu; Chenglin Wu; Yuyu Luo
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, evaluating visualization quality ischallenging: unlike natural images, it requires simultaneous judgment acrossdata encoding accuracy, information expressiveness, and visual aesthetics.Although multimodal large language models (MLLMs) have shown promisingperformance in aesthetic assessment of natural images, no systematic benchmarkexists for measuring their capabilities in evaluating visualizations. Toaddress this, we propose VisJudge-Bench, the first comprehensive benchmark forevaluating MLLMs' performance in assessing visualization aesthetics andquality.

74, TITLE: Residual Diffusion Bridge Model for Image Restoration
AUTHORS: Hebaixu Wang; Jing Zhang; Haoyang Chen; Haonan Guo; Di Wang; Jiayi Ma; Bo Du
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Besides,they indiscriminately reconstruct images through global noise injection andremoval, inevitably distorting undegraded regions due to imperfectreconstruction. To address these challenges, we propose the Residual DiffusionBridge Model (RDBM).

75, TITLE: Accelerating Materials Design Via LLM-Guided Evolutionary Search
AUTHORS: Nikhil Abhyankar; Sanchit Kabra; Saaketh Desai; Chandan K. Reddy
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We present LLM-guidedEvolution for MAterials design (LLEMA), a unified framework that couples thescientific knowledge embedded in large language models with chemistry-informedevolutionary rules and memory-based refinement.

76, TITLE: Group Size Effects and Collective Misalignment in LLM Multi-agent Systems
AUTHORS: Ariel Flint; Luca Maria Aiello; Romualdo Pastor-Satorras; Andrea Baronchelli
CATEGORY: arxiv-cs.MA [MA]
HIGHLIGHT: Abstract: Multi-agent systems of large language models (LLMs) are rapidly expandingacross domains, introducing dynamics not captured by single-agent evaluations.Yet, existing work has ...

77, TITLE: GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation
AUTHORS: Juepeng Zheng; Peifeng Zhang; Yibin Wen; Qingmei Li; Yang Zhang; Haohuan Fu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, weexplore a more practical and challenging setting, named Multi-Source ActiveDomain Adaptation (MS-ADA), to further enhance target-domain performance byselectively acquiring annotations from the target domain.

78, TITLE: Multi-Task Surrogate-Assisted Search with Bayesian Competitive Knowledge Transfer for Expensive Optimization
AUTHORS: Yi Lu; Xiaoming Xue; Kai Zhang; Liming Zhang; Guodong Chen; Chenming Cao; Piyang Liu; Kay Chen Tan
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: Considering the above, this paper introducesa Bayesian competitive knowledge transfer (BCKT) method developed to improvemulti-task SAS (MSAS) when addressing multiple EOPs simultaneously.Specifically, the transferability of knowledge is estimated from a Bayesianperspective that accommodates both prior beliefs and empirical evidence,enabling accurate competition between inner-task and inter-task solutions,ultimately leading to the adaptive use of promising solutions while effectivelysuppressing inferior ones. The effectiveness of our method in boosting variousSAS algorithms for both multi-task and many-task problems is empiricallyvalidated, complemented by comparative studies that demonstrate its superiorityover peer algorithms and its applicability to real-world scenarios.

79, TITLE: Emotion-Coherent Reasoning for Multimodal LLMs Via Emotional Rationale Verifier
AUTHORS: Hyeongseop Rha; Jeong Hun Yeo; Yeonju Kim; Yong Man Ro
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To addressthis, we propose a novel approach: the Emotional Rationale Verifier (ERV) andan Explanation Reward.

80, TITLE: Leveraging Hierarchical Organization for Medical Multi-document Summarization
AUTHORS: Yi-Li Hsu; Katelyn X. Mei; Lucy Lu Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We investigate two ways ofincorporating hierarchical organization across three large language models(LLMs), and conduct comprehensive evaluations of the resulting summaries usingautomated metrics, model-based metrics, and domain expert evaluation ofpreference, understandability, clarity, complexity, relevance, coverage,factuality, and coherence.

81, TITLE: QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture
AUTHORS: Shvetank Prakash; Andrew Cheng; Arya Tschand; Mark Mazumder; Varun Gohil; Jeffrey Ma; Jason Yik; Zishen Wan; Jessica Quaye; Elisavet Lydia Alvanaki; Avinash Kumar; Chandrashis Mazumdar; Tuhin Khare; Alexander Ingare; Ikechukwu Uchendu; Radhika Ghosal; Abhishek Tyagi; Chenyu Wang; Andrea Mattia Garavagno; Sarah Gu; Alice Guo; Grace Hur; Luca Carloni; Tushar Krishna; Ankita Nayak; Amir Yazdanbakhsh; Vijay Janapa Reddi
CATEGORY: arxiv-cs.AR [AR]
HIGHLIGHT: To this end, we present QuArch(pronounced 'quark'), the first benchmark designed to facilitate thedevelopment and evaluation of LLM knowledge and reasoning capabilitiesspecifically in computer architecture.

82, TITLE: WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models
AUTHORS: Issa Sugiura; Shuhei Kurita; Yusuke Oda; Daisuke Kawahara; Yasuo Okabe; Naoaki Okazaki
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, weintroduce WAON, a large-scale and high-quality Japanese image-text pair datasetcontaining approximately 155 million examples, collected from Common Crawl.

83, TITLE: Strategies for Robust Deep Learning Based Deformable Registration
AUTHORS: Joel Honkamaa; Pekka Marttinen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: LUMIR brainregistration challenge for Learn2Reg 2025 aims to advance the field byevaluating the performance of the registration on contrasts and modalitiesdifferent from those included in the training set. Here we describe oursubmission to the challenge, which proposes a very simple idea forsignificantly improving robustness by transforming the images into MIND featurespace before feeding them into the model.

84, TITLE: LimRank: Less Is More for Reasoning-Intensive Information Reranking
AUTHORS: Tingyu Song; Yilun Zhao; Siyue Zhang; Chen Zhao; Arman Cohan
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In thiswork, we demonstrate that modern LLMs can be effectively adapted using onlyminimal, high-quality supervision.

85, TITLE: Through The Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions
AUTHORS: Razaib Tariq; Minji Heo; Simon S. Woo; Shahroz Tariq
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Byintroducing the DMF dataset, we aim to drive future research toward closing thegap between controlled experiments and practical deepfake detection.

86, TITLE: PromptReverb: Multimodal Room Impulse Response Generation Through Latent Rectified Flow Matching
AUTHORS: Ali Vosoughi; Yongyi Zang; Qihui Yang; Nathan Peak; Randal Leistikow; Chenliang Xu
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Current methods suffer fromtwo fundamental limitations: the scarcity of full-band RIR datasets and theinability of existing models to generate acoustically accurate responses fromdiverse input modalities. We present PromptReverb, a two-stage generativeframework that addresses these challenges.

87, TITLE: From Slides to Chatbots: Enhancing Large Language Models with University Course Materials
AUTHORS: Tu Anh Dinh; Philipp Nicolas Schumacher; Jan Niehues
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Oneapplication of LLMs is to support student learning in educational settings.However, prior work has shown that LLMs still struggle to answer questionsaccurately within university-level computer science courses. In this work, weinvestigate how incorporating university course materials can enhance LLMperformance in this setting.

88, TITLE: Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication
AUTHORS: Yujie Wan; Chenxuan Liu; Shuai Wang; Tong Zhang; James Jianqiao Yu; Kejiang Ye; Dusit Niyato; Chengzhong Xu
CATEGORY: arxiv-cs.IT [IT]
HIGHLIGHT: To this end, we proposeintegrated rendering and communication (IRAC), which jointly optimizescollaboration status (i.e., deciding whether to engage large GS) and edge powerallocation (i.e., enabling remote rendering) under communication constraintsacross different users by minimizing a newly-derived GS switching function.Despite the nonconvexity of the problem, we propose an efficient penaltymajorization minimization (PMM) algorithm to obtain the critical pointsolution.

89, TITLE: MR-Align: Meta-Reasoning Informed Factuality Alignment for Large Reasoning Models
AUTHORS: Xinming Wang; Jian Xu; Bin Yu; Sheng Lian; Hongzhu Yi; Yi Chen; Yingjian Zhu; Boran Wang; Hongming Yang; Han Hu; Xu-Yao Zhang; Cheng-Lin Liu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Large reasoning models (LRMs) show strong capabilities in complex reasoning,yet their marginal gains on evidence-dependent factual questions are limited.We find this limitation is partially attributable to a reasoning-answer hitgap, where the model identifies the correct facts during reasoning but fails toincorporate them into the final response, thereby reducing factual fidelity. Toaddress this issue, we propose MR-ALIGN, a Meta-Reasoning informed alignmentframework that enhances factuality without relying on external verifiers.MR-ALIGN quantifies state transition probabilities along the model's thinkingprocess and constructs a transition-aware implicit reward that reinforcesbeneficial reasoning patterns while suppressing defective ones at the atomicthinking segments.

90, TITLE: Human-AI Collaborative Uncertainty Quantification
AUTHORS: Sima Noorani; Shayan Kiyani; George Pappas; Hamed Hassani
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We introduce Human AI Collaborative UncertaintyQuantification, a framework that formalizes how an AI model can refine a humanexpert's proposed prediction set with two goals: avoiding counterfactual harm,ensuring the AI does not degrade correct human judgments, and complementarity,enabling recovery of correct outcomes the human missed.

91, TITLE: Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method
AUTHORS: Bohan Li; Xin Jin; Hu Zhu; Hongsi Liu; Ruikai Li; Jiazhe Guo; Kaiwen Cai; Chao Ma; Yueming Jin; Hao Zhao; Xiaokang Yang; Wenjun Zeng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To bridge modalgaps, we further propose two novel techniques: a Gaussian splatting-basedsparse point map rendering strategy that enhances multi-view video generation,and a sensor-aware embedding strategy that explicitly models LiDAR sensorproperties for realistic multi-LiDAR simulation. Extensive experimentsdemonstrate that our method achieves superior generation fidelity andscalability compared to existing approaches, and validates its practical valuein downstream tasks.

92, TITLE: Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis
AUTHORS: Yujie Nie; Jianzhang Ni; Yonglong Ye; Yuan-Ting Zhang; Yun Kwok Wing; Xiangqing Xu; Xin Ma; Lizhou Fan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this study, wepropose a multimodal cross-enhanced fusion framework that synergisticallyleverages eye-tracking and facial features for AD detection.

93, TITLE: Multi-Agent Evolve: LLM Self-Improve Through Co-evolution
AUTHORS: Yixing Chen; Yiding Wang; Siqi Zhu; Haofei Yu; Tao Feng; Muhan Zhan; Mostofa Patwary; Jiaxuan You
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However,the success of RL for LLMs heavily relies on human-curated datasets andverifiable rewards, which limit their scalability and generality. RecentSelf-Play RL methods, inspired by the success of the paradigm in games and Go,aim to enhance LLM reasoning capabilities without human-annotated data.However, their methods primarily depend on a grounded environment for feedback(e.g., a Python interpreter or a game engine); extending them to generaldomains remains challenging.

94, TITLE: Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective
AUTHORS: Zhenya Huang; Jiayu Liu; Xin Lin; Zhiyuan Ma; Shangzi Xue; Tong Xiao; Qi Liu; Yee Whye Teh; Enhong Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However, the field still lacks a systematic taxonomy for theMWP survey along with a discussion of current development trends. Therefore, inthis paper, we aim to comprehensively review related research in MWP solvingthrough the lens of human cognition, to demonstrate how recent AI models areadvancing in simulating human cognitive abilities.

95, TITLE: Embracing Trustworthy Brain-Agent Collaboration As Paradigm Extension for Intelligent Assistive Technologies
AUTHORS: Yankai Chen; Xinni Zhang; Yifei Zhang; Yangning Li; Henry Peng Zou; Chunyu Miao; Weizhi Zhang; Xue Liu; Philip S. Yu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Despite these advancements, deploying agentic AI facestechnical hurdles and ethical concerns. Due to the lack of comprehensivediscussion on this emerging direction, this position paper argues that thefield is poised for a paradigm extension from BCI to Brain-Agent Collaboration(BAC).

96, TITLE: REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for E-commerce Visual Search System Optimization
AUTHORS: Yiwen Tang; Qiuyu Zhao; Zenghui Sun; Jinsong Lan; Xiaoyong Zhu; Bo Zheng; Kaifu Zhang
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: To alleviate the issue, we propose a novel frameworkREVISION.

97, TITLE: Beyond Augmentation: Leveraging Inter-Instance Relation in Self-Supervised Representation Learning
AUTHORS: Ali Javidani; Babak Nadjar Araabi; Mohammad Amin Sadeghi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper introduces a novel approach that integrates graph theory intoself-supervised representation learning.

98, TITLE: SARCLIP: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery
AUTHORS: Qiwei Ma; Zhiyu Wang; Wang Liu; Xukun Lu; Bin Deng; Puhong Duan; Xudong Kang; Shutao Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: While recent advancements in self-supervisedlearning and Masked Image Modeling (MIM) have paved the way for SAR foundationmodels, these approaches primarily focus on low-level visual features, oftenoverlooking multimodal alignment and zero-shot target recognition within SARimagery. To address this limitation, we construct SARCLIP-1M, a large-scalevision language dataset comprising over one million text-image pairs aggregatedfrom existing datasets.

99, TITLE: Is Temporal Difference Learning The Gold Standard for Stitching in RL?
AUTHORS: Michał Bortkiewicz; Władysław Pałucki; Mateusz Ostaszewski; Benjamin Eysenbach
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: The goal of this paper is to empirically studywhether the conventional wisdom about stitching actually holds in settingswhere function approximation is used.

100, TITLE: Mapping Faithful Reasoning in Language Models
AUTHORS: Jiazheng Li; Andreas Damianou; J Rosser; José Luis Redondo García; Konstantina Palla
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce Concept Walk, ageneral framework for tracing how a model's internal stance evolves withrespect to a concept direction during reasoning.

101, TITLE: A Novel Framework for Multi-Modal Protein Representation Learning
AUTHORS: Runjie Zheng; Zhen Wang; Anjie Qiao; Jiancong Xie; Jiahua Rao; Yuedong Yang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, two keychallenges hinder effective fusion: (i) cross-modal distributional mismatchamong embeddings produced by pre-trained intrinsic encoders, and (ii) noisyrelational graphs of extrinsic data that degrade GNN-based informationaggregation. We propose Diffused and Aligned Multi-modal Protein Embedding(DAMPE), a unified framework that addresses these through two core mechanisms.First, we propose Optimal Transport (OT)-based representation alignment thatestablishes correspondence between intrinsic embedding spaces of differentmodalities, effectively mitigating cross-modal heterogeneity.

102, TITLE: ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction Via Generation
AUTHORS: Jiahao Chang; Chongjie Ye; Yushuang Wu; Yuantao Chen; Yidan Zhang; Zhongjin Luo; Chenghong Li; Yihao Zhi; Xiaoguang Han
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In thiswork, we comprehensively analyze the reasons why diffusion-based 3D generativemethods fail to achieve high consistency, including (a) the insufficiency inconstructing and leveraging cross-view connections when extracting multi-viewimage features as conditions, and (b) the poor controllability of iterativedenoising during local detail generation, which easily leads to plausible butinconsistent fine geometric and texture details with inputs.

103, TITLE: Open Multimodal Retrieval-Augmented Factual Image Generation
AUTHORS: Yang Tian; Fan Liu; Jingyuan Zhang; Wei Bi; Yupeng Hu; Liqiang Nie
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Large Multimodal Models (LMMs) have achieved remarkable progress ingenerating photorealistic and prompt-aligned images, but they often produceoutputs that contradict verifiable knowledge, especially when prompts involvefine-grained attributes or time-sensitive events.

104, TITLE: PANORAMA: A Dataset and Benchmarks Capturing Decision Trails and Rationales in Patent Examination
AUTHORS: Hyunseung Lim; Sooyohn Nam; Sungmin Na; Ji Yong Cho; June Yong Yang; Hyungyu Shin; Yoonjoo Lee; Juho Kim; Moontae Lee; Hwajung Hong
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: However, this approach often overlooks the step-by-stepevaluations that examiners must make with profound information, includingrationales for the decisions provided in office actions documents, which alsomakes it harder to measure the current state of techniques in patent reviewprocesses. To fill this gap, we construct PANORAMA, a dataset of 8,143 U.S.patent examination records that preserves the full decision trails, includingoriginal applications, all cited references, Non-Final Rejections, and Noticesof Allowance.

105, TITLE: MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring
AUTHORS: Tengchao Yang; Sichen Guo; Mengzhao Jia; Jiaming Su; Yuanyang Liu; Zhihan Zhang; Meng Jiang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce MMTutorBench, the firstbenchmark for AI math tutoring, consisting of 685 problems built aroundpedagogically significant key-steps.

106, TITLE: VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting
AUTHORS: Hoonhee Cho; Jae-Young Kang; Giwon Lee; Hyemin Yang; Heejun Park; Seokwoo Jung; Kuk-Jin Yoon
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we propose VR-Drive, a novel E2E-AD framework thataddresses viewpoint generalization by jointly learning 3D scene reconstructionas an auxiliary task to enable planning-aware view synthesis.

107, TITLE: PaperAsk: A Benchmark for Reliability Evaluation of LLMs in Paper Search and Reading
AUTHORS: Yutao Wu; Xiao Liu; Yunhao Feng; Jiale Ding; Xingjun Ma
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: In this work, weintroduce PaperAsk, a benchmark that systematically evaluates LLMs across fourkey research tasks: citation retrieval, content extraction, paper discovery,and claim verification.

108, TITLE: $\text{E}^2\text{Rank}$: Your Text Embedding Can Also Be An Effective and Efficient Listwise Reranker
AUTHORS: Qi Liu; Yanzhao Zhang; Mingxin Li; Dingkun Long; Pengjun Xie; Jiaxin Mao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose asimple yet effective unified framework $\text{E}^2\text{Rank}$, means EfficientEmbedding-based Ranking (also means Embedding-to-Rank), which extends a singletext embedding model to perform both high-quality retrieval and listwisereranking through continued training under a listwise ranking objective,thereby achieving strong effectiveness with remarkable efficiency.

109, TITLE: Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges
AUTHORS: Liling Yang; Ning Chen; Jun Yue; Yidan Liu; Jiayi Ma; Pedram Ghamisi; Antonio Plaza; Leyuan Fang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We examine how differences in imaging physicsand data representation shape interaction design, and we analyze key techniquesfor alignment, integration, and knowledge transfer to tackle modalityheterogeneity, distribution shifts, and semantic gaps.

110, TITLE: Alias-Free ViT: Fractional Shift Invariance Via Linear Attention
AUTHORS: Hagay Michaeli; Daniel Soudry
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Building on thisline of work, we propose an Alias-Free ViT, which combines two main components.First, it uses alias-free downsampling and nonlinearities.

111, TITLE: MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with Customizable Identity Control
AUTHORS: Fatemeh Nazarieh; Zhenhua Feng; Diptesh Kanojia; Muhammad Awais; Josef Kittler
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Unlike previous methodsrequiring multiple reference images or fine-tuning, MAGIC-Talk maintainsidentity from a single image while ensuring smooth transitions across frames.Additionally, a progressive latent fusion strategy is introduced to improvelong-form video quality by reducing motion inconsistencies and flickering.Extensive experiments demonstrate that MAGIC-Talk outperforms state-of-the-artmethods in visual quality, identity preservation, and synchronization accuracy,offering a robust solution for talking face generation.

112, TITLE: Seeing Structural Failure Before It Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction
AUTHORS: Omer Jauhar Khan; Sudais Khan; Hafeez Anwar
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This paper aims toexplore the use of PINNs to predict the weight of small scale spaghettibridges, a task relevant to understanding load limits and potential failuremodes in simplified structural models.

113, TITLE: DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection
AUTHORS: Kangran Zhao; Yupeng Chen; Xiaoyu Zhang; Yize Chen; Weinan Guan; Baicheng Chen; Chengzhe Sun; Soumyya Kanti Datta; Qingshan Liu; Siwei Lyu; Baoyuan Wu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Building onit, we present DeepfakeBench-MM, the first unified benchmark for multimodaldeepfake detection.

114, TITLE: A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning
AUTHORS: Bingqing Song; Jiaxiang Li; Rong Wang; Songtao Lu; Mingyi Hong
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work, we propose a new framework to analyze theICL performance, for a class of realistic settings, which includes networkarchitectures, data encoding, data generation, and prompt construction process.As a first step, we construct a simple example with a one-layer transformer,and show an interesting result, namely when the pre-train data distribution isdifferent from the query task distribution, a properly constructed context canshift the output distribution towards the query task distribution, in aquantifiable manner, leading to accurate prediction on the query topic.

115, TITLE: Accident Anticipation Via Temporal Occurrence Prediction
AUTHORS: Tianhao Zhao; Yiyang Zou; Zihao Mao; Peilun Xiao; Yulin Huang; Hongda Yang; Yuxuan Li; Qun Li; Guobin Wu; Yutian Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our method employs a snippet-level encoder tojointly model spatial and temporal dynamics, and a Transformer-based temporaldecoder that predicts accident scores for all future horizons simultaneouslyusing dedicated temporal queries.

116, TITLE: Manifold Approximation Leads to Robust Kernel Alignment
AUTHORS: Mohammad Tariqul Islam; Du Liu; Deblina Sarkar
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we propose Manifold approximated Kernel Alignment (MKA),which incorporates manifold geometry into the alignment task.

117, TITLE: Mint: A Simple Test-Time Adaptation of Vision-Language Models Against Common Corruptions
AUTHORS: Wenxuan Bao; Ruxi Deng; Jingrui He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we investigate how corruptions affect CLIP's imageembeddings and uncover a consistent phenomenon we term as embedding variancecollapse, where both intra-class and inter-class variances shrink as corruptionseverity increases.

118, TITLE: Switchable Token-Specific Codebook Quantization For Face Image Compression
AUTHORS: Yongbo Wang; Haonan Wang; Guodong Mu; Ruixin Zhang; Jiaqi Chen; Jingyun Zhang; Jun Wang; Yuan Xie; Zhizhong Zhang; Shouhong Ding
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Motivated by theseobservations, we propose a Switchable Token-Specific Codebook Quantization forface image compression, which learns distinct codebook groups for differentimage categories and assigns an independent codebook to each token.

119, TITLE: FRBNet: Revisiting Low-Light Vision Through Frequency-Domain Radial Basis Network
AUTHORS: Fangtong Sun; Congyu Li; Ke Yang; Yuchen Pan; Hanwen Yu; Xichuan Zhang; Yiying Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: While recentstate-of-the-art methods have improved performance through invariant featurelearning modules, they still fall short due to incomplete modeling of low-lightconditions. Therefore, we revisit low-light image formation and extend theclassical Lambertian model to better characterize low-light conditions.

120, TITLE: JanusCoder: Towards A Foundational Visual-Programmatic Interface for Code Intelligence
AUTHORS: Qiushi Sun; Jingyang Gong; Yang Liu; Qiaosheng Chen; Lei Li; Kai Chen; Qipeng Guo; Ben Kao; Fei Yuan
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However,progress has been impeded by the scarcity of high-quality multimodal code data,a bottleneck stemming from challenges in synthesis and quality assessment. Toaddress these challenges, we make contributions from both a data and modelingperspective.

121, TITLE: BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement
AUTHORS: Ke Xue; Ruo-Tong Chen; Rong-Xi Tan; Xi Lin; Yunqi Shi; Siyuan Xu; Mingxuan Yuan; Chao Qian
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Recent progress has shown theeffectiveness and efficiency of BBO for chip placement, proving its potentialto achieve state-of-the-art results. Despite these advancements, the fieldlacks a unified, BBO-specific benchmark for thoroughly assessing variousproblem formulations and BBO algorithms.

122, TITLE: Sequential Multi-Agent Dynamic Algorithm Configuration
AUTHORS: Chen Lu; Ke Xue; Lei Yuan; Yao Wang; Yaoyuan Wang; Sheng Fu; Chao Qian
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, many complexalgorithms have inherent inter-dependencies among multiple parameters (e.g.,determining the operator type first and then the operator's parameter), whichare, however, not considered in previous approaches, thus leading tosub-optimal results. In this paper, we propose the sequential multi-agent DAC(Seq-MADAC) framework to address this issue by considering the inherentinter-dependencies of multiple parameters.

123, TITLE: Multimodal Prototypical Network for Interpretable Sentiment Classification
AUTHORS: Chenguang Song; Ke Chao; Bingjing Jia; Yiqing Shen
CATEGORY: Scientific Reports [SCIENTIFIC REPORTS]
HIGHLIGHT: To address the challenges, we propose M ulti M odal P rototypical Net works (MMPNet), which extends prototype-based interpretability to multimodal sentiment classification.

124, TITLE: Can Small and Reasoning Large Language Models Score Journal Articles for Research Quality and Do Averaging and Few-shot Help?
AUTHORS: Mike Thelwall; Ehsan Mohammadi
CATEGORY: arxiv-cs.DL [DL]
HIGHLIGHT: Assessing published academic journal articles is a common task forevaluations of departments and individuals.

125, TITLE: UltraVoice: Scaling Fine-Grained Style-Controlled Speech Conversations for Spoken Dialogue Models
AUTHORS: Wenming Tu; Guanrou Yang; Ruiqi Yan; Wenxi Chen; Ziyang Ma; Yipeng Kang; Kai Yu; Xie Chen; Zilong Zheng
CATEGORY: arxiv-eess.AS [AS]
HIGHLIGHT: Spoken dialogue models currently lack the ability for fine-grained speechstyle control, a critical capability for human-like interaction that is oftenoverlooked in favor of purely functional capabilities like reasoning andquestion answering. To address this limitation, we introduce UltraVoice, thefirst large-scale speech dialogue dataset engineered for multiple fine-grainedspeech style control.

126, TITLE: When UAV Swarm Meets IRS: Collaborative Secure Communications in Low-altitude Wireless Networks
AUTHORS: Jiahui Li; Xinyue Liang; Geng Sun; Hui Kang; Jiacheng Wang; Dusit Niyato; Shiwen Mao; Abbas Jamalipour
CATEGORY: arxiv-cs.NI [NI]
HIGHLIGHT: Specifically, we formulate a multi-objective optimization problem thatsimultaneously maximizes the secrecy rate while minimizing the maximum sidelobelevel and total energy consumption, requiring joint optimization of UAVexcitation current weights, flight trajectories, and IRS phase shifts.

127, TITLE: Human-Like Goalkeeping in A Realistic Football Simulation: A Sample-Efficient Reinforcement Learning Approach
AUTHORS: Alessandro Sestini; Joakim Bergdahl; Jean-Philippe Barrette-LaPierre; Florian Fuchs; Brady Chen; Micheal Jones; Linus Gisslén
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We evaluate our method training a goalkeeperagent in EA SPORTS FC 25, one of the best-selling football simulations today.Our agent outperforms the game's built-in AI by 10% in ball saving rate.Ablation studies show that our method trains agents 50% faster compared tostandard DRL methods.

128, TITLE: PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity
AUTHORS: Yuqian Yuan; Wenqiao Zhang; Xin Li; Shihao Wang; Kehan Li; Wentong Li; Jun Xiao; Lei Zhang; Beng Chin Ooi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper,we present PixelRefer, a unified region-level MLLM framework that enablesadvanced fine-grained understanding over user-specified regions across bothimages and videos.

129, TITLE: Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion
AUTHORS: Zilong Wang; Qingtian Zeng; Hua Duan; Cheng Cheng; Minghao Zou; Ziyang Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Existingmethods, however, struggle to capture complex relational patterns and mitigatedata sparsity. To address these challenges, we propose a novel FKGC frameworkfor conjugate relation modeling (CR-FKGC).

130, TITLE: Advantage Shaping As Surrogate Reward Maximization: Unifying Pass@K Policy Gradients
AUTHORS: Christos Thrampoulidis; Sadegh Mahdavi; Wenlong Deng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This note reconciles two seemingly distinct approaches to policy gradientoptimization for the Pass@K objective in reinforcement learning with verifiablerewards: (1) direct REINFORCE-style methods, and (2) advantage-shapingtechniques that directly modify GRPO. We show that these are two sides of thesame coin.

131, TITLE: Multiclass Identification of Van Der Waals Semiconductors Via Attention Neural Networks
AUTHORS: Xingchen Dong; Jiayi Ma; Kun Wang; Martin Jakobi; Ali K. Yetisen; Alexander W. Koch
CATEGORY: Advanced Photonics Research [ADVANCED PHOTONICS RESEARCH]
HIGHLIGHT: The quantitative analysis of RIAL and UNAL illustrates the versatility of attention convolutional network models in the wafer‐scale identification of van der Waals semiconductors.

132, TITLE: Incentivizing Agentic Reasoning in LLM Judges Via Tool-Integrated Reinforcement Learning
AUTHORS: Ran Xu; Jingjing Chen; Jiayu Ye; Yu Wu; Jun Yan; Carl Yang; Hongkun Yu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Large Language Models (LLMs) are widely used as judges to evaluate responsequality, providing a scalable alternative to human evaluation.

133, TITLE: RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance
AUTHORS: Jiuniu Wang; Gongjie Zhang; Quanhao Qian; Junlong Gao; Deli Zhao; Ran Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce RoboSVG, a unified multimodalframework for generating interactive SVGs guided by textual, visual, andnumerical signals.

134, TITLE: The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models
AUTHORS: Yao Lu; Yuqi Li; Wenbin Xie; Shanqing Yu; Qi Xuan; Zhaowei Zhu; Shiping Wen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This can disrupt the model's information flow and severelydegrade performance. To address these issues, we propose CLP, a novelcontinuous layer pruning framework that introduces two key innovations: adifferentiable concave gate algorithm that automatically identifies the bestcontinuous layer segments for pruning via gradient-based optimization; and acutoff endpoint tuning strategy that effectively restores model performance byfine-tuning only the layers adjacent to the pruned segments.

135, TITLE: Noisy Nonlinear Information and Entropy Numbers
AUTHORS: David Krieg; Erich Novak; Leszek Plaskota; Mario Ullrich
CATEGORY: arxiv-math.NA [NA]
HIGHLIGHT: In thisnote, we characterize the quality of optimal (dis-)continuous information thatis disturbed by deterministic noise in terms of entropy numbers.

136, TITLE: T-REGS: Minimum Spanning Tree Regularization for Self-Supervised Learning
AUTHORS: Julie Mordacq; David Loiseaux; Vicky Kalogeiton; Steve Oudot
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In thiswork, we introduce T-REGS, a simple regularization framework for SSL based onthe length of the Minimum Spanning Tree (MST) over the learned representation.We provide theoretical analysis demonstrating that T-REGS simultaneouslymitigates dimensional collapse and promotes distribution uniformity onarbitrary compact Riemannian manifolds.

137, TITLE: PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation Performance at Unseen Pre-Training Budgets
AUTHORS: Etienne Goffinet; Shane Bergsma; Avraham Sheinin; Natalia Vassilieva; Shaheer Muhammad; Preslav Nakov; Gurpreet Gosal
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We present \emph{PTPP-aware} adaptation scaling laws that make thepre-training budget an explicit variable, enabling accurate \emph{prediction}of adaptation loss at unseen \ptpp.

138, TITLE: FreeFuse: Multi-Subject LoRA Fusion Via Auto Masking at Test Time
AUTHORS: Yaoli Liu; Yao-Xiang Ding; Kun Zhou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper proposes FreeFuse, a novel training-free approach formulti-subject text-to-image generation through automatic fusion of multiplesubject LoRAs.

139, TITLE: Guiding Skill Discovery with Foundation Models
AUTHORS: Zhao Yang; Thomas M. Moerland; Mike Preuss; Aske Plaat; Vincent François-Lavet; Edward S. Hu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In thiswork, we propose a Foundation model Guided (FoG) skill discovery method, whichincorporates human intentions into skill discovery through foundation models.Specifically, FoG extracts a score function from foundation models to evaluatestates based on human intentions, assigning higher values to desirable statesand lower to undesirable ones.

140, TITLE: LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation
AUTHORS: Ghadi Nehme; Yanxia Zhang; Dule Shu; Matt Klenk; Faez Ahmed
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, currentmethods typically rely on large training datasets and struggle withcontrollability and generalization beyond the training distributions. Toovercome these limitations, we introduce LAMP (Linear Affine Mixing ofParametric shapes), a data-efficient framework for controllable andinterpretable 3D generation.

141, TITLE: Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization
AUTHORS: Amin Heyrani Nobari; Lyle Regenwetter; Cyril Picard; Ligong Han; Faez Ahmed
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce Optimize Any Topology (OAT), a foundation-modelframework that directly predicts minimum-compliance layouts for arbitraryaspect ratios, resolutions, volume fractions, loads, and fixtures.

142, TITLE: InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras
AUTHORS: Erich Liang; Roma Bhattacharjee; Sreemanti Dey; Rafael Moschopoulos; Caitlin Wang; Michel Liao; Grace Tan; Andrew Wang; Karhan Kayan; Stamatis Alexandropoulos; Jia Deng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, wepresent Intrinsics in Flux (InFlux), a real-world benchmark that providesper-frame ground truth intrinsics annotations for videos with dynamicintrinsics.

143, TITLE: Video-Thinker: Sparking "Thinking with Videos" Via Reinforcement Learning
AUTHORS: Shijian Wang; Jiarui Jin; Xingjian Wang; Linxin Song; Runhao Fu; Hecheng Wang; Zongyuan Ge; Yuan Lu; Xuelian Cheng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we propose Video-Thinker,which empowers MLLMs to think with videos by autonomously leveraging theirintrinsic "grounding" and "captioning" capabilities to generate reasoning cluesthroughout the inference process.

144, TITLE: EgoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks
AUTHORS: Matthias Jammot; Bjöern Braun; Paul Streli; Rafael Wampfler; Christian Holz
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, wepresent egoEMOTION, the first dataset that couples egocentric visual andphysiological signals with dense self-reports of emotion and personality acrosscontrolled and real-world scenarios.

145, TITLE: Learning Without Augmenting: Unsupervised Time Series Representation Learning Via Frame Projections
AUTHORS: Berken Utku Demirel; Christian Holz
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, wepropose an unsupervised representation learning method that replacesaugmentations by generating views using orthonormal bases and overcompleteframes.

146, TITLE: Transformers from Compressed Representations
AUTHORS: Juan C. Leon Alcazar; Mattia Soldan; Mohammad Saatialsoruji; Alejandro Pardo; Hani Itani; Juan Camilo Perez; Bernard Ghanem
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce TEMPEST (TransformErs froM comPressedrEpreSenTations), a method that exploits the inherent byte-stream structure ofcompressed files to design an effective tokenization and encoding strategy.

147, TITLE: Multi-Personality Generation of LLMs at Decoding-time
AUTHORS: Rongxin Chen; Yunfan Li; Yige Yuan; Bingbing Xu; Huawei Shen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose a novel Multi-Personality Generation(MPG) framework under the decoding-time combination paradigm.

148, TITLE: Positional Preservation Embedding for Multimodal Large Language Models
AUTHORS: Mouxiao Huang; Borui Jiang; Dehua Zheng; Hailin Hu; Kai Han; Xinghao Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we propose a novel encoding operatordubbed as \textbf{P}ositional \textbf{P}reservation \textbf{E}mbedding(\textbf{PPE}), which has the main hallmark of preservation of spatiotemporalstructure during visual token compression.

149, TITLE: PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language
AUTHORS: Guangyao Shi; Yuwei Wu; Vijay Kumar; Gaurav S. Sukhatme
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: We introduce PIP-LLM, a language-based coordination framework that consistsof PDDL-based team-level planning and Integer Programming (IP) basedrobot-level planning.

150, TITLE: SceneDecorator: Towards Scene-Oriented Story Generation with Scene Planning and Scene Consistency
AUTHORS: Quanjian Song; Donghao Zhou; Jingyu Lin; Fei Shen; Jiaze Wang; Xiaowei Hu; Cunjian Chen; Pheng-Ann Heng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper introduces scene-oriented story generation, addressing twokey challenges: (i) scene planning, where current methods fail to ensurescene-level narrative coherence by relying solely on text descriptions, and(ii) scene consistency, which remains largely unexplored in terms ofmaintaining scene consistency across multiple stories.

151, TITLE: Enpowering Your Pansharpening Models with Generalizability: Unified Distribution Is All You Need
AUTHORS: Yongchuan Cui; Peng Liu; Hui Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, due to sensor-specificcharacteristics and varying imaging conditions, these models suffer fromsubstantial performance degradation when applied to unseen satellite data,lacking generalizability and thus limiting their applicability. We argue thatthe performance drops stem primarily from distributional discrepancies fromdifferent sources and the key to addressing this challenge lies in bridging thegap between training and testing distributions.

152, TITLE: A Re-node Self-training Approach for Deep Graph-based Semi-supervised Classification on Multi-view Image Data
AUTHORS: Jingjun Bi; Fadi Dornaika
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, wepropose Re-node Self-taught Graph-based Semi-supervised Learning for Multi-viewData (RSGSLM).

153, TITLE: LongCat-Video Technical Report
AUTHORS: Meituan LongCat Team; Xunliang Cai; Qilong Huang; Zhuoliang Kang; Hongyu Li; Shijun Liang; Liya Ma; Siyu Ren; Xiaoming Wei; Rixu Xie; Tong Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Video generation is a critical pathway toward world models, with efficientlong video inference as a key capability. Toward this end, we introduceLongCat-Video, a foundational ...

154, TITLE: M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark
AUTHORS: Huixuan Zhang; Xiaojun Wan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this study, we introduce M$^3$T2IBench, a large-scale,multi-category, multi-instance, multi-relation along with anobject-detection-based evaluation metric, $AlignScore$, which aligns closelywith human evaluation.

155, TITLE: UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization
AUTHORS: Huixuan Zhang; Xiaojun Wan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: While existing studies haveproposed various methods for detecting AI-generated content, current benchmarksare limited in their coverage of diverse generative models and imagecategories, often overlooking end-to-end image editing and artistic images. Toaddress these limitations, we introduce UniAIDet, a unified and comprehensivebenchmark that includes both photographic and artistic images.

156, TITLE: Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning
AUTHORS: Prerna Ravi; Dong Won Lee; Beatriz Flamia; Jasmine David; Brandon Hanks; Cynthia Breazeal; Emma Anderson; Grace Lin
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we investigate whetherexplicit thread linkages can improve LLM-based coding of relational moves ingroup talk.

157, TITLE: SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size
AUTHORS: Jinhan Chen; Jianchun Liu; Hongli Xu; Xianjun Gao; Shilong Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To thisend, we introduce SABlock, a \underline{s}emantic-aware KV cache evictionframework with \underline{a}daptive \underline{block} sizes.

158, TITLE: Learning Linearity in Audio Consistency Autoencoders Via Implicit Regularization
AUTHORS: Bernardo Torres; Manuel Moussallam; Gabriel Meseguer-Brocal
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: This work presents astraightforward technique for constructing structured latent spaces, enablingmore intuitive and efficient audio processing.

159, TITLE: A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback
AUTHORS: Zhifeng Wang; Xinyue Zheng; Chunyan Zeng
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This leads to coarse or opaque student models,assumption-bound adaptivity that ignores diagnostic posteriors, and generic,non-actionable feedback. To address these limitations, this paper presents anend-to-end personalized learning agent, EduLoop-Agent, which integrates aNeural Cognitive Diagnosis model (NCD), a Bounded-Ability EstimationComputerized Adaptive Testing strategy (BECAT), and large language models(LLMs).

160, TITLE: OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models
AUTHORS: Hao Zheng; Zirui Pang; Ling li; Zhijie Deng; Yuhan Pu; Zhaowei Zhu; Xiaobo Xia; Jiaheng Wei
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To facilitate the development of MLLMs unlearning andalleviate the aforementioned limitations, we introduce OFFSIDE, a novelbenchmark for evaluating misinformation unlearning in MLLMs based on footballtransfer rumors.

161, TITLE: ENTP: Enhancing Low-Quality SFT Data Via Neural-Symbolic Text Purge-Mix
AUTHORS: Zile Yang; Ling Li; Na Di; Jinlong Pang; Yao Zhou; Hao Cheng; Bo Han; Jiaheng Wei
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce ENTP(Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), aframework that revitalizes low-quality corpora through symbolic purificationand neural reconstruction.

162, TITLE: Label Smoothing Improves Gradient Ascent in LLM Unlearning
AUTHORS: Zirui Pang; Hao Zheng; Zhijie Deng; Ling Li; Zixin Zhong; Jiaheng Wei
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Theoretically, we provide the theoreticalguidance on the selection of the optimal smoothing rate.

163, TITLE: HieraMamba: Video Temporal Grounding Via Hierarchical Anchor-Mamba Pooling
AUTHORS: Joungbin An; Kristen Grauman
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Video temporal grounding, the task of localizing the start and end times of anatural language query in untrimmed video, requires capturing both globalcontext and fine-grained ...

164, TITLE: ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language Models
AUTHORS: Bohan Li; Wenbin Huang; Yuhang Qiu; Yiwei Guo; Hankun Wang; Zhihan Li; Jing Peng; Ziyang Ma; Xie Chen; Kai Yu
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: We introduce ISA-Bench, a dynamic benchmarkevaluating instruction sensitivity for LALMs along three axes: instructiondescription, output format, and task composition.

165, TITLE: RefleXGen:The Unexamined Code Is Not Worth Using
AUTHORS: Bin Wang; Hui Li; AoFan Liu; BoTao Yang; Ao Yang; YiLu Zhong; Weixiang Huang; Yanping Zhang; Runhuai Huang; Weimin Zeng
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: This paper introduces RefleXGen, an innovative methodthat significantly enhances code security by integrating Retrieval-AugmentedGeneration (RAG) techniques with guided self-reflection mechanisms inherent inLLMs.

166, TITLE: Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction
AUTHORS: Jin Hu; Jiakai Wang; Linna Jing; Haolin Li; Haodong Liu; Haotong Qin; Aishan Liu; Ke Xu; Xianglong Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Specifically, in the dimension of the sampling method,we propose the residual-driven attacking direction stabilization to alleviatethe unstable adversarial optimization caused by the diversity of languagereferences.

167, TITLE: Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation
AUTHORS: Mackenzie Tapp; Sibi Chakravarthy Parivendan; Kashfia Sailunaz; Suresh Neethirajan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Using three configurations- a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), asubset of the APT-36K benchmark dataset, and their combination, wesystematically assessed model accuracy and generalization across environments.While the combined model achieved promising performance (AP = 0.86, AR = 0.87,PCK 0.5 = 0.869) on in-distribution data, substantial generalization failuresoccurred when applied to unseen barns and cow populations.

168, TITLE: DiffusionLane: Diffusion Model for Lane Detection
AUTHORS: Kunyang Zhou; Yeqin Shao
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we present a novel diffusion-based model for lane detection,called DiffusionLane, which treats the lane detection task as a denoisingdiffusion process in the parameter space of the lane.

169, TITLE: Variational Masked Diffusion Models
AUTHORS: Yichi Zhang; Alex Schwing; Zhizhen Zhao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To explicitly model dependencies amongtokens, we propose Variational Masked Diffusion (VMD), a framework thatintroduces latent variables into the masked diffusion process.

170, TITLE: AG-Fusion: Adaptive Gated Multimodal Fusion for 3d Object Detection in Complex Scenes
AUTHORS: Sixian Liu; Chen Xu; Qiang Wang; Donghai Shi; Yiwen Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose anovel Adaptive Gated Fusion (AG-Fusion) approach that selectively integratescross-modal knowledge by identifying reliable patterns for robust detection incomplex scenes.

171, TITLE: VoMP: Predicting Volumetric Mechanical Property Fields
AUTHORS: Rishit Dagli; Donglai Xiang; Vismay Modi; Charles Loop; Clement Fuji Tsang; Anka He Chen; Anita Hu; Gavriel State; David I. W. Levin; Maria Shugrina
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To obtain object-level training data, we propose an annotationpipeline combining knowledge from segmented 3D datasets, material databases,and a vision-language model, along with a new benchmark.

172, TITLE: Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition
AUTHORS: Yizhuo Wu; Francesco Fioranelli; Chang Gao
CATEGORY: arxiv-eess.SP [SP]
HIGHLIGHT: We introduce Neural-HAR, adimension-gated CNN accelerator tailored for real-time radar HAR onresource-constrained platforms.

173, TITLE: EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models
AUTHORS: Li Zhou; Lutong Yu; You Lyu; Yihang Lin; Zefeng Zhao; Junyi Ao; Yuhao Zhang; Benyou Wang; Haizhou Li
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present EchoMind, thefirst interrelated, multi-level benchmark that simulates the cognitive processof empathetic dialogue through sequential, context-linked tasks: spoken-contentunderstanding, vocal-cue perception, integrated reasoning, and responsegeneration.

174, TITLE: GraphTOP: Graph Topology-Oriented Prompting for Graph Neural Networks
AUTHORS: Xingbo Fu; Zhenyu Lei; Zihan Chen; Binchi Zhang; Chuxu Zhang; Jundong Li
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this study, we conduct a pioneering investigation of graphprompting in terms of graph topology.

175, TITLE: Understanding What Is Not Said:Referring Remote Sensing Image Segmentation with Scarce Expressions
AUTHORS: Kai Ye; Bowen Liu; Jianghang Lin; Jiayi Ji; Pingyang Dai; Liujuan Cao
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: Combined with a teacher-studentoptimization framework using dynamically scheduled EMA updates, LRB-WRELstabilizes training and enhances cross-modal generalization under noisy weaklyreferring supervision. Extensive experiments on our newly constructed benchmarkwith varying weakly referring data ratios validate both the theoreticalinsights and the practical effectiveness of WREL and LRB-WREL, demonstratingthat they can approach or even surpass models trained with fully annotatedreferring expressions.

176, TITLE: LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction
AUTHORS: Yuhang Gao; Xiang Xiang; Sheng Zhong; Guoyou Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose LOC, a generallanguage-guided framework adaptable to various occupancy networks, supportingboth supervised and self-supervised learning paradigms.

177, TITLE: Multi-dataset Joint Pre-training of Emotional EEG Enables Generalizable Affective Computing
AUTHORS: Qingzhu Zhang; Jiani Zhong; Zongsheng Li; Xinke Shen; Quanying Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To capture the long-term dependency and complex dynamics of EEG,we propose a hybrid encoder combining a Mamba-like linear attention channelencoder and a spatiotemporal dynamics model.

178, TITLE: The Lossy Horizon: Error-Bounded Predictive Coding for Lossy Text Compression (Episode I)
AUTHORS: Nnamdi Aghanya; Jun Li; Kewei Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Large Language Models (LLMs) can achieve near-optimal lossless compression byacting as powerful probability models.

179, TITLE: Batch Speculative Decoding Done Right
AUTHORS: Ranran Haoran Zhang; Soumik Dey; Ashirbad Mishra; Hansi Wu; Binbin Li; Rui Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In response, we (1) characterize the synchronizationrequirements that guarantee correctness, (2) present a correctness-first batchspeculative decoding EQSPEC that exposes realignment as consuming 40% ofoverhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequencesand dynamically forms same-length groups, to reduce the realignment overheadwhile preserving per-sequence speculative speedups.

180, TITLE: Toward Understanding The Transferability of Adversarial Suffixes in Large Language Models
AUTHORS: Sarah Ball; Niki Hasrati; Alexander Robey; Avi Schwarzschild; Frauke Kreuter; Zico Kolter; Andrej Risteski
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: On theother hand, we find that prompt semantic similarity only weakly correlates withtransfer success.

181, TITLE: A Survey on LLM Mid-training
AUTHORS: Chengying Tu; Xuemiao Zhang; Rongxiang Weng; Rumei Li; Chen Zhang; Yang Bai; Hongfei Yan; Jingang Wang; Xunliang Cai
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This survey provides a formal definition of mid-training forlarge language models (LLMs) and investigates optimization frameworks thatencompass data curation, training strategies, and model architectureoptimization.

182, TITLE: Evaluation Framework for Fault Diagnosis Using Technical Manuals in Retrieval-Augmented Large Language Models
AUTHORS: Sarah Lukens; Matthew Bishof; Nadir Siddiqui; Destiny West
CATEGORY: Annual Conference of the PHM Society [ANNUAL CONFERENCE OF THE PHM SOCIETY]
HIGHLIGHT: This study introduces an evaluation-driven framework for fault code recommendation, applied to a ground vehicle diagnosis system.

183, TITLE: I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions
AUTHORS: Shuhong Liu; Lin Gu; Ziteng Cui; Xuangeng Chu; Tatsuya Harada
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Participating in efforts to endow generative AI with the 3D physical worldperception, we propose I2-NeRF, a novel neural radiance field framework thatenhances isometric and isotropic metric perception under media degradation.While existing NeRF models predominantly rely on object-centric sampling,I2-NeRF introduces a reverse-stratified upsampling strategy to achievenear-uniform sampling across 3D space, thereby preserving isometry.

184, TITLE: Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation
AUTHORS: Stefan M. Fischer; Johannes Kiechle; Laura Daza; Lina Felsner; Richard Osuala; Daniel M. Lang; Karim Lekadir; Jan C. Peeken; Julia A. Schnabel
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce Progressive Growing of Patch Size, an automaticcurriculum learning approach for 3D medical image segmentation.

185, TITLE: Self-Calibrated Consistency Can Fight Back for Adversarial Robustness in Vision-Language Models
AUTHORS: Jiaxiang Liu; Jiawei Du; Xiao Liu; Prayag Tiwari; Mingkun Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we identify two key weaknesses of current CLIPadversarial attacks -- lack of semantic guidance and vulnerability to viewvariations -- collectively termed semantic and viewpoint fragility.

186, TITLE: Single-Teacher View Augmentation: Boosting Knowledge Distillation Via Angular Diversity
AUTHORS: Seonghoon Yu; Dongjun Nam; Dina Katabi; Jeany Son
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work,we propose a novel cost-efficient knowledge augmentation method for KD thatgenerates diverse multi-views by attaching multiple branches to a singleteacher.

187, TITLE: MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from 3D Scans
AUTHORS: Ahmet Serdar Karadeniz; Dimitrios Mallis; Danila Rukhovich; Kseniya Cherenkova; Anis Kacem; Djamila Aouada
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce a novel approach to CADreverse engineering inspired by how human designers manually perform the task.Our method leverages multi-plane cross-sections to extract 2D patterns andcapture fine parametric details more effectively.

188, TITLE: The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool Hallucination
AUTHORS: Chenlong Yin; Zeyang Sha; Shiwen Cui; Changhua Meng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Toaddress this gap, we pose the central question: Does strengthening reasoningincrease tool hallucination? To answer this, we introduce SimpleToolHalluBench,a diagnostic benchmark measuring tool hallucination in two failure modes: (i)no tool available, and (ii) only distractor tools available.

189, TITLE: Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models
AUTHORS: Hoang Phan; Xianjun Yang; Kevin Yao; Jingyu Zhang; Shengjie Bi; Xiaocheng Tang; Madian Khabsa; Lijuan Liu; Deren Lei
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Meanwhile, commonly used experience replayacross heterogeneous domains makes it nontrivial to decide how much trainingfocus each objective should receive. To address this, we propose RECAP-a replaystrategy with dynamic objective reweighting for general knowledge preservation.Our reweighting mechanism adapts in an online manner using short-horizonsignals of convergence and instability, shifting the post-training focus awayfrom saturated objectives and toward underperforming or volatile ones.

190, TITLE: Graph Neural Network Assisted Genetic Algorithm for Structural Dynamic Response and Parameter Optimization
AUTHORS: Sagnik Mukherjee
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: Conventional numerical approaches, including Finite ElementMethod (FEM) and Computational Fluid Dynamics (CFD) simulations, providehigh-fidelity results but are computationally expensive for iterativeoptimization tasks, as each evaluation requires solving the governing equationsfor every parameter combination. This study proposes a hybrid data-drivenframework that integrates a Graph Neural Network (GNN) surrogate model with aGenetic Algorithm (GA) optimizer to overcome these challenges.

191, TITLE: Multi- objective Redundancy Allocation Integrating Interval Uncertainty and Hesitant Fuzzy Aggregation with A Non-dominated Sorting Genetic Algorithm
AUTHORS: B. Maneckshaw; G.S. Mahapatra; Kash Barker
CATEGORY: Expert Systems with Applications [EXPERT SYSTEMS WITH APPLICATIONS]
HIGHLIGHT: 

192, TITLE: Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery
AUTHORS: Bo Yue; Sheng Xu; Kui Jia; Guiliang Liu
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this paper,we propose RoboCraft, a scalable humanoid co-design framework for fall recoverythat iteratively improves performance through the coupled updates of controlpolicy and morphology.

193, TITLE: Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics
AUTHORS: Matthew So; Judah Goldfeder; Mark Lis; Hod Lipson
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: The iris ResNet architecture reaches 91 ROC AUC score foriris-to-iris matching, providing clear evidence that the left and right irisesof an individual are correlated. Fingerprint models reproduce the positiveintra-subject suggested by prior work in this space.

194, TITLE: FlowCritic: Bridging Value Estimation with Flow Matching in Reinforcement Learning
AUTHORS: Shan Zhong; Shutong Ding; He Diao; Xiangyu Wang; Kah Chan Teh; Bei Peng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Inspired by flow matching's success in generativemodeling, we propose a generative paradigm for value estimation, namedFlowCritic.

195, TITLE: Efficient Low Rank Attention for Long-Context Inference in Large Language Models
AUTHORS: Tenghui Li; Guoxu Zhou; Xuyang Zhao; Yuning Qiu; Qibin Zhao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Existing approaches, such as KV quantization and pruning,reduce memory usage but suffer from numerical precision loss or suboptimalretention of key-value pairs. We introduce Low Rank Query and Key attention(LRQK), a two-stage framework that jointly decomposes the full-precision queryand key matrices into compact rank-\(r\) factors during the prefill stage, andthen uses these low-dimensional projections to compute proxy attention scoresin \(\mathcal{O}(lr)\) time at each decode step.

196, TITLE: CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models Via Reinforcement Learning
AUTHORS: Tianhui Liu; Hetian Pang; Xin Zhang; Jie Feng; Yong Li; Pan Hui
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address theselimitations and maximize the potential of LVLMs, we introduce\textbf{CityRiSE}, a novel framework for \textbf{R}eason\textbf{i}ng urban\textbf{S}ocio-\textbf{E}conomic status in LVLMs through pure reinforcementlearning (RL).

197, TITLE: AnyECG- Lab: An Exploration Study of Fine-tuning An ECG Foundation Model to Estimate Laboratory Values from Single-Lead ECG Signals
AUTHORS: Yujie Xiao; Gongzhen Tang; Wenhui Liu; Jun Li; Guangkun Nie; Zhuoran Kan; Deyun Zhang; Qinghao Zhao; Shenda Hong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we conduct an exploratory study leveragingtransfer learning to fine-tune ECGFounder, a large-scale pre-trained ECGfoundation model, on the Multimodal Clinical Monitoring in the EmergencyDepartment (MC-MED) dataset from Stanford.

198, TITLE: LightAgent: Mobile Agentic Foundation Models
AUTHORS: Yangqin Jiang; Chao Huang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Yet mobile GUI agents face a critical dilemma: truly on-devicemodels (4B or smaller) lack sufficient performance, while capable models(starting from 7B) are either too large for mobile deployment or prohibitivelycostly (e.g., cloud-only closed-source MLLMs). To resolve this, we proposeLightAgent, a mobile agentic foundation model solution that leveragesdevice-cloud collaboration to tap the cost-efficiency of on-device models andthe high capability of cloud models, while avoiding their drawbacks.Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPOtraining on synthetic GUI data for strong decision-making, integrates anefficient long-reasoning mechanism to utilize historical interactions undertight resources, and defaults to on-device execution-only escalatingchallenging subtasks to the cloud via real-time complexity assessment.Experiments on the online AndroidLab benchmark and diverse apps show LightAgentmatches or nears larger models, with a significant reduction in cloud costs.

199, TITLE: Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models
AUTHORS: Mohammad Atif Quamar; Mohammad Areeb; Nishant Sharma; Ananth Shreekumar; Jonathan Rosenthal; Muslum Ozgur Ozmen; Mikhail Kuznetsov; Z. Berkay Celik
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Inference-time methods provide aflexible alternative to fine-tuning, but their uniform computational effortoften yields suboptimal alignment. We hypothesize that for many alignmenttasks, the initial tokens of a response are disproportionately more critical.To leverage this principle, we introduce AdaSearch, a novel blockwise searchstrategy.

200, TITLE: Parallel BiLSTM-Transformer Networks for Forecasting Chaotic Dynamics
AUTHORS: Junwen Ma; Mingyu Ge; Yisen Wang; Yong Zhang; Weicheng Fu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: The hybrid model employs a dual-brancharchitecture, where the Transformer branch mainly captures long-rangedependencies while the BiLSTM branch focuses on extracting local temporalfeatures.

201, TITLE: From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups
AUTHORS: Faria Huq; Elijah L. Claggett; Hirokazu Shirado
CATEGORY: arxiv-cs.SI [SI]
HIGHLIGHT: We present anonline experiment with 557 participants who engaged in multi-round discussionson politically controversial topics while freely reconfiguring their discussiongroups.

202, TITLE: Large Language Models in Peer Review: Challenges and Opportunities
AUTHORS: Zhuanlan Sun
CATEGORY: Scientometrics [SCIENTOMETRICS]
HIGHLIGHT: 

203, TITLE: Frequency-Spatial Interaction Driven Network for Low-Light Image Enhancement
AUTHORS: Yunhong Tao; Wenbing Tao; Xiang Xiang
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: In this paper, wedevelop a novel frequency-spatial interaction-driven network (FSIDNet) for LLIEbased on two-stage architecture.

204, TITLE: Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for FMRI-to-Image Reconstruction
AUTHORS: Xu Zhang; Ruijie Quan; Wenguan Wang; Yi Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Reconstructing visual stimuli from fMRI signals is a central challengebridging machine learning and neuroscience. Recent diffusion-based methodstypically map fMRI activity to a ...

205, TITLE: WaveMAE: Wavelet Decomposition Masked Auto-Encoder for Remote Sensing
AUTHORS: Vittorio Bernuzzi; Leonardo Rossi; Tomaso Fontanini; Massimo Bertozzi; Andrea Prati
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, weintroduce WaveMAE, a masked autoencoding framework tailored for multispectralsatellite imagery.

206, TITLE: Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for VLM Hallucination Mitigation
AUTHORS: Zheng Qi; Chao Shang; Evangelia Spiliopoulou; Nikolaos Pappas
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address thesechallenges, we propose a simple yet effective method called Gaze Shift-GuidedCross-modal Fusion Enhancement (GIFT).

207, TITLE: PAHQ: Accelerating Automated Circuit Discovery Through Mixed-Precision Inference Optimization
AUTHORS: Xinhai Wang; Shu Yang; Liangyu Wang; Lin Zhang; Huanyi Xie; Lijie Hu; Di Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Our proposed method for acceleratingautomated circuit discovery, Per Attention Head Quantization (PAHQ), takes afundamentally different approach by optimizing the efficiency of eachindividual patching operation.

208, TITLE: VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions
AUTHORS: Thu Phuong Nguyen; Duc M. Nguyen; Hyotaek Jeon; Hyunwook Lee; Hyunmin Song; Sungahn Ko; Taehwan Kim
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To enhance spatial understanding, we propose anExpression-Aware Visual Prompting Module, trained on our synthesized multi-linemath expressions dataset to robustly guide attention in visually heterogeneousinputs.

209, TITLE: Rule-Based Explanations for Retrieval-Augmented LLM Systems
AUTHORS: Joel Rorseth; Parke Godfrey; Lukasz Golab; Divesh Srivastava; Jarek Szlichta
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present the first proposalto apply rules to explain the emerging class of large language models (LLMs)with retrieval-augmented generation (RAG).

210, TITLE: Cross-view Localization and Synthesis - Datasets, Challenges and Opportunities
AUTHORS: Ningli Xu; Rongjun Qin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper presents acomprehensive survey of advances in cross-view localization and synthesis,reviewing widely used datasets, highlighting key challenges, and providing anorganized overview of state-of-the-art techniques.

211, TITLE: Enhancing Graph Classification Robustness with Singular Pooling
AUTHORS: Sofiane Ennadir; Oleg Smirnov; Yassine Abbahaddou; Lele Cao; Johannes F. Lutzeyer
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Graph Neural Networks (GNNs) have achieved strong performance across a rangeof graph representation learning tasks, yet their adversarial robustness ingraph classification remains underexplored compared to node classification.While most existing defenses focus on the message-passing component, this workinvestigates the overlooked role of pooling operations in shaping robustness.We present a theoretical analysis of standard flat pooling methods (sum,average and max), deriving upper bounds on their adversarial risk andidentifying their vulnerabilities under different attack scenarios and graphstructures. Motivated by these insights, we propose \textit{Robust SingularPooling (RS-Pool)}, a novel pooling strategy that leverages the dominantsingular vector of the node embedding matrix to construct a robust graph-levelrepresentation.

212, TITLE: From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy
AUTHORS: Feng He; Guodong Tan; Qiankun Li; Jun Yu; Quan Wen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However,learning-based 3D reconstruction in XLFM remains underdeveloped due to two corechallenges: the absence of standardized datasets and the lack of methods thatcan efficiently model its angular-spatial structure while remaining physicallygrounded. We address these challenges by introducing three key contributions.First, we construct the XLFM-Zebrafish benchmark, a large-scale dataset andevaluation suite for XLFM reconstruction.

213, TITLE: A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration
AUTHORS: Chiara Bonfanti; Alessandro Druetto; Cataldo Basile; Tharindu Ranasinghe; Marcos Zampieri
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: The growing intersection of cybersecurity and law creates a complexinformation space where traditional legal research tools struggle to deal withnuanced connections between cases, ...

214, TITLE: Agent-GSPO: Communication-Efficient Multi-Agent Systems Via Group Sequence Policy Optimization
AUTHORS: Yijia Fan; Jusheng Zhang; Jing Yang; Keze Wang
CATEGORY: arxiv-cs.MA [MA]
HIGHLIGHT: To combat the prohibitive communication costs of ``free-for-all" multi-agentsystems (MAS), we introduce \textbf{Agent-GSPO}, a framework that directlyoptimizes for token economy using sequence-level reinforcement learning.Agent-GSPO leverages the stable and memory-efficient Group Sequence PolicyOptimization (GSPO) algorithm to train agents on a communication-aware rewardthat explicitly penalizes verbosity.

215, TITLE: Decoding Tourist Motivations from Uploaded Photos: Why Tourists Travel Abroad
AUTHORS: Ao Luo; Chayanon Phucharoen
CATEGORY: Consumer Behavior in Tourism and Hospitality [CONSUMER BEHAVIOR IN TOURISM AND HOSPITALITY]
HIGHLIGHT: Purpose This study aims to analyze user-generated travel photos (UGTPs) to decode tourists’ motivations for traveling abroad.

216, TITLE: Self-Attention Decomposition For Training Free Diffusion Editing
AUTHORS: Tharun Anand; Mohammad Hassan Vali; Arno Solin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our insight is that self-attention weightmatrices encode rich structural information about the data distribution learnedduring training.

217, TITLE: LUNA: Efficient and Topology-Agnostic Foundation Model for EEG Signal Analysis
AUTHORS: Berkay Döner; Thorir Mar Ingolfsson; Luca Benini; Yawei Li
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce LUNA (Latent Unified Network Architecture), aself-supervised foundation model that reconciles disparate electrode geometrieswhile scaling linearly -- not quadratically -- with channel count.

218, TITLE: Reduced AI Acceptance After The Generative AI Boom: Evidence From A Two-Wave Survey Study
AUTHORS: Joachim Baumann; Aleksandra Urman; Ulrich Leicht-Deobald; Zachary J. Roman; Anikó Hannák; Markus Christen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Yet, public attitudes toward AIuse, especially in impactful decision-making scenarios, are underexplored.Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)representative of the Swiss population, we examine shifts in public attitudestoward AI before and after the launch of ChatGPT.

219, TITLE: Far from The Shallow: Brain-Predictive Reasoning Embedding Through Residual Disentanglement
AUTHORS: Linyang He; Tianjun Zhong; Richard Antonello; Gavin Mischler; Micah Goldblum; Nima Mesgarani
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: By first probing an LM to identify feature-specific layers, ourmethod iteratively regresses out lower-level representations to produce fournearly orthogonal embeddings for lexicon, syntax, meaning, and, critically,reasoning. We used these disentangled embeddings to model intracranial (ECoG)brain recordings from neurosurgical patients listening to natural speech.

220, TITLE: Think Before Recommendation: Autonomous Reasoning-enhanced Recommender
AUTHORS: Xiaoyu Kong; Junguang Jiang; Bin Liu; Ziru Xu; Han Zhu; Jian Xu; Bo Zheng; Jiancan Wu; Xiang Wang
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: RecZero consists of twokey components: (1) "Think-before-Recommendation" prompt construction, whichemploys a structured reasoning template to guide the model in step-wiseanalysis of user interests, item features, and user-item compatibility; and (2)rule-based reward modeling, which adopts group relative policy optimization(GRPO) to compute rewards for reasoning trajectories and optimize the LLM.Additionally, the paper explores a hybrid paradigm, RecOne, which combinessupervised fine-tuning with RL, initializing the model with cold-startreasoning samples and further optimizing it with RL.

221, TITLE: On The Societal Impact of Machine Learning
AUTHORS: Joachim Baumann
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: The contributions in this thesis enable moreappropriate measurement of fairness in ML systems, systematic decomposition ofML systems to anticipate bias dynamics, and effective interventions that reducealgorithmic discrimination while maintaining system utility.

222, TITLE: DDTR: Diffusion Denoising Trace Recovery
AUTHORS: Maximilian Matyash; Avigdor Gal; Arik Senderovich
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: With recent technological advances, process logs, which were traditionallydeterministic in nature, are being captured from non-deterministic sources,such as uncertain sensors or machine learning models (that predict activitiesusing cameras). In the presence of stochastically-known logs, logs that containprobabilistic information, the need for stochastic trace recovery increases, tooffer reliable means of understanding the processes that govern such systems.We design a novel deep learning approach for stochastic trace recovery, basedon Diffusion Denoising Probabilistic Models (DDPM), which makes use of processknowledge (either implicitly by discovering a model or explicitly by injectingprocess knowledge in the training phase) to recover traces by denoising.

223, TITLE: Accurate and Scalable Multimodal Pathology Retrieval Via Attentive Vision-Language Alignment
AUTHORS: Hongyi Wang; Zhengjie Zhu; Jiabo Ma; Fang Wang; Yue Shi; Bo Luo; Jili Wang; Qiuyu Cai; Xiuming Zhang; Yen-Wei Chen; Lanfen Lin; Hao Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, effective retrieval of whole slide images(WSIs) remains challenging due to their gigapixel scale and the difficulty ofcapturing subtle semantic differences amid abundant irrelevant content. Toovercome these challenges, we present PathSearch, a retrieval framework thatunifies fine-grained attentive mosaic representations with global-wise slideembeddings aligned through vision-language contrastive learning.

224, TITLE: Autoregressive Styled Text Image Generation, But Make It Reliable
AUTHORS: Carmine Zaccagnino; Fabio Quattrini; Vittorio Pippi; Silvia Cascianelli; Alessio Tonioni; Rita Cucchiara
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we rethink theautoregressive formulation by framing HTG as a multimodal prompt-conditionedgeneration task, and tackle the content controllability issues by introducingspecial textual input tokens for better alignment with the visual ones.Moreover, we devise a Classifier-Free-Guidance-based strategy for ourautoregressive model.

225, TITLE: Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models
AUTHORS: Fiaz Ahmad; Nisar Hussain; Amna Qasim; Momina Hafeez; Muhammad Usman Grigori Sidorov; Alexander Gelbukh
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we aim to detect irony in Urdu by translating an EnglishIronic Corpus into the Urdu language.

226, TITLE: Estimating Pasture Biomass from Top-View Images: A Dataset for Precision Agriculture
AUTHORS: Qiyu Liao; Dadong Wang; Rebecca Haling; Jiajun Liu; Xun Li; Martyna Plomecka; Andrew Robson; Matthew Pringle; Rhys Pirie; Megan Walker; Joshua Whelan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present acomprehensive dataset of 1,162 annotated top-view images of pastures collectedacross 19 locations in Australia.

227, TITLE: PlanarTrack: A High-quality and Challenging Benchmark for Large-scale Planar Object Tracking
AUTHORS: Yifan Jiao; Xinran Liu; Xiaoqiong Liu; Xiaohui Yuan; Heng Fan; Libo Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Despite recent great advancement, furtherdevelopment of planar tracking, particularly in the deep learning era, islargely limited compared to generic tracking due to the lack of large-scaleplatforms. To mitigate this, we propose PlanarTrack, a large-scale high-qualityand challenging benchmark for planar tracking.

228, TITLE: Robust Uncertainty Quantification for Self-Evolving Large Language Models Via Continual Domain Pretraining
AUTHORS: Xiaofan Zhou; Lu Cheng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Conformal Prediction (CP)has shown promise in offering correctness guarantees for LLMs, but it facesmajor challenges in CDP: testing data often stems from unknown or shiftingdomain distributions, under which CP may no longer provide valid guarantees.Moreover, when high coverage is required, CP can yield excessively largeprediction sets for unanswerable queries, reducing informativeness. To addressthese challenges, we introduce an adaptive rejection and non-exchangeable CPframework.

229, TITLE: Hybrid-Vector Retrieval for Visually Rich Documents: Combining Single-Vector Efficiency and Multi-Vector Accuracy
AUTHORS: Juyeon Kim; Geon Lee; Dongwon Choi; Taeuk Kim; Kijung Shin
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: Existingapproaches fall into two paradigms: single-vector retrieval, which is efficientbut coarse, and multi-vector retrieval, which is accurate but computationallyexpensive. To address this trade-off, we propose HEAVEN, a two-stagehybrid-vector framework.

230, TITLE: STRIDER: Navigation Via Instruction-Aligned Structural Decision Space Optimization
AUTHORS: Diqi He; Xuehao Gao; Hao Li; Junwei Han; Dingwen Zhang
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Acritical challenge in this setting lies in ensuring agents' actions align withboth spatial structure and task intent over long-horizon execution. Existingmethods often fail to achieve robust navigation due to a lack of structureddecision-making and insufficient integration of feedback from previous actions.To address these challenges, we propose STRIDER (Instruction-Aligned StructuralDecision Space Optimization), a novel framework that systematically optimizesthe agent's decision space by integrating spatial layout priors and dynamictask feedback.

231, TITLE: Jarvis: Towards Personalized AI Assistant Via Personal KV-Cache Retrieval
AUTHORS: Binxiao Xu; Junyu Feng; Ruichuan An; Yulin Luo; Shilin Yan; Hao Liang; Ming Lu; Wentao Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: The rapid development of Vision-language models (VLMs) enables open-endedperception and reasoning. Recent works have started to investigate how to adaptgeneral-purpose VLMs into ...

232, TITLE: Frustratingly Easy Task-aware Pruning for Large Language Models
AUTHORS: Yuanhe Tian; Junjie Liu; Xican Yang; Haishan Ye; Yan Song
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose a simpleyet effective pruning approach for LLMs that preserves task-specificcapabilities while shrinking their parameter space.

233, TITLE: Windsock Is Dancing: Adaptive Multimodal Retrieval-Augmented Generation
AUTHORS: Shu Zhao; Tianyi Shen; Nilesh Ahuja; Omesh Tickoo; Vijaykrishnan Narayanan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, existing MRAG approaches suffer from static retrievalstrategies, inflexible modality selection, and suboptimal utilization ofretrieved information, leading to three critical challenges: determining whento retrieve, what modality to incorporate, and how to utilize retrievedinformation effectively. To address these challenges, we introduce Windsock, aquery-dependent module making decisions on retrieval necessity and modalityselection, effectively reducing computational overhead and improving responsequality.

234, TITLE: Probing Neural Combinatorial Optimization Models
AUTHORS: Zhiqin Zhang; Yining Ma; Zhiguang Cao; Hoong Chuin Lau
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Using CS-Probing, we find that prevalent NCO models imposevarying inductive biases on their learned representations, uncover directevidence related to model generalization, and identify key embedding dimensionsassociated with specific knowledge.

235, TITLE: Learning "Partner-Aware" Collaborators in Multi-Party Collaboration
AUTHORS: Abhijnan Nath; Nikhil Krishnaswamy
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we build on the AIalignment and safe interruptability literature to offer novel theoreticalinsights on collaborative behavior between LLM-driven collaborator agents andan intervention agent.

236, TITLE: SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection
AUTHORS: Zhixin Pan; Ziyu Shu; Linh Nguyen; Amberbir Alemayoh
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: In this paper, we propose SAND, aselfsupervised and adaptive NAS-driven framework for efficient HT detection.Specifically, this paper makes three key contributions. (1) We leverageself-supervised learning (SSL) to enable automated feature extraction,eliminating the dependency on manually engineered features.

237, TITLE: Towards Low-Latency and Adaptive Ransomware Detection Using Contrastive Learning
AUTHORS: Zhixin Pan; Ziyu Shu; Amberbir Alemayoh
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: While AI-basedapproaches had been proposed by prior works to assist ransomware detection,existing methods suffer from three major limitations, ad-hoc featuredependencies, delayed response, and limited adaptability to unseen variants. Inthis paper, we propose a framework that integrates self-supervised contrastivelearning with neural architecture search (NAS) to address these challenges.Specifically, this paper offers three important contributions. (1) We design acontrastive learning framework that incorporates hardware performance counters(HPC) to analyze the runtime behavior of target ransomware.

238, TITLE: Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts
AUTHORS: Nikesh Gyawali; Doina Caragea; Alex Vasenkov; Cornelia Caragea
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we introduce a sentence-level corpus forstance detection focused on three core financial metrics: debt, earnings pershare (EPS), and sales.

239, TITLE: From Prompt Optimization to Multi-Dimensional Credibility Evaluation: Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports
AUTHORS: Qiuli Wang; Xiaoming Li; Jie Chen; Yongxu Liu; Xingpeng Zhang; Chen Liu; Wei Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: This study aims to enhance the trustworthiness ofLLM-generated liver MRI reports by introducing a Multi-Dimensional CredibilityAssessment (MDCA) framework and providing guidance on institution-specificprompt optimization.

240, TITLE: Does Homophily Help in Robust Test-time Node Classification?
AUTHORS: Yan Jiang; Ruihong Qiu; Zi Huang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: With empiricalobservations and theoretical analysis, we reveal that transforming the testgraph structure by increasing homophily in homophilic graphs or decreasing itin heterophilic graphs can significantly improve the robustness and performanceof pre-trained GNNs on node classifications, without requiring model trainingor update.

241, TITLE: MoEMeta: Mixture-of-Experts Meta Learning for Few-Shot Relational Learning
AUTHORS: Han Wu; Jie Yin
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To address theselimitations, we propose MoEMeta, a novel meta-learning framework thatdisentangles globally shared knowledge from task-specific contexts to enableboth effective generalization and rapid adaptation.

242, TITLE: Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens
AUTHORS: Jiahao Ji; Tianyu Wang; Yeshu Li; Yushen Huo; Zhilin Zhang; Chuan Yu; Jian Xu; Bo Zheng
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: On top of the learned variable and temporal representations, avariable-aware fusion module is used to perform adaptive bidding outcomeprediction. To model the unique bidding data distribution, we devise azero-inflated projection module to incorporate the estimated non-zeroprobability into its value prediction, which makes up a joint optimizationobjective containing classification and regression.

243, TITLE: T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense on Text-to-Image Model
AUTHORS: Chenyu Zhang; Tairen Zhang; Lanjun Wang; Ruidong Chen; Wenhui Li; Anan Liu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: However, existingrisky prompt datasets are limited in three key areas: 1) limited riskycategories, 2) coarse-grained annotation, and 3) low effectiveness. To addressthese limitations, we introduce T2I-RiskyPrompt, a comprehensive benchmarkdesigned for evaluating safety-related tasks in T2I models.

244, TITLE: Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling
AUTHORS: Shuhong Zheng; Ashkan Mirzaei; Igor Gilitschenski
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce TIRE(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.It takes an initial 3D asset produced by an existing 3D generative model asinput and uses video tracking to identify the regions that need to be modified.Then, we adopt a subject-driven 2D inpainting model for progressively infillingthe identified regions.

245, TITLE: Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles
AUTHORS: Jose Luis Ponton; Eduardo Alvarado; Lin Geng Foo; Nuria Pelechano; Carlos Andujar; Marc Habermann
CATEGORY: arxiv-cs.GR [GR]
HIGHLIGHT: Our method utilizes pressure and inertialdata-accelerations and angular rates-captured by the insoles to reconstructhuman motion.

246, TITLE: Agentic Meta-Orchestrator for Multi-task Copilots
AUTHORS: Xiaofeng Zhu; Yunshen Zhou
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work, we propose an Agentic Meta-orchestrator (AMO) forhandling multiple tasks and scalable agents in copilot services, which canprovide both natural language and action responses.

247, TITLE: UrbanVLA: A Vision-Language-Action Model for Urban Micromobility
AUTHORS: Anqi Li; Zhiyong Wang; Jiazhao Zhang; Minghan Li; Yunpeng Qi; Zhibo Chen; Zhizheng Zhang; He Wang
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: To enable UrbanVLA to master both levelsof navigation, we employ a two-stage training pipeline.

248, TITLE: M-CIF: Multi-Scale Alignment For CIF-Based Non-Autoregressive ASR
AUTHORS: Ruixiang Mao; Xiangnan Ma; Qing Yang; Ziming Zhu; Yucheng Qiao; Yuan Ge; Tong Xiao; Shengxiang Gao; Zhengtao Yu; Jingbo Zhu
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: In this paper, we propose Multi-scale CIF(M-CIF), which performs multi-level alignment by integrating character andphoneme level supervision progressively distilled into subword representations,thereby enhancing robust acoustic-text alignment.

249, TITLE: Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions
AUTHORS: Ji Huang; Mengfei Li; Shuai Shao
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Large language models (LLMs) offer a promising way to simulate human surveyresponses, potentially reducing the cost of large-scale data collection.However, existing zero-shot methods suffer from prompt sensitivity and lowaccuracy, while conventional fine-tuning approaches mostly fit the training setdistributions and struggle to produce results more accurate than the trainingset itself, which deviates from the original goal of using LLMs to simulatesurvey responses. Building on this observation, we introduce Distribution ShiftAlignment (DSA), a two-stage fine-tuning method that aligns both the outputdistributions and the distribution shifts across different backgrounds.

250, TITLE: Language Server CLI Empowers Language Agents with Process Rewards
AUTHORS: Yifan Zhang; Lanser Contributors
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, Lanser-CLIcontributes: (i) a robust addressing scheme beyond brittle "file:line:col" viaa Selector DSL (symbolic, AST-path, and content-anchored selectors) with aprincipled relocation algorithm; (ii) deterministic Analysis Bundles thatnormalize Language Server responses and capture environment/capability metadatawith stable content hashes; (iii) a safety envelope for mutating operations(rename, code actions) with preview, workspace jails, and Git-aware,transactional apply; and (iv) a process-reward functional derived from LanguageServer facts (diagnostic deltas, disambiguation confidence, and safe-applychecks) that is computable online and replayable offline.

