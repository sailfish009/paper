1, TITLE: Explorations of Self-Repair in Language Models
AUTHORS: Cody Rushing ; Neel Nanda
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We highlight two different mechanisms that contribute to self-repair, including changes in the final LayerNorm scaling factor (which can repair up to 30% of the direct effect) and sparse sets of neurons implementing Anti-Erasure.

2, TITLE: OpenSUN3D: 1st Workshop Challenge on Open-Vocabulary 3D Scene Understanding
AUTHORS: FRANCIS ENGELMANN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: The goal of this workshop series is to provide a platform for exploration and discussion of open-vocabulary 3D scene understanding tasks, including but not limited to segmentation, detection and mapping.

3, TITLE: Unintended Impacts of LLM Alignment on Global Representation
AUTHORS: Michael J. Ryan ; William Held ; Diyi Yang
CATEGORY: cs.CL [cs.CL, cs.CY, cs.LG]
HIGHLIGHT: We explore how alignment impacts performance along three axes of global representation: English dialects, multilingualism, and opinions from and about countries worldwide.

4, TITLE: Genie: Generative Interactive Environments
AUTHORS: JAKE BRUCE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos.

5, TITLE: Dynamics-Guided Diffusion Model for Robot Manipulator Design
AUTHORS: Xiaomeng Xu ; Huy Ha ; Shuran Song
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: We present Dynamics-Guided Diffusion Model, a data-driven framework for generating manipulator geometry designs for a given manipulation task.

6, TITLE: GPTVQ: The Blessing of Dimensionality for LLM Quantization
AUTHORS: MART VAN BAALEN et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this work we show that the size versus accuracy trade-off of neural network quantization can be significantly improved by increasing the quantization dimensionality.

7, TITLE: Machine Unlearning of Pre-trained Large Language Models
AUTHORS: JIN YAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: We explore machine unlearning as a pivotal solution, with a focus on pre-trained models--a notably under-researched area.

8, TITLE: Optimized Deployment of Deep Neural Networks for Visual Pose Estimation on Nano-drones
AUTHORS: MATTEO RISSO et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This work proposes a new automatic optimization pipeline for visual pose estimation tasks using Deep Neural Networks (DNNs).

9, TITLE: On The Duality Between Sharpness-Aware Minimization and Adversarial Training
AUTHORS: YIHAO ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR, math.OC]
HIGHLIGHT: In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM.

10, TITLE: Gotcha! Don't Trick Me with Unanswerable Questions! Self-aligning Large Language Models for Responding to Unknown Questions
AUTHORS: Yang Deng ; Yong Zhao ; Moxin Li ; See-Kiong Ng ; Tat-Seng Chua
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: To avoid providing hallucinated answers to these unknown questions, existing studies typically investigate approaches to refusing to answer these questions. In this work, we propose a novel and scalable self-alignment method to utilize the LLM itself to enhance its response-ability to different types of unknown questions, being capable of not only refusing to answer but also providing explanation to the unanswerability of unknown questions.

11, TITLE: On The Multi-turn Instruction Following for Conversational Web Agents
AUTHORS: YANG DENG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web).

12, TITLE: Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment
AUTHORS: JIONGXIAO WANG et. al.
CATEGORY: cs.CR [cs.CR, cs.CL]
HIGHLIGHT: To effectively defend against the FJAttack with limited safety examples, we propose a Backdoor Enhanced Safety Alignment method inspired by an analogy with the concept of backdoor attacks.

13, TITLE: How Important Is Tokenization in French Medical Masked Language Models?
AUTHORS: Yanis Labrak ; Adrien Bazoge ; Beatrice Daille ; Mickael Rouvier ; Richard Dufour
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we seek to delve into the complexities of subword tokenization in French biomedical domain across a variety of NLP tasks and pinpoint areas where further enhancements can be made.

14, TITLE: Large Multimodal Agents: A Survey
AUTHORS: Junlin Xie ; Zhihong Chen ; Ruifei Zhang ; Xiang Wan ; Guanbin Li
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we conduct a systematic review of LLM-driven multimodal agents, which we refer to as large multimodal agents ( LMAs for short).

15, TITLE: KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models
AUTHORS: ZHUOHAO YU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we introduce KIEval, a Knowledge-grounded Interactive Evaluation framework, which incorporates an LLM-powered "interactor" role for the first time to accomplish a dynamic contamination-resilient evaluation.

16, TITLE: Advancing Parameter Efficiency in Fine-tuning Via Representation Editing
AUTHORS: MULING WU et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Despite the promising performance of current PEFT methods, they present challenges in hyperparameter selection, such as determining the rank of LoRA or Adapter, or specifying the length of soft prompts. In addressing these challenges, we propose a novel approach to fine-tuning neural models, termed Representation EDiting (RED), which scales and biases the representation produced at each layer.

17, TITLE: Benchmarking The Robustness of Panoptic Segmentation for Automated Driving
AUTHORS: YITING WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, 19 noise factors have been identified and implemented with 3 severity levels. Of these factors, this work proposes novel models for unfavourable light and snow.

18, TITLE: AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning
AUTHORS: JIANGUO ZHANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges.

19, TITLE: ToMBench: Benchmarking Theory of Mind in Large Language Models
AUTHORS: ZHUANG CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, existing ToM evaluations are hindered by challenges such as constrained scope, subjective judgment, and unintended contamination, yielding inadequate assessments. To address this gap, we introduce ToMBench with three key characteristics: a systematic evaluation framework encompassing 8 tasks and 31 abilities in social cognition, a multiple-choice question format to support automated and unbiased evaluation, and a build-from-scratch bilingual inventory to strictly avoid data leakage.

20, TITLE: Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions
AUTHORS: Clement Neo ; Shay B. Cohen ; Fazl Barez
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we investigate the interplay between attention heads and specialized "next-token" neurons in the Multilayer Perceptron that predict specific tokens.

21, TITLE: Self-Adaptive Reconstruction with Contrastive Learning for Unsupervised Sentence Embeddings
AUTHORS: Junlong Liu ; Xichen Shang ; Huawen Feng ; Junhao Zheng ; Qianli Ma
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: However, due to the token bias in pretrained language models, the models can not capture the fine-grained semantics in sentences, which leads to poor predictions. To address this issue, we propose a novel Self-Adaptive Reconstruction Contrastive Sentence Embeddings (SARCSE) framework, which reconstructs all tokens in sentences with an AutoEncoder to help the model to preserve more fine-grained semantics during tokens aggregating.

22, TITLE: MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained Language Models
AUTHORS: Nathanaï¿½l Carraz Rakotonirina ; Marco Baroni
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Transformer-based language models (LMs) track contextual information through large, hard-coded input windows. We introduce MemoryPrompt, a leaner approach in which the LM is complemented by a small auxiliary recurrent network that passes information to the LM by prefixing its regular input with a sequence of vectors, akin to soft prompts, without requiring LM finetuning.

23, TITLE: AttributionBench: How Hard Is Automatic Attribution Evaluation?
AUTHORS: Yifei Li ; Xiang Yue ; Zeyi Liao ; Huan Sun
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This verification, traditionally dependent on costly human evaluation, underscores the urgent need for automatic attribution evaluation methods. To bridge the gap in the absence of standardized benchmarks for these methods, we present AttributionBench, a comprehensive benchmark compiled from various existing attribution datasets.

24, TITLE: Seeing Is Believing: Mitigating Hallucination in Large Vision-Language Models Via CLIP-Guided Decoding
AUTHORS: Ailin Deng ; Zhirui Chen ; Bryan Hooi
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG, cs.MM]
HIGHLIGHT: We first perform empirical analysis on sentence-level LVLM hallucination, finding that CLIP similarity to the image acts as a stronger and more robust indicator of hallucination compared to token likelihoods. Motivated by this, we introduce our CLIP-Guided Decoding (CGD) approach, a straightforward but effective training-free approach to reduce object hallucination at decoding time.

25, TITLE: MultiLS: A Multi-task Lexical Simplification Framework
AUTHORS: Kai North ; Tharindu Ranasinghe ; Matthew Shardlow ; Marcos Zampieri
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present MultiLS, the first LS framework that allows for the creation of a multi-task LS dataset.

26, TITLE: PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning
AUTHORS: Simon Holk ; Daniel Marta ; Iolanda Leite
CATEGORY: cs.RO [cs.RO, cs.CL, cs.LG]
HIGHLIGHT: In this work, we approach the sample-efficiency challenge by expanding the information collected per query to contain both preferences and optional text prompting.

27, TITLE: Repetition Improves Language Model Embeddings
AUTHORS: Jacob Mitchell Springer ; Suhas Kotha ; Daniel Fried ; Graham Neubig ; Aditi Raghunathan
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this work, we address an architectural limitation of autoregressive models: token embeddings cannot contain information from tokens that appear later in the input.

28, TITLE: Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts
AUTHORS: Yuejiang Liu ; Alexandre Alahi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: Yet, the effectiveness of such weak-to-strong generalization remains limited, especially in the presence of large capability gaps. In this paper, we propose to address this challenge by harnessing a diverse set of specialized teachers, instead of a single generalist one, that collectively supervises the strong student.

29, TITLE: Low-Rank Representations Meets Deep Unfolding: A Generalized and Interpretable Network for Hyperspectral Anomaly Detection
AUTHORS: Chenyu Li ; Bing Zhang ; Danfeng Hong ; Jing Yao ; Jocelyn Chanussot
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: Accordingly, we propose a generalized and interpretable HAD network by deeply unfolding a dictionary-learnable LLR model, named LRR-Net$^+$, which is capable of spectrally decoupling the background structure and object properties in a more generalized fashion and eliminating the bias introduced by vital interference targets concurrently.

30, TITLE: Dynamic Memory Based Adaptive Optimization
AUTHORS: Balï¿½zs Szegedy ; Domonkos Czifra ; Pï¿½ter K?rï¿½si-Szabï¿½
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC]
HIGHLIGHT: As an approach to the last question, we introduce a general method called "Retrospective Learning Law Correction" or shortly RLLC.

31, TITLE: Convergence Analysis of Blurring Mean Shift
AUTHORS: Ryoya Yamasaki ; Toshiyuki Tanaka
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Blurring mean shift (BMS) algorithm, a variant of the mean shift algorithm, is a kernel-based iterative method for data clustering, where data points are clustered according to their convergent points via iterative blurring. In this paper, we analyze convergence properties of the BMS algorithm by leveraging its interpretation as an optimization procedure, which is known but has been underutilized in existing convergence studies.

32, TITLE: Path Planning Based on 2D Object Bounding-box
AUTHORS: Yanliang Huang ; Liguo Zhou ; Chang Liu ; Alois Knoll
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this study, we present a path planning method that utilizes 2D bounding boxes of objects, developed through imitation learning in urban driving scenarios.

33, TITLE: BSPA: Exploring Black-box Stealthy Prompt Attacks Against Image Generators
AUTHORS: YU TIAN et. al.
CATEGORY: cs.CR [cs.CR, cs.CL, cs.CV]
HIGHLIGHT: Nevertheless, they are constrained by labor-intensive design processes and heavily reliant on the quality of the given instructions. To achieve this, we introduce a black-box stealthy prompt attack (BSPA) that adopts a retriever to simulate attacks from API users.

34, TITLE: In-Context Learning of A Linear Transformer Block: Benefits of The MLP Component and One-Step GD Initialization
AUTHORS: Ruiqi Zhang ; Jingfeng Wu ; Peter L. Bartlett
CATEGORY: stat.ML [stat.ML, cs.CL, cs.LG]
HIGHLIGHT: We study the \emph{in-context learning} (ICL) ability of a \emph{Linear Transformer Block} (LTB) that combines a linear attention component and a linear multi-layer perceptron (MLP) component.

35, TITLE: Which Model to Transfer? A Survey on Transferability Estimation
AUTHORS: Yuhe Ding ; Bo Jiang ; Aijing Yu ; Aihua Zheng ; Jian Liang
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Despite extensive recent advances already devoted to this area, they have custom terminological definitions and experimental settings. In this survey, we present the first review of existing advances in this area and categorize them into two separate realms: source-free model transferability estimation and source-dependent model transferability estimation.

36, TITLE: ColBERT-XM: A Modular Multi-Vector Representation Model for Zero-Shot Multilingual Information Retrieval
AUTHORS: Antoine Louis ; Vageesh Saxena ; Gijs van Dijck ; Gerasimos Spanakis
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In this work, we present a novel modular dense retrieval model that learns from the rich data of a single high-resource language and effectively zero-shot transfers to a wide array of languages, thereby eliminating the need for language-specific labeled data.

37, TITLE: ArabianGPT: Native Arabic GPT-based Large Language
AUTHORS: Anis Koubaa ; Adel Ammar ; Lahouari Ghouti ; Omar Najar ; Serry Sibaee
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Consequently, there is a theoretical and practical imperative for developing LLMs predominantly focused on Arabic linguistic elements. To address this gap, this paper proposes ArabianGPT, a series of transformer-based models within the ArabianLLM suite designed explicitly for Arabic.

38, TITLE: Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing
AUTHORS: Jeong Hun Yeo ; Seunghee Han ; Minsu Kim ; Yong Man Ro
CATEGORY: cs.CV [cs.CV, cs.CL, eess.AS, eess.IV]
HIGHLIGHT: In this paper, we propose a novel framework, namely Visual Speech Processing incorporated with LLMs (VSP-LLM), to maximize the context modeling ability by bringing the overwhelming power of LLMs.

39, TITLE: Label-efficient Multi-organ Segmentation Method with Diffusion Model
AUTHORS: YONGZHI HUANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we present a label-efficient learning approach using a pre-trained diffusion model for multi-organ segmentation tasks in CT images.

40, TITLE: Farsight: Fostering Responsible AI Awareness During AI Application Prototyping
AUTHORS: Zijie J. Wang ; Chinmay Kulkarni ; Lauren Wilcox ; Michael Terry ; Michael Madaio
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CY, cs.LG]
HIGHLIGHT: We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers.

41, TITLE: Probabilistically-sound Beam Search with Masked Language Models
AUTHORS: Charlie Cowen-Breen ; Creston Brooks ; Robert Calef ; Anna Sappington
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We present probabilistically-sound methods for beam search with MLMs.

42, TITLE: Divide-or-Conquer? Which Part Should You Distill Your LLM?
AUTHORS: ZHUOFENG WU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper we devise a similar strategy that breaks down reasoning tasks into a problem decomposition phase and a problem solving phase and show that the strategy is able to outperform a single stage solution.

43, TITLE: Deep Coupling Network For Multivariate Time Series Forecasting
AUTHORS: KUN YI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings.

44, TITLE: Spatially-Aware Transformer Memory for Embodied Agents
AUTHORS: Junmo Cho ; Jaesik Yoon ; Sungjin Ahn
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information.

45, TITLE: ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models Against Stochastic Perturbation
AUTHORS: YI ZHANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: To tackle the challenges, we employ sequential analysis with efficacy and futility early stopping rules in the statistical testing for identifying AEs, and adaptive concentration inequalities to dynamically determine the "just-right" number of stochastic perturbations whenever the verification target is met.

46, TITLE: API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs
AUTHORS: KINJAL BASU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we focus on the task of identifying, curating, and transforming existing datasets and, in turn, introduce API-BLEND, a large corpora for training and systematic testing of tool-augmented LLMs.

47, TITLE: PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables Parameter-Efficient Transfer Learning
AUTHORS: Zhisheng Lin ; Han Fu ; Chenghao Liu ; Zhuo Li ; Jianling Sun
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: However, current approaches typically either train adapters on individual tasks or distill shared knowledge from source tasks, failing to fully exploit task-specific knowledge and the correlation between source and target tasks. To overcome these limitations, we propose PEMT, a novel parameter-efficient fine-tuning framework based on multi-task transfer learning.

48, TITLE: Fine-Tuning of Continuous-Time Diffusion Models As Entropy-Regularized Control
AUTHORS: MASATOSHI UEHARA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We present theoretical and empirical evidence that demonstrates our framework is capable of efficiently generating diverse samples with high genuine rewards, mitigating the overoptimization of imperfect reward models.

49, TITLE: GraphEdit: Large Language Models for Graph Structure Learning
AUTHORS: ZIRUI GUO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data.

50, TITLE: Does Combining Parameter-efficient Modules Improve Few-shot Transfer Accuracy?
AUTHORS: NADER ASADI et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Specifically, the efficiency of low-rank adaptation has facilitated the creation and sharing of hundreds of custom LoRA modules, each trained on distinct data from various downstream tasks. In this paper, we explore the composability of LoRA modules, examining if combining these pre-trained modules enhances generalization to unseen downstream tasks.

51, TITLE: ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition
AUTHORS: Lu Ye ; Ze Tao ; Yong Huang ; Yang Li
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we introduce ChunkAttention, a prefix-aware self-attention module that can detect matching prompt prefixes across multiple requests and share their key/value tensors in memory at runtime to improve the memory utilization of KV cache.

52, TITLE: EMIFF: Enhanced Multi-scale Image Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection
AUTHORS: ZHE WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Currently, two major challenges persist in vehicle-infrastructure cooperative 3D (VIC3D) object detection: $1)$ inherent pose errors when fusing multi-view images, caused by time asynchrony across cameras; $2)$ information loss in transmission process resulted from limited communication bandwidth. To address these issues, we propose a novel camera-based 3D detection framework for VIC3D task, Enhanced Multi-scale Image Feature Fusion (EMIFF).

53, TITLE: Unsupervised Domain Adaptation for Brain Vessel Segmentation Through Transwarp Contrastive Learning
AUTHORS: FENGMING LIN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This paper proposes a simple yet potent contrastive learning framework for UDA to narrow the inter-domain gap between labelled source and unlabelled target distribution.

54, TITLE: GS-EMA: Integrating Gradient Surgery Exponential Moving Average with Boundary-Aware Contrastive Learning for Enhanced Domain Generalization in Aneurysm Segmentation
AUTHORS: FENGMING LIN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: These shifts include differences in image appearance, intensity distribution, resolution, and aneurysm size, all of which complicate the segmentation process. To tackle these issues, we propose a novel domain generalization strategy that employs gradient surgery exponential moving average (GS-EMA) optimization technique coupled with boundary-aware contrastive learning (BACL).

55, TITLE: Ar-Spider: Text-to-SQL in Arabic
AUTHORS: Saleh Almohaimeed ; Saad Almohaimeed ; Mansour Al Ghanim ; Liqiang Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset.

56, TITLE: Causal Graph Discovery with Retrieval-Augmented Generation Based Large Language Models
AUTHORS: Yuzhe Zhang ; Yipeng Zhang ; Yidong Gan ; Lina Yao ; Chen Wang
CATEGORY: cs.CL [cs.CL, cs.LG, stat.ME]
HIGHLIGHT: We propose a novel method that utilizes the extensive knowledge contained within a large corpus of scientific literature to deduce causal relationships in general causal graph recovery tasks.

57, TITLE: Lasso with Latents: Efficient Estimation, Covariate Rescaling, and Computational-Statistical Gaps
AUTHORS: Jonathan Kelner ; Frederic Koehler ; Raghu Meka ; Dhruv Rohatgi
CATEGORY: stat.ML [stat.ML, cs.CC, cs.DS, cs.LG, math.ST, stat.TH]
HIGHLIGHT: In this work, we propose a natural sparse linear regression setting where strong correlations between covariates arise from unobserved latent variables.

58, TITLE: DEEM: Dynamic Experienced Expert Modeling for Stance Detection
AUTHORS: Xiaolong Wang ; Yile Wang ; Sijie Cheng ; Peng Li ; Yang Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, different from existing multi-agent works that require detailed descriptions and use fixed experts, we propose a Dynamic Experienced Expert Modeling (DEEM) method which can leverage the generated experienced experts and let LLMs reason in a semi-parametric way, making the experts more generalizable and reliable.

59, TITLE: How (un)ethical Are Instruction-centric Responses of LLMs? Unveiling The Vulnerabilities of Safety Guardrails to Harmful Queries
AUTHORS: Somnath Banerjee ; Sayan Layek ; Rima Hazra ; Animesh Mukherjee
CATEGORY: cs.CL [cs.CL, cs.CR]
HIGHLIGHT: In this study, we tackle a growing concern around the safety and ethical use of large language models (LLMs).

60, TITLE: The Surprising Effectiveness of Skip-Tuning in Diffusion Sampling
AUTHORS: JIAJUN MA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: As the sampling steps decrease, the generation process and the role of the UNet get closer to the push-forward transformations from Gaussian distribution to the target, posing a challenge for the network's complexity. To address this challenge, we propose Skip-Tuning, a simple yet surprisingly effective training-free tuning method on the skip connections.

61, TITLE: Semi-supervised Counting Via Pixel-by-pixel Density Distribution Modelling
AUTHORS: HUI LIN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We formulate the pixel-wise density value to regress as a probability distribution, instead of a single deterministic value. On this basis, we propose a semi-supervised crowd-counting model.

62, TITLE: Ranking Entities Along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies
AUTHORS: Nitesh Kumar ; Usashi Chatterjee ; Steven Schockaert
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We focus in particular on the task of ranking entities according to a given conceptual space dimension.

63, TITLE: A First Look at GPT Apps: Landscape and Vulnerability
AUTHORS: ZEJUN ZHANG et. al.
CATEGORY: cs.CR [cs.CR, cs.CL]
HIGHLIGHT: Thus, in this work, we conduct a pioneering exploration of GPT stores, aiming to study vulnerabilities and plagiarism within GPT applications.

64, TITLE: Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales
AUTHORS: SHUREN QI et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, such invariant representations typically exhibit limited discriminability, limiting their applications in larger-scale trustworthy vision tasks. For this open problem, we conduct a systematic investigation of hierarchical invariance, exploring this topic from theoretical, practical, and application perspectives.

65, TITLE: Enhancing ICU Patient Recovery: Using LLMs to Assist Nurses in Diary Writing
AUTHORS: Samuel Kernan Freire ; Margo MC van Mol ; Carola Schol ; Elif ï¿½zcan Vieira
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: However, realizing this vision involves addressing several socio-technical and practical research challenges. This paper discusses these challenges and proposes future research directions to utilize the potential of LLMs in ICU diary writing, ultimately improving the long-term recovery outcomes for ICU patients.

66, TITLE: Fine-Grained Detoxification Via Instance-Level Prefixes for Large Language Models
AUTHORS: Xin Yi ; Linlin Wang ; Xiaoling Wang ; Liang He
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose fine-grained detoxification via instance-level prefixes (FGDILP) to mitigate toxic text without additional cost.

67, TITLE: Towards Few-Shot Adaptation of Foundation Models Via Multitask Finetuning
AUTHORS: ZHUOYAN XU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: An emerging solution with recent success in vision and NLP involves finetuning a foundation model on a selection of relevant tasks, before its adaptation to a target task with limited labeled samples. In this paper, we study the theoretical justification of this multitask finetuning approach.

68, TITLE: Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models
AUTHORS: Hongbin Liu ; Michael K. Reiter ; Neil Zhenqiang Gong
CATEGORY: cs.CR [cs.CR, cs.CV, cs.LG]
HIGHLIGHT: In this work, we propose Mudjacking, the first method to patch foundation models to remove backdoors.

69, TITLE: Information-Theoretic Safe Bayesian Optimization
AUTHORS: Alessandro G. Bottero ; Carlos E. Luis ; Julia Vinogradska ; Felix Berkenkamp ; Jan Peters
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: In this paper, we propose an information-theoretic safe exploration criterion that directly exploits the GP posterior to identify the most informative safe parameters to evaluate.

70, TITLE: Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models
AUTHORS: YIRAN LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this work, we present the Prejudice-Caprice Framework (PCF) that comprehensively measures discrimination in LLMs by considering both their consistently biased preference and preference variation across diverse contexts.

71, TITLE: Source-Guided Similarity Preservation for Online Person Re-Identification
AUTHORS: Hamza Rami ; Jhony H. Giraldo ; Nicolas Winckler ; Stï¿½phane Lathuiliï¿½re
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In OUDA, person Re-ID models face two main challenges: catastrophic forgetting and domain shift. In this work, we propose a new Source-guided Similarity Preservation (S2P) framework to alleviate these two problems.

72, TITLE: Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding
AUTHORS: HAOMING LI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.GT, cs.IR]
HIGHLIGHT: The trained policy can subsequently be deployed for further data collection, resulting in an iterative training framework, which we refer to as iterative offline RL. In this work, we identify the performance bottleneck of this iterative offline RL framework, which originates from the ineffective exploration and exploitation caused by the inherent conservatism of offline RL algorithms.

73, TITLE: Optimizing Language Models for Human Preferences Is A Causal Inference Problem
AUTHORS: Victoria Lin ; Eli Ben-Michael ; Louis-Philippe Morency
CATEGORY: cs.LG [cs.LG, cs.CL, stat.ME]
HIGHLIGHT: In this paper, we present an initial exploration of language model optimization for human preferences from direct outcome datasets, where each sample consists of a text and an associated numerical outcome measuring the reader's response.

74, TITLE: Biomedical Entity Linking As Multiple Choice Question Answering
AUTHORS: Zhenxi Lin ; Ziheng Zhang ; Xian Wu ; Yefeng Zheng
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Although biomedical entity linking (BioEL) has made significant progress with pre-trained language models, challenges still exist for fine-grained and long-tailed entities. To address these challenges, we present BioELQA, a novel model that treats Biomedical Entity Linking as Multiple Choice Question Answering.

75, TITLE: Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning
AUTHORS: Hanqi Yan ; Qinglin Zhu ; Xinyu Wang ; Lin Gui ; Yulan He
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore, We propose Mirror, a Multiple-perspective self-reflection method for knowledge-rich reasoning, to avoid getting stuck at a particular reflection iteration.

76, TITLE: Spatiotemporal Observer Design for Predictive Learning of High-Dimensional Data
AUTHORS: Tongyi Liang ; Han-Xiong Li
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: How to make spatiotemporal forecasting with theoretical guarantees is still a challenging issue. In this work, we tackle this problem by applying domain knowledge from the dynamical system to the framework design of deep learning models.

77, TITLE: Linear Dynamics-embedded Neural Network for Long-Sequence Modeling
AUTHORS: Tongyi Liang ; Han-Xiong Li
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Inspired by the continuous state space models (SSMs) with multi-input and multi-output in control theory, we propose a new neural network called Linear Dynamics-embedded Neural Network (LDNN).

78, TITLE: TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow Attention for Commuting Flow Prediction
AUTHORS: YAN LUO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY]
HIGHLIGHT: While deep learning models offer improved accuracy, their black-box nature poses a trade-off between performance and explainability -- both vital for analyzing complex societal phenomena like commuting flows. To address this, we introduce TransFlower, an explainable, transformer-based model employing flow-to-flow attention to predict urban commuting patterns.

79, TITLE: Counterfactual Generation with Identifiability Guarantees
AUTHORS: HANQI YAN et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task.

80, TITLE: A Quantum-Classical Collaborative Training Architecture Based on Quantum State Fidelity
AUTHORS: RYAN L'ABBATE et. al.
CATEGORY: quant-ph [quant-ph, cs.AI]
HIGHLIGHT: In this study, we concentrate on quantum deep learning and introduce a collaborative classical-quantum architecture called co-TenQu.

81, TITLE: Dimension Independent Disentanglers from Unentanglement and Applications
AUTHORS: Fernando G. Jeronimo ; Pei Wu
CATEGORY: quant-ph [quant-ph, cs.CC]
HIGHLIGHT: Dimension Independent Disentanglers from Unentanglement and Applications

82, TITLE: Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network Models
AUTHORS: Peng Lin ; Martin Neil ; Norman Fenton
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Hence, we propose a new algorithm called stacking factorization (SF) to decompose the partitioned expressions.

83, TITLE: A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs
AUTHORS: Yonglin Jing
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE.

84, TITLE: Can We Forget How We Learned? Doxastic Redundancy in Iterated Belief Revision
AUTHORS: Paolo Liberatore
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Can We Forget How We Learned? Doxastic Redundancy in Iterated Belief Revision

85, TITLE: CommVQA: Situating Visual Question Answering in Communicative Contexts
AUTHORS: Nandita Shankar Naik ; Christopher Potts ; Elisa Kreiss
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: To evaluate how situating images within naturalistic contexts shapes visual questions, we introduce CommVQA, a VQA dataset consisting of images, image descriptions, real-world communicative scenarios where the image might appear (e.g., a travel website), and follow-up questions and answers conditioned on the scenario.

86, TITLE: TinyBenchmarks: Evaluating LLMs with Fewer Examples
AUTHORS: FELIPE MAIA POLO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, stat.ML]
HIGHLIGHT: In this paper, we investigate strategies to reduce the number of evaluations needed to assess the performance of an LLM on several key benchmarks.

87, TITLE: GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data
AUTHORS: Lele Cao ; Valentin Buchner ; Zineb Senane ; Fangkai Yang
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, I.7; I.4]
HIGHLIGHT: We propose GenCeption, a novel and annotation-free MLLM evaluation framework that merely requires unimodal data to assess inter-modality semantic coherence and inversely reflects the models' inclination to hallucinate.

88, TITLE: Improving Sentence Embeddings with An Automatically Generated NLI Dataset
AUTHORS: Soma Sato ; Hayato Tsukagoshi ; Ryohei Sasano ; Koichi Takeda
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We aim to improve sentence embeddings learned in an unsupervised setting by automatically generating an NLI dataset with an LLM and using it to fine-tune PromptEOL.

89, TITLE: Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models
AUTHORS: Guanming Xiong ; Junwei Bao ; Wen Zhao
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: Yet, fully leveraging LLMs to parse questions into logical forms in low-resource scenarios poses a substantial challenge. To tackle these hurdles, we introduce Interactive-KBQA, a framework designed to generate logical forms through direct interaction with knowledge bases (KBs).

90, TITLE: Dual Encoder: Exploiting The Potential of Syntactic and Semantic for Aspect Sentiment Triplet Extraction
AUTHORS: Xiaowei Zhao ; Yong Zhou ; Xiujuan Xu
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose a \emph{Dual Encoder: Exploiting the potential of Syntactic and Semantic} model (D2E2S), which maximizes the syntactic and semantic relationships among words.

91, TITLE: DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators
AUTHORS: XINGLIN LYU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose an alternative adaptation approach, named Decoding-enhanced Multi-phase Prompt Tuning (DeMPT), to make LLMs discriminately model and utilize the inter- and intra-sentence context and more effectively adapt LLMs to context-aware NMT.

92, TITLE: Infusing Hierarchical Guidance Into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition
AUTHORS: Haodong Zhao ; Ruifang He ; Mengnan Xiao ; Jing Xu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Besides, the comprehension of hierarchical semantics for MIDRR makes the conversion much harder. In this paper, we propose a prompt-based Parameter-Efficient Multi-level IDRR (PEMI) framework to solve the above problems.

93, TITLE: NuNER: Entity Recognition Encoder Pre-training Via LLM-Annotated Data
AUTHORS: Sergei Bogdanov ; Alexandre Constantin ; Timothï¿½e Bernard ; Benoit Crabbï¿½ ; Etienne Bernard
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we show how to use LLMs to create NuNER, a compact language representation model specialized in the Named Entity Recognition (NER) task.

94, TITLE: A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models
AUTHORS: STEFAN HEGSELMANN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we investigate the potential of large language models to generate patient summaries based on doctors' notes and study the effect of training data on the faithfulness and quality of the generated summaries.

95, TITLE: Fine-tuning Large Language Models for Domain-specific Machine Translation
AUTHORS: JIAWEI ZHENG et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: The aforementioned methods can struggle to translate rare words in domain transfer scenarios. To address these challenges, this paper proposes a prompt-oriented fine-tuning method, denoted as LlamaIT, to effectively and efficiently fine-tune a general-purpose LLM for domain-specific MT tasks.

96, TITLE: Re-Examine Distantly Supervised NER: A New Benchmark and A Simple Approach
AUTHORS: Yuepei Li ; Kang Zhou ; Qiao Qiao ; Qing Wang ; Qi Li
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: To tackle the prevalent issue of label noise, we introduce a simple yet effective approach, Curriculum-based Positive-Unlabeled Learning CuPUL, which strategically starts on "easy" and cleaner samples during the training process to enhance model resilience to noisy samples.

97, TITLE: Entity-level Factual Adaptiveness of Fine-tuning Based Abstractive Summarization Models
AUTHORS: JONGYOON SONG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we analyze the robustness of fine-tuning based summarization models to the knowledge conflict, which we call factual adaptiveness.

98, TITLE: GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?
AUTHORS: Yiping Jin ; Leo Wanner ; Alexander Shvets
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: However, despite enabling more detailed diagnostic insights, the HateCheck test cases are often generic and have simplistic sentence structures that do not match the real-world data. To address this limitation, we propose GPT-HateCheck, a framework to generate more diverse and realistic functional tests from scratch by instructing large language models (LLMs).

99, TITLE: Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A Case-Study in E-Commerce Opinion Summarization
AUTHORS: SWAROOP NATH et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Our contributions include a novel Reward Modelling technique, a new dataset (PromptOpinSumm) for Opinion Summarization, and a human preference dataset (OpinPref).

100, TITLE: Chitchat As Interference: Adding User Backstories to Task-Oriented Dialogues
AUTHORS: Armand Stricker ; Patrick Paroubek
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We assess the impact of this addition by testing two models: one trained solely on TODs and another trained on TODs with a preliminary chitchat interaction. Our analysis reveals that our enriched dataset poses a significant challenge to these systems.

101, TITLE: CARBD-Ko: A Contextually Annotated Review Benchmark Dataset for Aspect-Level Sentiment Classification in Korean
AUTHORS: DONGJUN JANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address the issue of dual-tagged aspect polarities, we propose a novel approach employing a Siamese Network.

102, TITLE: Unlocking The Power of Large Language Models for Entity Alignment
AUTHORS: XUHUI JIANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of the representation learning techniques. Against this backdrop, we introduce ChatEA, an innovative framework that incorporates large language models (LLMs) to improve EA.

103, TITLE: Let's Rectify Step By Step: Improving Aspect-based Sentiment Analysis with Diffusion Models
AUTHORS: SHUNYU LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We propose DiffusionABSA, a novel diffusion model tailored for ABSA, which extracts the aspects progressively step by step.

104, TITLE: Unsupervised Domain Adaptation Within Deep Foundation Latent Spaces
AUTHORS: Dmitry Kangin ; Plamen Angelov
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: The vision transformer-based foundation models, such as ViT or Dino-V2, are aimed at solving problems with little or no finetuning of features.

105, TITLE: PUAD: Frustratingly Simple Method for Robust Anomaly Detection
AUTHORS: Shota Sugawara ; Ryuji Imamura
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: As a demonstration, we propose a method that incorporates a simple out-of-distribution detection method on the feature space against state-of-the-art reconstruction-based approaches.

106, TITLE: EE3P: Event-based Estimation of Periodic Phenomena Properties
AUTHORS: Jakub Kolï¿½? ; Radim ?petlï¿½k ; Ji?ï¿½ Matas
CATEGORY: cs.CV [cs.CV, I.4.8]
HIGHLIGHT: We introduce a novel method for measuring properties of periodic phenomena with an event camera, a device asynchronously reporting brightness changes at independently operating pixels.

107, TITLE: Modified CycleGAN for The Synthesization of Samples for Wheat Head Segmentation
AUTHORS: Jaden Myers ; Keyhan Najafian ; Farhad Maleki ; Katie Ovens
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In the absence of an annotated dataset, synthetic data can be used for model development; however, due to the substantial differences between simulated and real data, a phenomenon referred to as domain gap, the resulting models often underperform when applied to real data. In this research, we aim to address this challenge by first computationally simulating a large-scale annotated dataset and then using a generative adversarial network (GAN) to fill the gap between simulated and real images.

108, TITLE: The Common Stability Mechanism Behind Most Self-Supervised Learning Approaches
AUTHORS: Abhishek Jha ; Matthew B. Blaschko ; Yuki M. Asano ; Tinne Tuytelaars
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: These inductive biases and constraints manifest themselves in the form of different optimization formulations in the SSL techniques, e.g. by utilizing negative examples in a contrastive formulation, or exponential moving average and predictor in BYOL and SimSiam. In this paper, we provide a framework to explain the stability mechanism of these different SSL techniques: i) we discuss the working mechanism of contrastive techniques like SimCLR, non-contrastive techniques like BYOL, SWAV, SimSiam, Barlow Twins, and DINO; ii) we provide an argument that despite different formulations these methods implicitly optimize a similar objective function, i.e. minimizing the magnitude of the expected representation over all data samples, or the mean of the data distribution, while maximizing the magnitude of the expected representation of individual samples over different data augmentations; iii) we provide mathematical and empirical evidence to support our framework.

109, TITLE: Outlier Detection By Ensembling Uncertainty with Negative Objectness
AUTHORS: Anja Deli? ; Matej Grci? ; Sini?a ?egvi?
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Outlier Detection By Ensembling Uncertainty with Negative Objectness

110, TITLE: On Normalization-equivariance Properties of Supervised and Unsupervised Denoising Methods: A Survey
AUTHORS: Sï¿½bastien Herbreteau ; Charles Kervrann
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Many methodological concepts have been introduced in the past decades and have improved performances significantly in recent years, especially with the emergence of convolutional neural networks and supervised deep learning. In this paper, we propose a survey of guided tour of supervised and unsupervised learning methods for image denoising, classifying the main principles elaborated during this evolution, with a particular concern given to recent developments in supervised learning.

111, TITLE: Attention-Guided Masked Autoencoders For Learning Image Representations
AUTHORS: Leon Sick ; Dominik Engel ; Pedro Hermosilla ; Timo Ropinski
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: By leveraging advances in unsupervised object discovery, we obtain an attention map of the scene which we employ in the loss function to put increased emphasis on reconstructing relevant objects, thus effectively incentivizing the model to learn more object-focused representations without compromising the established masking strategy.

112, TITLE: Fiducial Focus Augmentation for Facial Landmark Detection
AUTHORS: Purbayan Kar ; Vishal Chudasama ; Naoyuki Onoe ; Pankaj Wasnik ; Vineeth Balasubramanian
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This inadequacy can be attributed to the model's inability to effectively acquire appropriate facial structure information from the input images. To address this, we propose a novel image augmentation technique specifically designed for the FLD task to enhance the model's understanding of facial structures.

113, TITLE: Descripciï¿½n Automï¿½tica De Secciones Delgadas De Rocas: Una Aplicaciï¿½n Web
AUTHORS: Stalyn Paucar ; Christian Mejï¿½a-Escobar y Vï¿½ctor Collaguazo
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: The present proposal uses artificial intelligence techniques combining computer vision and natural language processing to generate a textual and verbal description from a thin section image of rock.

114, TITLE: Retinotopic Mapping Enhances The Robustness of Convolutional Neural Networks
AUTHORS: Jean-Nicolas Jï¿½rï¿½mie ; Emmanuel Daucï¿½ ; Laurent U Perrinet
CATEGORY: cs.CV [cs.CV, q-bio.NC]
HIGHLIGHT: This study investigates whether retinotopic mapping, a critical component of foveated vision, can enhance image categorization and localization performance when integrated into deep convolutional neural networks (CNNs).

115, TITLE: Font Impression Estimation in The Wild
AUTHORS: Kazuki Kitajima ; Daichi Haraguchi ; Seiichi Uchida
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, impressions attached to individual fonts are often missing and noisy because of the subjective characteristic of font impression annotation. To realize stable impression estimation even with such a dataset, we propose an exemplar-based impression estimation approach, which relies on a strategy of ensembling impressions of exemplar fonts that are similar to the input image.

116, TITLE: Seamless Human Motion Composition with Blended Positional Encodings
AUTHORS: German Barquero ; Sergio Escalera ; Cristina Palmero
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this context, we introduce FlowMDM, the first diffusion-based model that generates seamless Human Motion Compositions (HMC) without any postprocessing or redundant denoising steps. For this, we introduce the Blended Positional Encodings, a technique that leverages both absolute and relative positional encodings in the denoising chain.

117, TITLE: Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition
AUTHORS: CHUN-HSIAO YEH et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Second, given an image containing multiple personalized concepts, there lacks a holistic metric that evaluates performance on not just the degree of resemblance of personalized concepts, but also whether all concepts are present in the image and whether the image accurately reflects the overall text description. To address these issues, we introduce Gen4Gen, a semi-automated dataset creation pipeline utilizing generative models to combine personalized concepts into complex compositions along with text-descriptions.

118, TITLE: Optimal Transport on The Lie Group of Roto-translations
AUTHORS: Daan Bon ; Gautam Pai ; Gijs Bellaard ; Olga Mula ; Remco Duits
CATEGORY: cs.CV [cs.CV, math.DG, math.OC, 62H35, 68U10, 90B06, 68T45, 68U99]
HIGHLIGHT: In this paper, we develop a computational framework for optimal transportation over Lie groups, with a special focus on SE2.

119, TITLE: CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models
AUTHORS: Santiago Castro ; Amir Ziai ; Avneesh Saluja ; Zhuoning Yuan ; Rada Mihalcea
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this paper, we introduce a framework to significantly improve the ability of existing models to encode compositional language, with over 10% absolute improvement on compositionality benchmarks, while maintaining or improving the performance on standard object-recognition and retrieval benchmarks.

120, TITLE: Representing Online Handwriting for Recognition in Large Vision-Language Models
AUTHORS: ANASTASIIA FADEEVA et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we study online handwriting recognition with VLMs, going beyond naive OCR.

121, TITLE: Fine-tuning CLIP Text Encoders with Two-step Paraphrasing
AUTHORS: HYUNJAE KIM et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this study, we introduce a straightforward fine-tuning approach to enhance the representations of CLIP models for paraphrases.

122, TITLE: Computer Vision for Multimedia Geolocation in Human Trafficking Investigation: A Systematic Literature Review
AUTHORS: Opeyemi Bamigbade ; John Sheppard ; Mark Scanlon
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CY]
HIGHLIGHT: The findings suggest numerous potential paths for future impactful research on the subject.

123, TITLE: Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education
AUTHORS: A. J. KARRAN et. al.
CATEGORY: cs.CY [cs.CY, cs.AI, K.3.1; I.2.0]
HIGHLIGHT: This study investigates the acceptability of different artificial intelligence (AI) applications in education from a multi-stakeholder perspective, including students, teachers, and parents.

124, TITLE: Adversarial Robustness of Deep Learning-based Malware Detectors Via (De)Randomized Smoothing
AUTHORS: Daniel Gibert ; Giulio Zizzo ; Quan Le ; Jordi Planes
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain.

125, TITLE: Tight Inapproximability of Target Set Reconfiguration
AUTHORS: Naoto Ohsaka
CATEGORY: cs.DS [cs.DS, cs.CC, cs.DM]
HIGHLIGHT: We prove that it is NP-hard to approximate Minmax Target Set Reconfiguration within a factor of $2-o\left(\frac{1}{\operatorname{polylog} n}\right)$, where $n$ is the number of vertices.

126, TITLE: AI-Augmented Brainwriting: Investigating The Use of LLMs in Group Ideation
AUTHORS: Orit Shaer ; Angelora Cooper ; Osnat Mokryn ; Andrew L. Kun ; Hagit Ben Shoshan
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CY, H.5.2; J.4]
HIGHLIGHT: This paper explores twofold aspects of integrating LLMs into the creative process - the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas.

127, TITLE: The AffectToolbox: Affect Analysis for Everyone
AUTHORS: Silvan Mertes ; Dominik Schiller ; Michael Dietz ; Elisabeth Andrï¿½ ; Florian Lingenfelser
CATEGORY: cs.HC [cs.HC, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we present the AffectToolbox, a novel software system that aims to support researchers in developing affect-sensitive studies and prototypes.

128, TITLE: Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned During Human-Human Collaboration
AUTHORS: Eike Schneiders ; Christopher Fourie ; Stanley Celestin ; Julie Shah ; Malte Jung
CATEGORY: cs.HC [cs.HC, cs.AI, cs.RO]
HIGHLIGHT: In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation.

129, TITLE: CloChat: Understanding How People Customize, Interact, and Experience Personas in Large Language Models
AUTHORS: Juhye Ha ; Hyeon Jeon ; DaEun Han ; Jinwook Seo ; Changhoon Oh
CATEGORY: cs.HC [cs.HC, cs.CL]
HIGHLIGHT: In this research, we investigated how users customize agent personas and their impact on interaction quality, diversity, and dynamics.

130, TITLE: A Conversational Brain-Artificial Intelligence Interface
AUTHORS: ANJA MEUNIER et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, eess.SP]
HIGHLIGHT: We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class of Brain-Computer Interfaces (BCIs).

131, TITLE: Hands-Free VR
AUTHORS: JORGE ASKUR VAZQUEZ FERNANDEZ et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CL]
HIGHLIGHT: The paper introduces Hands-Free VR, a voice-based natural-language interface for VR.

132, TITLE: Faithful Temporal Question Answering Over Heterogeneous Sources
AUTHORS: Zhen Jia ; Philipp Christmann ; Gerhard Weikum
CATEGORY: cs.IR [cs.IR, cs.CL]
HIGHLIGHT: As implicit questions are sparse in prior benchmarks, we introduce a principled method for generating diverse questions.

133, TITLE: Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries
AUTHORS: Zijun Long ; Xuri Ge ; Richard Mccreadie ; Joemon Jose
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CV]
HIGHLIGHT: This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets.

134, TITLE: Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data
AUTHORS: YongKyung Oh ; Dongyoung Lim ; Sungil Kim
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this study, we propose three stable classes of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE.

135, TITLE: AutoMMLab: Automatically Generating Deployable Models from Language Instructions for Computer Vision Tasks
AUTHORS: ZEKANG YANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: While traditional AutoML approaches have been successfully applied in several critical steps of model development (e.g. hyperparameter optimization), there lacks a AutoML system that automates the entire end-to-end model production workflow. To fill this blank, we present AutoMMLab, a general-purpose LLM-empowered AutoML system that follows user's language instructions to automate the whole model production workflow for computer vision tasks.

136, TITLE: Break The Breakout: Reinventing LM Defense Against Jailbreak Attacks with Self-Refinement
AUTHORS: Heegyu Kim ; Sehyun Yuk ; Hyunsouk Cho
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CR]
HIGHLIGHT: We propose self-refine with formatting that achieves outstanding safety even in non-safety-aligned LMs and evaluate our method alongside several defense baselines, demonstrating that it is the safest training-free method against jailbreak attacks.

137, TITLE: When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination
AUTHORS: Martin Benfeghoul ; Umais Zahid ; Qinghai Guo ; Zafeirios Fountas
CATEGORY: cs.LG [cs.LG, cs.AI, I.2.0; I.2.8; I.2.10; I.4.5; I.4.10]
HIGHLIGHT: In an unfamiliar setting, a model-based reinforcement learning agent can be limited by the accuracy of its world model. In this work, we present a novel, training-free approach to improving the performance of such agents separately from planning and learning.

138, TITLE: Categorical Deep Learning: An Algebraic Theory of Architectures
AUTHORS: BRUNO GAVRANOVI? et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, math.CT, math.RA, stat.ML]
HIGHLIGHT: We present our position on the elusive quest for a general-purpose framework for specifying and studying deep learning architectures.

139, TITLE: Studying The Impact of Stochasticity on The Evaluation of Deep Neural Networks for Forest-Fire Prediction
AUTHORS: Harshit Kumar ; Biswadeep Chakraborty ; Beomseok Kang ; Saibal Mukhopadhyay
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction.

140, TITLE: Federated Fairness Without Access to Sensitive Groups
AUTHORS: Afroditi Papadaki ; Natalia Martinez ; Martin Bertran ; Guillermo Sapiro ; Miguel Rodrigues
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY, cs.DC]
HIGHLIGHT: In this work, we propose a new approach to guarantee group fairness that does not rely on any predefined definition of sensitive groups or additional labels.

141, TITLE: Multimodal Transformer With A Low-Computational-Cost Guarantee
AUTHORS: Sungjin Park ; Edward Choi
CATEGORY: cs.LG [cs.LG, cs.CV, cs.MM]
HIGHLIGHT: However, multimodal Transformers significantly suffer from a quadratic complexity of the multi-head attention with the input sequence length, especially as the number of modalities increases. To address this, we introduce Low-Cost Multimodal Transformer (LoCoMT), a novel multimodal attention mechanism that aims to reduce computational cost during training and inference with minimal performance loss.

142, TITLE: Practical Insights Into Knowledge Distillation for Pre-Trained Models
AUTHORS: Norah Alballa ; Marco Canini
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Our study conducts an extensive comparison of multiple KD techniques, including standard KD, tuned KD (via optimized temperature and weight parameters), deep mutual learning, and data partitioning KD. We assess these methods across various data distribution strategies to identify the most effective contexts for each.

143, TITLE: Smoothed Graph Contrastive Learning Via Seamless Proximity Integration
AUTHORS: Maysam Behmanesh ; Maks Ovsjanikov
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we present a Smoothed Graph Contrastive Learning model (SGCL), which leverages the geometric structure of augmented graphs to inject proximity information associated with positive/negative pairs in the contrastive loss, thus significantly regularizing the learning process.

144, TITLE: NeuralThink: Algorithm Synthesis That Extrapolates in General Tasks
AUTHORS: Bernardo Esteves ; Miguel Vasco ; Francisco S. Melo
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, these works are limited to symmetrical tasks, where the input and output dimensionalities are the same. To address this gap, we propose NeuralThink, a new recurrent architecture that can consistently extrapolate to both symmetrical and asymmetrical tasks, where the dimensionality of the input and output are different.

145, TITLE: Fixed Random Classifier Rearrangement for Continual Learning
AUTHORS: Shengyang Huang ; Jianwen Mo
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we analyze the variation of model predictions in sequential binary classification tasks and find that the norm of the equivalent one-class classifiers significantly affects the forgetting level.

146, TITLE: Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration
AUTHORS: Wonjeong Choi ; Jungwuk Park ; Dong-Jun Han ; Younghyun Park ; Jaekyun Moon
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains.

147, TITLE: Optimal Transport for Structure Learning Under Missing Data
AUTHORS: Vy Vo ; He Zhao ; Trung Le ; Edwin V. Bonilla ; Dinh Phung
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To this end, we propose in this paper a score-based algorithm, based on optimal transport, for learning causal structure from missing data.

148, TITLE: A Comprehensive Survey of Convolutions in Deep Learning: Applications, Challenges, and Future Trends
AUTHORS: ABOLFAZL YOUNESI et. al.
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: This survey paper provides a comprehensive examination and comparison of various CNN architectures, highlighting their architectural differences and emphasizing their respective advantages, disadvantages, applications, challenges, and future trends.

149, TITLE: A Bargaining-based Approach for Feature Trading in Vertical Federated Learning
AUTHORS: YUE CUI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.MA]
HIGHLIGHT: In this study, we propose a bargaining-based feature trading approach in VFL to encourage economically efficient transactions.

150, TITLE: Homeostatic Motion Planning with Innate Physics Knowledge
AUTHORS: Giulia Lafratta ; Bernd Porr ; Christopher Chandler ; Alice Miller
CATEGORY: cs.RO [cs.RO, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: Even simple animals are able to develop and execute complex plans, which has not yet been replicated in robotics using pure closed-loop input control. We propose a solution to this problem by defining a set of discrete and temporary closed-loop controllers, called "tasks", each representing a closed-loop behaviour.

151, TITLE: Safe Task Planning for Language-Instructed Multi-Robot Systems Using Conformal Prediction
AUTHORS: Jun Wang ; Guocheng He ; Yiannis Kantaros
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: However, these approaches lack mission performance and safety guarantees. To address this challenge, we introduce a new decentralized LLM-based planner that is capable of achieving high mission success rates.

152, TITLE: RoboEXP: Action-Conditioned Scene Graph Via Interactive Exploration for Robotic Manipulation
AUTHORS: HANXIAO JIANG et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce the novel task of interactive scene exploration, wherein robots autonomously explore environments and produce an action-conditioned scene graph (ACSG) that captures the structure of the underlying environment.

153, TITLE: Learning Inverse Kinodynamics for Autonomous Vehicle Drifting
AUTHORS: M. Suvarna ; O. Tehrani
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: In this work, we explore a data-driven learning-based approach to learning the kinodynamic model of a small autonomous vehicle, and observe the effect it has on motion planning, specifically autonomous drifting.

154, TITLE: CLIPPER+: A Fast Maximal Clique Algorithm for Robust Global Registration
AUTHORS: Kaveh Fathian ; Tyler Summers
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We present CLIPPER+, an algorithm for finding maximal cliques in unweighted graphs for outlier-robust global registration.

155, TITLE: A Survey of Music Generation in The Context of Interaction
AUTHORS: ISMAEL AGCHAR et. al.
CATEGORY: cs.SD [cs.SD, cs.AI, cs.LG, eess.AS]
HIGHLIGHT: This article presents a thorough review of music representation, feature analysis, heuristic algorithms, statistical and parametric modelling, and human and automatic evaluation measures, along with a discussion of which approaches and models seem most suitable for live interaction.

156, TITLE: Artificial Bee Colony Optimization of Deep Convolutional Neural Networks in The Context of Biomedical Imaging
AUTHORS: Adri Gomez Martin ; Carlos Fernandez del Cerro ; Monica Abella Garcia ; Manuel Desco Menendez
CATEGORY: eess.IV [eess.IV, cs.AI, cs.NE]
HIGHLIGHT: However, many algorithms proposed in the neuroevolutive literature are either too unreliable or limited to a small, predefined region of the hyperparameter space. To overcome these shortcomings, we propose the Chimera Algorithm, a novel, hybrid neuroevolutive algorithm that integrates the Artificial Bee Colony Algorithm with Evolutionary Computation tools to generate models from scratch, as well as to refine a given previous architecture to better fit the task at hand.

157, TITLE: Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data
AUTHORS: MAJID FARHADLOO et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.LG]
HIGHLIGHT: Given multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points.
