1, TITLE: Representation Learning of Structured Data for Medical Foundation Models
AUTHORS: VIJAY PRAKASH DWIVEDI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This paper examines the challenges LLMs face in processing medical codes due to the shortcomings of current tokenization methods. As a result, we introduce the UniStruct architecture to design a multimodal medical foundation model of unstructured text and structured data, which addresses these challenges by adapting subword tokenization techniques specifically for the structured medical codes.

2, TITLE: Differentiable Robot Rendering
AUTHORS: Ruoshi Liu ; Alper Canberk ; Shuran Song ; Carl Vondrick
CATEGORY: cs.RO [cs.RO, cs.CV, cs.GR]
HIGHLIGHT: A key challenge in applying them to robotic tasks is the modality gap between visual data and action data. We introduce differentiable robot rendering, a method allowing the visual appearance of a robot body to be directly differentiable with respect to its control parameters.

3, TITLE: Jailbreaking LLM-Controlled Robots
AUTHORS: Alexander Robey ; Zachary Ravichandran ; Vijay Kumar ; Hamed Hassani ; George J. Pappas
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: To assess the risks of deploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first algorithm designed to jailbreak LLM-controlled robots.

4, TITLE: Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens
AUTHORS: LIJIE FAN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Scaling up autoregressive models in vision has not proven as beneficial as in large language models. In this work, we investigate this scaling problem in the context of text-to-image generation, focusing on two critical factors: whether models use discrete or continuous tokens, and whether tokens are generated in a random or fixed raster order using BERT- or GPT-like transformer architectures.

5, TITLE: Harnessing Webpage UIs for Text-Rich Visual Understanding
AUTHORS: JUNPENG LIU et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Text-rich visual understanding-the ability to process environments where dense textual content is integrated with visuals-is crucial for multimodal large language models (MLLMs) to interact effectively with structured environments. To enhance this capability, we propose synthesizing general multimodal instructions from webpage UIs using text-based large language models (LLMs).

6, TITLE: How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs
AUTHORS: GUHAO FENG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, stat.ML]
HIGHLIGHT: In this paper, we conduct a rigorous theoretical analysis of LLMs' mathematical abilities, with a specific focus on their arithmetic performances.

7, TITLE: Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents
AUTHORS: LONG LI et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: Inspired by the research process of human researchers, we propose a Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant literature in a chain structure to effectively mirror the progressive development in a research domain.

8, TITLE: Exploring The Design Space of Visual Context Representation in Video MLLMs
AUTHORS: YIFAN DU et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this paper, we explore the design space for visual context representation, and aim to improve the performance of video MLLMs by finding more effective representation schemes.

9, TITLE: AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations
AUTHORS: Qian Tao ; Wenyuan Yu ; Jingren Zhou
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Large language models have shown exceptional capabilities in a wide range of tasks, such as text generation and video generation, among others.

10, TITLE: Looking Inward: Language Models Can Learn About Themselves By Introspection
AUTHORS: FELIX J BINDER et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We study introspection by finetuning LLMs to predict properties of their own behavior in hypothetical scenarios.

11, TITLE: DreamCraft3D++: Efficient Hierarchical 3D Generation with Multi-Plane Reconstruction Model
AUTHORS: JINGXIANG SUN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce DreamCraft3D++, an extension of DreamCraft3D that enables efficient high-quality generation of complex 3D assets.

12, TITLE: A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models
AUTHORS: QIAOYU TANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we propose a novel perspective based on Riemann sum approximation of the loss function to elucidate delta parameter editing operations.

13, TITLE: VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding
AUTHORS: RUNSEN XU et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: In this work, we present VLM-Grounder, a novel framework using vision-language models (VLMs) for zero-shot 3D visual grounding based solely on 2D images.

14, TITLE: Persistent Pre-Training Poisoning of LLMs
AUTHORS: YIMING ZHANG et. al.
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Our work evaluates for the first time whether language models can also be compromised during pre-training, with a focus on the persistence of pre-training attacks after models are fine-tuned as helpful and harmless chatbots (i.e., after SFT and DPO).

15, TITLE: Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models
AUTHORS: Linhao Luo ; Zicheng Zhao ; Chen Gong ; Gholamreza Haffari ; Shirui Pan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce graph-constrained reasoning (GCR), a novel framework that bridges structured knowledge in KGs with unstructured reasoning in LLMs.

16, TITLE: Quantity Vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?
AUTHORS: Idris Abdulmumin ; Bashir Shehu Galadanci ; Garba Aliyu ; Shamsuddeen Hassan Muhammad
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, it has been shown that too much of this data can be detrimental to the performance of the model if the available parallel data is comparatively extremely low. In this study, we investigate whether the monolingual data can also be too little and if this reduction, based on quality, has any effect on the performance of the translation model.

17, TITLE: LoRA Soups: Merging LoRAs for Practical Skill Composition Tasks
AUTHORS: AKSHARA PRABHAKAR et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: First, we identify practically occurring use-cases that can be studied under the realm of skill composition, e.g. solving hard math-word problems with code, creating a bot to answer questions on proprietary manuals or about domain-specialized corpora. Our main contribution is to show that concatenation of LoRAs (CAT), which optimally averages LoRAs that were individually trained on different skills, outperforms existing model- and data- merging techniques; for instance on math-word problems, CAT beats these methods by an average of 43% and 12% respectively.

18, TITLE: SimpleToM: Exposing The Gap Between Explicit ToM Inference and Implicit ToM Application in LLMs
AUTHORS: YULING GU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We create a new dataset, SimpleTom, containing concise, diverse stories (e.g., "The can of Pringles has moldy chips in it.

19, TITLE: Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions
AUTHORS: Michael J. Q. Zhang ; W. Bradley Knox ; Eunsol Choi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We speculate this is caused by current preference data labeling practice, where LLM responses are evaluated only on their prior contexts. To address this, we propose to assign preference labels by simulating their expected outcomes in the future turns.

20, TITLE: Movie Gen: A Cast of Media Foundation Models
AUTHORS: ADAM POLYAK et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, eess.IV]
HIGHLIGHT: We present Movie Gen, a cast of foundation models that generates high-quality, 1080p HD videos with different aspect ratios and synchronized audio.

21, TITLE: UniDrive: Towards Universal Driving Perception Across Camera Configurations
AUTHORS: Ye Li ; Wenzhao Zheng ; Xiaonan Huang ; Kurt Keutzer
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present UniDrive, a novel framework for vision-centric autonomous driving to achieve universal perception across camera configurations.

22, TITLE: LFOSum: Summarizing Long-form Opinions with Large Language Models
AUTHORS: Mir Tafseer Nayeem ; Davood Rafiei
CATEGORY: cs.CL [cs.CL, cs.AI, cs.ET, cs.HC, cs.IR]
HIGHLIGHT: To address those challenges, this paper introduces (1) a new dataset of long-form user reviews, each entity comprising over a thousand reviews, (2) two training-free LLM-based summarization approaches that scale to long inputs, and (3) automatic evaluation metrics.

23, TITLE: HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings
AUTHORS: Varun Gumma ; Anandhita Raghunath ; Mohit Jain ; Sunayana Sitaram
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We employ a uniform Retrieval Augmented Generation framework to generate responses, which are evaluated using both automated techniques and human evaluators on four specific metrics relevant to our application.

24, TITLE: Learning to Route with Confidence Tokens
AUTHORS: YU-NENG CHUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Depending on whether an answer is trustworthy, a system can then choose to route the question to another expert, or otherwise fall back on a safe default behavior. In this work, we study the extent to which LLMs can reliably indicate confidence in their answers, and how this notion of confidence can translate into downstream accuracy gains.

25, TITLE: Remember, Retrieve and Generate: Understanding Infinite Visual Concepts As Your Personalized Assistant
AUTHORS: Haoran Hao ; Jiaming Han ; Changsheng Li ; Yu-Feng Li ; Xiangyu Yue
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG, cs.MM]
HIGHLIGHT: In this paper, we introduce the Retrieval Augmented Personalization (RAP) framework for MLLMs' personalization.

26, TITLE: Geometric Trajectory Diffusion Models
AUTHORS: Jiaqi Han ; Minkai Xu ; Aaron Lou ; Haotian Ye ; Stefano Ermon
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we propose geometric trajectory diffusion models (GeoTDM), the first diffusion model for modeling the temporal distribution of 3D geometric trajectories.

27, TITLE: Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval
AUTHORS: YU XIA et. al.
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: For queries like "Find me a highly rated camera for wildlife photography compatible with my Nikon F-Mount lenses", existing methods may generate expansions that are semantically similar but structurally unrelated to user intents. To handle such semi-structured queries with both textual and relational requirements, in this paper we propose a knowledge-aware query expansion framework, augmenting LLMs with structured document relations from knowledge graph (KG).

28, TITLE: Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation
AUTHORS: RYOTARO SHIMIZU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.IR]
HIGHLIGHT: However, this approach fails to consider one crucial aspect of the systems: whether their outputs accurately reflect the users' (post-purchase) sentiments, i.e., whether and why they would like and/or dislike the recommended items. To shed light on this issue, we introduce new datasets and evaluation methods that focus on the users' sentiments.

29, TITLE: L3DG: Latent 3D Gaussian Diffusion
AUTHORS: BARBARA ROESSLE et. al.
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: We propose L3DG, the first approach for generative 3D modeling of 3D Gaussians through a latent 3D Gaussian diffusion formulation.

30, TITLE: Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation
AUTHORS: Jean-Pierre Sleiman ; Mayank Mittal ; Marco Hutter
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Reinforcement learning (RL) often necessitates a meticulous Markov Decision Process (MDP) design tailored to each task. This work aims to address this challenge by proposing a systematic approach to behavior synthesis and control for multi-contact loco-manipulation tasks, such as navigating spring-loaded doors and manipulating heavy dishwashers.

31, TITLE: MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs
AUTHORS: Andreas Opedal ; Haruki Shirakami ; Bernhard Sch�lkopf ; Abulhair Saparov ; Mrinmaya Sachan
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: Empirical investigations of such questions are impeded by two major flaws of current evaluations: (i) much of the evaluation data is contaminated, in the sense that it has already been seen during training, and (ii) benchmark datasets do not capture how problem proofs may be arbitrarily complex in various ways. As a step towards addressing these issues, we present a framework for evaluating LLMs on problems that have arbitrarily complex arithmetic proofs, called MathGAP.

32, TITLE: MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models
AUTHORS: PENG XIA et. al.
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs.

33, TITLE: Representing Model Weights with Language Using Tree Experts
AUTHORS: Eliahu Horwitz ; Bar Cavia ; Jonathan Kahana ; Yedid Hoshen
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: While effective, linear layers are computationally expensive as model weights are very high dimensional. To address this, we introduce Probing Experts (ProbeX), a theoretically motivated, lightweight probing method.

34, TITLE: CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building
AUTHORS: Walker Byrnes ; Miroslav Bogdanovic ; Avi Balakirsky ; Stephen Balakirsky ; Animesh Garg
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: We present CLIMB, a continual learning framework for robot task planning that leverages foundation models and execution feedback to guide domain model construction.

35, TITLE: Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation
AUTHORS: HYUNGJOO CHAE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To overcome the challenges in training LLMs as world models predicting next observations, such as repeated elements across observations and long HTML inputs, we propose a transition-focused observation abstraction, where the prediction objectives are free-form natural language descriptions exclusively highlighting important state differences between time steps.

36, TITLE: On The Role of Attention Heads in Large Language Model Safety
AUTHORS: ZHENHONG ZHOU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: However, existing research tends to overlook the safety impact of multi-head attention mechanisms, despite their crucial role in various model functionalities. Hence, in this paper, we aim to explore the connection between standard attention mechanisms and safety capability to fill this gap in the safety-related mechanistic interpretability.

37, TITLE: Learning Representations for Reasoning: Generalizing Across Diverse Structures
AUTHORS: Zhaocheng Zhu
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: For new entities, we propose a framework that learns neural operators in a dynamic programming algorithm computing path representations.

38, TITLE: Flex: End-to-End Text-Instructed Visual Navigation with Foundation Models
AUTHORS: Makram Chahine ; Alex Quach ; Alaa Maalouf ; Tsun-Hsuan Wang ; Daniela Rus
CATEGORY: cs.RO [cs.RO, cs.AI, 68T40, 68T05, 68T50, I.2.6; I.2.9; I.2.10; I.4.8]
HIGHLIGHT: In this work, we investigate the minimal data requirements and architectural adaptations necessary to achieve robust closed-loop performance with vision-based control policies under unseen text instructions and visual distribution shifts.

39, TITLE: Improving Multi-modal Large Language Model Through Boosting Vision Capabilities
AUTHORS: YANPENG SUN et. al.
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: We propose \textbf{Arcana}, a multiModal language model, which introduces two crucial techniques.

40, TITLE: Preference Diffusion for Recommendation
AUTHORS: Shuo Liu ; An Zhang ; Guoqing Hu ; Hong Qian ; Tat-seng Chua
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: Recently, diffusion models (DMs) have gained attention in recommendation for their ability to model complex distributions, yet current DM-based recommenders often rely on traditional objectives like mean squared error (MSE) or recommendation objectives, which are not optimized for personalized ranking tasks or fail to fully leverage DM's generative potential. To address this, we propose PreferDiff, a tailored optimization objective for DM-based recommenders.

41, TITLE: Facilitating Multi-turn Function Calling for LLMs Via Compositional Instruction Tuning
AUTHORS: MINGYANG CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While current research on function calling by LLMs primarily focuses on single-turn interactions, this paper addresses the overlooked necessity for LLMs to engage in multi-turn function calling--critical for handling compositional, real-world queries that require planning with functions but not only use functions. To facilitate this, we introduce an approach, BUTTON, which generates synthetic compositional instruction tuning data via bottom-up instruction construction and top-down trajectory generation.

42, TITLE: Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration
AUTHORS: YUN-YEN CHUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we propose the Meta-DiffuB framework - a novel scheduler-exploiter S2S-Diffusion paradigm designed to overcome the limitations of existing S2S-Diffusion models.

43, TITLE: Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?
AUTHORS: CHE LIU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This raises the question: *Can MedVLP succeed using purely synthetic data? * To address this, we use off-the-shelf generative models to create synthetic radiology reports and paired Chest X-ray (CXR) images, and propose an automated pipeline to build a diverse, high-quality synthetic dataset, enabling a rigorous study that isolates model and training settings, focusing entirely from the data perspective.

44, TITLE: Cliqueformer: Model-Based Optimization with Structured Transformers
AUTHORS: Jakub Grudzien Kuba ; Pieter Abbeel ; Sergey Levine
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, following first principles, we develop a model that learns the structure of an MBO task and empirically leads to improved designs.

45, TITLE: Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation
AUTHORS: CHENGYUE WU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we introduce Janus, an autoregressive framework that unifies multimodal understanding and generation.

46, TITLE: PUMA: Empowering Unified MLLM with Multi-granular Visual Generation
AUTHORS: RONGYAO FANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose PUMA, emPowering Unified MLLM with Multi-grAnular visual generation.

47, TITLE: Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems
AUTHORS: Isack Lee ; Haebin Seong
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: These methods often introduce deliberate and intentional biases similar to Political Correctness (PC) to ensure the ethical behavior of LLMs. In this paper, we delve into the intentional biases injected into LLMs for safety purposes and examine methods to circumvent these safety alignment techniques.

48, TITLE: Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland
AUTHORS: Luca Rolshoven ; Vishvaksenan Rasiah ; Srinanda Br�gger Bose ; Matthias St�rmer ; Joel Niklaus
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, 68T50, I.2; I.7]
HIGHLIGHT: Automated headnote creation has the potential to make hundreds of thousands of decisions more accessible for legal research in Switzerland alone. To kickstart this, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a novel cross-lingual resource featuring 18K court rulings from the Swiss Federal Supreme Court (SFSC), in German, French, and Italian, along with German headnotes.

49, TITLE: Breaking The Manual Annotation Bottleneck: Creating A Comprehensive Legal Case Criticality Dataset Through Semi-Automated Labeling
AUTHORS: Ronja Stern ; Ken Kawamura ; Matthias St�rmer ; Ilias Chalkidis ; Joel Niklaus
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, 68T50, I.2; I.7]
HIGHLIGHT: We evaluate several multilingual models, including fine-tuned variants and large language models, and find that fine-tuned models consistently outperform zero-shot baselines, demonstrating the need for task-specific adaptation. Our contributions include the introduction of this task and the release of a multilingual dataset to the research community.

50, TITLE: Pseudo Dataset Generation for Out-of-Domain Multi-Camera View Recommendation
AUTHORS: Kuan-Ying Lee ; Qian Zhou ; Klara Nahrstedt
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Based on the insight that many videos are edited from the original multi-camera videos, we propose transforming regular videos into pseudo-labeled multi-camera view recommendation datasets.

51, TITLE: Label-free Prediction of Fluorescence Markers in Bovine Satellite Cells Using Deep Learning
AUTHORS: Sania Sinha ; Aarham Wasit ; Won Seob Kim ; Jongkyoo Kim ; Jiyoon Yi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This study aims to develop a label-free method for predicting fluorescence markers in isolated BSCs using deep learning.

52, TITLE: MedINST: Meta Dataset of Biomedical Instructions
AUTHORS: WENHAN HAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Medical data and tasks, which vary in format, size, and other parameters, require extensive preprocessing and standardization for effective use in training LLMs. To address these challenges, we introduce MedINST, the Meta Dataset of Biomedical Instructions, a novel multi-domain, multi-task instructional meta-dataset.

53, TITLE: Boosting Imperceptibility of Stable Diffusion-based Adversarial Examples Generation with Momentum
AUTHORS: NASHRAH HAQUE et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We propose a novel framework, Stable Diffusion-based Momentum Integrated Adversarial Examples (SD-MIAE), for generating adversarial examples that can effectively mislead neural network classifiers while maintaining visual imperceptibility and preserving the semantic similarity to the original class label.

54, TITLE: BenTo: Benchmark Task Reduction with In-Context Transferability
AUTHORS: Hongyu Zhao ; Ming Li ; Lichao Sun ; Tianyi Zhou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a practically efficient metric for estimating the transferability between two tasks via in-context learning (ICL).

55, TITLE: Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning Via Image-Guided Diffusion
AUTHORS: Yijun Liang ; Shweta Bhardwaj ; Tianyi Zhou
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To overcome the limitation, we study image guidance to achieve a spectrum of interpolations between synthetic and real images.

56, TITLE: DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control
AUTHORS: YUJIE WEI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present DreamVideo-2, a zero-shot video customization framework capable of generating videos with a specific subject and motion trajectory, guided by a single image and a bounding box sequence, respectively, and without the need for test-time fine-tuning.

57, TITLE: An Evolved Universal Transformer Memory
AUTHORS: Edoardo Cetin ; Qi Sun ; Tianyu Zhao ; Yujin Tang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: Prior methods propose to offset the escalating costs of modern foundation models by dropping specific parts of their contexts with hand-designed rules, while attempting to preserve their original performance. We overcome this trade-off with Neural Attention Memory Models (NAMMs), introducing a learned network for memory management that improves both the performance and efficiency of transformers.

58, TITLE: Mechanistic Unlearning: Robust Knowledge Unlearning and Editing Via Mechanistic Localization
AUTHORS: Phillip Guo ; Aaquib Syed ; Abhay Sheshadri ; Aidan Ewart ; Gintare Karolina Dziugaite
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Methods for knowledge editing and unlearning in large language models seek to edit or remove undesirable knowledge or capabilities without compromising general language modeling performance.

59, TITLE: Learning Graph Quantized Tokenizers for Transformers
AUTHORS: LIMEI WANG et. al.
CATEGORY: cs.NE [cs.NE, cs.AI, cs.LG]
HIGHLIGHT: However, the development of tokenizers for graphs has lagged behind other modalities, with existing approaches relying on heuristics or GNNs co-trained with Transformers. To address this, we introduce GQT (\textbf{G}raph \textbf{Q}uantized \textbf{T}okenizer), which decouples tokenizer training from Transformer training by leveraging multi-task graph self-supervised learning, yielding robust and generalizable graph tokens.

60, TITLE: D-FINE: Redefine Regression Task in DETRs As Fine-grained Distribution Refinement
AUTHORS: YANSONG PENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce D-FINE, a powerful real-time object detector that achieves outstanding localization precision by redefining the bounding box regression task in DETR models.

61, TITLE: MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling
AUTHORS: YAKUN ZHU et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this paper, we focus on the downstream tasks of medical calculators, which use standardized tests to assess an individual's health status.

62, TITLE: Trust But Verify: Programmatic VLM Evaluation in The Wild
AUTHORS: Viraj Prabhu ; Senthil Purushwalkam ; An Yan ; Caiming Xiong ; Ran Xu
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose Programmatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating VLM responses to open-ended queries.

63, TITLE: Artificial Kuramoto Oscillatory Neurons
AUTHORS: Takeru Miyato ; Sindy L�we ; Andreas Geiger ; Max Welling
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: More recently, it was also hypothesized that dynamic (spatiotemporal) representations play an important role in both neuroscience and AI. Building on these ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a dynamical alternative to threshold units, which can be combined with arbitrary connectivity designs such as fully connected, convolutional, or attentive mechanisms.

64, TITLE: ORSO: Accelerating Reward Design Via Online Reward Selection and Policy Optimization
AUTHORS: Chen Bo Calvin Zhang ; Zhang-Wei Hong ; Aldo Pacchiano ; Pulkit Agrawal
CATEGORY: cs.LG [cs.LG, cs.AI, cs.RO]
HIGHLIGHT: This paper introduces Online Reward Selection and Policy Optimization (ORSO), a novel approach that frames shaping reward selection as an online model selection problem.

65, TITLE: DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation
AUTHORS: Meilu Zhu ; Axiu Mao ; Jun Liu ; Yixuan Yuan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, owing to the direct combination of LoRA and FL, current methods generally undergo two problems, i.e., aggregation deviation, and differential privacy (DP) noise amplification effect. To address these problems, we propose a novel privacy-preserving federated finetuning framework called \underline{D}eviation \underline{E}liminating and Nois\underline{e} \underline{R}egulating (DEeR).

66, TITLE: Scaling Wearable Foundation Models
AUTHORS: GIRISH NARAYANSWAMY et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.HC]
HIGHLIGHT: Using a dataset of up to 40 million hours of in-situ heart rate, heart rate variability, electrodermal activity, accelerometer, skin temperature, and altimeter per-minute data from over 165,000 people, we create LSM, a multimodal foundation model built on the largest wearable-signals dataset with the most extensive range of sensor modalities to date.

67, TITLE: Estimating The Probabilities of Rare Outputs in Language Models
AUTHORS: Gabriel Wu ; Jacob Hilton
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We consider the problem of low probability estimation: given a machine learning model and a formally-specified input distribution, how can we estimate the probability of a binary property of the model's output, even when that probability is too small to estimate by random sampling?

68, TITLE: $?-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models
AUTHORS: YAXIN LUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite the significant progress in multimodal large language models (MLLMs), their high computational cost remains a barrier to real-world deployment. Inspired by the mixture of depths (MoDs) in natural language processing, we aim to address this limitation from the perspective of ``activated tokens''.

69, TITLE: Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models
AUTHORS: CHENGYU DU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Additionally, these methods are typically designed for specific tasks, which limits their generalization to new domains. To address these limitations, we propose Progressive Thought Refinement (PTR), a framework that enables LLMs to refine their responses progressively.

70, TITLE: Self-Pluralising Culture Alignment for Large Language Models
AUTHORS: Shaoyang Xu ; Yongqi Leng ; Linhao Yu ; Deyi Xiong
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose CultureSPA, a Self-Pluralising Culture Alignment framework that allows LLMs to simultaneously align to pluralistic cultures.

71, TITLE: SLM-Mod: Small Language Models Surpass LLMs at Content Moderation
AUTHORS: Xianyang Zhan ; Agam Goyal ; Yilun Chen ; Eshwar Chandrasekharan ; Koustuv Saha
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large language models (LLMs) have shown promise in many natural language understanding tasks, including content moderation.

72, TITLE: Learning to Summarize from LLM-generated Feedback
AUTHORS: HWANJUN SONG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce FeedSum, a large-scale dataset containing multi-dimensional LLM feedback on summaries of varying quality across diverse domains.

73, TITLE: GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation
AUTHORS: ZIWEI YANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Current solutions, including statistical and deep learning methods, often fail to effectively integrate gene interaction knowledge from databases or explicitly learn subtype-specific interactions. To address this mismatch, we propose GeSubNet, which learns a unified representation capable of predicting gene interactions while distinguishing between different disease subtypes.

74, TITLE: Generative Location Modeling for Spatially Aware Object Insertion
AUTHORS: JOOYEOL YUN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we focus on the former, creating a location model dedicated to identifying realistic object locations.

75, TITLE: The Disparate Benefits of Deep Ensembles
AUTHORS: Kajetan Schweighofer ; Adrian Arnaiz-Rodriguez ; Sepp Hochreiter ; Nuria Oliver
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we investigate the interplay between the performance gains from Deep Ensembles and fairness.

76, TITLE: Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers
AUTHORS: SHWAI HE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In response to the first issue, we propose Router-Tuning, a method that fine-tunes only the router on a small dataset, drastically reducing the computational overhead associated with full model training.

77, TITLE: Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models
AUTHORS: Jiatao Li ; Xinyu Hu ; Xunjian Yin ; Xiaojun Wan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, previous research primarily focuses on optimizing the use of SGDs, with the inherent properties of SGDs remaining underexplored. Therefore, this paper conducts a comprehensive analysis of different types of SGDs and experiments on various knowledge-intensive tasks.

78, TITLE: Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models
AUTHORS: MAZDA MOAYERI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: We propose an automatic approach to recover the underlying skills relevant for any evaluation instance, by way of inspecting model-generated rationales.

79, TITLE: Enhancing Sentiment Analysis with Collaborative AI: Architecture, Predictions, and Deployment Strategies
AUTHORS: Chaofeng Zhang ; Jia Hou ; Xueting Tan ; Caijuan Chen ; Hiroshi Hashimoto
CATEGORY: cs.SE [cs.SE, cs.AI, cs.HC]
HIGHLIGHT: However, integrating diverse AI models for processing complex multimodal data and the associated high costs of feature extraction presents significant challenges. Motivated by the marketing oriented software development +needs, our study introduces a collaborative AI framework designed to efficiently distribute and resolve tasks across various AI systems to address these issues.

80, TITLE: Text-Guided Multi-Property Molecular Optimization with A Diffusion Language Model
AUTHORS: YIDA XIONG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a text-guided multi-property molecular optimization method utilizing transformer-based diffusion language model (TransDLM).

81, TITLE: Solving Prior Distribution Mismatch in Diffusion Models Via Optimal Transport
AUTHORS: ZHANPENG WANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Particularly noteworthy is prior error, defined as the discrepancy between the termination distribution of the forward process and the initial distribution of the reverse process. To address these deficiencies, this paper explores the deeper relationship between optimal transport(OT) theory and DMs with discrete initial distribution.

82, TITLE: Adversarial Neural Networks in Medical Imaging Advancements and Challenges in Semantic Segmentation
AUTHORS: HOUZE LIU et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This limitation becomes more pronounced with the exponential increase in imaging data, which traditional methods struggle to process efficiently and effectively. In response to these challenges, this study introduces the application of adversarial neural networks, a novel AI approach that not only automates but also refines the semantic segmentation process.

83, TITLE: SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs
AUTHORS: YIZHAO GAO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper argues that attention sparsity should be learned rather than predefined.

84, TITLE: Atomic Calibration of LLMs in Long-Form Generations
AUTHORS: CAIQI ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, this approach is insufficient for long-form generations, where responses often contain more complex statements and may include both accurate and inaccurate information. Therefore, we introduce atomic calibration, a novel approach that evaluates factuality calibration at a fine-grained level by breaking down long responses into atomic claims.

85, TITLE: MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems
AUTHORS: Nandan Thakur ; Suleman Kazi ; Ge Luo ; Jimmy Lin ; Amin Ahmad
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present an easy and efficient technique to get the best of both worlds.

86, TITLE: Self-Comparison for Dataset-Level Membership Inference in Large (Vision-)Language Models
AUTHORS: JIE REN et. al.
CATEGORY: cs.LG [cs.LG, cs.CL, cs.MM]
HIGHLIGHT: In this paper, we propose a novel dataset-level membership inference method based on Self-Comparison.

87, TITLE: Leveraging LLMs for Translating and Classifying Mental Health Data
AUTHORS: Konstantinos Skianis ; A. Seza Do?ru�z ; John Pavlopoulos
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large language models (LLMs) are increasingly used in medical fields.

88, TITLE: Roadmap Towards Superhuman Speech Understanding Using Large Language Models
AUTHORS: FAN BU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SD, eess.AS]
HIGHLIGHT: To guide the development of speech LLMs, we propose a five-level roadmap, ranging from basic automatic speech recognition (ASR) to advanced superhuman models capable of integrating non-semantic information with abstract acoustic knowledge for complex tasks.

89, TITLE: DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation
AUTHORS: GUOSHENG ZHAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce \textit{DriveDreamer4D}, which enhances 4D driving scene representation leveraging world model priors.

90, TITLE: Reverse-Engineering The Reader
AUTHORS: Samuel Kiegeland ; Ethan Gotlieb Wilcox ; Afra Amini ; David Robert Reich ; Ryan Cotterell
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we are interested in the opposite question: whether we can directly optimize a language model to be a useful cognitive model by aligning it to human psychometric data.

91, TITLE: AiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion
AUTHORS: SIYUAN JIANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SE]
HIGHLIGHT: In this paper, we propose a lightweight and effective LLM for code completion named aiXcoder-7B.

92, TITLE: Double-Bayesian Learning
AUTHORS: Stefan Jaeger
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: Contemporary machine learning methods will try to approach the Bayes error, as it is the lowest possible error any model can achieve.

93, TITLE: SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction
AUTHORS: XUAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: However, increasing the number of model layers and the length of input sequences significantly escalates the memory required to store key-value (KV) cache, posing challenges for efficient inference. To mitigate this issue, we present SimLayerKV, a simple yet effective method that reduces inter-layer KV cache redundancies by selectively dropping cache in identified lazy layers.

94, TITLE: Precipitation Nowcasting Using Diffusion Transformer with Causal Attention
AUTHORS: CHAORONG LI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: Current deep learning methods fall short in establishing effective dependencies between conditions and forecast results, while also lacking interpretability. To address this issue, we propose a Precipitation Nowcasting Using Diffusion Transformer with Causal Attention model.

95, TITLE: Instruction-Driven Game Engine: A Poker Case Study
AUTHORS: Hongqiu Wu ; Xingyuan Liu ; Yan Wang ; Hai Zhao
CATEGORY: cs.AI [cs.AI, cs.SE]
HIGHLIGHT: The Instruction-Driven Game Engine (IDGE) project aims to democratize game development by enabling a large language model (LLM) to follow free-form game descriptions and generate game-play processes.

96, TITLE: A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment
AUTHORS: Weishan Cai ; Wenjun Ma ; Yuncheng Jiang
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: However, the existing unsupervised EA methods still have some limitations, either their modeling complexity is high or they cannot balance the effectiveness and practicality of alignment. To overcome these issues, we propose a Simplifying and Learnable graph convolutional attention network for Unsupervised Knowledge Graphs alignment method (SLU).

97, TITLE: Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models
AUTHORS: Yuki Hou ; Haruki Tamoto ; Homei Miyashita
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Conventional dialogue agents often struggle with effective memory recall, leading to redundant retrieval and inadequate management of unique user associations. To address this, we propose SynapticRAG, a novel approach integrating synaptic dynamics into Retrieval-Augmented Generation (RAG).

98, TITLE: Tuning Language Models By Mixture-of-Depths Ensemble
AUTHORS: Haoyan Luo ; Lucia Specia
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce a novel tuning framework, Mixture-of-Depths (MoD), which trains late layers as ensembles contributing to the final logits through learned routing weights.

99, TITLE: Help Me Identify: Is An LLM+VQA System All We Need to Identify Visual Concepts?
AUTHORS: Shailaja Keyur Sampat ; Maitreya Patel ; Yezhou Yang ; Chitta Baral
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This is possible due to abstraction of attributes/properties that an object is composed of e.g. an object `bird' can be identified by the presence of a beak, feathers, legs, wings, etc. Inspired by this aspect of human reasoning, in this work, we present a zero-shot framework for fine-grained visual concept learning by leveraging large language model and Visual Question Answering (VQA) system.

100, TITLE: ActionCOMET: A Zero-shot Approach to Learn Image-specific Commonsense Concepts About Actions
AUTHORS: Shailaja Keyur Sampat ; Yezhou Yang ; Chitta Baral
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose ActionCOMET, a zero-shot framework to discern knowledge present in language models specific to the provided visual input.

101, TITLE: DepthSplat: Connecting Gaussian Splatting and Depth
AUTHORS: HAOFEI XU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present DepthSplat to connect Gaussian splatting and depth estimation and study their interactions.

102, TITLE: VL-GLUE: A Suite of Fundamental Yet Challenging Visuo-Linguistic Reasoning Tasks
AUTHORS: SHAILAJA KEYUR SAMPAT et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: al., 2018)- a multitask benchmark for natural language understanding, we propose VL-GLUE in this paper.

103, TITLE: Temporal-Enhanced Multimodal Transformer for Referring Multi-Object Tracking and Segmentation
AUTHORS: CHANGCHENG XIAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we introduce a compact Transformer-based method, termed TenRMOT.

104, TITLE: A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement
AUTHORS: HUI YUAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we identify a common pitfall of margin-based methods -- the under-specification of ideal LM behavior on preferred and dispreferred responses individually, which leads to two unintended consequences as the margin increases: (1) The probability of dispreferred (e.g., unsafe) responses may increase, resulting in potential safety alignment failures.

105, TITLE: Unconstrained Model Merging for Enhanced LLM Reasoning
AUTHORS: YIMING ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose an unconstrained model merging framework that accommodates both homogeneous and heterogeneous model architectures with a focus on reasoning tasks.

106, TITLE: Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations
AUTHORS: Aryan Shrivastava ; Jessica Hullman ; Max Lamparth
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we query LMs for free form responses and use a metric based on BERTScore to measure response inconsistency quantitatively.

107, TITLE: A New Approach for Fine-tuning Sentence Transformers for Intent Classification and Out-of-scope Detection Tasks
AUTHORS: Tianyi Zhang ; Atta Norouzian ; Aanchan Mohan ; Frederick Ducatelle
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This is compounded when OOS data is unknown. To mitigate this issue our work proposes to regularize the cross-entropy loss with an in-scope embedding reconstruction loss learned using an auto-encoder.

108, TITLE: Enhancing Fact Retrieval in PLMs Through Truthfulness
AUTHORS: Paul Youssef ; J�rg Schl�tterer ; Christin Seifert
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate the use of a helper model to improve fact retrieval.

109, TITLE: FAMSeC: A Few-shot-sample-based General AI-generated Image Detection Method
AUTHORS: Juncong Xu ; Yang Yang ; Han Fang ; Honggu Liu ; Weiming Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Therefore, training a general detector with few-shot samples is essential for modern detection mechanisms. To address this challenge, we propose FAMSeC, a general AI-generated image detection method based on LoRA-based Forgery Awareness Module and Semantic feature-guided Contrastive learning strategy.

110, TITLE: Attr-Int: A Simple and Effective Entity Alignment Framework for Heterogeneous Knowledge Graphs
AUTHORS: LINYAN YANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we investigate and tackle the problem of entity alignment between heterogeneous KGs.

111, TITLE: Data Defenses Against Large Language Models
AUTHORS: William Agnew ; Harry H. Jiang ; Cella Sum ; Maarten Sap ; Sauvik Das
CATEGORY: cs.CL [cs.CL, cs.CR, cs.CY]
HIGHLIGHT: In this paper, we define and build "data defenses" -- a novel strategy that directly empowers data owners to block LLMs from performing inference on their data.

112, TITLE: Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation
AUTHORS: SREYAN GHOSH et. al.
CATEGORY: eess.AS [eess.AS, cs.CL, cs.SD]
HIGHLIGHT: This phenomenon amplifies with named entities (NEs), where, in addition to insufficient contextual information or knowledge about the NEs, novel NEs keep emerging. To address these issues, we propose DARAG (Data- and Retrieval-Augmented Generative Error Correction), a novel approach designed to improve GEC for ASR in in-domain (ID) and OOD scenarios.

113, TITLE: See Behind Walls in Real-time Using Aerial Drones and Augmented Reality
AUTHORS: Sikai Yang ; Kang Yang ; Yuning Chen ; Fan Zhao ; Wan Du
CATEGORY: cs.MA [cs.MA, cs.CV, cs.HC]
HIGHLIGHT: This work presents ARD2, a framework that enables real-time through-wall surveillance using two aerial drones and an augmented reality (AR) device.

114, TITLE: Controllable Generation Via Locally Constrained Resampling
AUTHORS: Kareem Ahmed ; Kai-Wei Chang ; Guy Van den Broeck
CATEGORY: cs.LG [cs.LG, cs.CL, stat.ML]
HIGHLIGHT: We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint.

115, TITLE: AdaSwitch: Adaptive Switching Between Small and Large Agents for Effective Cloud-Local Collaborative Learning
AUTHORS: HAO SUN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose a novel LLM utilization paradigm that facilitates the collaborative operation of large cloud-based LLMs and smaller local-deployed LLMs.

116, TITLE: Better to Ask in English: Evaluation of Large Language Models on English, Low-resource and Cross-Lingual Settings
AUTHORS: Krishno Dey ; Prerona Tarannum ; Md. Arid Hasan ; Imran Razzak ; Usman Naseem
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recently, a few multi-lingual LLMs have emerged, but their performance in low-resource languages, especially the most spoken languages in South Asia, is less explored. To address this gap, in this study, we evaluate LLMs such as GPT-4, Llama 2, and Gemini to analyze their effectiveness in English compared to other low-resource languages from South Asia (e.g., Bangla, Hindi, and Urdu).

117, TITLE: Advancing Large Language Model Attribution Through Self-Improving
AUTHORS: LEI HUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Inspired by recent advances in self-improvement that enhance LLMs without manual annotation, we present START, a Self-Taught AttRibuTion framework for iteratively improving the attribution capability of LLMs.

118, TITLE: MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations
AUTHORS: LIANG XU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we tackle the problem of how to build and benchmark a large motion model (LMM).

119, TITLE: Axiomatization of Compact Initial Value Problems: Open Properties
AUTHORS: Andr� Platzer ; Long Qian
CATEGORY: cs.LO [cs.LO, cs.PL, math.LO, 03B70, 03D80, 03F03, 34C14, 34A38, 34C11, 65L70, 65G20, F.4.1; F.3.1; G.1.7; I.2.3]
HIGHLIGHT: This article proves the completeness of an axiomatization for initial value problems (IVPs) with compact initial conditions and compact time horizons for bounded open safety, open liveness and existence properties.

120, TITLE: Interpreting Token Compositionality in LLMs: A Robustness Analysis
AUTHORS: Nura Aljaafari ; Danilo S. Carvalho ; Andr� Freitas
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present Constituent-Aware Pooling (CAP), a methodology designed to analyse how LLMs process compositional linguistic structures.

121, TITLE: Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation
AUTHORS: FENGQI LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel speech-driven gesture generation method by emphasizing the semantic consistency of salient posture.

122, TITLE: Metacognitive Monitoring: A Human Ability Beyond Generative Artificial Intelligence
AUTHORS: Markus Huff ; Elanur Ulak�?
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We employed a cross-agent prediction model to compare the metacognitive performance of humans and ChatGPT in a language-based memory task involving garden-path sentences preceded by either fitting or unfitting context sentences.

123, TITLE: An Active Learning Framework for Inclusive Generation By Large Language Models
AUTHORS: Sabit Hassan ; Anthony Sicilia ; Malihe Alikhani
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Ensuring that Large Language Models (LLMs) generate text representative of diverse sub-populations is essential, particularly when key concepts related to under-represented groups are scarce in the training data. We address this challenge with a novel clustering-based active learning framework, enhanced with knowledge distillation.

124, TITLE: Enhancing Dataset Distillation Via Label Inconsistency Elimination and Learning Pattern Refinement
AUTHORS: Chuhao Zhou ; Chenxi Jiang ; Yi Xie ; Haozhi Cao ; Jianfei Yang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper illustrates our solution that ranks 1st in the ECCV-2024 Data Distillation Challenge (track 1). Our solution, Modified Difficulty-Aligned Trajectory Matching (M-DATM), introduces two key modifications to the original state-of-the-art method DATM: (1) the soft labels learned by DATM do not achieve one-to-one correspondence with the counterparts generated by the official evaluation script, so we remove the soft labels technique to alleviate such inconsistency; (2) since the removal of soft labels makes it harder for the synthetic dataset to learn late trajectory information, particularly on Tiny ImageNet, we reduce the matching range, allowing the synthetic data to concentrate more on the easier patterns.

125, TITLE: Co-Segmentation Without Any Pixel-level Supervision with Application to Large-Scale Sketch Classification
AUTHORS: Nikolaos-Antonios Ypsilantis ; Ond?ej Chum
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work proposes a novel method for object co-segmentation, i.e. pixel-level localization of a common object in a set of images, that uses no pixel-level supervision for training.

126, TITLE: SemSim: Revisiting Weak-to-Strong Consistency from A Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation
AUTHORS: SHIAO XIE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, two key limitations still persist, impeding its efficient adaptation: (1) the neglect of contextual dependencies results in inconsistent predictions for similar semantic features, leading to incomplete object segmentation; (2) the lack of exploitation of semantic similarity between labeled and unlabeled data induces considerable class-distribution discrepancy. To address these limitations, we propose a novel semi-supervised framework based on FixMatch, named SemSim, powered by two appealing designs from semantic similarity perspective: (1) rectifying pixel-wise prediction by reasoning about the intra-image pair-wise affinity map, thus integrating contextual dependencies explicitly into the final prediction; (2) bridging labeled and unlabeled data via a feature querying mechanism for compact class representation learning, which fully considers cross-image anatomical similarities.

127, TITLE: Quamba: A Post-Training Quantization Recipe for Selective State Space Models
AUTHORS: Hung-Yueh Chiang ; Chi-Chih Chang ; Natalia Frumkin ; Kai-Chiang Wu ; Diana Marculescu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Most notably, SSMs have highly sensitive feature maps within the selective scan mechanism (i.e., linear recurrence) and massive outliers in the output activations which are not present in the output of token-mixing in the self-attention modules. To address this issue, we propose a static 8-bit per-tensor SSM quantization method which suppresses the maximum values of the input activations to the selective SSM for finer quantization precision and quantizes the output activations in an outlier-free space with Hadamard transform.

128, TITLE: SBI-RAG: Enhancing Math Word Problem Solving for Students Through Schema-Based Instruction and Retrieval-Augmented Generation
AUTHORS: Prakhar Dixit ; Tim Oates
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IR]
HIGHLIGHT: Many students struggle with math word problems (MWPs), often finding it difficult to identify key information and select the appropriate mathematical operations.Schema-based instruction (SBI) is an evidence-based strategy that helps students categorize problems based on their structure, improving problem-solving accuracy. Building on this, we propose a Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) framework that incorporates a large language model (LLM).

129, TITLE: Influence Functions for Scalable Data Attribution in Diffusion Models
AUTHORS: BRUNO MLODOZENIEC et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Yet their widespread adoption poses challenges regarding data attribution and interpretability. In this paper, we aim to help address such challenges in diffusion models by developing an \textit{influence functions} framework.

130, TITLE: Enhancing Mathematical Reasoning in LLMs By Stepwise Correction
AUTHORS: ZHENYU WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a novel prompting method named Stepwise Correction (StepCo) that helps LLMs identify and revise incorrect steps in their generated reasoning paths.

131, TITLE: RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards
AUTHORS: XINZE LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG systems by aligning data preferences between different RAG modules.

132, TITLE: Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems
AUTHORS: Alireza Ghafarollahi ; Markus J. Buehler
CATEGORY: cond-mat.mtrl-sci [cond-mat.mtrl-sci, cond-mat.dis-nn, cond-mat.mes-hall, cs.AI, cs.MA]
HIGHLIGHT: We focus on the NbMoTa family of body-centered cubic (bcc) alloys, modeled using an ML-based interatomic potential, and target two key properties: the Peierls barrier and solute/screw dislocation interaction energy.

133, TITLE: ConsisSR: Delving Deep Into Consistency in Diffusion-based Image Super-Resolution
AUTHORS: JUNHAO GU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, T2I generation focuses on semantic consistency while Real-ISR emphasizes pixel-level reconstruction, which hinders existing methods from fully exploiting diffusion priors. To address this challenge, we introduce ConsisSR to handle both semantic and pixel-level consistency.

134, TITLE: Super-resolving Real-world Image Illumination Enhancement: A New Dataset and A Conditional Diffusion Model
AUTHORS: YANG LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, these methods do not work well in real-world low-light conditions as the images captured in such conditions lose most important information and contain significant unknown noises. To solve this problem, we propose a SRRIIE dataset with an efficient conditional diffusion probabilistic models-based method.

135, TITLE: Large Language Models Are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis
AUTHORS: Yiyi Chen ; Qiongxiu Li ; Russa Biswas ; Johannes Bjerva
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, I.1.2; I.1.5]
HIGHLIGHT: We hypothesize that there are linguistic regularities to this inherent vulnerability in LLMs and shed light on patterns of language confusion across LLMs. We introduce a novel metric, Language Confusion Entropy, designed to directly measure and quantify this confusion, based on language distributions informed by linguistic typology and lexical variation.

136, TITLE: A Watermark for Order-Agnostic Language Models
AUTHORS: RUIBO CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce Pattern-mark, a pattern-based watermarking framework specifically designed for order-agnostic LMs.

137, TITLE: De-mark: Watermark Removal in Large Language Models
AUTHORS: Ruibo Chen ; Yihan Wu ; Junfeng Guo ; Heng Huang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present De-mark, an advanced framework designed to remove n-gram-based watermarks effectively.

138, TITLE: Composing Novel Classes: A Concept-Driven Approach to Generalized Category Discovery
AUTHORS: Chuyu Zhang ; Peiyan Gu ; Xueyang Yu ; Xuming He
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite their progress, our analysis experiments show that novel classes can achieve impressive clustering results on the feature space of a known class pre-trained model, suggesting that existing methods may not fully utilize known class knowledge. To address it, we introduce a novel concept learning framework for GCD, named ConceptGCD, that categorizes concepts into two types: derivable and underivable from known class concepts, and adopts a stage-wise learning strategy to learn them separately.

139, TITLE: Hypothesis Testing The Circuit Hypothesis in LLMs
AUTHORS: CLAUDIA SHI et. al.
CATEGORY: cs.AI [cs.AI, cs.LG, stat.ML]
HIGHLIGHT: But how can we evaluate this hypothesis? In this paper, we formalize a set of criteria that a circuit is hypothesized to meet and develop a suite of hypothesis tests to evaluate how well circuits satisfy them.

140, TITLE: A Low Complexity Contextual Stacked Ensemble-learning Approach for Pedestrian Intent Prediction
AUTHORS: Chia-Yen Chiang ; Yasmin Fathy ; Gregory Slabaugh ; Mona Jaber
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In contrast, this work proposes a low-complexity ensemble-learning approach that employs contextual data for predicting the pedestrian's intent for crossing.

141, TITLE: A Note on Shumailov Et Al. (2024): `AI Models Collapse When Trained on Recursively Generated Data'
AUTHORS: Ali Borji
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we investigate the effects of fitting a distribution (through Kernel Density Estimation, or KDE) or a model to the data, followed by repeated sampling from it.

142, TITLE: ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization
AUTHORS: Xiutian Zhao ; Ke Wang ; Wei Peng
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, research on these tasks is limited by the insufficiency of public datasets, especially for non-English languages. To address this language resource gap in Chinese, we present ORCHID (Oral Chinese Debate), the first Chinese dataset for benchmarking target-independent stance detection and debate summarization.

143, TITLE: UniG: Modelling Unitary 3D Gaussians for View-consistent 3D Reconstruction
AUTHORS: JIAMIN WU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we present UniG, a view-consistent 3D reconstruction and novel view synthesis model that generates a high-fidelity representation of 3D Gaussians from sparse images.

144, TITLE: A Little Human Data Goes A Long Way
AUTHORS: Dhananjay Ashok ; Jonathan May
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We investigate the use of synthetic data in Fact Verification (FV) and Question Answering (QA) by studying the effects of incrementally replacing human generated data with synthetic points on eight diverse datasets.

145, TITLE: Optimal Quantization for Matrix Multiplication
AUTHORS: Or Ordentlich ; Yury Polyanskiy
CATEGORY: cs.IT [cs.IT, cs.AI, cs.CL, cs.LG, math.IT]
HIGHLIGHT: These representations subsequently are used by the decoder to estimate matrix product $A^\top B$. In this work, we provide a non-asymptotic lower bound on the mean squared error of this approximation (as a function of rate $R$) for the case of matrices $A,B$ with iid Gaussian entries.

146, TITLE: Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning
AUTHORS: Xiaodan Xing ; Junzhi Ning ; Yang Nan ; Guang Yang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Beyond mere data augmentation, our research in this paper highlights an additional, significant capacity of deep generative models: their ability to reveal and demonstrate patterns in medical images.

147, TITLE: Fundus to Fluorescein Angiography Video Generation As A Retinal Generative Foundation Model
AUTHORS: WEIYI ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce Fundus2Video, an autoregressive generative adversarial network (GAN) model that generates dynamic FFA videos from single CF images.

148, TITLE: Similarity-Dissimilarity Loss with Supervised Contrastive Learning for Multi-label Classification
AUTHORS: Guangming Huang ; Yunfei Long ; Cunjin Luo ; Sheng Liu
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: In this paper, we introduce five distinct relations between multi-label samples and propose a Similarity-Dissimilarity Loss with contrastive learning for multi-label classification.

149, TITLE: Hybrid Bundle-adjusting 3D Gaussians for View Consistent Rendering with Pose Optimization
AUTHORS: YANAN GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a hybrid bundle-adjusting 3D Gaussians model that enables view-consistent rendering with pose optimization.

150, TITLE: Day-Night Adaptation: An Innovative Source-free Adaptation Framework for Medical Image Segmentation
AUTHORS: Ziyang Chen ; Yiwen Ye ; Yongsheng Pan ; Yong Xia
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: During the nighttime process, after collecting the test data from the day, the model can be fine-tuned utilizing SFDA to further adapt to the target domain. With above insights, we propose a novel adaptation framework called Day-Night Adaptation (DyNA).

151, TITLE: MobA: A Two-Level Agent System for Efficient Mobile Task Automation
AUTHORS: ZICHEN ZHU et. al.
CATEGORY: cs.MA [cs.MA, cs.AI, cs.CL, cs.HC]
HIGHLIGHT: Current mobile assistants are limited by dependence on system APIs or struggle with complex user instructions and diverse interfaces due to restricted comprehension and decision-making abilities. To address these challenges, we propose MobA, a novel Mobile phone Agent powered by multimodal large language models that enhances comprehension and planning capabilities through a sophisticated two-level agent architecture.

152, TITLE: SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain Adaptation in Remote Sensing
AUTHORS: Bin Wang ; Fei Deng ; Shuang Wang ; Wen Luo ; Zhixuan Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Domain shift is well-known for undermining a model's generalization ability in the target domain. To address this, unsupervised domain adaptation (UDA) has emerged as a promising solution, enabling models to learn from unlabeled target domain data while training on labeled source domain data.

153, TITLE: MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures
AUTHORS: JINJIE NI et. al.
CATEGORY: cs.AI [cs.AI, cs.LG, cs.MM]
HIGHLIGHT: We propose multi-modal benchmark mixture and adaptation-rectification pipelines to reconstruct real-world task distributions, ensuring evaluations generalize effectively to real-world use cases.

154, TITLE: Inadequate Contrast Ratio of Road Markings As An Indicator for ADAS Failure
AUTHORS: Novel Certad ; Cristina Olaverri-Monreal ; Friedrich Wiesinger ; Tomasz E. Burghardt
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Inadequate Contrast Ratio of Road Markings As An Indicator for ADAS Failure

155, TITLE: Context-Enhanced Multi-View Trajectory Representation Learning: Bridging The Gap Through Self-Supervised Models
AUTHORS: TANGWEN QIAN et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: To this end, we propose MVTraj, a novel multi-view modeling method for trajectory representation learning.

156, TITLE: Supply Chain Network Extraction and Entity Classification Leveraging Large Language Models
AUTHORS: Tong Liu ; Hadi Meidani
CATEGORY: cs.LG [cs.LG, cs.CL, cs.IR]
HIGHLIGHT: This paper proposes a novel approach that leverages LLMs to extract and process raw textual information from publicly available sources to construct a comprehensive supply chain graph.

157, TITLE: Fine-Tuning Discrete Diffusion Models Via Reward Optimization with Applications to DNA and Protein Design
AUTHORS: CHENYU WANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We then formulate the reward maximization problem within discrete diffusion models, analogous to reinforcement learning (RL), while minimizing the KL divergence against pretrained diffusion models to preserve naturalness. To solve this RL problem, we propose a novel algorithm, DRAKES, that enables direct backpropagation of rewards through entire trajectories generated by diffusion models, by making the originally non-differentiable trajectories differentiable using the Gumbel-Softmax trick.

158, TITLE: DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering
AUTHORS: JIAHAO LU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering

159, TITLE: Let Me Finish My Sentence: Video Temporal Grounding with Holistic Text Understanding
AUTHORS: Jongbhin Woo ; Hyeonggon Ryu ; Youngjoon Jang ; Jae Won Cho ; Joon Son Chung
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A model may capture correlations between individual word tokens and arbitrary visual frames while possibly missing out on the global meaning. To address this, we introduce two primary contributions: (1) a visual frame-level gate mechanism that incorporates holistic textual information, (2) cross-modal alignment loss to learn the fine-grained correlation between query and relevant frames.

160, TITLE: Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding
AUTHORS: TAN DAT NGUYEN et. al.
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: The goal of this paper is to accelerate codec-based speech synthesis systems with minimum sacrifice to speech quality.

161, TITLE: LESS: Label-Efficient and Single-Stage Referring 3D Segmentation
AUTHORS: XUEXUN LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the semantic concepts from text query and visual cues are separately interacted during the training, and both instance and semantic labels for each object are required, which is time consuming and human-labor intensive. To mitigate these issues, we propose a novel Referring 3D Segmentation pipeline, Label-Efficient and Single-Stage, dubbed LESS, which is only under the supervision of efficient binary mask.

162, TITLE: Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction
AUTHORS: Chongyang Wan ; Shunbo Lei ; Yuan Luo
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Consequently, methods designed for short-term predictions may lead to inaccurate results and high computational costs in long-term settings. To adress these limitations, we propose a novel approach called Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer).

163, TITLE: Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation
AUTHORS: WENBO XU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This study introduces a meta-learning-based prototype approach that encourages the model to learn how to adapt quickly while preserving previous knowledge.

164, TITLE: Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models
AUTHORS: Yu Yuan ; Lili Zhao ; Kai Zhang ; Guangting Zheng ; Qi Liu
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper presents Shortcut Suite, a comprehensive test suite designed to evaluate the impact of shortcuts on LLMs' performance, incorporating six shortcut types, five evaluation metrics, and four prompting strategies.

165, TITLE: On Estimating The Trace of Quantum State Powers
AUTHORS: Yupan Liu ; Qisheng Wang
CATEGORY: quant-ph [quant-ph, cs.CC, cs.DS]
HIGHLIGHT: We investigate the computational complexity of estimating the trace of quantum state powers $\text{tr}(\rho^q)$ for an $n$-qubit mixed quantum state $\rho$, given its state-preparation circuit of size $\text{poly}(n)$.

166, TITLE: Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs
AUTHORS: SUMANTH DODDAPANENI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an extensible framework that includes evaluator LLMs (Hercule) and a novel test set (Recon) specifically designed for multilingual evaluation.

167, TITLE: Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors
AUTHORS: Georgios Chochlakis ; Alexandros Potamianos ; Kristina Lerman ; Shrikanth Narayanan
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This limitation is particularly evident in complex subjective domains such as emotion and morality, where priors significantly influence posterior predictions. In this work, we examine whether this is the result of the aggregation used in corresponding datasets, where trying to combine low-agreement, disparate annotations might lead to annotation artifacts that create detrimental noise in the prompt.

168, TITLE: SPIN: Self-Supervised Prompt INjection
AUTHORS: Leon Zhou ; Junfeng Yang ; Chengzhi Mao
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Various adversarial and jailbreak attacks have been proposed to bypass the safety alignment and cause the model to produce harmful responses. We introduce Self-supervised Prompt INjection (SPIN) which can detect and reverse these various attacks on LLMs.

169, TITLE: What Do Speech Foundation Models Not Learn About Speech?
AUTHORS: Abdul Waheed ; Hanin Atwany ; Bhiksha Raj ; Rita Singh
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: In our work, we analyze several prominent models such as Whisper, Seamless, Wav2Vec, HuBERT, and Qwen2-Audio focusing on their learned representations in both paralinguistic and non-paralinguistic tasks from the Dynamic-SUPERB benchmark.

170, TITLE: Proof Flow: Preliminary Study on Generative Flow Network Language Model Tuning for Formal Reasoning
AUTHORS: MATTHEW HO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a proof of concept in the domain of formal reasoning, specifically in the Neural Theorem Proving (NTP) setting, where proofs specified in a formal language such as Lean can be deterministically and objectively verified.

171, TITLE: Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and Surface Representation
AUTHORS: XUEZHI XIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a point-voxel fusion method, where we utilize a voxel branch based on sparse grid attention and the shifted window strategy to capture long-range dependencies and a point branch to capture fine-grained features to compensate for the information loss in the voxel branch.

172, TITLE: Unlocking The Capabilities of Masked Generative Models for Image Synthesis Via Self-Guidance
AUTHORS: JIWAN HUR et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: A key factor in the performance of continuous diffusion models stems from the guidance methods, which enhance the sample quality at the expense of diversity. In this paper, we extend these guidance methods to generalized guidance formulation for MGMs and propose a self-guidance sampling method, which leads to better generation quality.

173, TITLE: High Rate Multivariate Polynomial Evaluation Codes
AUTHORS: Swastik Kopparty ; Mrinal Kumar ; Harry Sha
CATEGORY: cs.IT [cs.IT, cs.CC, math.IT]
HIGHLIGHT: In this work, we give the first constructions of multivariate polynomial evaluation codes which overcome the rate limitation -- concretely, we give explicit evaluation domains $S \subseteq \mathbb{F}_q^m$ on which evaluating $m$-variate polynomials of degree at most $d$ gives a good code.

174, TITLE: From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning
AUTHORS: JUAN DIEGO TOSCANO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, physics.comp-ph]
HIGHLIGHT: In this review, we provide a comprehensive overview of the latest advancements in PINNs, focusing on improvements in network design, feature expansion, optimization techniques, uncertainty quantification, and theoretical insights.

175, TITLE: FedGTST: Boosting Global Transferability of Federated Models Via Statistics Tuning
AUTHORS: Evelyn Ma ; Chao Pan ; Rasoul Etesami ; Han Zhao ; Olgica Milenkovic
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Second, most approaches rely on indirect transferability metrics, which do not accurately reflect the final target loss or true degree of transferability. To address these gaps, we propose two enhancements to FL.

176, TITLE: Progressive Mixed-Precision Decoding for Efficient LLM Inference
AUTHORS: HAO MARK CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Instead, we propose a novel phase-aware method that selectively allocates precision during different phases of LLM inference, achieving both strong context extraction during prefill and efficient memory bandwidth utilization during decoding.

177, TITLE: FedCAP: Robust Federated Learning Via Customized Aggregation and Personalization
AUTHORS: YOUPENG LI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: However, due to its distributed nature, FL faces two key issues: the non-independent and identical distribution (non-IID) of user data and vulnerability to Byzantine threats. To address these challenges, in this paper, we propose FedCAP, a robust FL framework against both data heterogeneity and Byzantine attacks.

178, TITLE: LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch
AUTHORS: CAIGAO JIANG et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: In this paper, we propose a unified learning-based framework called LLMOPT to boost optimization generalization.

179, TITLE: Membership Testing for Semantic Regular Expressions
AUTHORS: Yifei Huang ; Matin Amini ; Alexis Le Glaunec ; Konstantinos Mamouras ; Mukund Raghothaman
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: In contrast, an important consideration in our setting is to minimize the cost of invoking the oracle. We demonstrate an $\Omega(|w|^2)$ lower bound on the number of oracle queries necessary to make this determination.

180, TITLE: Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation
AUTHORS: Yiming Wang ; Pei Zhang ; Baosong Yang ; Derek F. Wong ; Rui Wang
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this research track, we propose the Chain-of-Embedding (CoE) in the latent space to enable LLMs to perform output-free self-evaluation.

181, TITLE: Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes
AUTHORS: Dibyanayan Bandyopadhyay ; Mohammed Hasanuzzaman ; Asif Ekbal
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Various input attribution-based methods attempt to interpret their behavior, but they face challenges with implicitly offensive memes and non-causal attributions. To address these issues, we propose a framework based on a Structural Causal Model (SCM).

182, TITLE: CohEx: A Generalized Framework for Cohort Explanation
AUTHORS: Fanyu Meng ; Xin Liu ; Zhaodan Kong ; Xin Chen
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we discuss the unique challenges and opportunities associated with measuring cohort explanations, define their desired properties, and create a generalized framework for generating cohort explanations based on supervised clustering.

183, TITLE: Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations
AUTHORS: Lu Pang ; Tao Sun ; Weimin Lyu ; Haibin Ling ; Chao Chen
CATEGORY: cs.CR [cs.CR, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: However, real-world datasets often follow long-tailed distributions. In this paper, for the first time, we explore backdoor attack on such datasets.

184, TITLE: LoLDU: Low-Rank Adaptation Via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning
AUTHORS: YIMING SHI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, LoRA utilize random initialization and optimization of low-rank matrices to approximate updated weights, which can result in suboptimal convergence and an accuracy gap compared to full fine-tuning. To address these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning (PEFT) approach that significantly reduces trainable parameters by 2600 times compared to regular PEFT methods while maintaining comparable performance.

185, TITLE: GlossyGS: Inverse Rendering of Glossy Objects with 3D Gaussian Splatting
AUTHORS: SHUICHANG LAI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, these techniques generally have difficulty in producing believable geometries and materials for glossy objects, a challenge that stems from the inherent ambiguities of inverse rendering. To address this, we introduce GlossyGS, an innovative 3D-GS-based inverse rendering framework that aims to precisely reconstruct the geometry and materials of glossy objects by integrating material priors.

186, TITLE: AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents
AUTHORS: KE YANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: Autonomy via agents using large language models (LLMs) for personalized, standardized tasks boosts human efficiency.

187, TITLE: Reinforcement Learning with Euclidean Data Augmentation for State-Based Continuous Control
AUTHORS: Jinzhu Luo ; Dingyang Chen ; Qi Zhang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Prior work towards this objective has been largely restricted to perturbation-based data augmentation where new data points are created by perturbing the original ones, which has been impressively effective for tasks where the RL agent observes control states as images with perturbations including random cropping, shifting, etc. This work focuses on state-based control, where the RL agent can directly observe raw kinematic and task features, and considers an alternative data augmentation applied to these features based on Euclidean symmetries under transformations like rotations.

188, TITLE: MEGA: Memory-Efficient 4D Gaussian Splatting for Dynamic Scenes
AUTHORS: XINJIE ZHANG et. al.
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: This paper introduces a memory-efficient framework for 4DGS.

189, TITLE: DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone
AUTHORS: HONGFAN GAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To address the first challenge, we integrate the computational efficient state space model, namely Mamba, as the backbone denosing module for DDPMs.

190, TITLE: TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness
AUTHORS: Cheng Huang ; Pan Mu ; Cong Bai ; Peter AG Watson
CATEGORY: cs.LG [cs.LG, cs.AI, physics.ao-ph]
HIGHLIGHT: Second, these methods overlook the importance of meteorological factors in TC rainfall and their integration with the numerical weather prediction (NWP) model. Therefore, we propose Tropical Cyclone Precipitation Diffusion (TCP-Diffusion), a multi-modal model for global tropical cyclone precipitation forecasting.

191, TITLE: Signwriting-evaluation: Effective Sign Language Evaluation Via SignWriting
AUTHORS: Amit Moryossef ; Rotem Zilberman ; Ohad Langer
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a comprehensive suite of evaluation metrics specifically designed for SignWriting, including adaptations of standard metrics such as \texttt{BLEU} and \texttt{chrF}, the application of \texttt{CLIPScore} to SignWriting images, and a novel symbol distance metric unique to our approach.

192, TITLE: Pose-Based Sign Language Appearance Transfer
AUTHORS: Amit Moryossef ; Gerard Sant ; Zifan Jiang
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: We introduce a method for transferring the signer's appearance in sign language skeletal poses while preserving the sign content.

193, TITLE: The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties in Linear Subspaces
AUTHORS: Ahmed Oumar El-Shangiti ; Tatsuya Hiraoka ; Hilal AlQuabeh ; Benjamin Heinzerling ; Kentaro Inui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper investigates whether large language models (LLMs) utilize numerical attributes encoded in a low-dimensional subspace of the embedding space when answering logical comparison questions (e.g., Was Cristiano born before Messi?)

194, TITLE: Repetition Neurons: How Do Language Models Produce Repetitions?
AUTHORS: Tatsuya Hiraoka ; Kentaro Inui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces repetition neurons, regarded as skill neurons responsible for the repetition problem in text generation tasks.

195, TITLE: RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images with Autonomous Agents
AUTHORS: Zhuoran Liu ; Danpei Zhao ; Bo Yuan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, current interpretation methods often fail at tasks that require the combination of multiple perception methods and specialized tools. To fill this gap, this paper introduces Adaptive Disaster Interpretation (ADI), a novel task designed to solve requests by planning and executing multiple sequentially correlative interpretation tasks to provide a comprehensive analysis of disaster scenes.

196, TITLE: OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope
AUTHORS: WEI LIU et. al.
CATEGORY: physics.optics [physics.optics, cs.AI]
HIGHLIGHT: However, the hologram reconstruction process poses a significant bottleneck for timely data analysis. To address this challenge, we propose a novel reconstruction approach that integrates deep learning with the physical principles of off-axis holography.

197, TITLE: Adaptive and Oblivious Statistical Adversaries Are Equivalent
AUTHORS: Guy Blanc ; Gregory Valiant
CATEGORY: cs.LG [cs.LG, cs.CC, cs.DS]
HIGHLIGHT: We resolve a fundamental question about the ability to perform a statistical task, such as learning, when an adversary corrupts the sample.

198, TITLE: LLM-Human Pipeline for Cultural Context Grounding of Conversations
AUTHORS: Rajkumar Pujari ; Dan Goldwasser
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, it is a hard task for NLP models. In this paper, we tackle this problem by introducing a "Cultural Context Schema" for conversations.

199, TITLE: DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation
AUTHORS: HANBO CHENG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Although significant progress has been made in diffusion-based talking head generation, almost all methods rely on autoregressive strategies, which suffer from limited context utilization beyond the current generation step, error accumulation, and slower generation speed. To address these challenges, we present DAWN (Dynamic frame Avatar With Non-autoregressive diffusion), a framework that enables all-at-once generation of dynamic-length video sequences.

200, TITLE: RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images
AUTHORS: Kejun Ren ; Xin Wu ; Lianming Xu ; Li Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we propose a multimodal remote sensing detection network that employs a quad-directional selective scanning fusion strategy called RemoteDet-Mamba.

201, TITLE: CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy
AUTHORS: MIAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: In this paper, we aim to thoroughly examine the potential of using Large Language Models (LLMs) to assist professional psychotherapy.

202, TITLE: MixEHR-Nest: Identifying Subphenotypes Within Electronic Health Records Through Hierarchical Guided-Topic Modeling
AUTHORS: Ruohan Wang ; Zilong Wang ; Ziyang Song ; David Buckeridge ; Yue Li
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IR, q-bio.QM, J.3]
HIGHLIGHT: In this study, we propose a guided topic model, MixEHR-Nest, to infer sub-phenotype topics from thousands of disease using multi-modal EHR data.

203, TITLE: VidPanos: Generative Panoramic Videos from Casual Panning Videos
AUTHORS: JINGWEI MA et. al.
CATEGORY: cs.CV [cs.CV, cs.GR, I.3.3; I.4]
HIGHLIGHT: We present a method for synthesizing a panoramic video from a casually-captured panning video, as if the original video were captured with a wide-angle camera.

204, TITLE: Channel-Wise Mixed-Precision Quantization for Large Language Models
AUTHORS: Zihan Chen ; Bike Xie ; Jundong Li ; Cong Shen
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce Channel-Wise Mixed-Precision Quantization (CMPQ), a novel mixed-precision quantization method that allocates quantization precision in a channel-wise pattern based on activation distributions.

205, TITLE: Can MLLMs Understand The Deep Implication Behind Chinese Images?
AUTHORS: CHENHAO ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.CY]
HIGHLIGHT: To fill the gap, we introduce the **C**hinese **I**mage **I**mplication understanding **Bench**mark, **CII-Bench**, which aims to assess the higher-order perception and understanding capabilities of MLLMs for Chinese images.

206, TITLE: UniCoN: Universal Conditional Networks for Multi-Age Embryonic Cartilage Segmentation with Sparsely Annotated Data
AUTHORS: NISHCHAL SAPKOTA et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: While DL approaches have been proposed to automate cartilage segmentation, most such models have limited accuracy and generalizability, especially across data from different embryonic age groups. To address these limitations, we propose novel DL methods that can be adopted by any DL architectures -- including CNNs, Transformers, or hybrid models -- which effectively leverage age and spatial information to enhance model performance.

207, TITLE: Mitigating Hallucinations in Large Vision-Language Models Via Summary-Guided Decoding
AUTHORS: Kyungmin Min ; Minbeom Kim ; Kang-il Lee ; Dongryeol Lee ; Kyomin Jung
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CV]
HIGHLIGHT: (2) Methods that directly calibrate LVLM's output distribution to mitigate language priors can lead to a degradation in text quality or even exacerbate hallucinations. Based on these findings, we propose a novel method, Summary-Guided Decoding (SGD).

208, TITLE: PromptExp: Multi-granularity Prompt Explanation of Large Language Models
AUTHORS: XIMING DONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recent efforts in LLM explanation focus on natural language explanations, but they are prone to hallucinations and inaccuracies. To address this, we introduce OurTool, a framework for multi-granularity prompt explanations by aggregating token-level insights.

209, TITLE: The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion
AUTHORS: Xu Han ; Yuancheng Sun ; Kai Chen ; Kang Liu ; Qiwei Ye
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: While recent machine learning methods have made strides in protein structure generation, challenges persist in reconstructing diverse atomistic conformations that maintain geometric accuracy and chemical validity. In this paper, we present Latent Diffusion Backmapping (LDB), a novel approach leveraging denoising diffusion within latent space to address these challenges.

210, TITLE: Fairness-Enhancing Ensemble Classification in Water Distribution Networks
AUTHORS: Janine Strotherm ; Barbara Hammer
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this contribution, we investigate the applications of AI to socioeconomically relevant infrastructures such as those of water distribution networks (WDNs), where fairness issues have yet to gain a foothold.

211, TITLE: MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback
AUTHORS: ZONGHAI YAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, current large language models (LLMs) like GPT-4 struggle with professional MCQG due to outdated knowledge, hallucination issues, and prompt sensitivity, resulting in unsatisfactory quality and difficulty. To address these challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique and Correction) framework for converting medical cases into high-quality USMLE-style questions.

212, TITLE: Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement
AUTHORS: Yuxuan Liu ; Wenyuan Li ; Laizhong Cui ; Hailiang Yang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, we have identified two key issues with existing parallel decoding frameworks: (1) decoding heads fail to balance prediction accuracy and the parallelism of execution, and (2) parallel decoding is not a universal solution, as it can bring unnecessary overheads at some challenging decoding steps. To address these issues, we propose Cerberus, an adaptive parallel decoding framework introduces the gating mechanism to enable the LLMs to adaptively choose appropriate decoding approaches at each decoding step, along with introducing a new paradigm of decoding heads that introduce the sequential knowledge while maintaining execution parallelism.

213, TITLE: Linguistically Grounded Analysis of Language Models Using Shapley Head Values
AUTHORS: Marcell Fekete ; Johannes Bjerva
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate the processing of morphosyntactic phenomena, by leveraging a recently proposed method for probing language models via Shapley Head Values (SHVs).

214, TITLE: From Babbling to Fluency: Evaluating The Evolution of Language Models in Terms of Human Language Acquisition
AUTHORS: Qiyuan Yang ; Pengda Wang ; Luke D. Plonsky ; Frederick L. Oswald ; Hanjie Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Building on classical language development theories, we propose a three-stage framework to assess the abilities of LMs, ranging from preliminary word understanding to complex grammar and complex logical reasoning.

215, TITLE: Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation Based on Segment Anything
AUTHORS: Joonhyeon Song ; Seohwan Yun ; Seongho Yoon ; Joohyeok Kim ; Sangmin Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work proposes a novel approach beyond supervised learning for effective pathological image analysis, addressing the challenge of limited robust labeled data.

216, TITLE: Systems with Switching Causal Relations: A Meta-Causal Perspective
AUTHORS: MORITZ WILLIG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: As a result, new causal relationships may emerge, while existing ones change or disappear, resulting in an altered causal graph. To analyze these qualitative changes on the causal graph, we propose the concept of meta-causal states, which groups classical causal models into clusters based on equivalent qualitative behavior and consolidates specific mechanism parameterizations.

217, TITLE: IterSelectTune: An Iterative Training Framework for Efficient Instruction-Tuning Data Selection
AUTHORS: Jielin Song ; Siyu Liu ; Bin Zhu ; Yanghui Rao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce $\textbf{IterSelectTune}$, an efficient, cost-effective iterative training policy for selecting high-quality instruction data with no human involvement and limited reliance on GPT-4.

218, TITLE: DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech
AUTHORS: Jan Melechovsky ; Ambuj Mehrish ; Berrak Sisman ; Dorien Herremans
CATEGORY: eess.AS [eess.AS, cs.AI, cs.SD]
HIGHLIGHT: We propose a novel approach to disentangle speaker and accent representations using multi-level variational autoencoders (ML-VAE) and vector quantization (VQ) to improve flexibility and enhance personalization in speech synthesis.

219, TITLE: A Systematic Investigation of Knowledge Retrieval and Selection for Retrieval Augmented Generation
AUTHORS: Xiangci Li ; Jessica Ouyang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we perform a comprehensive analysis of how knowledge retrieval and selection influence downstream generation performance in RAG systems.

220, TITLE: Sensitivity of Generative VLMs to Semantically and Lexically Altered Prompts
AUTHORS: SRI HARSHA DUMPALA et. al.
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we evaluate the ability of generative VLMs to understand lexical and semantic changes in text using the SugarCrepe++ dataset.

221, TITLE: PopAlign: Diversifying Contrasting Patterns for A More Comprehensive Alignment
AUTHORS: ZEKUN MOORE WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: For RQ1, we propose PopAlign, a framework that integrates diversified contrasting patterns across the prompt, model, and pipeline levels, introducing six contrasting strategies that do not require additional feedback labeling procedures.

222, TITLE: LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models
AUTHORS: David Hoffmann ; Kailash Budhathoki ; Matthaeus Kleindessner
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: The evolving capabilities of large language models are accompanied by growing sizes and deployment costs, necessitating effective inference optimisation techniques. We propose a novel pruning method utilising centrality measures from graph theory, reducing both the computational requirements and the memory footprint of these models.

223, TITLE: MoR: Mixture of Ranks for Low-Rank Adaptation Tuning
AUTHORS: CHUANYU TANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: (2) MoE-style LoRA methods substantially increase parameters and inference latency, contradicting the goals of efficient fine-tuning and ease of application. To address these challenges, we introduce Mixture of Ranks (MoR), which learns rank-specific information for different tasks based on input and efficiently integrates multi-rank information.

224, TITLE: Breaking Chains: Unraveling The Links in Multi-Hop Knowledge Unlearning
AUTHORS: Minseok Choi ; ChaeHun Park ; Dohyun Lee ; Jaegul Choo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Our findings reveal that existing methods fail to completely remove multi-hop knowledge when one of the intermediate hops is unlearned. To address this issue, we propose MUNCH, a simple uncertainty-based approach that breaks down multi-hop queries into subquestions and leverages the uncertainty of the unlearned model in final decision-making.

225, TITLE: Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval
AUTHORS: Ingeol Baek ; Hwan Chang ; Byeongjeong Kim ; Jimin Lee ; Hwanhee Lee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a Probing-RAG, which utilizes the hidden state representations from the intermediate layers of language models to adaptively determine the necessity of additional retrievals for a given query.

226, TITLE: LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of The European Court of Human Rights
AUTHORS: Odysseas S. Chlapanis ; Dimitrios Galanis ; Ion Androutsopoulos
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present Legal Argument Reasoning (LAR), a novel task designed to evaluate the legal reasoning capabilities of Large Language Models (LLMs).

227, TITLE: Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging
AUTHORS: JACOB MORRISON et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this work, we investigate the effectiveness of adding new skills to preexisting models by training on the new skills in isolation and later merging with the general model (e.g. using task vectors).

228, TITLE: Retrospective Learning from Interactions
AUTHORS: ZIZHAO CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: This creates an avenue for continually learning from interactions without additional annotations. We introduce ReSpect, a method to learn from such signals in past interactions via retrospection.

229, TITLE: A Comparative Study on Reasoning Patterns of OpenAI's O1 Model
AUTHORS: SIWEI WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Enabling Large Language Models (LLMs) to handle a wider range of complex tasks (e.g., coding, math) has drawn great attention from many researchers.

230, TITLE: Red and Blue Language: Word Choices in The Trump & Harris 2024 Presidential Debate
AUTHORS: Philipp Wicke ; Marianna M. Bolognesi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We analyse how the language of Trump and Harris during the debate (September 10th 2024) differs in relation to the following semantic and pragmatic features, for which we formulated targeted hypotheses: framing values and ideology, appealing to emotion, using words with different degrees of concreteness and specificity, addressing others through singular or plural pronouns.

231, TITLE: Mitigating Biases to Embrace Diversity: A Comprehensive Annotation Benchmark for Toxic Language
AUTHORS: Xinmeng Hou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study introduces a prescriptive annotation benchmark grounded in humanities research to ensure consistent, unbiased labeling of offensive language, particularly for casual and non-mainstream language uses.

232, TITLE: BenchmarkCards: Large Language Model and Risk Reporting
AUTHORS: Anna Sokol ; Nuno Moniz ; Elizabeth Daly ; Michael Hind ; Nitesh Chawla
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, the rapidly expanding body of LLM benchmark literature lacks a standardized method for documenting crucial benchmark details, hindering consistent use and informed selection. BenchmarkCards addresses this gap by providing a structured framework specifically for documenting LLM benchmark properties rather than defining the entire evaluation process itself.

233, TITLE: LEGAL-UQA: A Low-Resource Urdu-English Dataset for Legal Question Answering
AUTHORS: Faizan Faisal ; Umair Yousaf
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, 68T50]
HIGHLIGHT: We present LEGAL-UQA, the first Urdu legal question-answering dataset derived from Pakistan's constitution.

234, TITLE: FaithBench: A Diverse Hallucination Benchmark for Summarization By Modern LLMs
AUTHORS: FORREST SHENG BAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper introduces FaithBench, a summarization hallucination benchmark comprising challenging hallucinations made by 10 modern LLMs from 8 different families, with ground truth annotations by human experts.

235, TITLE: ERAS: Evaluating The Robustness of Chinese NLP Models to Morphological Garden Path Errors
AUTHORS: Qinchan Li ; Sophie Hao
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper shows that Chinese NLP models are vulnerable to morphological garden path errors: errors caused by a failure to resolve local word segmentation ambiguities using sentence-level morphosyntactic context. We propose a benchmark, ERAS, that tests a model's vulnerability to morphological garden path errors by comparing its behavior on sentences with and without local segmentation ambiguities.

236, TITLE: Is Semantic Chunking Worth The Computational Cost?
AUTHORS: Renyi Qu ; Ruixuan Tu ; Forrest Bao
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: This study systematically evaluates the effectiveness of semantic chunking using three common retrieval-related tasks: document retrieval, evidence retrieval, and retrieval-based answer generation.

237, TITLE: Performance of Gaussian Mixture Model Classifiers on Embedded Feature Spaces
AUTHORS: Jeremy Chopin ; Rozenn Dahyot
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our first contribution is to investigate GMM based classification performance taking advantage of the embedded spaces CLIP and ImageBind.

238, TITLE: Interpreting and Analyzing CLIP's Zero-Shot Image Classification Via Mutual Knowledge
AUTHORS: Fawaz Sammani ; Nikos Deligiannis
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work provides a new approach for interpreting CLIP models for image classification from the lens of mutual knowledge between the two modalities.

239, TITLE: Inductive Gradient Adjustment For Spectral Bias In Implicit Neural Representations
AUTHORS: Kexuan Shi ; Hai Chen ; Leheng Zhang ; Shuhang Gu
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we delve into the linear dynamics model of MLPs and theoretically identify the empirical Neural Tangent Kernel (eNTK) matrix as a reliable link between spectral bias and training dynamics.

240, TITLE: Shavette: Low Power Neural Network Acceleration Via Algorithm-level Error Detection and Undervolting
AUTHORS: Mikael Rinkinen ; Lauri Koskinen ; Olli Silven ; Mehdi Safarpour
CATEGORY: cs.AR [cs.AR, cs.AI]
HIGHLIGHT: Reduced voltage operation is an effective technique for substantial energy efficiency improvement in digital circuits. This brief introduces a simple approach for enabling reduced voltage operation of Deep Neural Network (DNN) accelerators by mere software modifications.

241, TITLE: SoK: On Finding Common Ground in Loss Landscapes Using Deep Model Merging Techniques
AUTHORS: ARHAM KHAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Seeking new insights from work in related fields, here we survey literature in the field of model merging, a field that aims to combine the abilities of various neural networks by merging their parameters and identifying task-specific model components in the process.

242, TITLE: Normalizing Self-supervised Learning for Provably Reliable Change Point Detection
AUTHORS: Alexandra Bazarova ; Evgenia Romanenkova ; Alexey Zaytsev
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Change point detection (CPD) methods aim to identify abrupt shifts in the distribution of input data streams.

243, TITLE: Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images
AUTHORS: Arka Daw ; Megan Hong-Thanh Chung ; Maria Mahbub ; Amir Sadovnik
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR, cs.CV]
HIGHLIGHT: We introduce Hiding-in-Plain-Sight (HiPS) attacks, a novel class of adversarial attacks that subtly modifies model predictions by selectively concealing target object(s), as if the target object was absent from the scene.

244, TITLE: Unsupervised Skull Segmentation Via Contrastive MR-to-CT Modality Translation
AUTHORS: Kamil Kwarciak ; Mateusz Daniol ; Daria Hemmerling ; Marek Wodzinski
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: To overcome the difficulties we propose a fully unsupervised approach, where we do not perform the segmentation directly on MR images, but we rather perform a synthetic CT data generation via MR-to-CT translation and perform the segmentation there.

245, TITLE: Deep-learning Recognition and Tracking of Individual Nanotubes in Low-contrast Microscopy Videos
AUTHORS: Vladimir Pimonov ; Said Tahir ; Vincent Jourdain
CATEGORY: cond-mat.mes-hall [cond-mat.mes-hall, cs.CV, eess.IV, I.5.4]
HIGHLIGHT: This study addresses the challenge of analyzing the growth kinetics of carbon nanotubes using in-situ homodyne polarization microscopy (HPM) by developing an automated deep learning (DL) approach.

246, TITLE: Quasi-quantum States and The Quasi-quantum PCP Theorem
AUTHORS: Itai Arad ; Miklos Santha
CATEGORY: quant-ph [quant-ph, cs.CC]
HIGHLIGHT: We introduce $k$-local quasi-quantum states: a superset of the regular quantum states, defined by relaxing the positivity constraint.

247, TITLE: EOSpython Version 0.0.11: A Framework for Scenario Generation and A Solution System for The Agile Earth Observation Satellite Scheduling Problem
AUTHORS: Alex Elkj�r Vasegaard ; Andreas K�hne Larsen
CATEGORY: math.OC [math.OC, astro-ph.IM, cs.ET, cs.NA, cs.PL, math.NA, 05, 15, 65, 68, 90, G.1; G.2; I.6; J.2]
HIGHLIGHT: EOSpython Version 0.0.11: A Framework for Scenario Generation and A Solution System for The Agile Earth Observation Satellite Scheduling Problem

248, TITLE: Transformer Guided Coevolution: Improved Team Formation in Multiagent Adversarial Games
AUTHORS: Pranav Rajbhandari ; Prithviraj Dasgupta ; Donald Sofge
CATEGORY: cs.AI [cs.AI, cs.MA, cs.NE]
HIGHLIGHT: We propose BERTeam, a novel algorithm that uses a transformer-based deep neural network with Masked Language Model training to select the best team of players from a trained population.

249, TITLE: Anchored Alignment for Self-Explanations Enhancement
AUTHORS: Luis Felipe Villa-Arenas ; Ata Nizamoglu ; Qianli Wang ; Sebastian M�ller ; Vera Schmitt
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this work, we introduce a methodology for alignment designed to enhance the ability of large language models (LLMs) to articulate their reasoning (self-explanation) even in the absence of annotated rationale explanations.

250, TITLE: Research on Travel Route Planing Problems Based on Greedy Algorithm
AUTHORS: Yiquan Wang
CATEGORY: cs.AI [cs.AI, cs.IR]
HIGHLIGHT: Research on Travel Route Planing Problems Based on Greedy Algorithm

251, TITLE: A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities
AUTHORS: Gianluca Apriceno ; Valentina Tamma ; Tania Bailoni ; Jacopo de Berardinis ; Mauro Dragoni
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Despite the increasing attention that Multi-Modal Knowledge Graphs have received, there is a lack of consensus about the definitions and modelling of modalities, whose definition is often determined by application domains. In this paper, we propose a novel ontology design pattern that captures the separation of concerns between an entity (and the information it conveys), whose semantics can have different manifestations across different media, and its realisation in terms of a physical information entity.

252, TITLE: Large Language Models As A Tool for Mining Object Knowledge
AUTHORS: Hannah YoungEun An ; Lenhart K. Schubert
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: Large language models (LLMs) have demonstrated their ability to perform almost human-like text generation.

253, TITLE: Disjointness Violations in Wikidata
AUTHORS: Ege Atacan Do?an ; Peter F. Patel-Schneider
CATEGORY: cs.AI [cs.AI, cs.IR]
HIGHLIGHT: We use SPARQL queries to identify each ``culprit'' causing a disjointness violation and lay out formulas to identify and fix conflicting information.

254, TITLE: Optimal Transport for Probabilistic Circuits
AUTHORS: Adrian Ciotinga ; YooJung Choi
CATEGORY: cs.AI [cs.AI, cs.LG, math.OC]
HIGHLIGHT: We introduce a novel optimal transport framework for probabilistic circuits (PCs).

255, TITLE: Language Models As Semiotic Machines: Reconceptualizing AI Language Systems Through Structuralist and Post-Structuralist Theories of Language
AUTHORS: Elad Vromen
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: This paper proposes a novel framework for understanding large language models (LLMs) by reconceptualizing them as semiotic machines rather than as imitations of human cognition.

256, TITLE: BANTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla
AUTHORS: FABIHA HAIDER et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce BanTH, the first multi-label transliterated Bangla hate speech dataset comprising 37.3k samples.

257, TITLE: Mapping Bias in Vision Language Models: Signposts, Pitfalls, and The Road Ahead
AUTHORS: Kuleen Sasse ; Shan Chen ; Jackson Pond ; Danielle Bitterman ; John Osborne
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: In this paper, we analyze demographic biases across five models and six datasets.

258, TITLE: Bias in The Mirror : Are LLMs Opinions Robust to Their Own Adversarial Attacks ?
AUTHORS: Virgile Rennard ; Christos Xypolopoulos ; Michalis Vazirgiannis
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce a novel approach where two instances of an LLM engage in self-debate, arguing opposing viewpoints to persuade a neutral version of the model.

259, TITLE: MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation
AUTHORS: SATYA KRISHNA GORTI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address these issues, we focus on developing small, efficient, and open-source text-to-SQL models. We demonstrate the benefits of sampling multiple candidate SQL generations and propose our method, MSc-SQL, to critique them using associated metadata.

260, TITLE: "Let's Argue Both Sides": Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities
AUTHORS: Kaveh Eskandari Miandoab ; Vasanth Sarathy
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose Argument Generation as a method of forcing models to utilize their reasoning capabilities when other approaches such as chain-of-thought reasoning prove insufficient.

261, TITLE: POROver: Improving Safety and Reducing Overrefusal in Large Language Models with Overgeneration and Preference Optimization
AUTHORS: BATUHAN K. KARAMAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we examine how the overgeneration of training data using advanced teacher models (e.g., GPT-4o), including responses to both general-purpose and toxic prompts, influences the safety and overrefusal balance of instruction-following language models.

262, TITLE: Evaluating The Instruction-following Abilities of Language Models Using Knowledge Tasks
AUTHORS: Rudra Murthy ; Prince Kumar ; Praveen Venkateswaran ; Danish Contractor
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we focus our attention on developing a benchmark for instruction-following where it is easy to verify both task performance as well as instruction-following capabilities.

263, TITLE: The Mystery of The Pathological Path-star Task for Language Models
AUTHORS: Arvid Frydenlund
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We introduce a regularization method using structured samples of the same graph but with differing target nodes, improving results across a variety of model types.

264, TITLE: Reference-Based Post-OCR Processing with LLM for Diacritic Languages
AUTHORS: Thao Do
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: We propose a method utilizing available content-focused ebooks as a reference base to correct imperfect OCR-generated text, supported by large language models.

265, TITLE: GeoCoder: Solving Geometry Problems By Generating Modular Code Through Vision-Language Models
AUTHORS: Aditya Sharma ; Aman Dalmia ; Mehran Kazemi ; Amal Zouaq ; Christopher J. Pal
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: Yet, they still struggle with geometry problems and are significantly limited by their inability to perform mathematical operations not seen during pre-training, such as calculating the cosine of an arbitrary angle, and by difficulties in correctly applying relevant geometry formulas. To overcome these challenges, we present GeoCoder, which leverages modular code-finetuning to generate and execute code using a predefined geometry function library.

266, TITLE: Computational Approaches to Arabic-English Code-Switching
AUTHORS: Caroline Sabty
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we focus on the Named Entity Recognition (NER) task and other tasks that help propose a solution for the NER task on CS data, e.g., Language Identification.

267, TITLE: Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification
AUTHORS: ZEREN SHUI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a multi-task learning (MTL) framework that jointly fine-tunes PLMs on a dataset of primary interest together with multiple auxiliary CIC datasets to take advantage of additional supervision signals.

268, TITLE: Retrieval-Enhanced Named Entity Recognition
AUTHORS: Enzo Shiraishi ; Raphael Y. de Camargo ; Henrique L. P. Silva ; Ronaldo C. Prati
CATEGORY: cs.CL [cs.CL, cs.IR, I.2.7]
HIGHLIGHT: We propose RENER (Retrieval-Enhanced Named Entity Recognition), a technique for named entity recognition using autoregressive language models based on In-Context Learning and information retrieval techniques.

269, TITLE: NLIP_Lab-IITH Multilingual MT System for WAT24 MT Shared Task
AUTHORS: Maharaj Brahma ; Pramit Sahoo ; Maunendra Sankar Desarkar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper describes NLIP Lab's multilingual machine translation system for the WAT24 shared task on multilingual Indic MT task for 22 scheduled languages belonging to 4 language families.

270, TITLE: Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works
AUTHORS: Maria Levchenko
CATEGORY: cs.CL [cs.CL, cs.AI, 68U15, J.5; I.7.4]
HIGHLIGHT: This paper investigates the application of translation alignment algorithms in the creation of a Multilingual Digital Edition (MDE) of Alessandro Manzoni's Italian novel "I promessi sposi" ("The Betrothed"), with translations in eight languages (English, Spanish, French, German, Dutch, Polish, Russian and Chinese) from the 19th and 20th centuries.

271, TITLE: Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques
AUTHORS: Rahimanuddin Shaik ; Katikela Sreeharsha Kishore
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This research paper developed a novel approach to improve text generation in the context of joint Natural Language Generation (NLG) and Natural Language Understanding (NLU) learning.

272, TITLE: Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR
AUTHORS: Abhishek Gupta ; Amruta Parulekar ; Sameep Chattopadhyay ; Preethi Jyothi
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, eess.AS]
HIGHLIGHT: Parameter-efficient fine-tuning and text-only adaptation are two popular methods that have been used to address such low-resource settings. In this work, we investigate how these techniques can be effectively combined using a multilingual multimodal model like SeamlessM4T.

273, TITLE: BQA: Body Language Question Answering Dataset for Video Large Language Models
AUTHORS: SHINTARO OZAKI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Enabling current Video Large Language Models (VideoLLMs) to accurately interpret body language is a crucial challenge, as human unconscious actions can easily cause the model to misinterpret their intent. To address this, we propose a dataset, BQA, a body language question answering dataset, to validate whether the model can correctly interpret emotions from short clips of body language comprising 26 emotion labels of videos of body language.

274, TITLE: When Not to Answer: Evaluating Prompts on GPT Models for Effective Abstention in Unanswerable Math Word Problems
AUTHORS: Asir Saadat ; Tasmia Binte Sogir ; Md Taukir Azam Chowdhury ; Syem Aziz
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we investigate whether GPTs can appropriately respond to unanswerable math word problems by applying prompts typically used in solvable mathematical scenarios.

275, TITLE: Qtok: A Comprehensive Framework for Evaluating Multilingual Tokenizer Quality in Large Language Models
AUTHORS: Iaroslav Chelombitko ; Egor Safronov ; Aleksey Komissarov
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7; I.2.6; H.3.3]
HIGHLIGHT: We introduce Qtok, a tool designed to assess tokenizer quality with a specific emphasis on their performance in multilingual contexts.

276, TITLE: Generative Adversarial Synthesis of Radar Point Cloud Scenes
AUTHORS: Muhammad Saad Nawaz ; Thomas Dallmann ; Torsten Schoen ; Dirk Heberling
CATEGORY: cs.CV [cs.CV, cs.LG, eess.IV]
HIGHLIGHT: In this paper, we introduce radar scene synthesis using GANs as an alternative to the real dataset acquisition and simulation-based approaches.

277, TITLE: Latent Image and Video Resolution Prediction Using Convolutional Neural Networks
AUTHORS: Rittwika Kansabanik ; Adrian Barbu
CATEGORY: cs.CV [cs.CV, stat.AP]
HIGHLIGHT: This paper introduces a Video Quality Assessment (VQA) problem that has received little attention in the literature, called the latent resolution prediction problem.

278, TITLE: SAda-Net: A Self-Supervised Adaptive Stereo Estimation CNN For Remote Sensing Image Data
AUTHORS: Dominik Hirner ; Friedrich Fraundorfer
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This is especially true for remote sensing applications, where there is an excess of available data without proper ground truth. To tackle this problem, we propose a self-supervised CNN with self-improving adaptive abilities.

279, TITLE: DiRecNetV2: A Transformer-Enhanced Network for Aerial Disaster Recognition
AUTHORS: Demetris Shianios ; Panayiotis Kolios ; Christos Kyrkou
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Bridging this research gap, we introduce DiRecNetV2, an improved hybrid model that utilizes convolutional and transformer layers.

280, TITLE: H2OVL-Mississippi Vision Language Models Technical Report
AUTHORS: SHAIKAT GALIB et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: These models require strong language understanding and visual capabilities to enhance human-machine interaction. To address this need, we present H2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs using 240 hours of compute on 8 x H100 GPUs.

281, TITLE: Material Fingerprinting: Identifying and Predicting Perceptual Attributes of Material Appearance
AUTHORS: JIRI FILIP et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We reasoned that for many practical purposes, a compact representation of the perceptual appearance is more useful than an exhaustive physical description.This paper introduces a novel approach to material identification by encoding perceptual features obtained from dynamic visual stimuli.

282, TITLE: Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring
AUTHORS: Kristina Telegraph ; Christos Kyrkou
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This work presents advancements in multi-class vehicle detection using UAV cameras through the development of spatiotemporal object detection models.

283, TITLE: UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and NnU-Net ResEnc Planner
AUTHORS: Jintao Ren ; Kim Hochreuter ; Jesper Folsted Kallehauge ; Stine Sofia Korreman
CATEGORY: cs.CV [cs.CV, cs.AI, physics.med-ph]
HIGHLIGHT: Recently, two deep learning segmentation innovations have shown great promise: UMamba, which effectively captures long-range dependencies, and the nnU-Net Residual Encoder (ResEnc), which enhances feature extraction through multistage residual blocks. In this study, we integrate these strengths into a novel approach, termed 'UMambaAdj'.

284, TITLE: Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy
AUTHORS: Jintao Ren ; Kim Hochreuter ; Mathis Ersted Rasmussen ; Jesper Folsted Kallehauge ; Stine Sofia Korreman
CATEGORY: cs.CV [cs.CV, cs.AI, physics.med-ph]
HIGHLIGHT: By leveraging pre-RT images and their segmentations as prior knowledge, we address the challenge of tumor localization in mid-RT segmentation.

285, TITLE: 360U-Former: HDR Illumination Estimation with Panoramic Adapted Vision Transformers
AUTHORS: Jack Hilliard ; Adrian Hilton ; Jean-Yves Guillemaut
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: Consequently, high dynamic range images (HDRI) results usually exhibit a seam at the side borders and textures or objects that are warped at the poles. To address this shortcoming we propose a novel architecture, 360U-Former, based on a U-Net style Vision-Transformer which leverages the work of PanoSWIN, an adapted shifted window attention tailored to the ERP format.

286, TITLE: CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models
AUTHORS: YUJIAN ZHAO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, due to the high cost of constructing CC-ReID data, the existing data-driven models are hard to train efficiently on limited data, causing overfitting issue. To address this challenge, we propose a low-cost and efficient pipeline for generating controllable and high-quality synthetic data simulating the surveillance of real scenarios specific to the CC-ReID task.

287, TITLE: Multi-style Conversion for Semantic Segmentation of Lesions in Fundus Images By Adversarial Attacks
AUTHORS: Cl�ment Playout ; Renaud Duval ; Marie Carole Boucher ; Farida Cheriet
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper introduces a novel method, termed adversarial style conversion, to address the lack of standardization in annotation styles across diverse databases.

288, TITLE: MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models
AUTHORS: DONGHAO ZHOU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we introduce component-controllable personalization, a novel task that pushes the boundaries of T2I models by allowing users to reconfigure specific components when personalizing visual concepts.

289, TITLE: Accurate Checkerboard Corner Detection Under Defoucs
AUTHORS: Zezhun Shi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce a simplified objective function that reduces computation time and mitigates overfitting risks.

290, TITLE: Railway LiDAR Semantic Segmentation Based on Intelligent Semi-automated Data Annotation
AUTHORS: Florian Wulff ; Bernd Schaeufele ; Julian Pfeifer ; Ilja Radusch
CATEGORY: cs.CV [cs.CV, cs.SY, eess.SY]
HIGHLIGHT: Thus, we propose an approach for a point-wise 3D semantic segmentation based on the 2DPass network architecture using scans and images jointly.

291, TITLE: Augmentation Policy Generation for Image Classification Using Large Language Models
AUTHORS: Ant Duru ; Alptekin Temizel
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a strategy that uses large language models to automatically generate efficient augmentation policies, customized to fit the specific characteristics of any dataset and model architecture.

292, TITLE: Object Pose Estimation Using Implicit Representation For Transparent Objects
AUTHORS: Varun Burde ; Artem Moroz ; Vit Zeman ; Pavel Burget
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Recent research has been moving toward learning-based methods, which provide a more flexible and generalizable approach to object pose estimation utilizing deep learning. One such approach is the render-and-compare method, which renders the object from multiple views and compares it against the given 2D image, which often requires an object representation in the form of a CAD model.

293, TITLE: Explainable Binary Classification of Separable Shape Ensembles
AUTHORS: Zachary Grey ; Nicholas Fisher ; Andrew Glaws ; Gunay Dogan
CATEGORY: cs.CV [cs.CV, math.ST, stat.TH]
HIGHLIGHT: Observations of these collections of shapes can facilitate inferences about material properties and manufacturing processes. We seek to bolster this application, and related engineering/scientific tasks, using novel pattern recognition formalisms and inference over large ensembles of segmented curves -- i.e., facilitate principled assessments for quantifying differences in distributions of shapes.

294, TITLE: Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from A Collaborative Analysis of Greek Political Rhetoric By ChatGPT and Humans
AUTHORS: THANASIS TROBOUKIS et. al.
CATEGORY: cs.CY [cs.CY, cs.CL]
HIGHLIGHT: This chapter introduces a research project titled "Analyzing the Political Discourse: A Collaboration Between Humans and Artificial Intelligence", which was initiated in preparation for Greece's 2023 general elections.

295, TITLE: Privacy-Preserving Decentralized AI with Confidential Computing
AUTHORS: Dayeol Lee ; Jorge Antonio ; Hisham Khan
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: To address the limitation, we propose leveraging Confidential Computing (CC).

296, TITLE: Boosting Asynchronous Decentralized Learning with Model Fragmentation
AUTHORS: SAYAN BISWAS et. al.
CATEGORY: cs.DC [cs.DC, cs.AI]
HIGHLIGHT: We present DivShare, a novel asynchronous DL algorithm that achieves fast model convergence in the presence of communication stragglers.

297, TITLE: Eyelid Fold Consistency in Facial Modeling
AUTHORS: Lohit Petikam ; Charlie Hewitt ; Fatemeh Saleh ; Tadas Baltru?aitis
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: We propose a new definition of eyelid fold consistency and implement geometric processing techniques to model diverse eyelid shapes in a unified topology.

298, TITLE: LLM Confidence Evaluation Measures in Zero-Shot CSS Classification
AUTHORS: DAVID FARR et. al.
CATEGORY: cs.HC [cs.HC, cs.CL, cs.IR]
HIGHLIGHT: In this paper, we make three key contributions: (1) we propose an uncertainty quantification (UQ) performance measure tailored for data annotation tasks, (2) we compare, for the first time, five different UQ strategies across three distinct LLMs and CSS data annotation tasks, (3) we introduce a novel UQ aggregation strategy that effectively identifies low-confidence LLM annotations and disproportionately uncovers data incorrectly labeled by the LLMs.

299, TITLE: Perceptions of Discriminatory Decisions of Artificial Intelligence: Unpacking The Role of Individual Characteristics
AUTHORS: Soojong Kim
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CY]
HIGHLIGHT: This study investigates how personal differences (digital self-efficacy, technical knowledge, belief in equality, political ideology) and demographic factors (age, education, and income) are associated with perceptions of artificial intelligence (AI) outcomes exhibiting gender and racial bias and with general attitudes towards AI.

300, TITLE: Large Language Models As Narrative-Driven Recommenders
AUTHORS: Lukas Eberhard ; Thorsten Ruprechter ; Denis Helic
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CL]
HIGHLIGHT: Although large language models (LLMs) have been shown to excel in processing general natural language queries, their effectiveness for handling such recommendation requests remains relatively unexplored. To close this gap, we compare the performance of 38 open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in a movie recommendation setting.

301, TITLE: Context-aware Adaptive Personalised Recommendation: A Meta-hybrid
AUTHORS: Peter Tibensky ; Michal Kompan
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: In this paper, we propose a meta-hybrid recommender that uses machine learning to predict an optimal algorithm.

302, TITLE: Virtual Sensing for Real-Time Degradation Monitoring of Nuclear Systems: Leveraging DeepONet for Enhanced Sensing Coverage for Digital Twin-Enabling Technology
AUTHORS: RAISA BENTAY HOSSAIN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this study, DeepONet is trained with different operational conditions, which relaxes the requirement of continuous retraining, making it suitable for online and real-time prediction components for DT.

303, TITLE: Utilizing Large Language Models in An Iterative Paradigm with Domain Feedback for Molecule Optimization
AUTHORS: Khiem Le ; Nitesh V. Chawla
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: In this work, we facilitate utilizing LLMs in an iterative paradigm by proposing a simple yet highly effective domain feedback provider, namely $\text{Re}^2$DF.

304, TITLE: Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights
AUTHORS: Ameet Gadekar ; Aristides Gionis ; Suhas Thejaswi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY, cs.DM]
HIGHLIGHT: In this work, we focus on fair data summarization modeled as the fair $k$-supplier problem, where data consists of several groups, and a minimum number of centers must be selected from each group while minimizing the $k$-supplier objective.

305, TITLE: SSET: Swapping-Sliding Explanation for Time Series Classifiers in Affect Detection
AUTHORS: Nazanin Fouladgar ; Marjan Alirezaie ; Kary Fr�mling
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a swapping--sliding decision explanation for multivariate time series classifiers, called SSET.

306, TITLE: Syn2Real Domain Generalization for Underwater Mine-like Object Detection Using Side-Scan Sonar
AUTHORS: AAYUSH AGRAWAL et. al.
CATEGORY: cs.LG [cs.LG, cs.CV, eess.IV]
HIGHLIGHT: This scarcity leads to overfitting, where models perform well on training data but poorly on unseen data. This paper proposes a Syn2Real (Synthetic to Real) domain generalization approach using diffusion models to address this challenge.

307, TITLE: Integrating Large Language Models and Reinforcement Learning for Non-Linear Reasoning
AUTHORS: Yoav Alon ; Cristina David
CATEGORY: cs.LG [cs.LG, cs.PL]
HIGHLIGHT: Large Language Models (LLMs) were shown to struggle with long-term planning, which may be caused by the limited way in which they explore the space of possible solutions. We propose an architecture where a Reinforcement Learning (RL) Agent guides an LLM's space exploration: (1) the Agent has access to domain-specific information, and can therefore make decisions about the quality of candidate solutions based on specific and relevant metrics, which were not explicitly considered by the LLM's training objective; (2) the LLM can focus on generating immediate next steps, without the need for long-term planning.

308, TITLE: Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax
AUTHORS: Rushi Shah ; Mingyuan Yan ; Michael Curtis Mozer ; Dianbo Liu
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we propose a simple yet effective extension to ST-GS by employing decoupled temperatures for forward and backward passes, which we refer to as "Decoupled ST-GS".

309, TITLE: Golyadkin's Torment: Doppelg�ngers and Adversarial Vulnerability
AUTHORS: George I. Kamberov
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.LO]
HIGHLIGHT: We find that AD are inputs that are close to each other with respect to a perceptual metric defined in this paper.

310, TITLE: Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond
AUTHORS: Costin-Andrei Oncescu ; Sanket Purandare ; Stratos Idreos ; Sham Kakade
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Some of them, including long convolution sequence models (LCSMs), such as Hyena, address this issue at training time but remain quadratic during inference. We propose a method for speeding up LCSMs' exact inference to quasilinear $O(L\log^2L)$ time, identify the key properties that make this possible, and propose a general framework that exploits these.

311, TITLE: TabSeq: A Framework for Deep Learning on Tabular Data Via Sequential Ordering
AUTHORS: Al Zadid Sultan Bin Habib ; Kesheng Wang ; Mary-Anne Hartley ; Gianfranco Doretto ; Donald A. Adjeroh
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This work introduces TabSeq, a novel framework for the sequential ordering of features, addressing the vital necessity to optimize the learning process.

312, TITLE: ScFusionTTT: Single-cell Transcriptomics and Proteomics Fusion with Test-Time Training Layers
AUTHORS: DIAN MENG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose scFusionTTT, a novel method for Single-Cell multimodal omics Fusion with TTT-based masked autoencoder.

313, TITLE: PiLocNet: Physics-informed Neural Network on 3D Localization with Rotating Point Spread Function
AUTHORS: Mingda Lu ; Zitian Ao ; Chao Wang ; Sudhakar Prasad ; Raymond H. Chan
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, physics.optics]
HIGHLIGHT: For the 3D localization problem using point spread function (PSF) engineering, we propose a novel enhancement of our previously introduced localization neural network, LocNet.

314, TITLE: Communication-Efficient and Tensorized Federated Fine-Tuning of Large Language Models
AUTHORS: SAJJAD GHIASVAND et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we introduce FedTT and FedTT+, methods for adapting LLMs by integrating tensorized adapters into client-side models' encoder/decoder blocks.

315, TITLE: On Quantum Programming Languages
AUTHORS: Beno�t Valiron
CATEGORY: cs.LO [cs.LO, cs.PL]
HIGHLIGHT: I have had the chance to participate in the development of quantum programming languages since their early developments: the presentation aims to present my point of view on the evolution of the subject, my contributions, and the current research trends in the community.

316, TITLE: Automating IETF Insights Generation with AI
AUTHORS: Jaime Jim�nez
CATEGORY: cs.NI [cs.NI, cs.AI]
HIGHLIGHT: This paper presents the IETF Insights project, an automated system that streamlines the generation of comprehensive reports on the activities of the Internet Engineering Task Force (IETF) Working Groups.

317, TITLE: Selection of Filters for Photonic Crystal Spectrometer Using Domain-Aware Evolutionary Algorithms
AUTHORS: KIRILL ANTONOV et. al.
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: We aim to improve the found top-performing algorithms using our novel distance-driven extensions, that employ metrics on the space of filter selections.

318, TITLE: Configurable Embodied Data Generation for Class-Agnostic RGB-D Video Segmentation
AUTHORS: ANTHONY OPIPARI et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: This paper presents a method for generating large-scale datasets to improve class-agnostic video segmentation across robots with different form factors.

319, TITLE: Risk Assessment for Autonomous Landing in Urban Environments Using Semantic Segmentation
AUTHORS: Jes�s Alejandro Loera-Ponce ; Diego A. Mercado-Ravell ; Israel Becerra-Dur�n ; Luis Manuel Valentin-Coronado
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: In this paper, we address the vision-based autonomous landing problem in complex urban environments using deep neural networks for semantic segmentation and risk assessment.

320, TITLE: Synthesis and Perceptual Scaling of High Resolution Natural Images Using Stable Diffusion
AUTHORS: Leonardo Pettini ; Carsten Bogler ; Christian Doeller ; John-Dylan Haynes
CATEGORY: q-bio.NC [q-bio.NC, cs.CV]
HIGHLIGHT: Here, in contrast, we used a different approach (Stable Diffusion XL) to synthesise a custom stimulus set of photorealistic images that are characterized by gradual transitions where each image is a clearly interpretable but unique exemplar from the same category.

321, TITLE: On The Use of Audio to Improve Dialogue Policies
AUTHORS: Daniel Roncel ; Federico Costa ; Javier Hernando
CATEGORY: eess.AS [eess.AS, cs.CL, cs.SD]
HIGHLIGHT: In this paper, we propose new architectures to add audio information by combining speech and text embeddings using a Double Multi-Head Attention component.

322, TITLE: RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging
AUTHORS: TOBIAS CZEMPIEL et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: This study investigates the reconstruction of hyperspectral signatures from RGB data to enhance surgical imaging, utilizing the publicly available HeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery dataset.

323, TITLE: Scalable Drift Monitoring in Medical Imaging AI
AUTHORS: JAMESON MERKOW et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: This work extends the original framework's methodologies, providing a more scalable and adaptable solution for real-world healthcare settings and offers a reliable and cost-effective alternative to continuous performance monitoring addressing limitations of both continuous and periodic monitoring methods.

324, TITLE: Active Inference and Deep Generative Modeling for Cognitive Ultrasound
AUTHORS: Ruud JG van Sloun
CATEGORY: eess.SP [eess.SP, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we put forth that US imaging systems can be recast as information-seeking agents that engage in reciprocal interactions with their anatomical environment.
