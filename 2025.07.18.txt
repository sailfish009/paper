1, TITLE: AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation
AUTHORS: POTSAWEE MANAKUL et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: This work presents a systematic study of Large Audio Model(LAM) as a Judge, AudioJudge, investigating whether it can provide a unifiedevaluation framework that addresses both challenges.

2, TITLE: Safeguarding Federated Learning-based Road Condition Classification
AUTHORS: Sheng Liu ; Panos Papadimitratos
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: However, TLFAs for FL-based RCC systems are largelymissing. We address this challenge with a threefold contribution: 1) wedisclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introducea novel label-distance-based metric to precisely quantify the safety risksposed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveragingneuron-wise analysis of the output layer to mitigate TLFA effects.

3, TITLE: Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models
AUTHORS: GEN LUO et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: To address thesechallenges, our key idea is to embed a new visual parameter space into apre-trained LLM, enabling stable learning of visual knowledge from noisy datavia delta tuning.

4, TITLE: HairFormer: Transformer-Based Dynamic Neural Hair Simulation
AUTHORS: Joy Xiaoji Zhang ; Jingsen Zhu ; Hanyu Chen ; Steve Marschner
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: We propose a Transformer-powered static network thatpredicts static draped shapes for any hairstyle, effectively resolvinghair-body penetrations and preserving hair fidelity.

5, TITLE: VisionThink: Smart and Efficient Vision Language Model Via Reinforcement Learning
AUTHORS: SENQIAO YANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: While theperformance drops significantly in a small subset of OCR-related tasks, modelsstill perform accurately in most other general VQA tasks with only 1/4resolution. Therefore, we propose to dynamically process distinct samples withdifferent resolutions, and present a new paradigm for visual token compression,namely, VisionThink.

6, TITLE: Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models
AUTHORS: Arian Mousakhan ; Sudhanshu Mittal ; Silvio Galesso ; Karim Farid ; Thomas Brox
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this work, wedevelop a model using simple design choices, and without additional supervisionor sensors, such as maps, depth, or multiple cameras.

7, TITLE: QSpark: Towards Reliable Qiskit Code Generation
AUTHORS: Kiana Kheiri ; Aamna Aamir ; Andriy Miranskyy ; Chen Ding
CATEGORY: cs.SE [cs.SE, cs.AI, quant-ph]
HIGHLIGHT: QSpark: Towards Reliable Qiskit Code Generation

8, TITLE: Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos
AUTHORS: Kaihua Chen ; Tarasha Khurana ; Deva Ramanan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We explore novel-view synthesis for dynamic scenes from monocular videos.Prior approaches rely on costly test-time optimization of 4D representations ordo not preserve scene geometry when trained in a feed-forward manner.

9, TITLE: Probabilistic Soundness Guarantees in LLM Reasoning Chains
AUTHORS: WEIQIU YOU et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Probabilistic Soundness Guarantees in LLM Reasoning Chains

10, TITLE: Learning Robust Negation Text Representations
AUTHORS: Thinh Hung Truong ; Karin Verspoor ; Trevor Cohn ; Timothy Baldwin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a strategy to improvenegation robustness of text encoders, by distilling data from large languagemodels using diverse patterns of negation and hedging.

11, TITLE: GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training
AUTHORS: ADITHYAVAIRAVAN MURALI et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: We introduce a novel and performant on-generator training recipe forthe discriminator.

12, TITLE: The Serial Scaling Hypothesis
AUTHORS: Yuxi Liu ; Konpat Preechakul ; Kananart Kuwaranancharoen ; Yutong Bai
CATEGORY: cs.LG [cs.LG, cs.CC, stat.ML, 68Q15, 68Q10, 68T07, F.1.1; F.1.3; I.2.6]
HIGHLIGHT: We argue that recognizing the serialnature of computation holds profound implications on machine learning, modeldesign, hardware development.

13, TITLE: VLMgineer: Vision Language Models As Robotic Toolsmiths
AUTHORS: GEORGE JIAYUAN GAO et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: Given the vast and impressivecommon-sense, reasoning, and creative capabilities of today's foundationmodels, we investigate whether these models can provide useful priors toautomatically design and effectively wield such tools? We present VLMgineer, aframework that harnesses the code generation abilities of vision languagemodels (VLMs) together with evolutionary search to iteratively co-designphysical tools and the action plans that operate them to perform a task.

14, TITLE: Generative Multi-Target Cross-Domain Recommendation
AUTHORS: JINQIU JIN et. al.
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: Developing more effective solutions for MTCDR remains an important area forfurther exploration.

15, TITLE: Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation
AUTHORS: YANCHEN GUAN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper,we propose an accident anticipation framework employing a dual-brancharchitecture that effectively integrates visual information from dashcam videoswith structured textual data derived from accident reports.

16, TITLE: World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving
AUTHORS: YANCHEN GUAN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, this objective is limited by twofundamental challenges: the scarcity of diverse, high-quality training data andthe frequent absence of crucial object-level cues due to environmentaldisruptions or sensor deficiencies. To tackle these issues, we propose acomprehensive framework combining generative scene augmentation with adaptivetemporal reasoning.

17, TITLE: Voxtral
AUTHORS: ALEXANDER H. LIU et. al.
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: We present Voxtral Mini and Voxtral Small, two multimodal audio chat models.Voxtral is trained to comprehend both spoken audio and text documents,achieving state-of-the-art performance across a diverse range of audiobenchmarks, while preserving strong text capabilities.

18, TITLE: AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning
AUTHORS: YIMING REN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Controllable captioning is essential for precise multimodal alignment andinstruction following, yet existing models often lack fine-grained control andreliable evaluation protocols. To address this gap, we present the AnyCapProject, an integrated solution spanning model, dataset, and evaluation.

19, TITLE: Automating Steering for Safe Multimodal Large Language Models
AUTHORS: LYUCHENG WU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR, cs.LG, cs.MM]
HIGHLIGHT: To improve thesafety of MLLMs during inference, we introduce a modular and adaptiveinference-time intervention technology, AutoSteer, without requiring anyfine-tuning of the underlying model.

20, TITLE: Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility
AUTHORS: MICHAEL A. LEPORI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we identify linear representations thatdiscriminate between modal categories within a variety of LMs, or modaldifference vectors.

21, TITLE: MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models
AUTHORS: ZHIWEI LIU et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: We introduce \oursystemname, an open-source Model ContextProtocol (MCP)-based framework that automates end-to-end task generation anddeep evaluation of LLM agents across diverse domains.

22, TITLE: AutoPartGen: Autogressive 3D Part Generation and Discovery
AUTHORS: MINGHAO CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce AutoPartGen, a model that generates objects composed of 3D partsin an autoregressive manner.

23, TITLE: Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities
AUTHORS: Hao Sun ; Mihaela van der Schaar
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: This paperprovides a comprehensive review of recent advances in LLM alignment through thelens of inverse reinforcement learning (IRL), emphasizing the distinctionsbetween RL techniques employed in LLM alignment and those in conventional RLtasks. In particular, we highlight the necessity of constructing neural rewardmodels from human data and discuss the formal and practical implications ofthis paradigm shift.

24, TITLE: SHIELD: A Secure and Highly Enhanced Integrated Learning for Robust Deepfake Detection Against Adversarial Attacks
AUTHORS: Kutub Uddin ; Awais Khan ; Muhammad Umar Farooq ; Khalid Malik
CATEGORY: cs.SD [cs.SD, cs.AI, cs.CR, cs.LG, eess.AS]
HIGHLIGHT: In thisarticle, we propose a novel collaborative learning method called SHIELD todefend against generative AF attacks.

25, TITLE: Efficient Adaptation of Pre-trained Vision Transformer Underpinned By Approximately Orthogonal Fine-Tuning Strategy
AUTHORS: YITING YANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: These low-rank matrices are commonly derivedthrough the multiplication structure of down-projection and up-projectionmatrices, exemplified by methods such as LoRA and Adapter. In this work, weobserve an approximate orthogonality among any two row or column vectors withinany weight matrix of the backbone parameters; however, this property is absentin the vectors of the down/up-projection matrices.

26, TITLE: Taming Diffusion Transformer for Real-Time Mobile Video Generation
AUTHORS: YUSHU WU et. al.
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: In this work, we propose a series of novel optimizations tosignificantly accelerate video generation and enable real-time performance onmobile platforms.

27, TITLE: Rethinking The Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities
AUTHORS: LIUYI WANG et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CL, cs.CV]
HIGHLIGHT: For the first time, we systematically evaluate severalego-centric VLN methods in physical robotic settings across different technicalpipelines, including classification models for single-step discrete actionprediction, a diffusion model for dense waypoint prediction, and a train-free,map-based large language model (LLM) integrated with path planning.

28, TITLE: Imbalance in Balance: Online Concept Balancing in Generation Models
AUTHORS: YUKAI SHI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we attempt to explore the causal factorsfor poor concept responses through elaborately designed experiments.

29, TITLE: HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation
AUTHORS: WEIHUANG LIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation

30, TITLE: AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research
AUTHORS: YILUN ZHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce AbGen, the first benchmark designed to evaluate the capabilitiesof LLMs in designing ablation studies for scientific research.

31, TITLE: LoViC: Efficient Long Video Generation with Context Compression
AUTHORS: JIAXIU JIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce LoViC, aDiT-based framework trained on million-scale open-domain videos, designed toproduce long, coherent videos through a segment-wise generation process.

32, TITLE: Assessing Adaptive World Models in Machines with Novel Games
AUTHORS: LANCE YING et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: However, current understanding and evaluation of world models inartificial intelligence (AI) remains narrow, often focusing on staticrepresentations learned from training on a massive corpora of data, instead ofthe efficiency and efficacy of models in learning these representations throughinteraction and exploration within a novel environment. In this Perspective, weprovide a view of world model induction drawing on decades of research incognitive science on how humans learn and adapt so efficiently; we then callfor a new evaluation framework for assessing adaptive world models in AI.Concretely, we propose a new benchmarking paradigm based on suites of carefullydesigned games with genuine, deep and continually refreshing novelty in theunderlying game structures -- we refer to this kind of games as novel games.

33, TITLE: FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction
AUTHORS: QIANRU ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Meanwhile, they are susceptible to data noiseissues in time series. This paper proposes a novel framework, FLDmamba (Fourierand Laplace Transform Decomposition Mamba), addressing these limitations.FLDmamba leverages the strengths of both Fourier and Laplace transforms toeffectively capture both multi-scale periodicity, transient dynamics withintime series data, and improve the robustness of the model to the data noiseissue.

34, TITLE: AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation
AUTHORS: HENGKAI TAN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG, cs.RO]
HIGHLIGHT: To address the data collection challenges posed by thisparadigm -- such as low coverage density, behavioral redundancy, and safetyrisks -- we introduce ATARA (Automated Task-Agnostic Random Actions), ascalable self-supervised framework that accelerates collection by over $30\times $ compared to human teleoperation.

35, TITLE: Synergy: End-to-end Concept Model
AUTHORS: Keli Zheng ; Zerong Xie
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: In this paper, we present Synergy, a language model that bridges differentlevels of abstraction in an end-to-end fashion through a learned routingmechanism.

36, TITLE: Camera-based Implicit Mind Reading By Capturing Higher-order Semantic Dynamics of Human Gaze Within Environmental Context
AUTHORS: MENGKE SONG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Emotion recognition,as a step toward mind reading,seeks to infer internalstates from external cues.Most existing methods rely on explicit signals-suchas facial expressions,speech,or gestures-that reflect only bodily responses andoverlook the influence of environmental context.These cues are oftenvoluntary,easy to mask,and insufficient for capturing deeper,implicit emotions.Physiological signal-based approaches offer more direct access to internalstates but require complex sensors that compromise natural behavior and limitscalability.Gaze-based methods typically rely on static fixation analysis andfail to capture the rich,dynamic interactions between gaze and theenvironment,and thus cannot uncover the deep connection between emotion andimplicit behavior.To address these limitations,we propose a novelcamera-based,user-unaware emotion recognition approach that integrates gazefixation patterns with environmental semantics and temporal dynamics.Leveragingstandard HD cameras,our method unobtrusively captures users'eye appearance andhead movements in natural settings-without the need for specialized hardware oractive user participation.From these visual cues,the system estimates gazetrajectories over time and space, providing the basis for modeling the spatial,semantic,and temporal dimensions of gaze behavior.

37, TITLE: Supervised Fine Tuning on Curated Data Is Reinforcement Learning (and Can Be Improved)
AUTHORS: Chongli Qin ; Jost Tobias Springenberg
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Behavior Cloning (BC) on curated (or filtered) data is the predominantparadigm for supervised fine-tuning (SFT) of large language models; as well asfor imitation learning of control policies. Here, we draw on a connectionbetween this successful strategy and the theory and practice of finding optimalpolicies via Reinforcement Learning (RL).

38, TITLE: Leveraging Language Prior for Infrared Small Target Detection
AUTHORS: Pranav Singh ; Pravendra Singh
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a novel multimodal IRSTDframework that incorporates language priors to guide small target detection.

39, TITLE: Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes
AUTHORS: Tyler Loakman ; William Thorne ; Chenghua Lin
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate whether the ability ofLarge Language Models (LLMs) to explain humour depends on the particular humourform.

40, TITLE: Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning
AUTHORS: ZIHUA ZHAO et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, recentadvances on sample selection either mostly rely on an oracle model to offlineselect a high-quality coreset, which is limited in the cold-start scenarios, orfocus on online selection based on real-time model predictions, which has notsufficiently or efficiently considered the noisy correspondence. To addressthis dilemma, we propose a novel Differential-Informed Sample Selection(DISSect) method, which accurately and efficiently discriminates the noisycorrespondence for training acceleration.

41, TITLE: GLAD: Generalizable Tuning for Vision-Language Models
AUTHORS: Yuqi Peng ; Pengfei Wang ; Jianzhuang Liu ; Shifeng Chen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To mitigate thisrisk, we introduce a gradient-based regularization technique.

42, TITLE: Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models
AUTHORS: YUDONG JIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In thispaper, we propose a novel sliding iterative denoising process to enhance thespatio-temporal consistency of the 4D diffusion model.

43, TITLE: The Imitation Game: Turing Machine Imitator Is Length Generalizable Reasoner
AUTHORS: ZHOUQI HUA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: From thisperspective, this paper proposes Turing MAchine Imitation Learning (TAIL) toimprove the length generalization ability of LLMs.

44, TITLE: Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation
AUTHORS: YI XIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Subsequently, we introduce animproved Bidirectional LLaMA architecture by replacing causal attention withbidirectional attention and incorporating 2D RoPE, which together form ouradvanced model, MaskGIL.

45, TITLE: Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models
AUTHORS: YIFAN XU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: 2D multi-view images present visual consistencywith 3D point clouds and provide more detailed representations of scenecomponents, which can naturally compensate for these deficiencies. Based onthese insights, we propose Argus, a novel 3D multimodal framework thatleverages multi-view images for enhanced 3D scene understanding with LLMs.

46, TITLE: Improving Physics-informed Neural Network Extrapolation Via Transfer Learning and Adaptive Activation Functions
AUTHORS: Athanasios Papastathopoulos-Katsaros ; Alexandra Stavrianidi ; Zhandong Liu
CATEGORY: cs.LG [cs.LG, cs.AI, cs.NA, math.DS, math.NA, stat.ML]
HIGHLIGHT: In this paper, weintroduce a transfer learning (TL) method to improve the extrapolationcapability of PINNs.

47, TITLE: FastWDM3D: Fast and Accurate 3D Healthy Tissue Inpainting
AUTHORS: ALICIA DURRER et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In previous editions of the BraTS LocalSynthesis of Healthy Brain Tissue via Inpainting Challenge, denoising diffusionprobabilistic models (DDPMs) demonstrated qualitatively convincing results butsuffered from low sampling speed. To mitigate this limitation, we adapted a 2Dimage generation approach, combining DDPMs with generative adversarial networks(GANs) and employing a variance-preserving noise schedule, for the task of 3Dinpainting.

48, TITLE: Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization
AUTHORS: ZIYI WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, CLIP often struggles to focus ontask-relevant regions across domains, i.e., domain-invariant regions, resultingin suboptimal performance on unseen target domains. To address this challenge,we propose an attention-refocusing scheme, called Simulate, Refocus andEnsemble (SRE), which learns to reduce the domain shift by aligning theattention maps in CLIP via attention refocusing.

49, TITLE: A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models
AUTHORS: Weijieying Ren ; Jingxi Zhu ; Zehao Liu ; Tianxiang Zhao ; Vasant Honavar
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We introduce aunified taxonomy that spans five key design dimensions: data-centricapproaches, neural architecture design, learning-focused strategies, multimodallearning, and LLM-based modeling systems.

50, TITLE: Compact Vision Transformer By Reduction of Kernel Complexity
AUTHORS: Yancheng Wang ; Yingzhen Yang
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce Transformerwith Kernel Complexity Reduction, or KCR-Transformer, a compact transformerblock equipped with differentiable channel selection, guided by a novel andsharp theoretical generalization bound.

51, TITLE: Weakly Supervised Visible-Infrared Person Re-Identification Via Heterogeneous Expert Collaborative Consistency Learning
AUTHORS: Yafei Zhang ; Lingqi Kong ; Huafeng Li ; Jie Wen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To reduce the reliance of visible-infrared person re-identification (ReID)models on labeled cross-modal samples, this paper explores a weakly supervisedcross-modal person ReID method that uses only single-modal sample identitylabels, addressing scenarios where cross-modal identity labels are unavailable.To mitigate the impact of missing cross-modal labels on model performance, wepropose a heterogeneous expert collaborative consistency learning framework,designed to establish robust cross-modal identity correspondences in a weaklysupervised manner.

52, TITLE: DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment
AUTHORS: JUNJIE GAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose DeQA-Doc, a framework that leverages the visual languagecapabilities of MLLMs and a soft label strategy to regress continuous documentquality scores.

53, TITLE: Teach Old SAEs New Domain Tricks with Boosting
AUTHORS: NIKITA KORIAGIN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We propose training asecondary SAE specifically to model the reconstruction error of a pretrainedSAE on domain-specific texts, effectively capturing features missed by theprimary model.

54, TITLE: VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding
AUTHORS: SHIHAO WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose Instructed Temporal Groundingfor Videos (VideoITG), featuring customized frame sampling aligned with userinstructions.

55, TITLE: Vision-and-Language Training Helps Deploy Taxonomic Knowledge But Does Not Fundamentally Alter It
AUTHORS: YULU QIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Most results in the literature haveshown inconsistent or marginal differences, both behaviorally andrepresentationally. In this work, we start from the hypothesis that the domainin which VL training could have a significant effect is lexical-conceptualknowledge, in particular its taxonomic organization.

56, TITLE: Achieving Robust Channel Estimation Neural Networks By Designed Training Data
AUTHORS: Dianxin Luan ; John Thompson
CATEGORY: eess.SP [eess.SP, cs.AI]
HIGHLIGHT: In this paper, we propose design criteria togenerate synthetic training datasets for neural networks, which guarantee thatafter training the resulting networks achieve a certain mean squared error(MSE) on new and previously unseen channels.

57, TITLE: 3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection Via Keypoint-Guided Point Clustering
AUTHORS: ZI WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces a registration-basedanomaly detection framework that combines multi-prototype alignment withcluster-wise discrepancy analysis to enable precise 3D anomaly localization.Specifically, each test sample is first registered to multiple normalprototypes to enable direct structural comparison.

58, TITLE: RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images
AUTHORS: Xiaozheng Jiang ; Wei Zhang ; Xuerui Mao
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Despite numerous efforts devoted, mainstream detectors stillunderperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, amulti-stage feature fusion and enhancement model explicitly tailored for RStiny object detection in various RS scenarios.

59, TITLE: A Survey of Context Engineering for Large Language Models
AUTHORS: LINGRUI MEI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Ultimately,this survey provides a unified framework for both researchers and engineersadvancing context-aware AI.

60, TITLE: Transformer-based Spatial Grounding: A Comprehensive Survey
AUTHORS: Ijazul Haq ; Muhammad Saqib ; Yingjie Zhang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper presents a systematicliterature review of transformer-based spatial grounding approaches from 2018to 2025.

61, TITLE: Logit Arithmetic Elicits Long Reasoning Capabilities Without Training
AUTHORS: YUNXIANG ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To this end, we propose a decoding-time approach, ThinkLogit, whichutilizes logits arithmetic (Liu et al., 2024) to tune a target large LM forlong reasoning using a substantially smaller model as guider.

62, TITLE: Merge Kernel for Bayesian Optimization on Permutation Space
AUTHORS: Zikai Xie ; Linjiang Chen
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Inspired by the closerelationship between the Mallows kernel and pairwise comparison, we propose anovel framework for generating kernel functions on permutation space based onsorting algorithms.

63, TITLE: DASViT: Differentiable Architecture Search for Vision Transformer
AUTHORS: Pengjin Wu ; Ferrante Neri ; Zhenhua Feng
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: DASViT: Differentiable Architecture Search for Vision Transformer

64, TITLE: Ranking Vectors Clustering: Theory and Applications
AUTHORS: Ali Fattahi ; Ali Eshragh ; Babak Aslani ; Meysam Rabiee
CATEGORY: cs.LG [cs.LG, cs.CC, stat.AP, stat.ME]
HIGHLIGHT: We study the problem of clustering ranking vectors, where each vectorrepresents preferences as an ordered list of distinct integers.

65, TITLE: CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling
AUTHORS: TRONG-THANG PHAM et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, CT research in this area has been limited by thelack of publicly available eye-tracking datasets and the three-dimensionalcomplexity of CT volumes. To address these challenges, we present the firstpublicly available eye gaze dataset on CT, called CT-ScanGaze.

66, TITLE: A Semi-Supervised Learning Method for The Identification of Bad Exposures in Large Imaging Surveys
AUTHORS: YUFENG LUO et. al.
CATEGORY: astro-ph.IM [astro-ph.IM, cs.AI]
HIGHLIGHT: We introduce a machine-learning-basedapproach to detect poor-quality exposures in large imaging surveys, with afocus on the DECam Legacy Survey (DECaLS) in regions of low extinction (i.e.,$E(B-V)<0.04$).

67, TITLE: R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning
AUTHORS: XIAOHAN GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose Redundancy-Removal Mixture ofExperts (R^2MoE), a parameter-efficient framework for lifelong visual conceptlearning that effectively learns new concepts while incurring minimal parameteroverhead.

68, TITLE: Benchmarking Deception Probes Via Black-to-White Performance Boosts
AUTHORS: Avi Parrack ; Carlo Leonardo Attubato ; Stefan Heimersheim
CATEGORY: cs.AI [cs.AI, cs.LG, I.2.7; K.4.1]
HIGHLIGHT: However, it's unclear how effective these probes areat detecting deception in practice, nor whether such probes are resistant tosimple counter strategies from a deceptive assistant who wishes to evadedetection. In this paper, we compare white-box monitoring (where the monitorhas access to token-level probe activations) to black-box monitoring (withoutsuch access).

69, TITLE: FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers
AUTHORS: QIANG WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Furthermore, existing approaches lacksupport for multi-character animation, as driving features from differentindividuals frequently interfere with one another, complicating the task. Toaddress these challenges, we propose FantasyPortrait, a diffusion transformerbased framework capable of generating high-fidelity and emotion-rich animationsfor both single- and multi-character scenarios.

70, TITLE: Automatically Assessing Oral Narratives of Afrikaans and IsiXhosa Children
AUTHORS: R. LOUW et. al.
CATEGORY: cs.CL [cs.CL, eess.AS]
HIGHLIGHT: We present a system forautomatically assessing oral narratives of preschool children in Afrikaans andisiXhosa.

71, TITLE: City-VLM: Towards Multidomain Perception Scene Understanding Via Multimodal Incomplete Learning
AUTHORS: PENGLEI SUN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Our method demonstrates pragmatic andgeneralization performance across multiple outdoor scenes.

72, TITLE: SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models
AUTHORS: XIANGYU DONG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.RO]
HIGHLIGHT: To address this,we drew inspiration from the evolution capabilities of natural agents, andproposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with theability to continuously evolve during testing.

73, TITLE: QuestA: Expanding Reasoning Capacity in LLMs Via Question Augmentation
AUTHORS: JIAZHENG LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, 68T50]
HIGHLIGHT: We achieve new state-of-the-art results on mathbenchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)on AIME25, and 35.5% (+4.0%) on HMMT25.

74, TITLE: WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring
AUTHORS: Reza Riahi Samani ; Alfredo Nunez ; Bart De Schutter
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: This paper presents a novel deep learning-based framework for infrastructurehealth monitoring using drive-by vibration response signals.

75, TITLE: Demographic-aware Fine-grained Classification of Pediatric Wrist Fractures
AUTHORS: Ammar Ahmed ; Ali Shariq Imran ; Zenun Kastrati ; Sher Muhammad Daudpota
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this study, we employ a multifaceted approach toaddress the challenge of recognizing wrist pathologies using an extremelylimited dataset.

76, TITLE: DiffOSeg: Omni Medical Image Segmentation Via Multi-Expert Collaboration Diffusion Model
AUTHORS: Han Zhang ; Xiangde Luo ; Yong Chen ; Kang Li
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we propose DiffOSeg, atwo-stage diffusion-based framework, which aims to simultaneously achieve bothconsensus-driven (combining all experts' opinions) and preference-driven(reflecting experts' individual assessments) segmentation.

77, TITLE: Hierarchical Rectified Flow Matching with Mini-Batch Couplings
AUTHORS: Yichi Zhang ; Yici Yan ; Alex Schwing ; Zhizhen Zhao
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we study howto gradually adjust the complexity of the distributions across different levelsof the hierarchy via mini-batch couplings.

78, TITLE: Unleashing Vision Foundation Models for Coronary Artery Segmentation: Parallel ViT-CNN Encoding and Variational Fusion
AUTHORS: CAIXIA DONG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Accurate coronary artery segmentation is critical for computeraided diagnosisof coronary artery disease (CAD), yet it remains challenging due to the smallsize, complex morphology, and low contrast with surrounding tissues. To addressthese challenges, we propose a novel segmentation framework that leverages thepower of vision foundation models (VFMs) through a parallel encodingarchitecture.

79, TITLE: HairShifter: Consistent and High-Fidelity Video Hair Transfer Via Anchor-Guided Animation
AUTHORS: WANGZHENG SHI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose HairShifter, a novel "AnchorFrame + Animation" framework that unifies high-quality image hair transfer withsmooth and coherent video animation.

80, TITLE: FLEXITOKENS: Flexible Tokenization for Evolving Language Models
AUTHORS: Abraham Toluase Owodunni ; Orevaoghene Ahia ; Sachin Kumar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, wedevelop byte-level LMs with learnable tokenizers to make tokenization adaptive.Our models include a submodule that learns to predict boundaries between theinput byte sequence, encoding it into variable-length segments.

81, TITLE: HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models
AUTHORS: Ashray Gupta ; Rohan Joseph ; Sunny Rai
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Analogies test a model's ability to infer implicit relationships betweenconcepts, making them a key benchmark for evaluating reasoning capabilities.While large language models (LLMs) are widely evaluated for reasoning inEnglish, their abilities in Indic languages remain understudied, limiting ourunderstanding of whether these models generalize across languages. To addressthis gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405multiple-choice questions sourced from Indian government exams.

82, TITLE: SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation
AUTHORS: Shiqi Huang ; Shuting He ; Huaiyuan Qin ; Bihan Wen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Whilecurrent OV segmentation models perform well on natural image datasets, theirdirect application to remote sensing faces challenges such as diverselandscapes, seasonal variations, and the presence of small or ambiguous objectsin aerial imagery. To overcome these challenges, we propose $\textbf{SCORE}$($\textbf{S}$cene $\textbf{C}$ontext matters in $\textbf{O}$pen-vocabulary$\textbf{RE}$mote sensing instance segmentation), a framework that integratesmulti-granularity scene context, i.e., regional context and global context, toenhance both visual and textual representations.

83, TITLE: Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning
AUTHORS: SUORONG YANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we introduce a dynamic dataset pruning framework thatadaptively selects training samples based on both task-driven difficulty andcross-modality semantic consistency.

84, TITLE: Enhancing Cross-task Transfer of Large Language Models Via Activation Steering
AUTHORS: XINYU TANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate whether cross-task transfer can beachieved via latent space steering without parameter updates or inputexpansion.

85, TITLE: Feature-Enhanced TResNet for Fine-Grained Food Image Classification
AUTHORS: Lulu Liu ; Zhiyong Xiao
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However,existing Convolutional Neural Networks (CNNs) face significant challenges whendealing with fine-grained food images that are similar in shape but subtle indetail. To address this challenge, this study presents an innovative method forclassifying food images, named Feature-Enhanced TResNet (FE-TResNet),specifically designed to address fine-grained food images and accuratelycapture subtle features within them.

86, TITLE: Leveraging Pre-Trained Visual Models for AI-Generated Video Detection
AUTHORS: Keerthi Veeramachaneni ; Praveen Tirupattur ; Amrit Singh Bedi ; Mubarak Shah
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the field of video generation has advanced beyond DeepFakes,creating an urgent need for methods capable of detecting AI-generated videoswith generic content. To address this gap, we propose a novel approach thatleverages pre-trained visual models to distinguish between real and generatedvideos.

87, TITLE: TransEvalnia: Reasoning-based Evaluation and Ranking of Translations
AUTHORS: Richard Sproat ; Tianyu Zhao ; Llion Jones
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present TransEvalnia, a prompting-based translation evaluation and rankingsystem that uses reasoning in performing its evaluations and ranking.

88, TITLE: DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization
AUTHORS: Dongyeun Lee ; Jiwan Hur ; Hyounguk Shon ; Jae Young Lee ; Junmo Kim
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: However, these approaches often overlook outliers,leading to degraded performance at low bit-widths. In this paper, we propose aDMQ which combines Learned Equivalent Scaling (LES) and channel-wisePower-of-Two Scaling (PTS) to effectively address these challenges.

89, TITLE: Revisiting Reliability in The Reasoning-based Pose Estimation Benchmark
AUTHORS: JUNSU KIM et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The reasoning-based pose estimation (RPE) benchmark has emerged as a widelyadopted evaluation standard for pose-aware multimodal large language models(MLLMs). Despite its significance, we identified critical reproducibility andbenchmark-quality issues that hinder fair and consistent quantitativeevaluations.

90, TITLE: Probabilistic Algorithm for Computing All Local Minimizers of Morse Functions on A Compact Domain
AUTHORS: Mohab Safey El Din ; Georgy Scholten ; Emmanuel Tr�lat
CATEGORY: cs.SC [cs.SC, math.OC]
HIGHLIGHT: In this article, we design an algorithmable to compute all local minimizers of f on K .

91, TITLE: Social and Political Framing in Search Engine Results
AUTHORS: Amrit Poudel ; Tim Weninger
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Social and Political Framing in Search Engine Results

92, TITLE: Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis
AUTHORS: WANG XI et. al.
CATEGORY: cs.CL [cs.CL, 68T50, 68T07, I.2.7; I.2.11; H.5.2]
HIGHLIGHT: Existing methods often produce presentations withlogical inconsistencies and suboptimal layouts, thereby struggling to meetprofessional standards. To address these challenges, we introduce RCPS(Reflective Coherent Presentation Synthesis), a novel framework integratingthree key components: (1) Deep Structured Narrative Planning; (2) AdaptiveLayout Generation; (3) an Iterative Optimization Loop.

93, TITLE: Label-Consistent Dataset Distillation with Detector-Guided Refinement
AUTHORS: Yawen Zou ; Guang Li ; Zi Wang ; Chunzhi Gu ; Chao Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Although diffusion models havemade significant progress in dataset distillation, the generated surrogatedatasets often contain samples with label inconsistencies or insufficientstructural detail, leading to suboptimal downstream performance. To addressthese issues, we propose a detector-guided dataset distillation framework thatexplicitly leverages a pre-trained detector to identify and refine anomaloussynthetic samples, thereby ensuring label consistency and improving imagequality.

94, TITLE: ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion
AUTHORS: HOANG-SON VO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces ATL-Diff, a novelapproach addressing synchronization limitations while reducing noise andcomputational costs.

95, TITLE: Computational-Statistical Tradeoffs from NP-hardness
AUTHORS: Guy Blanc ; Caleb Koch ; Carmen Strassle ; Li-Yang Tan
CATEGORY: cs.CC [cs.CC, cs.DS, cs.LG]
HIGHLIGHT: Theforward implication has been known since (Pitt and Valiant, 1988); we prove thereverse implication.

96, TITLE: Synthesizing Reality: Leveraging The Generative AI-Powered Platform Midjourney for Construction Worker Detection
AUTHORS: Hongyang Zhao ; Tianyu Liang ; Sina Davari ; Daeho Kim
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This study presents anovel image synthesis methodology tailored for construction worker detection,leveraging the generative-AI platform Midjourney.

97, TITLE: FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval
AUTHORS: Jeong-Woo Park ; Young-Eun Kim ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Early fusion tends to excessively focus on explicitly mentioned textualdetails and neglect visual context, whereas late fusion struggles to capturefine-grained semantic alignments between image regions and textual tokens. Toaddress these issues, we propose FAR-Net, a multi-stage fusion frameworkdesigned with enhanced semantic alignment and adaptive reconciliation,integrating two complementary modules.

98, TITLE: MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval
AUTHORS: Jeong-Woo Park ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In contrast, methods based on multimodal large language models(MLLMs) often focus exclusively on applying changes indicated by the text,without fully utilizing the contextual visual information from the referenceimage. To address these issues, we propose multi-faceted Chain-of-Thought withre-ranking (MCoT-RE), a training-free zero-shot CIR framework.

99, TITLE: FIQ: Fundamental Question Generation with The Integration of Question Embeddings for Video Question Answering
AUTHORS: Ju-Young Oh ; Ho-Joong Kim ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose a fundamental questiongeneration with the integration of question embeddings for video questionanswering (FIQ), a novel approach designed to strengthen the reasoning abilityof the model by enhancing the fundamental understanding of videos.

100, TITLE: Local Representative Token Guided Merging for Text-to-Image Generation
AUTHORS: Min-Jeong Lee ; Hee-Dong Kim ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we proposelocal representative token guided merging (ReToM), a novel token mergingstrategy applicable to any attention mechanism in image generation.

101, TITLE: Aligning Humans and Robots Via Reinforcement Learning from Implicit Human Feedback
AUTHORS: Suzie Kim ; Hye-Bin Shin ; Seong-Whan Lee
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: We propose a novel reinforcement learning from implicit human feedback(RLIHF) framework that utilizes non-invasive electroencephalography (EEG)signals, specifically error-related potentials (ErrPs), to provide continuous,implicit feedback without requiring explicit user intervention.

102, TITLE: NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement
AUTHORS: Yang Yang ; Dongni Mao ; Hiroaki Santo ; Yasuyuki Matsushita ; Fumio Okura
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: Whileneural parametric models are actively studied for humans and animals, plantleaves present unique challenges due to their diverse shapes and flexibledeformation. To this problem, we introduce a neural parametric model forleaves, NeuraLeaf.

103, TITLE: BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training
AUTHORS: RUI LI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.DC]
HIGHLIGHT: In this work, we present the first in-depth characterization of LLM trainingstartup overhead based on real production data.

104, TITLE: Emotional Support with LLM-based Empathetic Dialogue Generation
AUTHORS: Shiquan Wang ; Ruiyu Fang ; Zhongjiang He ; Shuangyong Song ; Yongxiang Li
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: This paper presents our solution for the NLPCC 2025 Task 8 ESCevaluation, where we leverage large-scale language models enhanced by promptengineering and finetuning techniques.

105, TITLE: Continuous Marine Tracking Via Autonomous UAV Handoff
AUTHORS: HEEGYEONG KIM et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: We present a seamless UAVhandoff framework, where target transfer is attempted via high-confidencefeature matching, achieving 82.9\% target coverage.

106, TITLE: Unified Medical Image Segmentation with State Space Modeling Snake
AUTHORS: RUICHENG ZHANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We propose Mamba Snake, a novel deep snake framework enhanced by statespace modeling for UMIS.

107, TITLE: Latent Policy Steering with Embodiment-Agnostic Pretrained World Models
AUTHORS: Yiqi Wang ; Mrinal Verghese ; Jeff Schneider
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: However, the performance of these policies is heavilydependent on the number of training demonstrations, which requires expensivedata collection in the real world. In this work, we aim to reduce datacollection efforts when learning visuomotor robot policies by leveragingexisting or cost-effective data from a wide range of embodiments, such aspublic robot datasets and the datasets of humans playing with objects (humandata from play).

108, TITLE: $?^3$: Scalable Permutation-Equivariant Visual Geometry Learning
AUTHORS: YIFAN WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce $\pi^3$, a feed-forward neural network that offers a novelapproach to visual geometry reconstruction, breaking the reliance on aconventional fixed reference view.

109, TITLE: SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery
AUTHORS: Peijun Wang ; Jinhua Zhao
CATEGORY: cs.CV [cs.CV, I.4]
HIGHLIGHT: Small object detection remains a challenging problem in the field of objectdetection. To address this challenge, we propose an enhanced YOLOv8-basedmodel, SOD-YOLO.

110, TITLE: Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?
AUTHORS: Xi Ai ; Mahardika Krisna Ihsani ; Min-Yen Kan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We examine code-mixed coreferential statements conveyedidentical knowledge across languages to study cross-lingual knowledgeconsistency. We use some interpretability approaches to analyze the behavior ofa model in cross-lingual contexts, discovering that multilingual models showdifferent levels of consistency, subject to language families, linguisticfactors, and a bottleneck in cross-lingual consistency on a particular layer.In addition, we evaluate common strategies aimed at improving multilingualperformance to observe whether these strategies can improve knowledgeconsistency at the same time.

111, TITLE: RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction
AUTHORS: Keli Deng ; Jie Nie ; Yuntao Qian
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To thisend, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to anunobservable feature LDM (ULDM) for SR.

112, TITLE: From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation
AUTHORS: MENGXI LIU et. al.
CATEGORY: cs.CV [cs.CV, eess.SP]
HIGHLIGHT: We present NeckSense, a novel wearable system for head pose tracking thatleverages multi-channel bio-impedance sensing with soft, dry electrodesembedded in a lightweight, necklace-style form factor.

113, TITLE: AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis
AUTHORS: S M Rafiuddin ; Sadia Kamal ; Mohammed Rakib ; Arunkumar Bagavathi ; Atriya Sen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce AdaptiSent, a new framework for Multimodal Aspect-BasedSentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanismsto improve sentiment classification and aspect term extraction from both textand images.

114, TITLE: ParaStudent: Generating and Evaluating Realistic Student Code By Teaching LLMs to Struggle
AUTHORS: Mihran Miroyan ; Rose Niousha ; Joseph E. Gonzalez ; Gireeja Ranade ; Narges Norouzi
CATEGORY: cs.CY [cs.CY, cs.AI, cs.SE]
HIGHLIGHT: We present ParaStudent, a systematicstudy of LLM-based "student-like" code generation in an introductoryprogramming course setting.

115, TITLE: MUPAX: Multidimensional Problem Agnostic EXplainable AI
AUTHORS: Vincenzo Dentamaro ; Felice Franchini ; Giuseppe Pirlo ; Irina Voiculescu
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: We propose MULTIDIMENSIONAL PROBLEMAGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainabilitytechnique, with guaranteed convergency.

116, TITLE: Formal Verification for JavaScript Regular Expressions: A Proven Semantics and Its Applications
AUTHORS: Aur�le Barri�re ; Victor Deng ; Cl�ment Pit-Claudel
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: We present the first mechanized, succinct, practical, complete, andproven-faithful semantics for a modern regular expression language withbacktracking semantics.

117, TITLE: Task-Specific Audio Coding for Machines: Machine-Learned Latent Features Are Codes for That Machine
AUTHORS: Anastasia Kuznetsova ; Inseon Jang ; Wootaek Lim ; Minje Kim
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS]
HIGHLIGHT: This work introduces an efficient ACoM method that can compress andquantize any chosen intermediate feature representation of an already trainedspeech/audio downstream model.

118, TITLE: Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications
AUTHORS: YUCHENG TANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a multimodal uncertaintypropagation model (MUPM) based on uncertainty propagation, to characterise therelationship among the uncertainties arising from image-only, text-only, andjoint image-text variations in MLLM inputs.

119, TITLE: Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection
AUTHORS: Jingyao Wang ; Yiming Chen ; Lingyu Si ; Changwen Zheng
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the challenges,this paper proposes a Hierarchical Coresets Selection (HCS) mechanism toadvance the adaptation of VLMs in complex wide-area scene understanding.

120, TITLE: LanePerf: A Performance Estimation Framework for Lane Detection
AUTHORS: Yin Wu ; Daniel Slieter ; Ahmed Abouelazm ; Christian Hubschneider ; J. Marius Z�llner
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paperfirst adapts five well-performing performance estimation methods from imageclassification to lane detection, building a baseline.

121, TITLE: Strategy Adaptation in Large Language Model Werewolf Agents
AUTHORS: Fuya Nakamori ; Yin Jou Huang ; Fei Cheng
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: This study proposes a method to improve the performance of Werewolf agents byswitching between predefined strategies based on the attitudes of other playersand the context of conversations.

122, TITLE: PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database
AUTHORS: HUI SUN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.DB]
HIGHLIGHT: To solve those challenges, wepropose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucialdesigns: 1) We propose an automated multi-knowledge learning-based compressionframework as compressors' backbone to enhance compression ratio and robustness;2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compressionthroughput and computing resource usage; 3) we introduce data blockpartitioning and Step-wise Model Passing (SMP) mechanisms for parallelacceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meetthe complex application scenarios, where the former runs on aresource-constrained single GPU and the latter is multi-GPU accelerated.

123, TITLE: Federated Learning for Commercial Image Sources
AUTHORS: Shreyansh Jain ; Koteswar Rao Jerripothula
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: This paper introduces a new dataset containing23,326 images collected from eight different commercial sources and classifiedinto 31 categories, similar to the Office-31 dataset.

124, TITLE: Large Language Models' Internal Perception of Symbolic Music
AUTHORS: Andrew Shin ; Kunitake Kaneko
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, cs.SD, eess.AS]
HIGHLIGHT: Large language models (LLMs) excel at modeling relationships between stringsin natural language and have shown promise in extending to other symbolicdomains like coding or mathematics.

125, TITLE: $S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation
AUTHORS: Junhong Min ; Youngpil Jeon ; Jimin Kim ; Minyong Choi
CATEGORY: cs.CV [cs.CV, cs.AI, cs.RO]
HIGHLIGHT: This approach enables a more robust joint estimation of disparity,occlusion, and confidence.

126, TITLE: Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models
AUTHORS: Alex Zook ; Josef Spjut ; Jonathan Tremblay
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: Game design hinges on understanding how static rules and content translateinto dynamic player behavior - something modern generative systems that inspectonly a game's code or assets struggle to capture. We present an automateddesign iteration framework that closes this gap by pairing a reinforcementlearning (RL) agent, which playtests the game, with a large multimodal model(LMM), which revises the game based on what the agent does.

127, TITLE: CIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration
AUTHORS: Sidaty El Hadramy ; Oumeymah Cherkaoui ; Philippe C. Cattin
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, fine-tuning regularizationparameters in learning-based DIR frameworks is computationally expensive, oftenrequiring multiple training iterations. To address this, we propose cIDI, anovel DIR framework based on Implicit Neural Representations (INRs) thatconditions the registration process on regularization hyperparameters.

128, TITLE: AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability
AUTHORS: Tomohiro Suzuki ; Ryota Tanaka ; Calvin Yeung ; Keisuke Fujii
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, its practical applicationis hindered by two factors: a lack of realistic sports datasets and unclearreliability for sports tasks. To address these challenges, we introduce theAthleticsPose dataset, a new public dataset featuring ``real'' motions capturedfrom 23 athletes performing various athletics events on an athletic field.Using this dataset, we trained a representative 3D pose estimation model andperformed a comprehensive evaluation.

129, TITLE: MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results
AUTHORS: YUKI KONDO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: Building on the success of the MVA2023 SOD4SBchallenge, this paper introduces the SMOT4SB challenge, which leveragestemporal information to address limitations of single-frame detection.

130, TITLE: Assessing The Reliability of LLMs Annotations in The Context of Demographic Bias and Model Explanation
AUTHORS: HADI MOHAMMADI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study investigates the extent to whichannotator demographic features influence labeling decisions compared to textcontent. Using a Generalized Linear Mixed Model, we quantify this inf luence,finding that while statistically present, demographic factors account for aminor fraction ( 8%) of the observed variance, with tweet content being thedominant factor.

131, TITLE: Making Language Model A Hierarchical Classifier and Generator
AUTHORS: YIHONG WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Motivated by human's hierarchical thinking capability, we proposethat a hierarchical decoder architecture could be built with different layersdecoding texts simultaneously. Due to limited time and computationallyresources, we choose to adapt a pretrained language model into this form ofhierarchical decoder.

132, TITLE: Improving Drug Identification in Overdose Death Surveillance Using Large Language Models
AUTHORS: ARTHUR J. FUNNELL et. al.
CATEGORY: cs.CL [cs.CL, q-bio.QM, I.2.7; J.3]
HIGHLIGHT: Fine-tuned BioClinicalBERT models achieved near-perfectperformance, with macro F1 scores >=0.998 on the internal test set.

133, TITLE: Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition
AUTHORS: Yufei Peng ; Yonggang Zhang ; Yiu-ming Cheung
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Advanced fine-tuning methods typically adjust visualencoders while neglecting the semantics derived from the frozen text encoder,overlooking the visual and textual alignment. To strengthen this alignment, wepropose a novel approach, Semantic-guided fine-tuning of foundation model forlong-tailed visual recognition (Sage), which incorporates semantic guidancederived from textual modality into the visual fine-tuning process.Specifically, we introduce an SG-Adapter that integrates class descriptions assemantic guidance to guide the fine-tuning of the visual encoder.

134, TITLE: HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals
AUTHORS: Guimin Hu ; Daniel Hershcovich ; Hasti Seifi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To facilitate this, weintroduce a multimodal dataset and task, of matching user descriptions tovibration haptic signals, and highlight two primary challenges: (1) lack oflarge haptic vibration datasets annotated with textual descriptions ascollecting haptic descriptions is time-consuming, and (2) limited capability ofexisting tasks and models to describe vibration signals in text. To advancethis area, we create HapticCap, the first fully human-annotatedhaptic-captioned dataset, containing 92,070 haptic-text pairs for userdescriptions of sensory, emotional, and associative attributes of vibrations.Based on HapticCap, we propose the haptic-caption retrieval task and presentthe results of this task from a supervised contrastive learning framework thatbrings together text representations within specific categories and vibrations.Overall, the combination of language model T5 and audio model AST yields thebest performance in the haptic-caption retrieval task, especially whenseparately trained for each description category.

135, TITLE: Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization
AUTHORS: SONGLIN LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In thisstudy, we explore a form of weak supervision that improves the annotationefficiency and detection performance, namely scribble annotation supervision.We re-annotated mainstream IML datasets with scribble labels and propose thefirst scribble-based IML (Sc-IML) dataset.

136, TITLE: InSight: AI Mobile Screening Tool for Multiple Eye Disease Detection Using Multimodal Fusion
AUTHORS: ANANYA RAGHU et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: We develop InSight, anAI-based app that combines patient metadata with fundus images for accuratediagnosis of five common eye diseases to improve accessibility of screenings.

137, TITLE: Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection
AUTHORS: Sandipan Sarma ; Agney Talwarr ; Arijit Sur
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We advocate that HOI-specificcues must be anticipated at the encoder stage itself to obtain a stronger sceneinterpretation. Consequently, we build a top-down framework named Funnel-HOIinspired by the human tendency to grasp well-defined concepts first and thenassociate them with abstract concepts during scene understanding.

138, TITLE: Tensor-Tensor Products, Group Representations, and Semidefinite Programming
AUTHORS: Alex Dunbar ; Elizabeth Newman
CATEGORY: math.OC [math.OC, cs.CV, cs.NA, math.NA, math.RT, 90C22, 15A69, 65F99]
HIGHLIGHT: As applications of the M-SDP framework, we provide acharacterization of certain nonnegative quadratic forms and solve low-ranktensor completion problems.

139, TITLE: DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation
AUTHORS: Ekta Balkrishna Gavas ; Chinmay Hegde ; Nasir Memon ; Sudipta Banerjee
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose DiffClean whicherases makeup traces using a text-guided diffusion model to defend againstmakeup attacks.

140, TITLE: MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration
AUTHORS: SHIRUI ZHAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.AR]
HIGHLIGHT: This paper introduces \textbf{MC$^2$A}, an algorithm-hardwareco-design framework, enabling efficient and flexible optimization for MCMCacceleration.

141, TITLE: The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations
AUTHORS: Carlos Arriaga ; Gonzalo Mart�nez ; Eneko Sendin ; Javier Conde ; Pedro Reviriego
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this paper, we present GEA, the Generative Energy Arena, an arenathat incorporates information on the energy consumption of the model in theevaluation process.

142, TITLE: DINO-VO: A Feature-based Visual Odometry Leveraging A Visual Foundation Model
AUTHORS: Maulana Bisyir Azhari ; David Hyunchul Shim
CATEGORY: cs.CV [cs.CV, cs.AI, cs.RO]
HIGHLIGHT: In this paper, we present DINO-VO, afeature-based VO system leveraging DINOv2 visual foundation model for itssparse feature matching.

143, TITLE: Predicting Soccer Penalty Kick Direction Using Human Action Recognition
AUTHORS: David Freire-Obreg�n ; Oliverio J. Santana ; Javier Lorenzo-Navarro ; Daniel Hern�ndez-Sosa ; Modesto Castrill�n-Santana
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This work presents a noveldataset of manually annotated soccer penalty kicks to predict shot directionbased on pre-kick player movements. We propose a deep learning classifier tobenchmark this dataset that integrates HAR-based feature embeddings withcontextual metadata.

144, TITLE: Imitating Mistakes in A Learning Companion AI Agent for Online Peer Learning
AUTHORS: Sosui Moribe ; Taketoshi Ushiama
CATEGORY: cs.AI [cs.AI, cs.MA]
HIGHLIGHT: In this study, we assume that a learner's peers with the sameproficiency level as the learner make the same mistakes as the learner does andfocus on English composition as a specific example to validate this approach.

145, TITLE: A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs
AUTHORS: L�o Sauli�res
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: This paper focuses on asub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aimsto explain the actions of an agent that has learned by reinforcement learning.We propose an intuitive taxonomy based on two questions "What" and "How".

146, TITLE: FormulaOne: Measuring The Depth of Algorithmic Reasoning Beyond Competitive Programming
AUTHORS: GAL BENIAMINI et. al.
CATEGORY: cs.AI [cs.AI, cs.CC, math.LO]
HIGHLIGHT: To illuminate the limits of frontier model capabilities, we turnaway from contrived competitive programming puzzles, and instead focus onreal-life research problems.

147, TITLE: Feature-based Analysis of Oral Narratives from Afrikaans and IsiXhosa Children
AUTHORS: EMMA SHARRATT et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Using simple machine learningmethods, we analyse recorded stories from four- and five-year-old Afrikaans-and isiXhosa-speaking children.

148, TITLE: Overview of The TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management
AUTHORS: LUIS GASCO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: However, the adoption andprogress of these technologies critically depend on the development of reliableand fair models, properly evaluated on public data and open benchmarks, whichhave so far been unavailable in this domain. To address this gap, we present TalentCLEF 2025, the first evaluationcampaign focused on skill and job title intelligence.

149, TITLE: GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems
AUTHORS: Jisoo Lee ; Raeyoung Chang ; Dongwook Kwon ; Harmanpreet Singh ; Nikhil Verma
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce GEMMAS, a graph-based evaluation framework that analyzesthe internal collaboration process by modeling agent interactions as a directedacyclic graph.

150, TITLE: The First Open Machine Translation System for The Chechen Language
AUTHORS: Abu-Viskhan A. Umishov ; Vladislav A. Grigorian
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce the first open-source model for translation between thevulnerable Chechen language and Russian, and the dataset collected to train andevaluate it.

151, TITLE: A Computational Framework to Identify Self-Aspects in Text
AUTHORS: Jaya Caporusso ; Matthew Purver ; Senja Pollak
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This Ph.D. proposal introduces a plan to develop a computational framework toidentify Self-aspects in text.

152, TITLE: SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts
AUTHORS: Marc Brinner ; Sina Zarriess
CATEGORY: cs.CL [cs.CL, cs.IR, cs.LG]
HIGHLIGHT: We introduce SemCSE, an unsupervised method for learning semantic embeddingsof scientific texts.

153, TITLE: Formalizing Attack Scenario Description: A Proposed Model
AUTHORS: Quentin Goux ; Nadira Lammari
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Among these processes, onecan mention both the generation of scripts for attack simulation and trainingpurposes, as well as the analysis of attacks. Therefore, the paper's mainresearch contribution is a novel formal model that encompasses the attack'scontext description and its scenario.

154, TITLE: Modeling Open-World Cognition As On-Demand Synthesis of Probabilistic Models
AUTHORS: LIONEL WONG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.PL]
HIGHLIGHT: Here, we explore the hypothesis thatpeople use a combination of distributed and symbolic representations toconstruct bespoke mental models tailored to novel situations. We propose acomputational implementation of this idea -- a ``Model Synthesis Architecture''(MSA) -- using language models to implement global relevance-based retrievaland model synthesis and probabilistic programs to implement bespoke, coherentworld models.

155, TITLE: MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps
AUTHORS: Maximiliano Hormaz�bal Lagos ; �lvaro Bueno S�ez ; H�ctor Cerezo-Costas ; Pedro Alonso Doval ; Jorge Alcalde Vesteiro
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntasy Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables inSpanish).

156, TITLE: Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection
AUTHORS: Riku Inoue ; Masamitsu Tsuchiya ; Yuji Yasui
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, this method facesissues with learning conflicts between objectness and class predictions. To address this issue and further enhance performance, we propose a novelmodel, Decoupled PROB.

157, TITLE: Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows
AUTHORS: JUDY LONG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This study presents thefirst comprehensive review of large-scale, pixel-wise crop mapping workflows,encompassing both conventional supervised methods and emerging transferlearning approaches.

158, TITLE: VITA: Vision-to-Action Flow Matching Policy
AUTHORS: DECHEN GAO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.RO]
HIGHLIGHT: We present VITA, a Vision-To-Action flow matching policy that evolves latentvisual representations into latent actions for visuomotor control.

159, TITLE: A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image
AUTHORS: HIEU TANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, selecting anappropriate deep learning architecture to optimize performance while avoidingoverfitting remains a critical challenge. To address these issues, we propose adeep-learning based framework for landslide detection from remote sensing imagein this paper.

160, TITLE: SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning
AUTHORS: KHANG TRUONG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In the context of remote sensing,image captioning plays a significant role in interpreting vast and complexsatellite imagery, aiding applications such as environmental monitoring,disaster assessment, and urban planning. This motivates us, in this paper, topresent a transformer based network architecture for remote sensing imagecaptioning (RSIC) in which multiple techniques of Static Expansion,Memory-Augmented Self-Attention, Mesh Transformer are evaluated and integrated.We evaluate our proposed models using two benchmark remote sensing imagedatasets of UCM-Caption and NWPU-Caption.

161, TITLE: MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification
AUTHORS: Said Ohamouddou ; Abdellatif El Afia ; Hanaa El Afia ; Raddouane Chiheb
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We present MS-DGCNN++, a hierarchical multiscale fusiondynamic graph convolutional network that uses semantically meaningful featureextraction at local, branch, and canopy scales with cross-scale informationpropagation.

162, TITLE: WhoFi: Deep Person Re-Identification Via Wi-Fi Channel Signal Encoding
AUTHORS: Danilo Avola ; Daniele Pannone ; Dario Montagnini ; Emad Emam
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: To address thesechallenges, we introduce WhoFi, a novel pipeline that utilizes Wi-Fi signalsfor person re-identification.

163, TITLE: FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation Via Kolmogorov-Arnold Enhanced Spatial Attention Networks
AUTHORS: CHRISTINA THRAINER et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, eess.IV]
HIGHLIGHT: This paper presents FORTRESS(Function-composition Optimized Real-Time Resilient Structural Segmentation), anew architecture that balances accuracy and speed by using a special methodthat combines depthwise separable convolutions with adaptive Kolmogorov-ArnoldNetwork integration.

164, TITLE: FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization
AUTHORS: Chuancheng Shi ; Yixiang Chen ; Burong Lei ; Jichao Chen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization

165, TITLE: A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains
AUTHORS: ANTONIO FINOCCHIARO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose an efficientapproach for detecting hand-objects interactions from streaming egocentricvision that operates in real time.

166, TITLE: Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction
AUTHORS: ZHENNAN XIAO et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we present an automated lung maturityevaluation pipeline for diffusion-weighted magnetic resonance images thatconsists of a deep learning-based fetal lung segmentation model and amodel-fitting lung maturity assessment.

167, TITLE: Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in A Healthy Cohort
AUTHORS: Ernesto Elias Vidal Rosas ; Imran Razzak ; Shoaib Jameel
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, an innovative imaging omicsframework was introduced, combining retinal microvascular traits derivedthrough deep learning based image processing with serum lipidomic data tohighlight asymptomatic biomarkers of cardiovascular risk beyond theconventional lipid panel.

168, TITLE: Channel-wise Motion Features for Efficient Motion Segmentation
AUTHORS: Riku Inoue ; Masamitsu Tsuchiya ; Yuji Yasui
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel cost-volume-based motion featurerepresentation, Channel-wise Motion Features.

169, TITLE: Variance-Based Pruning for Accelerating and Compressing Trained Networks
AUTHORS: Uranik Berisha ; Jens Mehnert ; Alexandru Paul Condurache
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: On ImageNet-1k recognition tasks, wedemonstrate that directly after pruning DeiT-Base retains over 70% of itsoriginal performance and requires only 10 epochs of fine-tuning to regain 99%of the original accuracy while simultaneously reducing MACs by 35% and modelsize by 36%, thus speeding up the model by 1.44x.

170, TITLE: A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique
AUTHORS: Homare Sueyoshi ; Kiyoshi Nishikawa ; Hitoshi Kiya
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: We propose a privacy-preserving semantic-segmentation method for applyingperceptual encryption to images used for model training in addition to testimages.

171, TITLE: Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation
AUTHORS: HANLEI SHI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation

172, TITLE: Prompt Injection 2.0: Hybrid AI Threats
AUTHORS: Jeremy McHugh ; Kristina ?ekrst ; Jon Cefalu
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Modern prompt injection attacks can nowcombine with traditional cybersecurity exploits to create hybrid threats thatsystematically evade traditional security controls. This paper presents acomprehensive analysis of Prompt Injection 2.0, examining how prompt injectionsintegrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),and other web security vulnerabilities to bypass traditional security measures.We build upon Preamble's foundational research and mitigation technologies,evaluating them against contemporary threats, including AI worms, multi-agentinfections, and hybrid cyber-AI attacks.

173, TITLE: An Ultra-low-power CGRA for Accelerating Transformers at The Edge
AUTHORS: Rohit Prasad
CATEGORY: cs.AR [cs.AR, cs.AI]
HIGHLIGHT: Aswitchless mesh torus interconnect network further minimizes power and latencyby enabling direct communication between PEs and MOBs, eliminating the need forcentralized switching.

174, TITLE: Autonomy for Older Adult-Agent Interaction
AUTHORS: Jiaxin An
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: Autonomy for Older Adult-Agent Interaction

175, TITLE: Assay2Mol: Large Language Model-based Drug Design Using BioAssay Context
AUTHORS: Yifan Deng ; Spencer S. Ericksen ; Anthony Gitter
CATEGORY: cs.LG [cs.LG, cs.AI, q-bio.QM]
HIGHLIGHT: We present Assay2Mol, a largelanguage model-based workflow that can capitalize on the vast existingbiochemical screening assays for early-stage drug discovery.

176, TITLE: SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs
AUTHORS: KOSSI AMOUZOUVI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a framework that evaluates howwell each relation fits with different geometric transformations.

177, TITLE: Data Transformation Strategies to Remove Heterogeneity
AUTHORS: SANGBONG YOO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This survey explores the intricacies of data heterogeneity and itsunderlying sources.

178, TITLE: Learning What Matters: Probabilistic Task Selection Via Mutual Information for Model Finetuning
AUTHORS: PRATEEK CHANDA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, 68T50, I.2.7; I.2.6; I.2.4]
HIGHLIGHT: We provide theoreticalguarantees, including weak submodularity for budgeted variants, and demonstrateconsistent empirical improvements on Llama 2 and Mistral across evaluationsuites such as MMLU and BIGBench.

179, TITLE: Topology-Aware Activation Functions in Neural Networks
AUTHORS: Pavel Snopov ; Oleg R. Musin
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: This study explores novel activation functions that enhance the ability ofneural networks to manipulate data topology during training.

180, TITLE: Can Mental Imagery Improve The Thinking Capabilities of AI Systems?
AUTHORS: Slimane Larabi
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we investigate howto integrate mental imagery into a machine thinking framework and how thiscould be beneficial in initiating the thinking process.

181, TITLE: A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments Under Data Sharing Constraints
AUTHORS: Youssef Tawfilis ; Hossam Amer ; Minar El-Aasser ; Tallal Elshabrawy
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Moreover, obtaining large datasets is challenging dueto privacy concerns and copyright restrictions, as most devices are unwillingto share their data. To address these challenges, we propose a novel approachfor decentralized GAN training that enables the utilization of distributed dataand underutilized, low-capability devices while not sharing data in its rawform.

182, TITLE: Adversarial Attacks to Image Classification Systems Using Evolutionary Algorithms
AUTHORS: Sergio Nesmachnow ; Jamal Toutouh
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: The proposed approach explores the latent space of a generativeadversarial network with an evolutionary algorithm to find vectors representingadversarial attacks.

183, TITLE: Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms
AUTHORS: Walter P. Casas ; Jamal Toutouh
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: This paper presents an empirical analysis of different coevolutionaryGAN training strategies, focusing on the impact of selection and replacementmechanisms.

184, TITLE: Dual-Numbers Reverse AD for Functional Array Languages
AUTHORS: Tom Smeding ; Miko?aj Konarski ; Simon Peyton Jones ; Andrew Fitzgibbon
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: In this paper we introducefirst-class support for multidimensional arrays in dual-numbers reverse-mode ADwith little to no performance overhead.

185, TITLE: Towards Formal Verification of LLM-Generated Code from Natural Language Prompts
AUTHORS: AARON COUNCILMAN et. al.
CATEGORY: cs.PL [cs.PL, cs.AI]
HIGHLIGHT: However,LLMs often generate incorrect code that users need to fix and the literaturesuggests users often struggle to detect these errors. In this work we seek tooffer formal guarantees of correctness to LLM generated code; such guaranteescould improve the experience of using AI Code Assistants and potentially enablenatural language programming for users with little or no programming knowledge.To address this challenge we propose to incorporate a formal query languagethat can represent a user's intent in a formally defined but naturallanguage-like manner that a user can confirm matches their intent.

186, TITLE: Enter The Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering
AUTHORS: MUHAMMAD FADHIL GINTING et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Unlike traditional EQA settings, which typicallyfocus either on understanding the present environment alone or on recalling asingle past observation, LA-EQA challenges an agent to reason over past,present, and possible future states, deciding when to explore, when to consultits memory, and when to stop gathering observations and provide a final answer.Standard EQA approaches based on large models struggle in this setting due tolimited context windows, absence of persistent memory, and an inability tocombine memory recall with active exploration. To address this, we propose astructured memory system for robots, inspired by the mind palace method fromcognitive science.

187, TITLE: Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired By Guide Dog Behaviour
AUTHORS: Emma M. A. Harrison
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: This research explores the effectiveness of three reinforcementlearning algorithms in training a simulated quadruped robot for autonomousnavigation and obstacle avoidance.

188, TITLE: Single Conversation Methodology: A Human-Centered Protocol for AI-Assisted Software Development
AUTHORS: Salvador D. Escobedo
CATEGORY: cs.SE [cs.SE, cs.AI, cs.HC]
HIGHLIGHT: We propose the Single Conversation Methodology (SCM), a novel and pragmaticapproach to software development using large language models (LLMs).

189, TITLE: A Fuzzy Approach to Project Success: Measuring What Matters
AUTHORS: Jo�o Granja-Correia ; Remedios Hern�ndez-Linares ; Luca Ferranti ; Arm�nio Rego
CATEGORY: cs.SE [cs.SE, cs.CL, H.4.m]
HIGHLIGHT: This paper introduces a novel approach to project success evaluation byintegrating fuzzy logic into an existing construct.

190, TITLE: Cognitive Modelling Aspects of Neurodevelopmental Disorders Using Standard and Oscillating Neighbourhood SOM Neural Networks
AUTHORS: Spyridon Revithis ; Nadine Marcus
CATEGORY: q-bio.NC [q-bio.NC, cs.NE, I.2.6; I.2.0; J.3]
HIGHLIGHT: Background/Introduction: In this paper, the neural network class ofSelf-Organising Maps (SOMs) is investigated in terms of its theoretical andapplied validity for cognitive modelling, particularly of neurodevelopmentaldisorders.

191, TITLE: UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets
AUTHORS: Zhichao Sheng ; Shilin Zhou ; Chen Gong ; Zhenghua Li
CATEGORY: eess.AS [eess.AS, cs.AI, cs.CL, cs.MM, cs.SD]
HIGHLIGHT: Specifically, we propose a unified representation fordiverse SLU tasks, enabling full utilization of heterogeneous datasets acrossmultiple tasks.

192, TITLE: Pathology-Guided Virtual Staining Metric for Evaluation and Training
AUTHORS: Qiankai Wang ; James E. D. Tweel ; Parsin Haji Reza ; Anita Layton
CATEGORY: eess.IV [eess.IV, cs.CV, cs.SY, eess.SY]
HIGHLIGHT: In this study, we introduce PaPIS (Pathology-Aware Perceptual ImageSimilarity), a novel FR-IQA metric specifically tailored for virtual stainingevaluation.

193, TITLE: TRIQA: Image Quality Assessment By Contrastive Pretraining on Ordered Distortion Triplets
AUTHORS: Rajesh Sureddi ; Saman Zadtootaghaj ; Nabajeet Barman ; Alan C. Bovik
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Image Quality Assessment (IQA) models aim to predict perceptual image qualityin alignment with human judgments.

194, TITLE: Pixel Perfect MegaMed: A Megapixel-Scale Vision-Language Foundation Model for Generating High Resolution Medical Images
AUTHORS: Zahra TehraniNasab ; Amar Kumar ; Tal Arbel
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: By leveraging vision-language alignmenttechniques tailored to medical terminology and imaging modalities, PixelPerfect MegaMed bridges the gap between textual descriptions and visualrepresentations at unprecedented resolution levels. We apply our model to theCheXpert dataset and demonstrate its ability to generate clinically faithfulchest X-rays from text prompts.

195, TITLE: SpectraLift: Physics-Guided Spectral-Inversion Network for Self-Supervised Hyperspectral Image Super-Resolution
AUTHORS: Ritik Shah ; Marco F. Duarte
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We present SpectraLift, a fullyself-supervised framework that fuses LR-HSI and HR-MSI inputs using only theMSI's Spectral Response Function (SRF).

196, TITLE: Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: An Application on The DermaMNIST Dataset
AUTHORS: Nerma Kadric ; Amila Akagic ; Medina Kapo
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: Improving Diagnostic Accuracy of Pigmented Skin Lesions With CNNs: An Application on The DermaMNIST Dataset

197, TITLE: From Variability To Accuracy: Conditional Bernoulli Diffusion Models with Consensus-Driven Correction for Thin Structure Segmentation
AUTHORS: Jinseo An ; Min Jin Lee ; Kyu Won Shim ; Helen Hong
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We propose a novel frameworkthat corrects segmentation results by leveraging consensus from multiplediffusion model outputs.
