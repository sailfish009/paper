1, TITLE: RLAD: Training LLMs to Discover Abstractions for Solving Reasoning Problems
AUTHORS: Yuxiao Qu; Anikait Singh; Yoonho Lee; Amrith Setlur; Ruslan Salakhutdinov; Chelsea Finn; Aviral Kumar
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : To address more effective reasoning, weintroduce reasoning abstractions: concise natural language descriptions ofprocedural and factual knowledge that guide the model toward learningsuccessful reasoning. We train models to be capable of proposing multipleabstractions given a problem, followed by RL that incentivizes building asolution while using the information provided by these abstractions.

2, TITLE: Interactive Training: Feedback-Driven Neural Network Optimization
AUTHORS: Wentao Zhang; Yang Young Lu; Yuntian Deng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this paper, we introduceInteractive Training, an open-source framework that enables real-time,feedback-driven intervention during neural network training by human experts orautomated AI agents.

3, TITLE: Information Seeking for Robust Decision Making Under Partial Observability
AUTHORS: Djengo Cyun-Jyun Fang; Tsung-Wei Ke
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : To evaluate InfoSeeker, we introduce a novel benchmarksuite featuring partially observable environments with incomplete observationsand uncertain dynamics.

4, TITLE: Multiplier-free In-Memory Vector-Matrix Multiplication Using Distributed Arithmetic
AUTHORS: Felix Zeller; John Reuben; Dietmar Fey
CATEGORY: arxiv-cs.AR [AR]
HIGHLIGHT: Highlight : In this work, we extend the DA technique to multiply aninput vector with a constant matrix.

5, TITLE: WAInjectBench: Benchmarking Prompt Injection Detections for Web Agents
AUTHORS: Yinuo Liu; Ruohan Xu; Xilong Wang; Yuqi Jia; Neil Zhenqiang Gong
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Highlight : Multiple prompt injection attacks have been proposed against web agents. Atthe same time, various methods have been developed to detect general promptinjection attacks, but none have been systematically evaluated for web agents.In this work, we bridge this gap by presenting the first comprehensivebenchmark study on detecting prompt injection attacks targeting web agents.

6, TITLE: Learning A Dense Reasoning Reward Model from Expert Demonstration Via Inverse Reinforcement Learning
AUTHORS: Claudio Fanconi; Nicolás Astorga; Mihaela van der Schaar
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Byunifying training signals, inference-time selection, and token-leveldiagnostics into a single reasoning reward, this work suggests reusableprocess-level rewards with broad potential to enhance multi-step reasoning inlanguage models.

7, TITLE: Detection of Chagas Disease from The ECG: The George B. Moody PhysioNet Challenge 2025
AUTHORS: Matthew A. Reyna; Zuzana Koscova; Jan Pavlus; Soheil Saghafi; James Weigle; Andoni Elola; Salman Seyedi; Kiersten Campbell; Qiao Li; Ali Bahrami Rad; Antônio H. Ribeiro; Antonio Luiz P. Ribeiro; Reza Sameni; Gari D. Clifford
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Significance: Over 630participants from 111 teams submitted over 1300 entries during the Challenge,representing diverse approaches from academia and industry worldwide.

8, TITLE: Test-Time Anchoring for Discrete Diffusion Posterior Sampling
AUTHORS: Litu Rout; Andreas Lugmayr; Yasamin Jafarian; Srivatsan Varadharajan; Constantine Caramanis; Sanjay Shakkottai; Ira Kemelmacher-Shlizerman
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : To overcome theselimitations, we introduce Anchored Posterior Sampling (APS) for maskeddiffusion foundation models, built on two key innovations -- quantizedexpectation for gradient-like guidance in discrete embedding space, andanchored remasking for adaptive decoding.

9, TITLE: UniVerse: Unleashing The Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction
AUTHORS: Jin Cao; Hongrui Wu; Ziyong Feng; Hujun Bao; Xiaowei Zhou; Sida Peng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : To thisend, we introduce UniVerse, a unified framework for robust reconstruction basedon a video diffusion model.

10, TITLE: Addressing Pitfalls in The Evaluation of Uncertainty Estimation Methods for Natural Language Generation
AUTHORS: Mykyta Ielanskyi; Kajetan Schweighofer; Lukas Aichberger; Sepp Hochreiter
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : For QA tasks, we show that marginalizing over multiple LLM-as-a-judgevariants leads to reducing the evaluation biases.

11, TITLE: Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of Scaling Laws, Benefits, and Pitfalls
AUTHORS: Feiyang Kang; Newsha Ardalani; Michael Kuchnik; Youssef Emad; Mostafa Elhoushi; Shubhabrata Sengupta; Shang-Wen Li; Ramya Raghavendra; Ruoxi Jia; Carole-Jean Wu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Training data plays a crucial role in Large Language Models (LLM) scaling,yet high quality data is of limited supply. Synthetic data techniques offer apotential path toward sidestepping these limitations.

12, TITLE: VideoNSA: Native Sparse Attention Scales Video Understanding
AUTHORS: Enxin Song; Wenhao Chai; Shusheng Yang; Ethan Armand; Xiaojun Shan; Haiyang Xu; Jianwen Xie; Zhuowen Tu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Video understanding in multimodal language models remains limited by contextlength: models often miss key transition frames and struggle to maintaincoherence across long time scales. To address this, we adapt Native SparseAttention (NSA) to video-language models.

13, TITLE: Self-Forcing++: Towards Minute-Scale High-Quality Video Generation
AUTHORS: Justin Cui; Jie Wu; Ming Li; Tao Yang; Xiaojie Li; Rui Wang; Andrew Bai; Yuanhao Ban; Cho-Jui Hsieh
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this paper, wepropose a simple yet effective approach to mitigate quality degradation inlong-horizon video generation without requiring supervision from long-videoteachers or retraining on long video datasets.

14, TITLE: BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic Bioinformatics
AUTHORS: Florensia Widjaja; Zhangtianyi Chen; Juexiao Zhou
CATEGORY: arxiv-q-bio.QM [QM]
HIGHLIGHT: Highlight : We present a platform of 38 MCP-converted bioinformatics tools,extensively validated to show that 94.7% successfully executed complexworkflows across three widely used AI-agent platforms.

15, TITLE: Towards Better Optimization For Listwise Preference in Diffusion Models
AUTHORS: Jiamu Bai; Xin Yu; Meilong Xu; Weitao Lu; Xin Pan; Kiwan Maeng; Daniel Kifer; Jian Wang; Yu Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, we propose Diffusion-LPO, a simple and effectiveframework for Listwise Preference Optimization in diffusion models withlistwise data.

16, TITLE: MDSEval: A Meta-Evaluation Benchmark for Multimodal Dialogue Summarization
AUTHORS: Yinhong Liu; Jianfeng He; Hang Su; Ruixue Lian; Yi Nian; Jake Vincent; Srikanth Vishnubhotla; Robinson Piramuthu; Saab Mansour
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we introduce MDSEval, the firstmeta-evaluation benchmark for MDS, consisting image-sharing dialogues,corresponding summaries, and human judgments across eight well-defined qualityaspects.

17, TITLE: The Unreasonable Effectiveness of Scaling Agents for Computer Use
AUTHORS: Gonzalo Gonzalez-Pumariega; Vincent Tu; Chih-Lun Lee; Jiachen Yang; Ang Li; Xin Eric Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce Behavior Best-of-N (bBoN), a methodthat scales over agents by generating multiple rollouts and selecting amongthem using behavior narratives that describe the agents' rollouts.

18, TITLE: VOGUE: Guiding Exploration with Visual Uncertainty Improves Multimodal Reasoning
AUTHORS: Rui Liu; Dian Yu; Tong Zheng; Runpeng Dai; Zongxia Li; Wenhao Yu; Zhenwen Liang; Linfeng Song; Haitao Mi; Pratap Tokekar; Dong Yu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce $\textbf{VOGUE (Visual Uncertainty GuidedExploration)}$, a novel method that shifts exploration from the output (text)to the input (visual) space.

19, TITLE: CLUE: Non-parametric Verification from Experience Via Hidden-State Clustering
AUTHORS: Zhenwen Liang; Ruosen Li; Yujun Zhou; Linfeng Song; Dian Yu; Xinya Du; Haitao Mi; Dong Yu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: Assessing the quality of Large Language Model (LLM) outputs presents acritical challenge. Previous methods either rely on text-level information(e.g., reward models, majority ...

20, TITLE: Unsupervised Dynamic Feature Selection for Robust Latent Spaces in Vision Tasks
AUTHORS: Bruno Corcuera; Carlos Eiras-Franco; Brais Cancela
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : This paper presents anovel approach for enhancing latent representations using unsupervised DynamicFeature Selection (DFS).

21, TITLE: Veri-R1: Toward Precise and Faithful Claim Verification Via Online Reinforcement Learning
AUTHORS: Qi He; Cheng Qian; Xiusi Chen; Bingxiang He; Yi R. Fung; Heng Ji
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : However,existing approaches to online claim verification, which requires iterativeevidence retrieval and reasoning, still mainly rely on prompt engineering orpre-designed reasoning workflows, without unified training to improve necessaryskills. Therefore, we introduce Veri-R1, an online reinforcement learning (RL)framework that enables an LLM to interact with a search engine and to receivereward signals that explicitly shape its planning, retrieval, and reasoningbehaviors.

22, TITLE: StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?
AUTHORS: Yanxu Chen; Zijun Yao; Yantao Liu; Jin Ye; Jianing Yu; Lei Hou; Juanzi Li
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: Large language models (LLMs) have recently demonstrated strong capabilitiesas autonomous agents, showing promise in reasoning, tool use, and sequentialdecision-making. While prior ...

23, TITLE: VidGuard-R1: AI-Generated Video Detection and Explanation Via Reasoning MLLMs and RL
AUTHORS: Kyoungjun Park; Yifan Yang; Juheon Yi; Shicheng Zheng; Yifei Shen; Dongqi Han; Caihua Shan; Muhammad Muaz; Lili Qiu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: With the rapid advancement of AI-generated videos, there is an urgent needfor effective detection tools to mitigate societal risks such as misinformationand reputational harm. In ...

24, TITLE: Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness
AUTHORS: Erfan Shayegani; Keegan Hines; Yue Dong; Nael Abu-Ghazaleh; Roman Lutz; Spencer Whitehead; Vidhisha Balachandran; Besmira Nushi; Vibhav Vineet
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : In this paper, we show that CUAsconsistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goalsregardless of feasibility, safety, reliability, or context.

25, TITLE: NLD-LLM: A Systematic Framework for Evaluating Small Language Transformer Models on Natural Language Description
AUTHORS: Hamed Jelodar; Mohammad Meymani; Parisa Hamedi; Tochukwu Emmanuel Nwankwo; Samita Bai; Roozbeh Razavi-Far; Ali A. Ghorbani
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we propose NLD-LLM, a systematic NLPframework to evaluate the performance of language models to generate accurateand concise source code descriptions.

26, TITLE: Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed
AUTHORS: Isha Gupta; Rylan Schaeffer; Joshua Kazdan; Ken Ziyu Liu; Sanmi Koyejo
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : However, apair of recent studies reported being unable to successfully transfer imagejailbreaks between vision-language models (VLMs). To explain this strikingdifference, we propose a fundamental distinction regarding the transferabilityof attacks against machine learning models: attacks in the input data-space cantransfer, whereas attacks in model representation space do not, at least notwithout geometric alignment of representations.

27, TITLE: MultiModal Action Conditioned Video Generation
AUTHORS: Yichen Li; Antonio Torralba
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Current video models fail as world model as they lack fine-graiend control.General-purpose household robots require real-time fine motor control to handledelicate tasks and urgent situations. In this work, we introduce fine-grainedmultimodal actions to capture such precise control.

28, TITLE: FreeViS: Training-free Video Stylization with Inconsistent References
AUTHORS: Jiacong Xu; Yiqun Mei; Ke Zhang; Vishal M. Patel
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this paper, we propose FreeViS, a training-freevideo stylization framework that generates stylized videos with rich styledetails and strong temporal coherence.

29, TITLE: INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models
AUTHORS: Ulas Berk Karli; Ziyao Shangguan; Tesca FItzgerald
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : We present \textbf{INSIGHT}, alearning framework for leveraging token-level uncertainty signals to predictwhen a VLA should request help.

30, TITLE: Every Step Counts: Decoding Trajectories As Authorship Fingerprints of DLLMs
AUTHORS: Qi Li; Runpeng Yu; Haiquan Lu; Xinchao Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we showthat the decoding mechanism of dLLMs not only enhances model utility but alsocan be used as a powerful tool for model attribution.

31, TITLE: FINCH: Financial Intelligence Using Natural Language for Contextualized SQL Handling
AUTHORS: Avinash Kumar Singh; Bhaskarjit Sarmah; Stefano Pasquali
CATEGORY: arxiv-q-fin.CP [CP]
HIGHLIGHT: Highlight : While progress has beensignificant, applying it to the financial domain remains especially difficultdue to complex schema, domain-specific terminology, and high stakes of error.Despite this, there is no dedicated large-scale financial dataset to advanceresearch, creating a critical gap. To address this, we introduce a curatedfinancial dataset (FINCH) comprising 292 tables and 75,725 natural language-SQLpairs, enabling both fine-tuning and rigorous evaluation.

32, TITLE: Do AI Models Perform Human-like Abstract Reasoning Across Modalities?
AUTHORS: Claas Beger; Ryan Yi; Shuhao Fu; Arseny Moskvichev; Sarah W. Tsai; Sivasankaran Rajamanickam; Melanie Mitchell
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We evaluate models under settings thatvary the input modality (textual vs. visual), whether the model is permitted touse external Python tools, and, for reasoning models, the amount of reasoningeffort.

33, TITLE: InvThink: Towards AI Safety Via Inverse Reasoning
AUTHORS: Yubin Kim; Taehan Kim; Eugene Park; Chunjong Park; Cynthia Breazeal; Daniel McDuff; Hae Won Park
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We present InvThink, a simple yet powerful approach that gives large languagemodels (LLMs) the capability of inverse thinking: reasoning through failuremodes before generating responses.

34, TITLE: InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in Tool-Augmented Agents
AUTHORS: Yaxin Du; Yuanshuo Zhang; Xiyuan Yang; Yifan Zhou; Cheng Wang; Gongyi Zou; Xianghe Pang; Wenhao Wang; Menglan Chen; Shuo Tang; Zhiyu Li; Feiyu Xiong; Siheng Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: Information seeking is a fundamental requirement for humans. However,existing LLM agents rely heavily on open-web search, which exposes twofundamental weaknesses: online content ...

35, TITLE: PolySim: Bridging The Sim-to-Real Gap for Humanoid Control Via Multi-Simulator Dynamics Randomization
AUTHORS: Zixing Lei; Zibo Zhou; Sheng Yin; Yueru Chen; Qingyao Xu; Weixin Li; Yunhong Wang; Bowei Tang; Wei Jing; Siheng Chen
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : We thus introduce PolySim, a WBC trainingplatform that integrates multiple heterogeneous simulators.

36, TITLE: FlashResearch: Real-time Agent Orchestration for Efficient Deep Research
AUTHORS: Lunyiu Nie; Nedim Lipka; Ryan A. Rossi; Swarat Chaudhuri
CATEGORY: arxiv-cs.DC [DC]
HIGHLIGHT: Highlight : Thisarchitectural bottleneck results in high latency, poor runtime adaptability,and inefficient resource allocation, making them impractical for interactiveapplications. To overcome this, we introduce FlashResearch, a novel frameworkfor efficient deep research that transforms sequential processing intoparallel, runtime orchestration by dynamically decomposing complex queries intotree-structured sub-tasks.

37, TITLE: VaPR -- Vision-language Preference Alignment for Reasoning
AUTHORS: Rohan Wadhawan; Fabrice Y Harel-Canada; Zi-Yi Dou; Suhaila Shakiah; Robinson Piramuthu; Nanyun Peng
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : To this end, we introduce a hard-negative responsegeneration framework based on LLM-guided response editing, that producesrejected responses with targeted errors, maintaining stylistic and lengthsimilarity to the accepted ones.

38, TITLE: To Mask or to Mirror: Human-AI Alignment in Collective Reasoning
AUTHORS: Crystal Qian; Aaron Parisi; Clémentine Bouleau; Vivian Tsai; Maël Lebreton; Lucas Dixon
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We present an empirical framework for assessingcollective alignment, in contrast to prior work on the individual level.

39, TITLE: Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors
AUTHORS: Guangyao Zhai; Yue Zhou; Xinyan Deng; Lars Heckler; Nassir Navab; Benjamin Busam
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Large-scale pre-training of foundation visualencoders has advanced many fields, as the enormous quantity of data helps tolearn the general distribution of normal images. We observe that the anomalyamount in an image directly correlates with the difference in the learntembeddings and utilize this to design a few-shot anomaly detector termedFoundAD.

40, TITLE: RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning Via Multi-Stage Reinforcement Learning
AUTHORS: Sicheng Feng; Kaiwen Tuo; Song Wang; Lingdong Kong; Jianke Zhu; Huan Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Fine-grained visual reasoning remains a core challenge for multimodal largelanguage models (MLLMs). The recently introduced ReasonMap highlights this gapby showing that even ...

41, TITLE: To Model Human Linguistic Prediction, Make LLMs Less Superhuman
AUTHORS: Byung-Doh Oh; Tal Linzen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In thisposition paper, we argue that LLMs' superhumanness is primarily driven by twofactors: compared to humans, LLMs have much stronger long-term memory for factsand training examples, and they have much better short-term memory for previouswords in the text. We advocate for creating models that have human-likelong-term and short-term memory, and outline some possible directions forachieving this goal.

42, TITLE: Visual Odometry with Transformers
AUTHORS: Vlardimir Yugay; Duy-Kien Nguyen; Theo Gevers; Cees G. M. Snoek; Martin R. Oswald
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce VoT, short for Visualodometry Transformer, which processes sequences of monocular frames byextracting features and modeling global relationships through temporal andspatial attention.

43, TITLE: Chain-of-Thought Reasoning in Streaming Full-Duplex End-to-End Spoken Dialogue Systems
AUTHORS: Siddhant Arora; Jinchuan Tian; Hayato Futami; Jiatong Shi; Yosuke Kashiwagi; Emiru Tsunoo; Shinji Watanabe
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Most end-to-end (E2E) spoken dialogue systems (SDS) rely on voice activitydetection (VAD) for turn-taking, but VAD fails to distinguish between pausesand turn completions. Duplex SDS models address this by predicting outputcontinuously, including silence tokens, thus removing the need for explicitVAD.

44, TITLE: Stream RAG: Instant and Accurate Spoken Dialogue Systems with Streaming Tool Usage
AUTHORS: Siddhant Arora; Haidar Khan; Kai Sun; Xin Luna Dong; Sajal Choudhary; Seungwhan Moon; Xinyuan Zhang; Adithya Sagar; Surya Teja Appini; Kaushik Patnaik; Sanat Sharma; Shinji Watanabe; Anuj Kumar; Ahmed Aly; Yue Liu; Florian Metze; Zhaojiang Lin
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : A key challenge is thattool integration substantially increases response latency, disruptingconversational flow. To mitigate this, we propose Streaming Retrieval-AugmentedGeneration (Streaming RAG), a novel framework that reduces user-perceivedlatency by predicting tool queries in parallel with user speech, even beforethe user finishes speaking.

45, TITLE: Sycophantic AI Decreases Prosocial Intentions and Promotes Dependence
AUTHORS: Myra Cheng; Cinoo Lee; Pranav Khadpe; Sunny Yu; Dyllan Han; Dan Jurafsky
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: Highlight : Here we show the pervasivenessand harmful impacts of sycophancy when people seek advice from AI.

46, TITLE: Equilibrium Matching: Generative Modeling with Implicit Energy-Based Models
AUTHORS: Runqian Wang; Yilun Du
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We introduce Equilibrium Matching (EqM), a generative modeling frameworkbuilt from an equilibrium dynamics perspective.

47, TITLE: Purrception: Variational Flow Matching for Vector-Quantized Image Generation
AUTHORS: Răzvan-Andrei Matişan; Vincent Tao Hu; Grigory Bartosh; Björn Ommer; Cees G. M. Snoek; Max Welling; Jan-Willem van de Meent; Mohammad Mahdi Derakhshani; Floor Eijkelboom
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce Purrception, a variational flow matching approach forvector-quantized image generation that provides explicit categoricalsupervision while maintaining continuous transport dynamics.

48, TITLE: Local Linear Attention: An Optimal Interpolation of Linear and Softmax Attention For Test-Time Regression
AUTHORS: Yifei Zuo; Yutong Yin; Zhichen Zeng; Ang Li; Banghua Zhu; Zhaoran Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: Transformer architectures have achieved remarkable success in variousdomains. While efficient alternatives to Softmax Attention have been widelystudied, the search for more ...

49, TITLE: Think Right: Learning to Mitigate Under-Over Thinking Via Adaptive, Attentive Compression
AUTHORS: Joykirat Singh; Justin Chih-Yao Chen; Archiki Prasad; Elias Stengel-Eskin; Akshay Nambi; Mohit Bansal
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : To address under-adaptivityand strike a balance between under- and overthinking, we propose TRAAC (ThinkRight with Adaptive, Attentive Compression), an online post-training RL methodthat leverages the model's self-attention over a long reasoning trajectory toidentify important steps and prune redundant ones.

50, TITLE: DiFFPO: Training Diffusion LLMs to Reason Fast and Furious Via Reinforcement Learning
AUTHORS: Hanyang Zhao; Dawen Liang; Wenpin Tang; David Yao; Nathan Kallus
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We propose DiFFPO, Diffusion Fast and Furious Policy Optimization, a unifiedframework for training masked diffusion large language models (dLLMs) to reasonnot only better (furious), but also faster via reinforcement learning (RL).

51, TITLE: Position: Privacy Is Not Just Memorization!
AUTHORS: Niloofar Mireshghallah; Tianshi Li
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Highlight : This position paper argues that the privacy landscape of LLMsystems extends far beyond training data extraction, encompassing risks fromdata collection practices, inference-time context leakage, autonomous agentcapabilities, and the democratization of surveillance through deep inferenceattacks. We present a comprehensive taxonomy of privacy risks across the LLMlifecycle -- from data collection through deployment -- and demonstrate throughcase studies how current privacy frameworks fail to address these multifacetedthreats.

52, TITLE: Multimodal Foundation Models for Early Disease Detection
AUTHORS: Md Talha Mohsin; Ismail Abdulrashid
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Our research presents a multimodalfoundation model that consolidates diverse patient data through anattention-based transformer framework.

53, TITLE: Inferring Dynamic Physical Properties from Video Foundation Models
AUTHORS: Guanqi Zhan; Xianzheng Ma; Weidi Xie; Andrew Zisserman
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : (ii) We explore three ways to inferthe physical property from videos: (a) an oracle method where we supply thevisual cues that intrinsically reflect the property using classical computervision techniques; (b) a simple read out mechanism using a visual prompt andtrainable prompt vector for cross-attention on pre-trained video generative andself-supervised models; and (c) prompt strategies for Multi-modal LargeLanguage Models (MLLMs).

54, TITLE: Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What to Use Instead
AUTHORS: Feiyang Kang; Michael Kuchnik; Karthik Padthe; Marin Vlastelica; Ruoxi Jia; Carole-Jean Wu; Newsha Ardalani
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this work, we challenge whether high SFT scores translate toimproved performance after RL.

55, TITLE: EvoStruggle: A Dataset Capturing The Evolution of Struggle Across Activities and Skill Levels
AUTHORS: Shijia Feng; Michael Wray; Walterio Mayol-Cuevas
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We define the struggle determination problem as a temporal actionlocalization task, focusing on identifying and precisely localizing strugglesegments with start and end times.

56, TITLE: Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming Attacks
AUTHORS: Ruohao Guo; Afshin Oroojlooy; Roshan Sridhar; Miguel Ballesteros; Alan Ritter; Dan Roth
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We propose DialTree-RPO, an on-policyreinforcement learning framework integrated with tree search that autonomouslydiscovers diverse multi-turn attack strategies by treating the dialogue as asequential decision-making problem, enabling systematic exploration withoutmanually curated data.

57, TITLE: AdvEvo-MARL: Shaping Internalized Safety Through Adversarial Co-Evolution in Multi-Agent Reinforcement Learning
AUTHORS: Zhenyu Pan; Yiting Zhang; Zhuo Liu; Yolo Yunlong Tang; Zeliang Zhang; Haozheng Luo; Yuwei Han; Jianshu Zhang; Dennis Wu; Hong-Yu Chen; Haoran Lu; Haoyang Fang; Manling Li; Chenliang Xu; Philip S. Yu; Han Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : To stabilize learning and foster cooperation, we introduce apublic baseline for advantage estimation: agents within the same functionalgroup share a group-level mean-return baseline, enabling lower-variance updatesand stronger intra-group coordination.

58, TITLE: Is It Thinking or Cheating? Detecting Implicit Reward Hacking By Measuring Reasoning Effort
AUTHORS: Xinpeng Wang; Nitish Joshi; Barbara Plank; Rico Angell; He He
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : To detect implicit reward hacking, we propose TRACE(Truncated Reasoning AUC Evaluation).

59, TITLE: Measurement-Guided Consistency Model Sampling for Inverse Problems
AUTHORS: Amirreza Tanevardi; Pooria Abbas Rad Moghadam; Sajjad Amini
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: Highlight : In this paper, we present amodified consistency sampling approach tailored for inverse problemreconstruction: the sampler's stochasticity is guided by ameasurement-consistency mechanism tied to the measurement operator, whichenforces fidelity to the acquired measurements while retaining the efficiencyof consistency-based generation.

60, TITLE: SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment
AUTHORS: Yuxun Tang; Lan Liu; Wenhao Feng; Yiwen Zhao; Jionghao Han; Yifeng Yu; Jiatong Shi; Qin Jin
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Highlight : In this work, we introduceSingMOS-Pro, a dataset for automatic singing quality assessment.

61, TITLE: The Three Regimes of Offline-to-Online Reinforcement Learning
AUTHORS: Lu Li; Tianwei Ni; Yihao Sun; Pierre-Luc Bacon
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : However, its empirical behavior is highlyinconsistent: design choices of online-fine tuning that work well in onesetting can fail completely in another. We propose a stability--plasticityprinciple that can explain this inconsistency: we should preserve the knowledgeof pretrained policy or offline dataset during online fine-tuning, whichever isbetter, while maintaining sufficient plasticity.

62, TITLE: LLM-Based Multi-Task Bangla Hate Speech Detection: Type, Severity, and Target
AUTHORS: Md Arid Hasan; Firoj Alam; Md Fahad Hossain; Usman Naseem; Syed Ishtiaque Ahmed
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We address these gapsby introducing the first multi-task Bangla hate-speech dataset,BanglaMultiHate, one of the largest manually annotated corpus to date. Buildingon this resource, we conduct a comprehensive, controlled comparison spanningclassical baselines, monolingual pretrained models, and LLMs under zero-shotprompting and LoRA fine-tuning.

63, TITLE: ARUQULA -- An LLM Based Text2SPARQL Approach Using ReAct and Knowledge Graph Exploration Utilities
AUTHORS: Felix Brei; Lorenz Bühmann; Johannes Frey; Daniel Gerber; Lars-Peter Meyer; Claus Stadler; Kirill Bulert
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In thispaper we introduce a generalized method based on SPINACH, an LLM backed agentthat translates natural language questions to SPARQL queries not in a singleshot, but as an iterative process of exploration and execution.

64, TITLE: TriAlignXA: An Explainable Trilemma Alignment Framework for Trustworthy Agri-product Grading
AUTHORS: Jianfei Xie; Ziyang Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We redefine the role of algorithms from'decision-makers' to 'providers of transparent decision-making bases',designing the explainable AI framework--TriAlignXA.

65, TITLE: Learning to Decide with Just Enough: Information-Theoretic Context Summarization for CMDPs
AUTHORS: Peidong Liu; Junjiang Lin; Shaowen Wang; Yao Xu; Haiqing Li; Xuhao Xie; Siyi Wu; Hao Li
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We propose an information-theoreticsummarization approach that uses large language models (LLMs) to compresscontextual inputs into low-dimensional, semantically rich summaries.

66, TITLE: Taking A SEAT: Predicting Value Interpretations from Sentiment, Emotion, Argument, and Topic Annotations
AUTHORS: Adina Nicola Dobrinoiu; Ana Cristiana Marcu; Amir Homayounirad; Luciano Cavalcante Siebert; Enrico Liscio
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : To this end, we investigate whether a language model can predictindividual value interpretations by leveraging multi-dimensional subjectiveannotations as a proxy for their interpretive lens.

67, TITLE: Uncovering Overconfident Failures in CXR Models Via Augmentation-Sensitivity Risk Scoring
AUTHORS: Han-Jay Shu; Wei-Ning Chiu; Shun-Ting Chang; Meng-Ping Huang; Takeshi Tohyama; Ahram Han; Po-Chih Kuo
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Deep learning models achieve strong performance in chest radiograph (CXR)interpretation, yet fairness and reliability concerns persist.

68, TITLE: AMAS: Adaptively Determining Communication Topology for LLM-based Multi-Agent System
AUTHORS: Hui Yi Leong; Yuheng Li; Yuqing Wu; Wenwen Ouyang; Wei Zhu; Jiechao Gao; Wei Han
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Conventional MAS architectures are fundamentally restricted byinflexible, hand-crafted graph topologies that lack contextual responsiveness,resulting in diminished efficacy across varied academic and commercialworkloads. To surmount these constraints, we introduce AMAS, aparadigm-shifting framework that redefines LLM-based MAS through a noveldynamic graph designer.

69, TITLE: Glaucoma Detection and Structured OCT Report Generation Via A Fine-tuned Multimodal Large Language Model
AUTHORS: Jalil Jalili; Yashraj Gavhane; Evan Walker; Anna Heinke; Christopher Bowd; Akram Belghith; Massimo A. Fazio; Christopher A. Girkin; C. Gustavo De Moraes; Jeffrey M. Liebmann; Sally L. Baxter; Robert N. Weinreb; Linda M. Zangwill; Mark Christopher
CATEGORY: arxiv-q-bio.QM [QM]
HIGHLIGHT: Highlight : Design:Retrospective cohort study of 1,310 subjects contributing 43,849 Spectralis ONHOCT circle scans (1,331 glaucomatous and 867 healthy eyes) from the DIGS andADAGES cohorts.

70, TITLE: Next-Generation LLM for UAV: From Natural Language to Autonomous Flight
AUTHORS: Liangqi Yuan; Chuhao Deng; Dong-Jun Han; Inseok Hwang; Sabine Brunswicker; Christopher G. Brinton
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : We demonstrate the system's feasibilitythrough three representative use cases spanning different operational scales:multi-UAV patrol, multi-POI delivery, and multi-hop relocation.

71, TITLE: Automated Defect Detection for Mass-Produced Electronic Components Based on YOLO Object Detection Models
AUTHORS: Wei-Lung Mao; Chun-Chi Wang; Po-Heng Chou; Yen-Ting Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In thispaper, we propose an automated defect detection system for the dual in-linepackage (DIP) that is widely used in industry, using digital camera optics anda deep learning (DL)-based model.

72, TITLE: A Cybersecurity AI Agent Selection and Decision Support Framework
AUTHORS: Masike Malatji
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : This paper presents a novel, structured decision support framework thatsystematically aligns diverse artificial intelligence (AI) agent architectures,reactive, cognitive, hybrid, and learning, with the comprehensive NationalInstitute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.

73, TITLE: Data Selection for Fine-tuning Vision Language Models Via Cross Modal Alignment Trajectories
AUTHORS: Nilay Naharas; Dang Nguyen; Nesihan Bulut; Mohammadhossein Bateni; Vahab Mirrokni; Baharan Mirzasoleiman
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, we proposethe first principled method for data-efficient instruction tuning of LVLMs.

74, TITLE: ExGRPO: Learning to Reason from Experience
AUTHORS: Runzhe Zhan; Yafu Li; Zhi Wang; Xiaoye Qu; Dongrui Liu; Jing Shao; Derek F. Wong; Yu Cheng
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this paper, we are the first to investigate what makes areasoning experience valuable and identify rollout correctness and entropy aseffective indicators of experience value.

75, TITLE: Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal Sentiment Analysis
AUTHORS: Han Wu; Yanming Sun; Yunhe Yang; Derek F. Wong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Multimodal sentiment analysis (MSA) leverages information fusion from diversemodalities (e.g., text, audio, visual) to enhance sentiment prediction.However, simple fusion techniques often fail to account for variations inmodality quality, such as those that are noisy, missing, or semanticallyconflicting.

76, TITLE: Study on LLMs for Promptagator-Style Dense Retriever Training
AUTHORS: Daniel Gwon; Nour Jedidi; Jimmy Lin
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: Highlight : In this work, westudy the impact of open-source LLMs at accessible scales ($\leq$14Bparameters) as an alternative.

77, TITLE: Predictive Preference Learning from Human Interventions
AUTHORS: Haoyuan Cai; Zhenghao Peng; Bolei Zhou
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Although most interactive imitationlearning methods focus on correcting the agent's action at the current state,they do not adjust its actions in future states, which may be potentially morehazardous. To address this, we introduce Predictive Preference Learning fromHuman Interventions (PPL), which leverages the implicit preference signalscontained in human interventions to inform predictions of future rollouts.

78, TITLE: Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning
AUTHORS: Xuchen Li; Xuzhao Li; Jiahui Gao; Renjie Pi; Shiyu Hu; Wentao Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : However, this pixel-level information is oftenoverused, leading to inefficiency and distraction from irrelevant visualdetails. To address these challenges, we propose the first framework foradaptive pixel reasoning that dynamically determines necessary pixel-leveloperations based on the input query.

79, TITLE: G$^2$RPO: Granular GRPO for Precise Reward in Flow Models
AUTHORS: Yujie Zhou; Pengyang Ling; Jiazi Bu; Yibin Wang; Yuhang Zang; Jiaqi Wang; Li Niu; Guangtao Zhai
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : While existing methods effectivelyexplore potential high-value samples, they suffer from sub-optimal preferencealignment due to sparse and narrow reward signals. To address these challenges,we propose a novel Granular-GRPO (G$^2$RPO) framework that achieves precise andcomprehensive reward assessments of sampling directions in reinforcementlearning of flow models.

80, TITLE: How Do Language Models Compose Functions?
AUTHORS: Apoorv Khandelwal; Ellie Pavlick
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we investigate how feedforward LLMssolve two-hop factual recall tasks, which can be expressed compositionally as$g(f(x))$.

81, TITLE: Continual Personalization for Diffusion Models
AUTHORS: Yu-Chien Liao; Jr-Jen Chen; Chi-Pin Huang; Ci-Siang Lin; Meng-Lin Wu; Yu-Chiang Frank Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We present a novellearning strategy of Concept Neuron Selection (CNS), a simple yet effectiveapproach to perform personalization in a continual learning scheme.

82, TITLE: WALT: Web Agents That Learn Tools
AUTHORS: Viraj Prabhu; Yutong Dai; Matthew Fernandez; Jing Gu; Krithika Ramakrishnan; Yanqi Luo; Silvio Savarese; Caiming Xiong; Junnan Li; Zeyuan Chen; Ran Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce WALT (Web Agents that Learn Tools),a framework that reverse-engineers latent website functionality into reusableinvocable tools.

83, TITLE: Symmetric Division of Linear Ordinary Differential Operators
AUTHORS: Lixin Du; Manuel Kauers
CATEGORY: arxiv-cs.SC [SC]
HIGHLIGHT: Abstract: The symmetric product of two ordinary linear differential operators $L_1,L_2$is an operator whose solution set contains the product $f_1f_2$ of any solution$f_1$ of $L_1$ and any ...

84, TITLE: Dynamic Target Attack
AUTHORS: Kedong Xiu; Churui Zeng; Tianhang Zheng; Xinzhe Huang; Xiaojun Jia; Di Wang; Puning Zhao; Zhan Qin; Kui Ren
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Highlight : In this paper, we propose Dynamic Target Attack (DTA), a new jailbreakingframework relying on the target LLM's own responses as targets to optimize theadversarial prompts.

85, TITLE: RainSeer: Fine-Grained Rainfall Reconstruction Via Physics-Guided Modeling
AUTHORS: Lin Chen; Jun Chen; Minghui Qiu; Shuxin Zhong; Binghong Chen; Kaishun Wu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We introduce RainSeer, a structure-aware reconstruction frameworkthat reinterprets radar reflectivity as a physically grounded structuralprior-capturing when, where, and how rain develops.

86, TITLE: Learning to Generate Object Interactions with Physics-Guided Video Diffusion
AUTHORS: David Romero; Ariana Bermudez; Hao Li; Fabio Pizzati; Ivan Laptev
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : To address thislimitation, we introduce KineMask, an approach for physics-guided videogeneration that enables realistic rigid body control, interactions, andeffects.

87, TITLE: Can LLMs Refuse Questions They Do Not Know? Measuring Knowledge-Aware Refusal in Factual Tasks
AUTHORS: Wenbo Pan; Jie Xu; Qiguang Chen; Junhao Dong; Libo Qin; Xinfeng Li; Haining Yu; Xiaohua Jia
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : On the other hand, existing calibration metrics areproxy-based, capturing the performance of auxiliary calibration processesrather than the model's actual refusal behavior. In this work, we propose theRefusal Index (RI), a principled metric that measures how accurately LLMsrefuse questions they do not know.

88, TITLE: Derandomised Tensor Product Gap Amplification for Quantum Hamiltonians
AUTHORS: Thiago Bergamaschi; Tony Metger; Thomas Vidick; Tina Zhang
CATEGORY: arxiv-quant-ph [ARXIV-QUANT-PH]
HIGHLIGHT: Highlight : In this work, following Dinur's model, we introduce a new quantum gapamplification procedure for Hamiltonians which uses random walks on expandergraphs to derandomise (subsample the terms of) the tensor product amplificationof a Hamiltonian.

89, TITLE: DisCo- Layout: Disentangling and Coordinating Semantic and Physical Refinement in A Multi-Agent Framework for 3D Indoor Layout Synthesis
AUTHORS: Jialin Gao; Donghao Zhou; Mingjian Liang; Lihao Liu; Chi-Wing Fu; Xiaowei Hu; Pheng-Ann Heng
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Abstract: 3D indoor layout synthesis is crucial for creating virtual environments.Traditional methods struggle with generalization due to fixed datasets. Whilerecent LLM and VLM-based ...

90, TITLE: Enhancing Noise Robustness of Parkinson's Disease Telemonitoring Via Contrastive Feature Augmentation
AUTHORS: Ziming Tang; Chengbin Hou; Tianyu Zhang; Bangxu Tian; Jinbao Wang; Hairong Lv
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : To address thesechallenges, NoRo, a noise-robust UPDRS prediction framework is proposed.

91, TITLE: VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual Reprogramming
AUTHORS: Duy Nguyen; Dat Nguyen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Inspired by recent implications that existing backbones have textural biases,we propose making use of domain-specific textural bias for domain adaptationvia visual reprogramming, namely VirDA.

92, TITLE: A Tale of LLMs and Induced Small Proxies: Scalable Agents for Knowledge Mining
AUTHORS: Sipeng Zhang; Longfei Yun; Zilong Wang; Jingbo Shang; Letian Peng
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce Falconer, acollaborative framework that combines the agentic reasoning of LLMs withlightweight proxy models for scalable knowledge mining.

93, TITLE: LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud Reconstruction
AUTHORS: Mario Resino; Borja Pérez; Jaime Godoy; Abdulla Al-Kaff; Fernando García
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : This work proposed a 3D autoencoder architecture, named LiLa-Net, whichencodes efficient features from real traffic environments, employing only theLiDAR's point clouds.

94, TITLE: Emotional Text-To-Speech Based on Mutual-Information-Guided Emotion-Timbre Disentanglement
AUTHORS: Jianing Yang; Sheng Li; Takahiro Shinozaki; Yuki Saito; Hiroshi Saruwatari
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Highlight : The proposed method employs a style disentanglement method toguide two feature extractors, reducing mutual information between timbre andemotion features, and effectively separating distinct style components from thereference speech.

95, TITLE: DeMuon: A Decentralized Muon for Matrix Optimization Over Graphs
AUTHORS: Chuan He; Shuyi Ren; Jingwei Mao; Erik G. Larsson
CATEGORY: arxiv-math.OC [OC]
HIGHLIGHT: Highlight : In this paper, we propose DeMuon, a method for decentralized matrixoptimization over a given communication topology.

96, TITLE: MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments
AUTHORS: Darshan Deshpande; Varun Gangal; Hersh Mehta; Anand Kannappan; Rebecca Qian; Peng Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Notably, the best performing GPT-5 model only achieves a 60\%Correctness score on MEMTRACK.

97, TITLE: GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing
AUTHORS: Mengtian Li; Yunshu Bai; Yimin Chu; Yijun Shen; Zhongmei Li; Weifeng Ge; Zhifeng Xie; Chaofeng Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce GaussianMorphing, a novel framework for semantic-aware 3D shapeand texture morphing from multi-view images.

98, TITLE: AccurateRAG: A Framework for Building Accurate Retrieval-Augmented Question-Answering Applications
AUTHORS: Linh The Nguyen; Chi Tran; Dung Ngoc Nguyen; Van-Cuong Pham; Hoang Ngo; Dat Quoc Nguyen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce AccurateRAG -- a novel framework for constructinghigh-performance question-answering applications based on retrieval-augmentedgeneration (RAG).

99, TITLE: SoK: Measuring What Matters for Closed-Loop Security Agents
AUTHORS: Mudita Khurana; Raunak Jain
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce CLASP: the Closed-Loop AutonomousSecurity Performance framework which aligns the security lifecycle(reconnaissance, exploitation, root cause analysis, patch synthesis,validation) with core agentic capabilities (planning, tool use, memory,reasoning, reflection & perception) providing a common vocabulary and rubricfor assessing agentic capabilities in security tasks.

100, TITLE: The Disparate Impacts of Speculative Decoding
AUTHORS: Jameson Sandler; Ahmet Üstün; Marco Romanelli; Sara Hooker; Ferdinando Fioretto
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : The practice of speculative decoding, whereby inference is probabilisticallysupported by a smaller, cheaper, ``drafter'' model, has become a standardtechnique for systematically reducing the decoding time of large languagemodels. This paper conducts an analysis of speculative decoding through thelens of its potential disparate speed-up rates across tasks.

101, TITLE: NoiseShift: Resolution-Aware Noise Recalibration for Better Low-Resolution Image Generation
AUTHORS: Ruozhen He; Moayed Haji-Ali; Ziyan Yang; Vicente Ordonez
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We propose NoiseShift, a training-free method thatrecalibrates the noise level of the denoiser conditioned on resolution size.NoiseShift requires no changes to model architecture or sampling schedule andis compatible with existing models.

102, TITLE: LSPO: Length-aware Dynamic Sampling for Policy Optimization in LLM Reasoning
AUTHORS: Weizhe Chen; Sven Koenig; Bistra Dilkina
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this paper, motivatedby studies of overthinking in LLMs, we propose Length-aware Sampling for PolicyOptimization (LSPO), a novel meta-RLVR algorithm that dynamically selectstraining data at each step based on the average response length.

103, TITLE: Extracting O*NET Features from The NLx Corpus to Build Public Use Aggregate Labor Market Data
AUTHORS: Stephen Meisenbacher; Svetlozar Nestorov; Peter Norlander
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: Highlight : We describe the construction of a dataset of occupation, state, andindustry level features aggregated by monthly active jobs from 2015 - 2025.

104, TITLE: Asymmetric Proximal Policy Optimization: Mini-critics Boost LLM Reasoning
AUTHORS: Jiashun Liu; Johan Obando-Ceron; Han Lu; Yancheng He; Weixun Wang; Wenbo Su; Bo Zheng; Pablo Samuel Castro; Aaron Courville; Ling Pan
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacingthem with average advantage baselines. This shift is largely pragmatic:conventional value functions are ...

105, TITLE: The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models
AUTHORS: Phuc Minh Nguyen; Chinh D. La; Duy M. H. Nguyen; Nitesh V. Chawla; Binh T. Nguyen; Khoa D. Doan
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Second, weuncover the winner-take-all phenomenon: RLVR disproportionately reinforcesproblems with high likelihood, correct solutions, under the base model, whilesuppressing other initially low-likelihood ones. Through extensive theoreticaland empirical analysis on multiple mathematical reasoning benchmarks, we showthat this effect arises from the inherent on-policy sampling in standard RLobjectives, causing the model to converge toward narrow solution strategies.Based on these insights, we propose a simple yet effective data curationalgorithm that focuses RLVR learning on low-likelihood problems, achievingnotable improvement in Pass@$k$ performance.

106, TITLE: DisCo: Reinforcement with Diversity Constraints for Multi-Human Generation
AUTHORS: Shubhankar Borse; Farzad Farhadzadeh; Munawar Hayat; Fatih Porikli
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce DisCo (Reinforcement with Diversity Constraints), thefirst RL-based framework to directly optimize identity diversity in multi-humangeneration.

107, TITLE: Pool Me Wisely: On The Effect of Pooling in Transformer-Based Models
AUTHORS: Sofiane Ennadir; Levente Zólyomi; Oleg Smirnov; Tianze Wang; John Pertoft; Filip Cornell; Lele Cao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : While much of the literature has focused on attentionmechanisms, the role of pooling remains underexplored despite its criticalimpact on model behavior. In this paper, we introduce a theoretical frameworkthat rigorously characterizes the expressivity of Transformer-based modelsequipped with widely used pooling methods by deriving closed-form bounds ontheir representational capacity and the ability to distinguish similar inputs.Our analysis extends to different variations of attention formulations,demonstrating that these bounds hold across diverse architectural variants.

108, TITLE: Clarifying Semantics of In-Context Examples for Unit Test Generation
AUTHORS: Chen Yang; Lin Yang; Ziqi Wang; Dong Wang; Jianyi Zhou; Junjie Chen
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: Highlight : In this paper, we propose CLAST, a noveltechnique that systematically refines unit tests to improve their semanticclarity, thereby enhancing their utility as in-context examples.

109, TITLE: NGGAN: Noise Generation GAN Based on The Practical Measurement Dataset for Narrowband Powerline Communications
AUTHORS: Ying-Ren Chien; Po-Heng Chou; You-Jie Peng; Chun-Yuan Huang; Hen-Wai Tsao; Yu Tsao
CATEGORY: arxiv-eess.SP [SP]
HIGHLIGHT: Highlight : In this study, we propose a novel generative adversarial network(GAN) called noise generation GAN (NGGAN) that learns the complicatedcharacteristics of practically measured noise samples for data synthesis.

110, TITLE: POLAR: Automating Cyber Threat Prioritization Through LLM-Powered Assessment
AUTHORS: Luoxi Tang; Yuqiao Meng; Ankita Patra; Weicheng Ma; Muchao Ye; Zhaohan Xi
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Highlight : In this paper, we investigate the intrinsic vulnerabilities ofLLMs in CTI, focusing on challenges that arise from the nature of the threatlandscape itself rather than the model architecture.

111, TITLE: Pack and Force Your Memory: Long-form and Consistent Video Generation
AUTHORS: Xiaofei Wu; Guozhen Zhang; Zhiyong Xu; Yuan Zhou; Qinglin Lu; Xuming He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Long-form video generation presents a dual challenge: models must capturelong-range dependencies while preventing the error accumulation inherent inautoregressive decoding. To address these challenges, we make twocontributions.

112, TITLE: Flow-Matching Guided Deep Unfolding for Hyperspectral Image Reconstruction
AUTHORS: Yi Ai; Yuanhao Cai; Yulun Zhang; Xiaokang Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Althoughcompressive sensing systems such as CASSI improve efficiency, accuratereconstruction is still challenged by severe degradation and loss of finespectral details. We propose the Flow-Matching-guided Unfolding network (FMU),which, to our knowledge, is the first to integrate flow matching into HSIreconstruction by embedding its generative prior within a deep unfoldingframework.

113, TITLE: Automated Genomic Interpretation Via Concept Bottleneck Models for Medical Robotics
AUTHORS: Zijun Li; Jinchang Zhang; Ming Zhang; Guoyu Lu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We propose an automated genomic interpretation module that transforms raw DNAsequences into actionable, interpretable decisions suitable for integrationinto medical automation and robotic systems.

114, TITLE: Learning to Reason for Hallucination Span Detection
AUTHORS: Hsuan Su; Ting-Yao Hu; Hema Swetha Koppula; Kundan Krishna; Hadi Pouransari; Cheng-Yu Hsieh; Cem Koc; Joseph Yitan Cheng; Oncel Tuzel; Raviteja Vemulapalli
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Thisnaturally raises the question of whether explicit reasoning can help thecomplex task of detecting hallucination spans. To answer this question, wefirst evaluate pretrained models with and without Chain-of-Thought (CoT)reasoning, and show that CoT reasoning has the potential to generate at leastone correct answer when sampled multiple times.

115, TITLE: User to Video: A Model for Spammer Detection Inspired By Video Classification Technology
AUTHORS: Haoyang Zhang; Zhou Yang; Yucai Pang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : If the userbehavior subspace is viewed as a frame image, consecutive frame images areviewed as a video. Following this novel idea, a model for spammer detectionbased on user videoization, called UVSD, is proposed.

116, TITLE: Latency-aware Multimodal Federated Learning Over UAV Networks
AUTHORS: Shaba Shaon; Dinh C. Nguyen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : To address the computational complexity of our latency minimizationproblem, we propose an efficient iterative optimization algorithm combiningblock coordinate descent and successive convex approximation techniques, whichprovides high-quality approximate solutions.

117, TITLE: GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning
AUTHORS: Silvia Sapora; Devon Hjelm; Alexander Toshev; Omar Attia; Bogdan Mazoure
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this work, we introduce GRACE (GeneratingRewards As CodE), a method for using Large Language Models within anevolutionary search to reverse-engineer an interpretable, code-based rewardfunction directly from expert trajectories.

118, TITLE: Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network
AUTHORS: Jinshuo Zhang; Yafei Wang; Xinping Yi; Wenjin Wang; Shi Jin; Symeon Chatzinotas; Björn Ottersten
CATEGORY: arxiv-eess.SP [SP]
HIGHLIGHT: Highlight : Leveragingthese, we propose the backbone of the framework with an attention-based TEmodule, achieving linear computational complexity.

119, TITLE: UpSafe$^\circ$C: Upcycling for Controllable Safety in Large Language Models
AUTHORS: Yuhao Sun; Zhuoer Xu; Shiwen Cui; Kun Yang; Lingyun Yu; Yongdong Zhang; Hongtao Xie
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Inthis work, we propose UpSafe$^\circ$C, a unified framework for enhancing LLMsafety through safety-aware upcycling.

120, TITLE: Growing Visual Generative Capacity for Pre-Trained MLLMs
AUTHORS: Hanyu Wang; Jiaming Han; Ziyan Yang; Qi Zhao; Shanchuan Lin; Xiangyu Yue; Abhinav Shrivastava; Zhenheng Yang; Hao Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Inthis work, we present Bridge, a pure autoregressive unified MLLM that augmentspre-trained visual understanding models with generative ability through aMixture-of-Transformers architecture, enabling both image understanding andgeneration within a single next-token prediction framework.

121, TITLE: Human-Robo-advisor Collaboration in Decision-making: Evidence from A Multiphase Mixed Methods Experimental Study
AUTHORS: Hasan Mahmuda; Najmul Islam; Satish Krishnan
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: Highlight : While prior research hasexamined user interactions with RAs, less is known about how individualsinterpret RA roles and integrate their advice into decision-making. To addressthis gap, this study employs a multiphase mixed methods design integrating abehavioral experiment (N = 334), thematic analysis, and follow-up quantitativetesting.

122, TITLE: Median2Median: Zero-shot Suppression of Structured Noise in Images
AUTHORS: Jianxu Wang; Ge Wang
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: Highlight : Mostdata-driven approaches rely on large datasets with high-quality labels andstill suffer from limited generalizability, whereas existing zero-shot methodsavoid this limitation but remain effective only for independent and identicallydistributed (i.i.d.) noise. To address this gap, we propose Median2Median(M2M), a zero-shot denoising framework designed for structured noise.

123, TITLE: Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery
AUTHORS: Minh Tran; Maksim Siniukov; Zhangyu Jin; Mohammad Soleymani
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, weintroduce Discrete Facial Encoding (DFE), an unsupervised, data-drivenalternative of compact and interpretable dictionary of facial expressions from3D mesh sequences learned through a Residual Vector Quantized VariationalAutoencoder (RVQ-VAE).

124, TITLE: Automating Data-Driven Modeling and Analysis for Engineering Applications Using Large Language Model Agents
AUTHORS: Yang Liu; Zaid Abulawi; Abhiram Garimidi; Doyeong Lim
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Inthis study, we propose an innovative pipeline utilizing Large Language Model(LLM) agents to automate data-driven modeling and analysis, with a particularemphasis on regression tasks.

125, TITLE: MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics
AUTHORS: Changmin Lee; Jihyun Lee; Tae-Kyun Kim
CATEGORY: arxiv-cs.GR [GR]
HIGHLIGHT: Highlight : In this work, wepresent MPMAvatar, a framework for creating 3D human avatars from multi-viewvideos that supports highly realistic, robust animation, as well asphotorealistic rendering from free viewpoints.

126, TITLE: Drawing Conclusions from Draws: Rethinking Preference Semantics in Arena-Style LLM Evaluation
AUTHORS: Raphael Tang; Crystina Zhang; Wenyan Li; Carmen Lai; Pontus Stenetorp; Yao Lu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Theprevailing approach for modeling these rating dynamics is to view battles astwo-player game matches, as in chess, and apply the Elo rating system and itsderivatives. In this paper, we critically examine this paradigm.

127, TITLE: From Videos to Indexed Knowledge Graphs -- Framework to Marry Methods for Multimodal Content Analysis and Understanding
AUTHORS: Basem Rizk; Joel Walsh; Mark Core; Benjamin Nye
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Analysis of multi-modal content can be tricky, computationally expensive, andrequire a significant amount of engineering efforts. Lots of work withpre-trained models on static data is out there, yet fusing these opensourcemodels and methods with complex data such as videos is relatively challenging.In this paper, we present a framework that enables efficiently prototypingpipelines for multi-modal content analysis.

128, TITLE: AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation
AUTHORS: Anukriti Singh; Kasra Torshizi; Khuzema Habib; Kelin Yu; Ruohan Gao; Pratap Tokekar
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : Existing keypoint-based approaches can focus on manipulation-centricfeatures and be lightweight, but either depend on manual heuristics ortask-coupled selection, limiting scalability and semantic understanding. Toaddress this, we propose AFFORD2ACT, an affordance-guided framework thatdistills a minimal set of semantic 2D keypoints from a text prompt and a singleimage.

129, TITLE: OpusAnimation: Code-Based Dynamic Chart Generation
AUTHORS: Bozheng Li; Miao Yang; Zhenhan Chen; Jiawang Cao; Mushui Liu; Yi Lu; Yongliang Wu; Bin Zhang; Yangguang Ji; Licheng Tang; Jay Wu; Wenbo Zhu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : To bridge this researchgap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the firstbenchmark evaluating MLLM's capability on dynamic chart generation tasks fromthree dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, andVideo-to-Chart tasks.

130, TITLE: Towards Interpretable and Inference-Optimal COT Reasoning with Sparse Autoencoder-Guided Generation
AUTHORS: Daniel Zhao; Abhilash Shankarampeta; Lanxiang Hu; Tajana Rosing; Hao Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We propose a novel method that leverages sparse autoencoders (SAEs) andclustering techniques to analyze the internal token representations of largelanguage models (LLMs) and guide generations in mathematical reasoning tasks.Our approach first trains an SAE to generate sparse vector representations fortraining tokens, then applies k-means clustering to construct a graph wherevertices represent token clusters and weighted edges capture sequential tokentransitions.

131, TITLE: One More Question Is Enough, Expert Question Decomposition (EQD) Model for Domain Quantitative Reasoning
AUTHORS: Mengyu Wang; Sotirios Sabanis; Miguel de Carvalho; Shay B. Cohen; Tiejun Ma
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we propose Expert QuestionDecomposition (EQD), an approach designed to balance the use of domainknowledge with computational efficiency.

132, TITLE: Parallel Scaling Law: Unveiling Reasoning Generalization Through A Cross-Linguistic Perspective
AUTHORS: Wen Yang; Junhong Wu; Chong Li; Chengqing Zong; Jiajun Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : This raises a crucial question:$\textit{Does the reasoning capability achieved from English RPT effectivelytransfer to other languages?} $ We address this by systematically evaluatingEnglish-centric LRMs on multilingual reasoning benchmarks and introducing ametric to quantify cross-lingual transferability.

133, TITLE: Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning
AUTHORS: Tianchong Jiang; Jingtian Ji; Xiangshan Tan; Jiading Fang; Anand Bhattad; Vitor Guizilini; Matthew R. Walter
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : To evaluate policy robustness under realisticviewpoint shifts, we introduce six manipulation tasks in RoboSuite andManiSkill that pair "fixed" and "randomized" scene variants, decouplingbackground cues from camera pose.

134, TITLE: Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving
AUTHORS: Haibo Hu; Lianming Huang; Xinyu Wang; Yufei Cui; Shangyu Wu; Nan Guan; Chun Jason Xue
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : Vision-Language Models (VLMs) are increasingly applied in autonomous drivingfor unified perception and reasoning, but high inference latency hindersreal-time deployment.

135, TITLE: Pure-Pass: Fine-Grained, Adaptive Masking for Dynamic Token-Mixing Routing in Lightweight Image Super-Resolution
AUTHORS: Junyu Wu; Jie Liu; Jie Tang; Gangshan Wu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : However, several limitationsremain, such as poor adaptability, coarse-grained masking and spatialinflexibility, among others. We propose Pure-Pass (PP), a pixel-level maskingmechanism that identifies pure pixels and exempts them from expensivecomputations.

136, TITLE: ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations
AUTHORS: Qiyuan Zeng; Chengmeng Li; Jude St. John; Zhongyi Zhou; Junjie Wen; Guorui Feng; Yichen Zhu; Yi Xu
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : We present ActiveUMI, a framework for a data collection system that transfersin-the-wild human demonstrations to robots capable of complex bimanualmanipulation.

137, TITLE: Constrained Adaptive Rejection Sampling
AUTHORS: Paweł Parys; Sairam Vaidya; Taylor Berg-Kirkpatrick; Loris D'Antoni
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We present Constrained Adaptive Rejection Sampling (CARS), anapproach that strictly improves the sample-efficiency of RS withoutdistributional distortion.

138, TITLE: Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions
AUTHORS: Mengyu Yang; Yiming Chen; Haozheng Pei; Siddhant Agarwal; Arun Balajee Vasudevan; James Hays
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Everyday object interactions produce sounds unique tothe objects involved. We introduce the sounding object detection task toevaluate a model's ability to link these sounds to the objects directlyinvolved.

139, TITLE: An Efficient Deep Template Matching and In-Plane Pose Estimation Method Via Template-Aware Dynamic Convolution
AUTHORS: Ke Jia; Ji Zhou; Hanxin Li; Zhigan Zhou; Haojie Chu; Xiaojie Li
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Meanwhile,most deep learning-based approaches only estimate similarity scores withoutexplicitly modeling geometric pose, making them inadequate for real-worlddeployment. To overcome these limitations, we propose a lightweight end-to-endframework that reformulates template matching as joint localization andgeometric regression, outputting the center coordinates, rotation angle, andindependent horizontal and vertical scales.

140, TITLE: Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs
AUTHORS: Yongyi Su; Haojie Zhang; Shijie Li; Nanqing Liu; Jingyi Liao; Junyi Pan; Yuan Liu; Xiaofen Xing; Chong Sun; Chen Li; Nancy F. Chen; Shuicheng Yan; Xulei Yang; Xun Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : However, existing approaches for vision tasks often rely on indirectrepresentations, such as generating coordinates as text for detection, whichlimits performance and prevents dense prediction tasks like segmentation. Toovercome these challenges, we introduce Patch-as-Decodable Token (PaDT), aunified paradigm that enables MLLMs to directly generate both textual anddiverse visual outputs.

141, TITLE: SCRIBES: Web-Scale Script-Based Semi-Structured Data Extraction with Reinforcement Learning
AUTHORS: Shicheng Liu; Kai Sun; Lisheng Fu; Xilun Chen; Xinyuan Zhang; Zhaojiang Lin; Rulin Shao; Yue Liu; Anuj Kumar; Wen-tau Yih; Xin Luna Dong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this paper, we introduceSCRIBES (SCRIpt-Based Semi-Structured Content Extraction at Web-Scale), a novelreinforcement learning framework that leverages layout similarity acrosswebpages within the same site as a reward signal.

142, TITLE: Demystifying The Roles of LLM Layers in Retrieval, Knowledge, and Reasoning
AUTHORS: Xinyuan Song; Keyu Wang; PengXiang Li; Lu Yin; Shiwei Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Inthis work, we present a systematic study of depth utilization across diversedimensions, including evaluation protocols, task categories, and modelarchitectures.

143, TITLE: Optimal Control Meets Flow Matching: A Principled Route to Multi-Subject Fidelity
AUTHORS: Eric Tillmann Bill; Enis Simsar; Thomas Hofmann
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce the first theoreticalframework with a principled, optimizable objective for steering samplingdynamics toward multi-subject fidelity.

144, TITLE: What MLLMs Learn About When They Learn About Multimodal Reasoning: Perception, Reasoning, or Their Integration?
AUTHORS: Jiwan Chung; Neel Joshi; Pratyusha Sharma; Youngjae Yu; Vibhav Vineet
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce MathLens, a benchmark designed to disentangle thesubskills of multimodal reasoning while preserving the complexity oftextbook-style geometry problems.

145, TITLE: ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models
AUTHORS: Krishna Teja Chitty-Venkata; Murali Emani
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We capture the step-by-step reasoning process ofVLMs and the final descriptive answers. Our goal with this dataset is to enablethe development of more robust VLMs while contributing to the broaderunderstanding of multimodal reasoning mechanisms.

146, TITLE: Towards Human-Centered RegTech: Unpacking Professionals' Strategies and Needs for Using LLMs Safely
AUTHORS: Siying Hu; Yaxing Yao; Zhicong Lu
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: Highlight : The study found that theseexperts are commonly concerned about sensitive information leakage,intellectual property infringement, and uncertainty regarding the quality ofmodel outputs.

147, TITLE: A Rigorous Benchmark with Multidimensional Evaluation for Deep Research Agents: From Answers to Reports
AUTHORS: Yang Yao; Yixu Wang; Yuxuan Zhang; Yi Lu; Tianle Gu; Lingyu Li; Dingyi Zhao; Keming Wu; Haozhe Wang; Ping Nie; Yan Teng; Yingchun Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : The framework enables comprehensive evaluation oflong-form reports generated by DRAs, incorporating integrated scoring metricsfor semantic quality, topical focus, and retrieval trustworthiness.

148, TITLE: Reliable End-to-End Material Information Extraction from The Literature with Source-Tracked Multi-Stage Large Language Models
AUTHORS: Xin Wang; Anshu Raj; Matthew Luebbe; Haiming Wen; Shuozhi Xu; Kun Lu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : The pipeline integrates iterative extraction with source tracking toenhance both accuracy and reliability.

149, TITLE: BioBlobs: Differentiable Graph Partitioning for Protein Representation Learning
AUTHORS: Xin Wang; Carlos Oliver
CATEGORY: arxiv-q-bio.BM [BM]
HIGHLIGHT: Highlight : We introduce BioBlobs, a plug-and-play, fully differentiablemodule that represents proteins by dynamically partitioning structures intoflexibly-sized, non-overlapping substructures ("blobs").

150, TITLE: FideDiff: Efficient Diffusion Model for High-Fidelity Image Motion Deblurring
AUTHORS: Xiaoyang Liu; Zhengyan Zhou; Zihang Xu; Jiezhang Cao; Zheng Chen; Yulun Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We reformulate motion deblurring as a diffusion-like process whereeach timestep represents a progressively blurred image, and we train aconsistency model that aligns all timesteps to the same clean image.

151, TITLE: F2LLM Technical Report: Matching SOTA Embedding Performance with 6 Million Open-Source Data
AUTHORS: Ziyin Zhang; Zihan Liao; Hang Yu; Peng Di; Rui Wang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce F2LLM - Foundation to Feature Large Language Models, a suite ofstate-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B.

152, TITLE: Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation
AUTHORS: Seungseop Lim; Gibaeg Kim; Wooseok Han; Jean Seo; Hyunkyung Lee; Jaehyo Yoo; Eunho Yang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Trainingon such data induces a novel failure mechanism we term Format Inertia, wheremodels tend to generate repetitive, format-correct, but diagnosticallyuninformative questions in long medical dialogues. To mitigate this observedfailure mechanism, we adopt a simple, data-centric method that rebalances theturn-count distribution of the training dataset.

153, TITLE: MedQ-Bench: Evaluating and Exploring Medical Image Quality Assessment Abilities in MLLMs
AUTHORS: Jiyao Liu; Jinjie Wei; Wanying Qu; Chenglong Ma; Junzhi Ning; Yunheng Li; Ying Chen; Xinzhe Luo; Pengcheng Chen; Xin Gao; Ming Hu; Huihui Xu; Xin Wang; Shujian Gao; Dingkang Yang; Zhongying Deng; Jin Ye; Lihao Liu; Junjun He; Ningsheng Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : To evaluate reasoning ability, we propose a multi-dimensional judgingprotocol that assesses model outputs along four complementary axes.

154, TITLE: Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks Via Shapley Value
AUTHORS: Wangxuan Fan; Ching Wang; Siqi Li; Nan Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We propose \textbf{ShapKAN}, a pruning framework usingShapley value attribution to assess node importance in a shift-invariantmanner.

155, TITLE: Enhancing Large Language Model Reasoning with Reward Models: An Analytical Survey
AUTHORS: Qiyuan Liu; Hao Xu; Xuhong Chen; Wei Chen; Yee Whye Teh; Ning Miao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this paper, we provide a systematicintroduction to RMs, along with a comprehensive survey of their applications inLLM reasoning.

156, TITLE: Formal Framework for Quantum Advantage
AUTHORS: Harry Buhrman; Niklas Galke; Konstantinos Meichanetzidis
CATEGORY: arxiv-quant-ph [ARXIV-QUANT-PH]
HIGHLIGHT: Highlight : Motivated by notions of quantum heuristics and by average-case rather thanworst-case algorithmic analysis, we define quantum computational advantage interms of individual problem instances.

157, TITLE: Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction
AUTHORS: Ethan G. Rogers; Cheng Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : To address the decoder bottleneck in neuralcompression, we develop a new compression-reconstruction framework based onincorporating low-rank representation in an autoencoder with vectorquantization.

158, TITLE: RESTRAIN: From Spurious Votes to Signals -- Self-Driven RL with Self-Penalization
AUTHORS: Zhaoning Yu; Will Su; Leitian Tao; Haozhu Wang; Aashu Singh; Hanchao Yu; Jianyu Wang; Hongyang Gao; Weizhe Yuan; Jason Weston; Ping Yu; Jing Xu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce RESTRAIN (REinforcement learning withSelf-restraint), a self-penalizing RL framework that converts the absence ofgold labels into a useful learning signal.

159, TITLE: Detecting LLM-Generated Spam Reviews By Integrating Language Model Embeddings and Graph Neural Network
AUTHORS: Xin Liu; Rongwu Xu; Xinyi Jia; Jason Liao; Jiao Sun; Ling Huang; Wei Xu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : To address thisthreat, we propose FraudSquad, a hybrid detection model that integrates textembeddings from a pre-trained language model with a gated graph transformer forspam node classification.

160, TITLE: KAIROS: Unified Training for Universal Non-Autoregressive Time Series Forecasting
AUTHORS: Kuiye Ding; Fanda Fan; Zheya Wang; Hongxiao Li; Yifan Wang; Lei Wang; Chunjie Luo; Jianfeng Zhan
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We present KAIROS, a non-autoregressive time seriesforecasting framework that directly models segment-level multi-peakdistributions.

161, TITLE: From Frames to Clips: Efficient Key Clip Selection for Long-Form Video Understanding
AUTHORS: Guangyu Sun; Archit Singhal; Burak Uzkent; Mubarak Shah; Chen Chen; Garin Kessler
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Tomaintain a fixed computational budget while accommodating the larger tokenfootprint of clips, we propose an adaptive resolution strategy that dynamicallybalances spatial resolution and clip length, ensuring a constant token countper video.

162, TITLE: Step-Aware Policy Optimization for Reasoning in Diffusion Large Language Models
AUTHORS: Shaoan Xie; Lingjing Kong; Xiangchen Song; Xinshuai Dong; Guangyi Chen; Eric P. Xing; Kun Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Diffusion language models (dLLMs) offer a promising, non-autoregressiveparadigm for text generation, yet training them for complex reasoning remains akey challenge.

163, TITLE: AortaDiff: A Unified Multitask Diffusion Framework For Contrast-Free AAA Imaging
AUTHORS: Yuxuan Ou; Ning Bi; Jiazhen Pan; Jiancheng Yang; Boliang Yu; Usama Zidan; Regent Lee; Vicente Grau
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : However, most adopt amulti-stage pipeline that first generates images and then performssegmentation, which leads to error accumulation and fails to leverage sharedsemantic and anatomical structures. To address this, we propose a unified deeplearning framework that generates synthetic CECT images from NCCT scans whilesimultaneously segmenting the aortic lumen and thrombus.

164, TITLE: Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for Improved Cross-Corpus Speech Enhancement
AUTHORS: Nikolai Lund Kühne; Jesper Jensen; Jan Østergaard; Zheng-Hua Tan
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Abstract: Recent advances in speech enhancement have shown that models combining Mambaand attention mechanisms yield superior cross-corpus generalizationperformance. At the same time, ...

165, TITLE: 4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing
AUTHORS: Lei Liu; Can Wang; Zhenghao Chen; Dong Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : This model incorporates 4D VGGT geometry features extracted fromthe initial scene, enabling it to capture underlying 4D geometric structuresduring editing.

166, TITLE: MATCH: Multi-faceted Adaptive Topo-Consistency for Semi-Supervised Histopathology Segmentation
AUTHORS: Meilong Xu; Xiaoling Hu; Shahira Abousamra; Chen Li; Chao Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : This is particularly challenging inhistopathology image analysis, where objects are densely distributed. Toaddress this issue, we propose a semi-supervised segmentation frameworkdesigned to robustly identify and preserve relevant topological features.

167, TITLE: LOGicalThought: Logic-Based Ontological Grounding of LLMs for High-Assurance Reasoning
AUTHORS: Navapat Nananukul; Yue Zhang; Ryan Lee; Eric Boxer; Jonathan May; Vibhav Giridhar Gogate; Jay Pujara; Mayank Kejriwal
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : In thispaper, we propose a novel neurosymbolically-grounded architecture calledLOGicalThought (LogT) that uses an advanced logical language and reasoner inconjunction with an LLM to construct a dual symbolic graph context andlogic-based context.

168, TITLE: Learning to Look at The Other Side: A Semantic Probing Study of Word Embeddings in LLMs with Enabled Bidirectional Attention
AUTHORS: Zhaoxin Feng; Jianfei Ma; Emmanuele Chersoni; Xiaojing Zhao; Xiaoyi Bao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : However, theirapplication in text embedding tasks has been relatively slow, along with theanalysis of their semantic representation in probing tasks, due to theconstraints of the unidirectional attention mechanism. This paper aims to explore whether such constraints can be overcome byenabling bidirectional attention in LLMs.

169, TITLE: Diffusion Models and The Manifold Hypothesis: Log-Domain Smoothing Is Geometry Adaptive
AUTHORS: Tyler Farghly; Peter Potaptchik; Samuel Howard; George Deligiannidis; Jakiw Pidstrigach
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : A leading conjecture, based on the manifold hypothesis, attributesthis success to their ability to adapt to low-dimensional geometric structurewithin the data. This work provides evidence for this conjecture, focusing onhow such phenomena could result from the formulation of the learning problemthrough score matching.

170, TITLE: Kabr-tools: Automated Framework for Multi-Species Behavioral Monitoring
AUTHORS: Jenna Kline; Maksim Kholiavchenko; Samuel Stevens; Nina van Tiel; Alison Zhong; Namrata Banerji; Alec Sheets; Sowbaranika Balasubramaniam; Isla Duporge; Matthew Thompson; Elizabeth Campolongo; Jackson Miliko; Neil Rosser; Tanya Berger-Wolf; Charles V. Stewart; Daniel I. Rubenstein
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Traditional field observations are often limited in scope,time-consuming, and labor-intensive, hindering the assessment of behavioralresponses across landscapes. To address this, we present kabr-tools (KenyanAnimal Behavior Recognition Tools), an open-source package for automatedmulti-species behavioral monitoring.

171, TITLE: Joint Deblurring and 3D Reconstruction for Macrophotography
AUTHORS: Yifan Zhao; Liangchen Li; Yuqi Zhou; Kai Wang; Yan Liang; Juyong Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, we propose a jointdeblurring and 3D reconstruction method for macrophotography.

172, TITLE: HiSpec: Hierarchical Speculative Decoding for LLMs
AUTHORS: Avinash Kumar; Sujay Sanghavi; Poulami Das
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We propose $ \underline{\textit{Hi}}\textit{erarchical}\underline{\textit{Spec}}\textit{ulative Decoding (HiSpec)}$, a framework forhigh-throughput speculative decoding that exploits $\textit{early-exit (EE)models}$ for low-overhead intermediate verification.

173, TITLE: GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents
AUTHORS: Yejin Kim; Youngbin Lee; Juhyeong Kim; Yongjae Lee
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : This study demonstrates that GuruAgents, prompt-guided AI agents, cansystematically operationalize the strategies of legendary investment gurus.

174, TITLE: Calibrating The Full Predictive Class Distribution of 3D Object Detectors for Autonomous Driving
AUTHORS: Cornelius Schröder; Marius-Raphael Schlüter; Markus Lienkamp
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We propose twoauxiliary regularizing loss terms which introduce either calibration of thedominant prediction or the full prediction vector as a training goal.

175, TITLE: An Algorithmic Information-Theoretic Perspective on The Symbol Grounding Problem
AUTHORS: Zhangchi Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : This paper provides a definitive, unifying framework for the Symbol GroundingProblem (SGP) by reformulating it within Algorithmic Information Theory (AIT).

176, TITLE: Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using GPT-4o: Building A Two-Stage Self-Correction Loop with Structured Output (SLSO) Framework
AUTHORS: Nanaka Hosokawa; Ryo Takahashi; Tomoya Kitano; Yukihiro Iida; Chisako Muramatsu; Tatsuro Hayashi; Yuta Seino; Xiangrong Zhou; Takeshi Hara; Akitoshi Katsumata; Hiroshi Fujita
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this study, we utilized the multimodal capabilities of OpenAI GPT-4o toautomatically generate jaw cyst findings on dental panoramic radiographs.

177, TITLE: ROI-GS: Interest-based Local Quality 3D Gaussian Splatting
AUTHORS: Quoc-Anh Bui; Gilles Rougeron; Géraldine Morin; Simone Gasparini
CATEGORY: arxiv-cs.GR [GR]
HIGHLIGHT: Highlight : We propose ROI-GS, anobject-aware framework that enhances local details through object-guided cameraselection, targeted Object training, and seamless integration of high-fidelityobject of interest reconstructions into the global scene.

178, TITLE: RefineShot: Rethinking Cinematography Understanding with Foundational Skill Evaluation
AUTHORS: Hang Wu; Yujun Cai; Haonan Ge; Hongkai Chen; Ming-Hsuan Yang; Yiwei Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : As the most comprehensivebenchmark for this task, ShotBench spans a wide range of cinematic concepts andVQA-style evaluations, with ShotVL achieving state-of-the-art results on it.However, our analysis reveals that ambiguous option design in ShotBench andShotVL's shortcomings in reasoning consistency and instruction adherenceundermine evaluation reliability, limiting fair comparison and hindering futureprogress. To overcome these issues, we systematically refine ShotBench throughconsistent option restructuring, conduct the first critical analysis ofShotVL's reasoning behavior, and introduce an extended evaluation protocol thatjointly assesses task accuracy and core model competencies.

179, TITLE: From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?
AUTHORS: Hanqun Cao; Hongrui Zhang; Junde Xu; Zhou Zhang; Lingdong Shen; Minghao Sun; Ge Liu; Jinbo Xu; Wu-Jun Li; Jinren Ni; Cesar de la Fuente-Nunez; Tianfan Fu; Yejin Choi; Pheng-Ann Heng; Fang Wu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : Protein language models (PLMs) have advanced computational protein sciencethrough large-scale pretraining and scalable architectures.

180, TITLE: Can AI Truly Represent Your Voice in Deliberations? A Comprehensive Study of Large-Scale Opinion Aggregation with LLMs
AUTHORS: Shenzhe Zhu; Shu Yang; Michiel A. Bakker; Alex Pentland; Jiaxin Pei
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Studying andfixing these issues requires a comprehensive evaluation at a large scale, yetcurrent practice often relies on LLMs as judges, which show weak alignment withhuman judgments. To address this, we present DeliberationBank, a large-scalehuman-grounded dataset with (1) opinion data spanning ten deliberationquestions created by 3,000 participants and (2) summary judgment data annotatedby 4,500 participants across four dimensions (representativeness,informativeness, neutrality, policy approval).

181, TITLE: Rethinking KL Regularization in RLHF: From Value Estimation to Gradient Optimization
AUTHORS: Kezhao Liu; Jason Klein Liu; Mingtao Chen; Yiming Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In contrast, we show that the recently adopted '$k_3$ as loss' (likein GRPO) is merely a first-order, biased approximation of the principled loss.Furthermore, we argue that common off-policy implementations of '$k_n$ as loss'methods are biased due to neglected importance sampling, and we propose aprincipled correction.

182, TITLE: DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing
AUTHORS: Zihan Zhou; Shilin Lu; Shuli Leng; Shaocong Zhang; Zhuming Lian; Xinlei Yu; Adams Wai-Kin Kong
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : This work proposes thefirst framework to effectively harness FLUX's rich prior for drag-basedediting, dubbed DragFlow, achieving substantial gains over baselines.

183, TITLE: Representational Alignment Across Model Layers and Brain Regions with Hierarchical Optimal Transport
AUTHORS: Shaan Shah; Meenakshi Khosla
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We evaluate HOT on vision models, large language models, andhuman visual cortex recordings.

184, TITLE: Beyond Majority Voting: LLM Aggregation By Leveraging Higher-Order Information
AUTHORS: Rui Ai; Yuqi Pan; David Simchi-Levi; Milind Tambe; Haifeng Xu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In thiswork, we design two new aggregation algorithms called Optimal Weight (OW) andInverse Surprising Popularity (ISP), leveraging both first-order andsecond-order information.

185, TITLE: Rethinking The Shape Convention of An MLP
AUTHORS: Meng-Hsi Chen; Yu-Ang Lee; Feng-Ting Liao; Da-shan Shiu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We propose that this projection canremain fixed at random initialization throughout training, enabling efficienttraining and inference implementations.

186, TITLE: How to Find Fantastic Papers: Self-Rankings As A Powerful Predictor of Scientific Impact Beyond Peer Review
AUTHORS: Buxin Su; Natalie Collina; Garrett Wen; Didong Li; Kyunghyun Cho; Jianqing Fan; Bingxin Zhao; Weijie Su
CATEGORY: arxiv-stat.AP [AP]
HIGHLIGHT: Highlight : In this paper, we investigate anunderexplored measure for identifying high-impact research: authors' ownrankings of their multiple submissions to the same AI conference.

187, TITLE: FOR-Prompting: From Objection to Revision Via An Asymmetric Prompting Protocol
AUTHORS: He Zhang; Anzhou Zhang; Jian Dai
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We present FOR-Prompting (FromObjection to Revision Prompting), an asymmetric protocol where a Defenderproposes an answer, an Objectioner raises question-style objections with nodirect fixes, and a Host enforces consistency and closure.

188, TITLE: Machine Learning for Detection and Analysis of Novel LLM Jailbreaks
AUTHORS: John Hawkins; Aditya Pramar; Rodney Beard; Rohitash Chandra
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this study, we analyse the abilityof different machine learning models to distinguish jailbreak prompts fromgenuine uses, including looking at our ability to identify jailbreaks that usepreviously unseen strategies.

189, TITLE: Extreme Value Forecasting Using Relevance-based Data Augmentation with Deep Learning Models
AUTHORS: Junru Hua; Rahul Ahluwalia; Rohitash Chandra
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : In this study, we present a data augmentation framework for extremevalue forecasting.

190, TITLE: BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks
AUTHORS: Sagnik Anupam; Davis Brown; Shuo Li; Eric Wong; Hamed Hassani; Osbert Bastani
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We find, for example, that o4-mini deploys a wider variety of strategiesto circumvent captcha resolution than other models and DeepSeek-R1 consistentlymisleads users about pop-up banner closure.

191, TITLE: LVTINO: LAtent Video ConsisTency INverse SOlver for High Definition Video Restoration
AUTHORS: Alessio Spagnoletti; Andrés Almansa; Marcelo Pereyra
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We address this challenge by leveraging recentadvances in Video Consistency Models (VCMs), which distill video latentdiffusion models into fast generators that explicitly capture temporalcausality. Building on this foundation, we propose LVTINO, the first zero-shotor plug-and-play inverse solver for high definition video restoration withpriors encoded by VCMs.

192, TITLE: Unlocking Vision-Language Models for Video Anomaly Detection Via Fine-Grained Prompting
AUTHORS: Shu Zou; Xinyu Tian; Lukas Wesemann; Fabian Waschkowski; Zhaoyuan Yang; Jing Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Beyond accuracy, our framework provides interpretable reasoning tracestowards anomaly and demonstrates strong generalization across datasets and VLMbackbones.

193, TITLE: Explore Briefly, Then Decide: Mitigating LLM Overthinking Via Cumulative Entropy Regulation
AUTHORS: Tianyi Jiang; Yi Bin; Yujuan Ding; Kainian Zhu; Fei Ma; Jingkuan Song; Heng Tao Shen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : This issue may degrade the efficiency ofthe models and make them difficult to adapt the reasoning depth to thecomplexity of problems. To address this, we introduce a novel metric TokenEntropy Cumulative Average (TECA), which measures the extent of explorationthroughout the reasoning process.

194, TITLE: More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for Diverse Exploration
AUTHORS: Xiaoyang Yuan; Yujuan Ding; Yi Bin; Wenqi Shao; Jinyu Cai; Jingkuan Song; Yang Yang; Heng Tao Shen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : Drawing inspiration from multi-teacherstrategies in knowledge distillation, we introduce Adaptive Multi-GuidancePolicy Optimization (AMPO), a novel framework that adaptively leveragesguidance from multiple proficient teacher models, but only when the on-policymodel fails to generate correct solutions.

195, TITLE: GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation
AUTHORS: Weijia Dou; Xu Zhang; Yi Bin; Jian Liu; Bo Peng; Guoqing Wang; Yang Yang; Heng Tao Shen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : The geometric cues are not eliminated during the2D-to-3D transfer but remain latent within the noisy and view-aggregatedfeatures. To exploit this property, we propose GeoPurify that applies a smallStudent Affinity Network to purify 2D VLM-generated 3D point features usinggeometric priors distilled from a 3D self-supervised teacher model.

196, TITLE: MicroCLIP: Unsupervised CLIP Adaptation Via Coarse-Fine Token Fusion for Fine-Grained Image Classification
AUTHORS: Sathira Silva; Eman Ali; Chetan Arora; Muhammad Haris Khan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We propose $\textbf{microCLIP}$, a self-trainingframework that jointly refines CLIP's visual and textual representations usingfine-grained cues.

197, TITLE: PsychCounsel-Bench: Evaluating The Psychology Intelligence of Large Language Models
AUTHORS: Min Zeng
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : This is because, just asa human counselor must pass a certification exam to practice, an LLM mustdemonstrate sufficient psychological knowledge to meet the standards requiredfor such a role. To address this, we introduce PsychCounsel-Bench, a benchmarkgrounded in U.S.national counselor examinations, a licensure test forprofessional counselors that requires about 70\% accuracy to pass.PsychCounsel-Bench comprises approximately 2,252 carefully curatedsingle-choice questions, crafted to require deep understanding and broad enoughto cover various sub-disciplines of psychology.

198, TITLE: PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal Positional Encoding and Reinforcement Learning
AUTHORS: Raahul Krishna Durairaju; K. Saruladha
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We introduce PyramidStyler, a transformer frameworkwith Pyramidal Positional Encoding (PPE): a hierarchical, multi-scale encodingthat captures both local details and global context while reducingcomputational load.

199, TITLE: StealthAttack: Robust 3D Gaussian Splatting Poisoning Via Density-Guided Illusions
AUTHORS: Bo-Hsu Ke; You-Zhe Xie; Yu-Lun Liu; Wei-Chen Chiu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Our method strategicallyinjects Gaussian points into low-density regions identified via Kernel DensityEstimation (KDE), embedding viewpoint-dependent illusory objects clearlyvisible from poisoned views while minimally affecting innocent views.Additionally, we introduce an adaptive noise strategy to disrupt multi-viewconsistency, further enhancing attack effectiveness.

200, TITLE: VL-KnG: Visual Scene Understanding for Navigation Goal Identification Using Spatiotemporal Knowledge Graphs
AUTHORS: Mohamad Al Mdfaa; Svetlana Lukina; Timur Akhtyamov; Arthur Nigmatzyanov; Dmitrii Nalberskii; Sergey Zagoruyko; Gonzalo Ferrer
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : Vision-language models (VLMs) have shown potential for robot navigation butencounter fundamental limitations: they lack persistent scene memory, offerlimited spatial reasoning, and do not scale effectively with video duration forreal-time application. We present VL-KnG, a Visual Scene Understanding systemthat tackles these challenges using spatiotemporal knowledge graph constructionand computationally efficient query processing for navigation goalidentification.

201, TITLE: HRTFformer: A Spatially-Aware Transformer for Personalized HRTF Upsampling in Immersive Audio Rendering
AUTHORS: Xuyi Hu; Jian Li; Shaojie Zhang; Stefan Goetz; Lorenzo Picinali; Ozgur B. Akan; Aidan O. T. Hogg
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Highlight : To enhance spatialcoherence, we introduce a neighbor dissimilarity loss that promotes magnitudesmoothness, yielding more realistic upsampling.

202, TITLE: VarCoNet: A Variability-aware Self-supervised Framework for Functional Connectome Extraction from Resting-state FMRI
AUTHORS: Charalampos Lamprou; Aamna Alshehhi; Leontios J. Hadjileontiadis; Mohamed L. Seghier
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: Highlight : Here, by considering functional inter-individualvariability as meaningful data rather than noise, we introduce VarCoNet, anenhanced self-supervised framework for robust functional connectome (FC)extraction from resting-state fMRI (rs-fMRI) data.

203, TITLE: VLA-R1: Enhancing Reasoning in Vision-Language-Action Models
AUTHORS: Angen Ye; Zeyu Zhang; Boyuan Wang; Xiaofeng Wang; Dapeng Zhang; Zheng Zhu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : Vision-Language-Action (VLA) models aim to unify perception, languageunderstanding, and action generation, offering strong cross-task andcross-scene generalization with broad impact on embodied AI.

204, TITLE: The Unseen Frontier: Pushing The Limits of LLM Sparsity with Surrogate-Free ADMM
AUTHORS: Kwanhee Lee; Hyeondo Jang; Dongyeop Lee; Dan Alistarh; Namhoon Lee
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : This work breaks through the currentimpasse, presenting a principled and effective method called $\texttt{Elsa}$,which achieves extreme sparsity levels of up to 90% while retaining high modelfidelity.

205, TITLE: ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly Detection
AUTHORS: Sanghyu Yoon; Dongmin Kim; Suhee Yoon; Ye Seul Sim; Seungdong Yoa; Hye-Seung Cho; Soonyoung Lee; Hankook Lee; Woohyung Lim
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Thislimitation restricts research flexibility and prevents models from fullyleveraging domain knowledge for detection. ReTabAD addresses this gap byrestoring textual semantics to enable context-aware tabular AD research.

206, TITLE: REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing
AUTHORS: Thanh Ma; Tri-Tam La; Lam-Thu Le Huu; Minh-Nghi Nguyen; Khanh-Van Pham Luu; Huu-Hoa Nguyen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We construct a regulation specific dataset and evaluate REBoton classification and question answering tasks, achieving state of the artperformance with an F1 score of 98.89%.

207, TITLE: Breaking The Code: Security Assessment of AI Code Agents Through Systematic Jailbreaking Attacks
AUTHORS: Shoumik Saha; Jifan Chen; Sam Mayers; Sanjay Krishna Gouda; Zijian Wang; Varun Kumar
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Highlight : Using seven LLMs from fivefamilies as backends, we find that under prompt-only conditions in JAWS-0, codeagents accept 61% of attacks on average; 58% are harmful, 52% parse, and 27%run end-to-end.

208, TITLE: LadderMoE: Ladder-Side Mixture of Experts Adapters for Bronze Inscription Recognition
AUTHORS: Rixin Zhou; Peiqiang Qiu; Qian Zhang; Chuntao Li; Xi Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : However, automatic BI recognitionremains difficult due to severe visual degradation, multi-domain variabilityacross photographs, rubbings, and tracings, and an extremely long-tailedcharacter distribution. To address these challenges, we curate a large-scale BIdataset comprising 22454 full-page images and 198598 annotated charactersspanning 6658 unique categories, enabling robust cross-domain evaluation.Building on this resource, we develop a two-stage detection-recognitionpipeline that first localizes inscriptions and then transcribes individualcharacters.

209, TITLE: AIReg-Bench: Benchmarking Language Models That Assess AI Regulation Compliance
AUTHORS: Bill Marino; Rosco Hunter; Zubair Jamali; Marinos Emmanouil Kalpakos; Mudra Kashyap; Isaiah Hinton; Alexa Hanson; Maahum Nazir; Christoph Schnabl; Felix Steffek; Hongkai Wen; Nicholas D. Lane
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : However, there is presently no way to benchmark theperformance of LLMs at this task. To fill this void, we introduce AIReg-Bench:the first benchmark dataset designed to test how well LLMs can assesscompliance with the EU AI Act (AIA).

210, TITLE: Retrieval-Augmented Framework for LLM-Based Clinical Decision Support
AUTHORS: Leon Garza; Anantaa Kotal; Michael A. Grasso; Emre Umucu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : This paper proposes a clinicaldecision support system powered by Large Language Models (LLMs) to assistprescribing clinicians.

211, TITLE: FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic Documents for Training Document Understanding Models
AUTHORS: Karan Dua; Hitesh Laxmichand Patel; Puneet Mittal; Ranjeet Gupta; Amit Agarwal; Praneet Pabolu; Srikant Panda; Hansa Meghwani; Graham Horwood; Fahad Shah
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce FlexDoc, ascalable synthetic data generation framework that combines Stochastic Schemasand Parameterized Sampling to produce realistic, multilingual semi-structureddocuments with rich annotations.

212, TITLE: TAG-EQA: Text-And-Graph for Event Question Answering Via Structured Prompting Strategies
AUTHORS: Maithili Kadam; Francis Ferraro
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce TAG-EQA (Text-And-Graph for Event QuestionAnswering), a prompting framework that injects causal event graphs into LLMinputs by converting structured relations into natural-language statements.TAG-EQA spans nine prompting configurations, combining three strategies(zero-shot, few-shot, chain-of-thought) with three input modalities (text-only,graph-only, text+graph), enabling a systematic analysis of when and howstructured knowledge aids inference.

213, TITLE: AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative Recommendation with Adaptive Intelligence
AUTHORS: Bo Ma; Hang Li; ZeHua Hu; XiaoFan Gui; LuYao Liu; Simon Lau
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We propose a three-tierlearning strategy combining rapid response for simple queries, intelligentreasoning for complex preferences, and deep collaboration for challengingscenarios.

214, TITLE: LLM4Rec: Large Language Models for Multimodal Generative Recommendation with Causal Debiasing
AUTHORS: Bo Ma; Hang Li; ZeHua Hu; XiaoFan Gui; LuYao Liu; Simon Lau
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: Highlight : Contemporary generative recommendation systems face significant challenges inhandling multimodal data, eliminating algorithmic biases, and providingtransparent decision-making processes. This paper introduces an enhancedgenerative recommendation framework that addresses these limitations throughfive key innovations: multimodal fusion architecture, retrieval-augmentedgeneration mechanisms, causal inference-based debiasing, explainablerecommendation generation, and real-time adaptive learning capabilities.

215, TITLE: Bridging Collaborative Filtering and Large Language Models with Dynamic Alignment, Multimodal Fusion and Evidence-grounded Explanations
AUTHORS: Bo Ma; LuYao Liu; Simon Lau; Chandler Yuan; and XueY Cui; Rosie Zhang
CATEGORY: arxiv-cs.IR [IR]
HIGHLIGHT: Highlight : Our work introduces \model{}, a framework that tackles theselimitations through three key innovations.

216, TITLE: VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation
AUTHORS: Arman Behnam
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, we propose VGDM: Vision-Guided Diffusion Model for Brain TumorDetection and Segmentation framework, a transformer-driven diffusion frameworkfor brain tumor detection and segmentation.

217, TITLE: Pre-Hoc Predictions in AutoML: Leveraging LLMs to Enhance Model Selection and Benchmarking for Tabular Datasets
AUTHORS: Yannis Belkhiter; Seshu Tirupathi; Giulio Zizzo; Sachin Sharma; John D. Kelleher
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : The field of AutoML has made remarkable progress in post-hoc model selection,with libraries capable of automatically identifying the most performing modelsfor a given dataset. Nevertheless, these methods often rely on exhaustivehyperparameter searches, where methods automatically train and test differenttypes of models on the target dataset.

218, TITLE: Microscaling Floating Point Formats for Large Language Models
AUTHORS: Marco Cococcioni; Dario Pagani; Federico Rossi
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: Highlight : The increasing computational and memory demands of large language models(LLMs) necessitate innovative approaches to optimize resource usage withoutcompromising performance. This paper leverages microscaling floating-pointformats, a novel technique designed to address these challenges by reducing thestorage and computational overhead associated with numerical representations inLLMs.

219, TITLE: Risk Phase Transitions in Spiked Regression: Alignment Driven Benign and Catastrophic Overfitting
AUTHORS: Jiping Li; Rishi Sonthalia
CATEGORY: arxiv-stat.ML [ML]
HIGHLIGHT: Highlight : The study presents anexact expression for the generalization error, leading to a comprehensiveclassification of benign, tempered, and catastrophic overfitting regimes basedon spike strength, the aspect ratio $c=d/n$ (particularly as $c \to \infty$),and target alignment.

220, TITLE: GeoSURGE: Geo-localization Using Semantic Fusion with Hierarchy of Geographic Embeddings
AUTHORS: Angel Daruna; Nicholas Meegan; Han-Pang Chiu; Supun Samarasekera; Rakesh Kumar
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We formulate geo-localization as aligningthe visual representation of the query image with a learned geographicrepresentation.

221, TITLE: Learning Time-Series Representations By Hierarchical Uniformity-Tolerance Latent Balancing
AUTHORS: Amin Jalali; Milad Soltany; Michael Greenspan; Ali Etemad
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : We propose TimeHUT, a novel method for learning time-series representationsby hierarchical uniformity-tolerance balancing of contrastive representations.Our method uses two distinct losses to learn strong representations with theaim of striking an effective balance between uniformity and tolerance in theembedding space.

222, TITLE: Holistic Order Prediction in Natural Scenes
AUTHORS: Pierre Musacchio; Hyunmin Lee; Jaesik Park
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We comprehensively benchmark and ablate our approach to highlightits effectiveness.

223, TITLE: A Novel Algorithm for Representing Positive Semi-Definite Polynomials As Sums of Squares with Rational Coefficients
AUTHORS: Zhenbing Zeng; Yong Huang; Lu Yang; Yongsheng Rao
CATEGORY: arxiv-cs.SC [SC]
HIGHLIGHT: Highlight : This paper presents a novel algorithm for constructing a sum-of-squares (SOS)decomposition for positive semi-definite polynomials with rationalcoefficients.

224, TITLE: BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge Transfer Across Biosignals
AUTHORS: Chenqi Li; Yu Liu; Timothy Denison; Tingting Zhu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Specifically,we introduce an efficient strategy for selecting alignment positions where thebridge should be constructed, along with a flexible prototype network as thebridge architecture.

225, TITLE: REPAIR: Robust Editing Via Progressive Adaptive Intervention and Reintegration
AUTHORS: Yisu Wang; Ming Wang; Haoyuan Song; Wenjie Huang; Chaozheng Wang; Yi Xie; Xuming Ran
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : REPAIR mitigatesthe instability and conflicts of large-scale sequential edits through aclosed-loop feedback mechanism coupled with dynamic memory management.Furthermore, by incorporating frequent knowledge fusion and enforcing stronglocality guards, REPAIR effectively addresses the shortcomings of traditionaldistribution-agnostic approaches that often overlook unintended ripple effects.Our experiments demonstrate that REPAIR boosts editing accuracy by 10%-30%across multiple model families and significantly reduces knowledge forgetting.This work introduces a robust framework for developing reliable, scalable, andcontinually evolving LLMs.

226, TITLE: Minimum Selective Subset on Unit Disk Graphs and Circle Graphs
AUTHORS: Bubai Manna
CATEGORY: arxiv-cs.CG [CG]
HIGHLIGHT: Highlight : On the positive side, we present aPTAS for unit disk graphs, which works without requiring a geometricrepresentation and applies for arbitrary c.

227, TITLE: ClustViT: Clustering-based Token Merging for Semantic Segmentation
AUTHORS: Fabio Montello; Ronja Güldenring; Lazaros Nalpantidis
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : We propose ClustViT, where we expand upon the VisionTransformer (ViT) backbone and address semantic segmentation.

228, TITLE: Predictive Modeling and Explainable AI for Veterinary Safety Profiles, Residue Assessment, and Health Outcomes Using Real-World Data and Physicochemical Properties
AUTHORS: Hossein Sholehrasa; Xuan Xu; Doina Caragea; Jim E. Riviere; Majid Jaberi-Douraki
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Highlight : This study introduces a predictiveframework for classifying outcomes (Death vs. Recovery) using ~1.28 millionreports (1987-2025 Q1) from the U.S. FDA's OpenFDA Center for VeterinaryMedicine.

229, TITLE: Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion
AUTHORS: Yule Wang; Joseph Yu; Chengrui Li; Weihan Li; Anqi Wu
CATEGORY: arxiv-q-bio.NC [NC]
HIGHLIGHT: Highlight : Similarly, decoding-based methods have quantified semantic featuresfrom neural populations but have not uncovered their underlying organizations.This leaves open a scientific question: "how feature-specific visualinformation is distributed across neural populations in higher visual areas,and whether it is organized into structured, semantically meaningfulsubspaces." To tackle this problem, we present MIG-Vis, a method that leveragesthe generative power of diffusion models to visualize and validate thevisual-semantic attributes encoded in neural latent subspaces.

230, TITLE: NeuroSwift: A Lightweight Cross-Subject Framework for FMRI Visual Reconstruction of Complex Scenes
AUTHORS: Shiyi Zhang; Dong Liang; Yihang Zhou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Reconstructing visual information from brain activity via computer visiontechnology provides an intuitive understanding of visual neural mechanisms.Despite progress in decoding ...

231, TITLE: Understanding The Geospatial Reasoning Capabilities of LLMs: A Trajectory Recovery Perspective
AUTHORS: Thinh Hung Truong; Jey Han Lau; Jianzhong Qi
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We frame trajectory recovery as a proxy task, which requires modelsto reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset withover 4,000 real-world trajectories across diverse regions and transportationmodes.

232, TITLE: Fine-tuning with RAG for Improving LLM Learning of New Skills
AUTHORS: Humaid Ibrahim; Nikolai Rozanov; Marek Rei
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Whileretrieval-augmented generation (RAG) can improve performance by providingruntime guidance, it requires maintaining external knowledge databases and addscomputational overhead at every deployment. We propose a simple pipeline thatconverts inference-time retrieval into learned competence through distillation.Our approach: (1) extracts compact, reusable hints from agent failures, (2)uses these hints to generate improved teacher trajectories via one-shotretrieval at episode start, and (3) trains student models on these trajectorieswith hint strings removed, forcing internalization rather than memorization.Across two interactive benchmarks, ALFWorld (household tasks) and WebShop(online shopping), distilled students consistently outperform baseline agents,achieving up to 91% success on ALFWorld (vs. 79% for baselines) and improvingWebShop scores to 72 (vs. 61 for baselines), while using 10-60% fewer tokensthan retrieval-augmented teachers depending on the environment.

233, TITLE: Small Is Sufficient: Reducing The World AI Energy Consumption Through Model Selection
AUTHORS: Tiago da Silva Barros; Frédéric Giroire; Ramon Aparicio-Pardo; Joanna Moulierac
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: Highlight : We explore how the AI community can adopt energy sobriety today by focusingon model selection during inference.

234, TITLE: Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects
AUTHORS: Georgios Kouros; Minye Wu; Tinne Tuytelaars
CATEGORY: arxiv-cs.GR [GR]
HIGHLIGHT: Highlight : We propose a relightable framework that integrates amicrofacet BRDF with the specular-glossiness parameterization into 2D GaussianSplatting with deferred shading.

235, TITLE: VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation
AUTHORS: Arthur Zhang; Xiangyun Meng; Luca Calliari; Dong-Ki Kim; Shayegan Omidshafiei; Joydeep Biswas; Ali Agha; Amirreza Shaban
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Highlight : Towards addressingthis, we introduce VENTURA, a vision-language navigation system that finetunesinternet-pretrained image diffusion models for path planning.

236, TITLE: RealClass: A Framework for Classroom Speech Simulation with Public Datasets and Game Engines
AUTHORS: Ahmed Adel Attia; Jing Liu; Carol Espy Wilson
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Highlight : In this paper, we introduce a scalable methodology for synthesizing classroomnoise and RIRs using game engines, a versatile framework that can extend toother domains beyond the classroom.

237, TITLE: GFSR-Net: Guided Focus Via Segment-Wise Relevance Network for Interpretable Deep Learning in Medical Imaging
AUTHORS: Jhonatan Contreras; Thomas Bocklitz
CATEGORY: arxiv-eess.IV [IV]
HIGHLIGHT: Highlight : We introduce the Guided Focus via Segment-Wise RelevanceNetwork (GFSR-Net), an approach designed to improve interpretability andreliability in medical imaging.

238, TITLE: The Current State of AI Bias Bounties: An Overview of Existing Programmes and Research
AUTHORS: Sergej Kucenko; Nathaniel Dennler; Fengxiang He
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: Highlight : In the absence of a state-of-the-art review, this survey aimed toidentify and analyse existing AI bias bounty programmes and to present academicliterature on bias bounties.

239, TITLE: From Keywords to Semantics: Perceptions of Large Language Models in Data Discovery
AUTHORS: Maura E Halstead; Mark A. Green; Caroline Jay; Richard Kingston; David Topping; Alexander Singleton
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: Highlight : This matching requires researchers to know the exact wording thatother researchers previously used, creating a challenging process that couldlead to missing relevant data. Large Language Models (LLMs) could enhance datadiscovery by removing this requirement and allowing researchers to askquestions with natural language.

240, TITLE: Aligning Video Models with Human Social Judgments Via Behavior-Guided Fine-Tuning
AUTHORS: Kathy Garcia; Leyla Isik
CATEGORY: arxiv-q-bio.NC [NC]
HIGHLIGHT: Highlight : We study (Q1) whether modern video and language models capturehuman-perceived similarity in social videos, and (Q2) how to instill thisstructure into models using human behavioral data.

241, TITLE: Human-AI Teaming Co-Learning in Military Operations
AUTHORS: Clara Maathuis; Kasper Cools
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: In a time of rapidly evolving military threats and increasingly complexoperational environments, the integration of AI into military operations provessignificant advantages. At ...

242, TITLE: Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents
AUTHORS: Lingzhong Dong; Ziqi Zhou; Shuaibo Yang; Haiyue Sheng; Pengzhou Cheng; Zongru Wu; Zheng Wu; Gongshen Liu; Zhuosheng Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : In this work, we introduce a new evaluation framework todiagnose reasoning-execution gaps.

243, TITLE: LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction
AUTHORS: Sheng-Hsiang Hung; Ting-Yu Yen; Wei-Fang Sun; Simon See; Shih-Hsuan Hung; Hung-Kuo Chu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Highlight : In this work, we introduce LoBE-GS, a novelLoad-Balanced and Efficient 3D Gaussian Splatting framework, that re-engineersthe large-scale 3DGS pipeline.

244, TITLE: Chronological Thinking in Full-Duplex Spoken Dialogue Language Models
AUTHORS: Donghang Wu; Haoyang Zhang; Chen Chen; Tianyu Zhang; Fei Tian; Xuerui Yang; Gang Yu; Hexin Liu; Nana Hou; Yuchen Hu; Eng Siong Chng
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : However, during the listening phase, existing systems keep the agent idle byrepeatedly predicting the silence token, which departs from human behavior: weusually engage in lightweight thinking during conversation rather thanremaining absent-minded. Inspired by this, we propose Chronological Thinking, aon-the-fly conversational thinking mechanism that aims to improve responsequality in full-duplex SDLMs.

245, TITLE: ReSSFormer: A Recursive Sparse Structured Transformer for Scalable and Long-Context Reasoning
AUTHORS: Haochen You; Baojing Liu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: While Transformer architectures have demonstrated impressive scalabilityacross domains, they continue to face challenges in long-context reasoning,computational efficiency, and ...

246, TITLE: Plan Then Action:High-Level Planning Guidance Reinforcement Learning for LLM Reasoning
AUTHORS: Zhihao Dou; Qinjian Zhao; Zhongwei Wan; Dinggen Zhang; Weida Wang; Towsif Raiyan; Benteng Chen; Qingtao Pan; Yang Ouyang; Zhiqiang Gao; Shufei Zhang; Sumon Biswas
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : Existingapproaches, such as tree-based algorithms and reinforcement learning (RL),attempt to address this issue but suffer from high computational costs andoften fail to produce optimal reasoning trajectories. To tackle this challenge,we propose Plan-Then-Action Enhanced Reasoning with Group Relative PolicyOptimization PTA-GRPO, a two-stage framework designed to improve bothhigh-level planning and fine-grained CoT reasoning.

247, TITLE: Aristotle: IMO-level Automated Theorem Proving
AUTHORS: Tudor Achim; Alex Best; Kevin Der; Mathïs Fédérico; Sergei Gukov; Daniel Halpern-Leister; Kirsten Henningsgard; Yury Kudryashov; Alexander Meiburg; Martin Michelsen; Riley Patterson; Eric Rodriguez; Laura Scharff; Vikram Shanker; Vladmir Sicca; Hari Sowrirajan; Aidan Swope; Matyas Tamas; Vlad Tenev; Jonathan Thomm; Harold Williams; Lawrence Wu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce Aristotle, an AI system that combines formal verification withinformal reasoning, achieving gold-medal-equivalent performance on the 2025International Mathematical Olympiad problems.

248, TITLE: A Locally Executable AI System for Improving Preoperative Patient Communication: A Multi-Domain Clinical Evaluation
AUTHORS: Motoki Sato; Yuki Matsushita; Hidekazu Takahashi; Tomoaki Kakazu; Sou Nagata; Mizuho Ohnuma; Atsushi Yoshikawa; Masayuki Yamamura
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We present LENOHA (Low Energy, No Hallucination, LeaveNo One Behind Architecture), a safety-first, local-first system that routesinputs with a high-precision sentence-transformer classifier and returnsverbatim answers from a clinician-curated FAQ for clinical queries, eliminatingfree-text generation in the clinical path.

249, TITLE: OntoLogX: Ontology-Guided Knowledge Graph Extraction from Cybersecurity Logs with Large Language Models
AUTHORS: Luca Cotti; Idilio Drago; Anisa Rula; Devis Bianchini; Federico Cerutti
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Highlight : We introduce OntoLogX, an autonomous Artificial Intelligence(AI) agent that leverages Large Language Models (LLMs) to transform raw logsinto ontology-grounded Knowledge Graphs (KGs).

250, TITLE: Style Over Story: A Process-Oriented Study of Authorial Creativity in Large Language Models
AUTHORS: Donghoon Jung; Jiwoo Choi; Songeun Chae; Seohyon Jung
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Highlight : We introduce constraint-baseddecision-making as a lens for authorial creativity.

