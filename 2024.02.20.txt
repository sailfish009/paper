
1, TITLE: KMMLU: Measuring Massive Multitask Language Understanding in Korean
AUTHORS: GUIJIN SON et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose KMMLU, a new Korean benchmark with 35,030 expert-level multiple-choice questions across 45 subjects ranging from humanities to STEM.

2, TITLE: Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis
AUTHORS: CHRISTIAN REISER et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, density fields often represent geometry in a "fuzzy" manner, which hinders exact localization of the surface. In this work, we modify density fields to encourage them to converge towards surfaces, without compromising their ability to reconstruct thin structures.

3, TITLE: ARKS: Active Retrieval in Knowledge Soup for Code Generation
AUTHORS: HONGJIN SU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce Active Retrieval in Knowledge Soup (ARKS), an advanced strategy for generalizing large language models for code.

4, TITLE: What Evidence Do Language Models Find Convincing?
AUTHORS: Alexander Wan ; Eric Wallace ; Dan Klein
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: . In this work, we study how LLMs answer this question.

5, TITLE: ROSE Doesn't Do That: Boosting The Safety of Instruction-Tuned Large Language Models with Reverse Prompt Contrastive Decoding
AUTHORS: Qihuang Zhong ; Liang Ding ; Juhua Liu ; Bo Du ; Dacheng Tao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we present reverse prompt contrastive decoding (ROSE), a simple-yet-effective method to directly boost the safety of existing instruction-tuned LLMs without any additional training.

6, TITLE: Revisiting Knowledge Distillation for Autoregressive Language Models
AUTHORS: QIHUANG ZHONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In response to this problem, we conduct a series of analyses and reveal that different tokens have different teaching modes, neglecting which will lead to performance degradation. Motivated by this, we propose a simple yet effective adaptive teaching approach (ATKD) to improve the KD.

7, TITLE: Learning By Reconstruction Produces Uninformative Features For Perception
AUTHORS: Randall Balestriero ; Yann LeCun
CATEGORY: cs.CV [cs.CV, cs.AI, stat.ML]
HIGHLIGHT: Despite interpretability of the reconstruction and generation, we identify a misalignment between learning by reconstruction, and learning for perception.

8, TITLE: Token-Ensemble Text Generation: On Attacking The Automatic AI-Generated Text Detection
AUTHORS: Fan Huang ; Haewoon Kwak ; Jisun An
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study proposes a novel token-ensemble generation strategy to challenge the robustness of current AI-content detection approaches.

9, TITLE: Can Large Multimodal Models Uncover Deep Semantics Behind Images?
AUTHORS: Yixin Yang ; Zheng Li ; Qingxiu Dong ; Heming Xia ; Zhifang Sui
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we introduce DEEPEVAL, a comprehensive benchmark to assess Large Multimodal Models' (LMMs) capacities of visual deep semantics.

10, TITLE: ChatGPT Based Data Augmentation for Improved Parameter-Efficient Debiasing of LLMs
AUTHORS: PENGRUI HAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY, 68T50, I.2.7; K.4.1]
HIGHLIGHT: This work introduces a novel approach utilizing ChatGPT to generate synthetic training data, aiming to enhance the debiasing of LLMs.

11, TITLE: KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning Over Knowledge Graph
AUTHORS: JINHAO JIANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions.

12, TITLE: Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs
AUTHORS: JIEJUN TAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a novel collaborative approach, namely SlimPLM, that detects missing knowledge in LLMs with a slim proxy model, to enhance the LLM's knowledge acquisition process.

13, TITLE: Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding
AUTHORS: ZHUOMING CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces Sequoia, a scalable, robust, and hardware-aware algorithm for speculative decoding.

14, TITLE: MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization
AUTHORS: ZHIYU YANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks.

15, TITLE: LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative Tasks
AUTHORS: HANQING WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we propose LoRA-Flow, which utilizes dynamic weights to adjust the impact of different LoRAs.

16, TITLE: Question Answering Over Spatio-Temporal Knowledge Graph
AUTHORS: Xinbang Dai ; Huiying Li ; Guilin Qi
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.4; I.2.7]
HIGHLIGHT: In response, we propose STCQA, a new spatio-temporal KGQA approach that utilizes a novel STKG embedding method named STComplEx.

17, TITLE: Counter-intuitive: Large Language Models Can Better Understand Knowledge Graphs Than We Thought
AUTHORS: Xinbang Dai ; Yuncheng Hua ; Tongtong Wu ; Yang Sheng ; Guilin Qi
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.4; I.2.7]
HIGHLIGHT: In this paper, we employ complex question answering (CQA) as a task to assess the LLM's ability of comprehending KG knowledge.

18, TITLE: Federated Fine-tuning of Large Language Models Under Heterogeneous Language Tasks and Client Resources
AUTHORS: Jiamu Bai ; Daoyuan Chen ; Bingchen Qian ; Liuyi Yao ; Yaliang Li
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Federated Fine-tuning of Large Language Models Under Heterogeneous Language Tasks and Client Resources

19, TITLE: Language Models As Science Tutors
AUTHORS: ALEXIS CHEVALIER et. al.
CATEGORY: physics.ed-ph [physics.ed-ph, cs.AI, cs.CL]
HIGHLIGHT: However, model development has not focused on real-life use-cases of LMs for science, including applications in education that require processing long scientific documents. To address this, we introduce TutorEval and TutorChat.

20, TITLE: Direct Large Language Model Alignment Through Self-Rewarding Contrastive Prompt Distillation
AUTHORS: AIWEI LIU et. al.
CATEGORY: cs.CL [cs.CL, 68T50, I.2.7]
HIGHLIGHT: In this paper, we propose a method to evaluate the response preference by using the output probabilities of response pairs under contrastive prompt pairs, which could achieve better performance on LLaMA2-7B and LLaMA2-13B compared to RLAIF. Based on this, we propose an automatic alignment method, Direct Large Model Alignment (DLMA).

21, TITLE: Training Language Model Agents Without Modifying Language Models
AUTHORS: SHAOKUN ZHANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications.

22, TITLE: Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models
AUTHORS: Christian Schlarmann ; Naman Deep Singh ; Francesco Croce ; Matthias Hein
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, stat.ML]
HIGHLIGHT: We propose an unsupervised adversarial fine-tuning scheme to obtain a robust CLIP vision encoder, which yields robustness on all vision down-stream tasks (VLMs, zero-shot classification) that rely on CLIP.

23, TITLE: GTBench: Uncovering The Strategic Reasoning Limitations of LLMs Via Game-Theoretic Evaluations
AUTHORS: JINHAO DUAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: As Large Language Models (LLMs) are integrated into critical real-world applications, their strategic and logical reasoning abilities are increasingly crucial.

24, TITLE: Adaptive Skeleton Graph Decoding
AUTHORS: SHUOWEI JIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose Skeleton Graph Decoding (SGD), which uses dependencies exposed between sub-problems to support information forwarding between dependent sub-problems for improved quality while exposing parallelization opportunities for decoding independent sub-problems.

25, TITLE: OneBit: Towards Extremely Low-bit Large Language Models
AUTHORS: YUZHUANG XU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper boldly quantizes the weight matrices of LLMs to 1-bit, paving the way for the extremely low bit-width deployment of LLMs. For this target, we introduce a 1-bit quantization-aware training (QAT) framework named OneBit, including a novel 1-bit parameter representation method to better quantize LLMs as well as an effective parameter initialization method based on matrix decomposition to improve the convergence speed of the QAT framework.

26, TITLE: Syntactic Language Change in English and German: Metrics, Parsers, and Convergences
AUTHORS: YANRAN CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance.

27, TITLE: Language Models Are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models Through Task Arithmetic
AUTHORS: Rishabh Bhardwaj ; Do Duc Anh ; Soujanya Poria
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Aligned language models face a significant limitation as their fine-tuning often results in compromised safety. To tackle this, we propose a simple method RESTA that performs LLM safety realignment.

28, TITLE: Perils of Self-Feedback: Self-Bias Amplifies in Large Language Models
AUTHORS: WENDA XU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We discovered that such a contrary is due to LLM's bias towards their own output. In this paper, we formally define LLM's self-bias -- the tendency to favor its own generation -- using two statistics.

29, TITLE: Have Seen Me Before? Automating Dataset Updates Towards Reliable and Timely Evaluation
AUTHORS: JIAHAO YING et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose to automate dataset updates for reliable and timely evaluation.

30, TITLE: AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling
AUTHORS: JUN ZHAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music.

31, TITLE: Direct Consistency Optimization for Compositional Text-to-Image Personalization
AUTHORS: Kyungmin Lee ; Sangkyung Kwak ; Kihyuk Sohn ; Jinwoo Shin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, they still lack in synthesizing images of different scenarios or styles that are possible in the original pretrained models. To address this, we propose to fine-tune the T2I model by maximizing consistency to reference images, while penalizing the deviation from the pretrained model.

32, TITLE: M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text Detection
AUTHORS: YUXIA WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The need to identify and differentiate such content from genuine human-generated text is critical in combating disinformation, preserving the integrity of education and scientific fields, and maintaining trust in communication. In this work, we address this problem by introducing a new benchmark involving multilingual, multi-domain and multi-generator for MGT detection -- M4GT-Bench.

33, TITLE: Multi-Task Inference: Can Large Language Models Follow Multiple Instructions at Once?
AUTHORS: Guijin Son ; Sangwon Baek ; Sangdae Nam ; Ilgyun Jeong ; Seungone Kim
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we analyze whether LLMs also hold the capability to handle multiple instructions simultaneously, denoted as Multi-Task Inference.

34, TITLE: Evaluating Program Repair with Semantic-Preserving Transformations: A Naturalness Assessment
AUTHORS: Thanh Le-Cong ; Dat Nguyen ; Bach Le ; Toby Murray
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: In this paper, we investigate the naturalness of semantic-preserving transformations and their impacts on the evaluation of NPR.

35, TITLE: DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models
AUTHORS: XIAOYU TIAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce DriveVLM, an autonomous driving system leveraging Vision-Language Models (VLMs) for enhanced scene understanding and planning capabilities.

36, TITLE: A Chinese Dataset for Evaluating The Safeguards in Large Language Models
AUTHORS: YUXIA WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Warning: this paper contains example data that may be offensive, harmful, or biased.

37, TITLE: Learning From Failure: Integrating Negative Examples When Fine-tuning Large Language Models As Agents
AUTHORS: Renxi Wang ; Haonan Li ; Xudong Han ; Yixuan Zhang ; Timothy Baldwin
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: In this paper, we contend that large language models can learn from failures through appropriate data cleaning and fine-tuning strategies.

38, TITLE: K-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text
AUTHORS: Abe Bohan Hou ; Jingyu Zhang ; Yichen Wang ; Daniel Khashabi ; Tianxing He
CATEGORY: cs.CL [cs.CL, cs.CR, cs.CY, cs.LG]
HIGHLIGHT: We propose k-SemStamp, a simple yet effective enhancement of SemStamp, utilizing k-means clustering as an alternative of LSH to partition the embedding space with awareness of inherent semantic structure.

39, TITLE: Emergent Word Order Universals from Cognitively-Motivated Language Models
AUTHORS: TATSUKI KURIBAYASHI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We study the word-order universals through a computational simulation with language models (LMs).

40, TITLE: Universal Physics Transformers
AUTHORS: BENEDIKT ALKIN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, physics.flu-dyn]
HIGHLIGHT: We introduce Universal Physics Transformers (UPTs), a novel learning paradigm which models a wide range of spatio-temporal problems - both for Lagrangian and Eulerian discretization schemes.

41, TITLE: Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!
AUTHORS: ZHANHUI ZHOU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This framework, named Emulated Disalignment (ED), adversely combines a pair of open-source pre-trained and safety-aligned language models in the output space to produce a harmful language model without any training.

42, TITLE: ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning
AUTHORS: RENQIU XIA et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, to comprehensively and rigorously benchmark the ability of the off-the-shelf MLLMs in the chart domain, we construct ChartX, a multi-modal evaluation set covering 18 chart types, 7 chart tasks, 22 disciplinary topics, and high-quality chart data.

43, TITLE: Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models
AUTHORS: Sijia Chen ; Baochun Li ; Di Niu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem.

44, TITLE: Uncovering Latent Human Wellbeing in Language Model Embeddings
AUTHORS: Pedro Freire ; ChengCheng Tan ; Adam Gleave ; Dan Hendrycks ; Scott Emmons
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG, I.2.7]
HIGHLIGHT: Do language models implicitly learn a concept of human wellbeing?

45, TITLE: Aligning Modalities in Vision Large Language Models Via Preference Fine-tuning
AUTHORS: Yiyang Zhou ; Chenhang Cui ; Rafael Rafailov ; Chelsea Finn ; Huaxiu Yao
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: In this work, we frame the hallucination problem as an alignment issue, tackle it with preference tuning.

46, TITLE: BEARS Make Neuro-Symbolic Models Aware of Their Reasoning Shortcuts
AUTHORS: EMANUELE MARCONATO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge - encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts.

47, TITLE: Continual Learning on Graphs: Challenges, Solutions, and Opportunities
AUTHORS: Xikun Zhang ; Dongjin Song ; Dacheng Tao
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To bridge the gap, we provide a comprehensive review of existing continual graph learning (CGL) algorithms by elucidating the different task settings and categorizing the existing methods based on their characteristics.

48, TITLE: DB-LLM: Accurate Dual-Binarization for Efficient LLMs
AUTHORS: HONG CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we empirically relieve the micro and macro characteristics of ultra-low bit quantization and present a novel Dual-Binarization method for LLMs, namely DB-LLM.

49, TITLE: Towards Theoretical Understandings of Self-Consuming Generative Models
AUTHORS: Shi Fu ; Sen Zhang ; Yingjie Wang ; Xinmei Tian ; Dacheng Tao
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper tackles the emerging challenge of training generative models within a self-consuming loop, wherein successive generations of models are recursively trained on mixtures of real and synthetic data from previous generations. We construct a theoretical framework to rigorously evaluate how this training regimen impacts the data distributions learned by future models.

50, TITLE: Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation
AUTHORS: Siyuan Wang ; Zhuohan Long ; Zhihao Fan ; Zhongyu Wei ; Xuanjing Huang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations.

51, TITLE: LongAgent: Scaling Language Models to 128k Context Through Multi-Agent Collaboration
AUTHORS: JUN ZHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose \textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4.

52, TITLE: Advancing Translation Preference Modeling with RLHF: A Step Towards Cost-Effective Solution
AUTHORS: NUO XU et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we explore leveraging reinforcement learning with human feedback (\textit{RLHF}) to improve translation quality.

53, TITLE: LLM Can Achieve Self-Regulation Via Hyperparameter Aware Generation
AUTHORS: SIYIN WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address the aforementioned challenges, we propose a novel text generation paradigm termed Hyperparameter Aware Generation (HAG).

54, TITLE: Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models
AUTHORS: WENXUAN WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: To this end, we introduce Asclepius, a novel Med-MLLM benchmark that rigorously and comprehensively assesses model capability in terms of: distinct medical specialties (cardiovascular, gastroenterology, etc.) and different diagnostic capacities (perception, disease analysis, etc.).

55, TITLE: Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement
AUTHORS: CHENKAI SUN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: In this work, we examine the problem from a novel angle, focusing on how data can be better represented for more efficient retrieval in the context of LLM customization.

56, TITLE: LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation
AUTHORS: KEYANG XUAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We find that even though LVLM has a superior performance compared to LLMs, its profound reasoning may present limited power with a lack of evidence. Based on these observations, we propose LEMMA: LVLM-Enhanced Multimodal Misinformation Detection with External Knowledge Augmentation.

57, TITLE: Query-Based Adversarial Prompt Generation
AUTHORS: Jonathan Hayase ; Ema Borevkovic ; Nicholas Carlini ; Florian Tram�r ; Milad Nasr
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.LG]
HIGHLIGHT: We improve on prior work with a query-based attack that leverages API access to a remote language model to construct adversarial examples that cause the model to emit harmful strings with (much) higher probability than with transfer-only attacks.

58, TITLE: EVEDIT: Event-based Knowledge Editing with Deductive Editing Boundaries
AUTHORS: JIATENG LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Such editing methods could thus encounter an uncertain editing boundary, leaving a lot of relevant knowledge in ambiguity: Queries that could be answered pre-edit cannot be reliably answered afterward. In this work, we analyze this issue by introducing a theoretical framework for KE that highlights an overlooked set of knowledge that remains unchanged and aids in knowledge deduction during editing, which we name as the deduction anchor.

59, TITLE: DiLightNet: Fine-grained Lighting Control for Diffusion-based Image Generation
AUTHORS: CHONG ZENG et. al.
CATEGORY: cs.CV [cs.CV, cs.GR]
HIGHLIGHT: This paper presents a novel method for exerting fine-grained lighting control during text-driven diffusion-based image generation.

60, TITLE: Efficient Multimodal Learning from Data-centric Perspective
AUTHORS: MUYANG HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we demonstrate the possibility to beat the scaling law and train a smaller but better MLLM by exploring more informative training data.

61, TITLE: ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model
AUTHORS: GUIMING HARDY CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study aims to bridge the performance gap between traditional-scale LVLMs and resource-friendly lite versions by adopting high-quality training data.

62, TITLE: AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning Via Controllable Question Decomposition
AUTHORS: ZHAORUN CHEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recent advancements in large language models (LLMs) have shown promise in multi-step reasoning tasks, yet their reliance on extensive manual labeling to provide procedural feedback remains a significant impediment. To address this challenge, in this paper, we propose a novel self-supervised framework AutoPRM that efficiently enhances the fine-tuning of LLMs for intricate reasoning challenges.

63, TITLE: SciAgent: Tool-augmented Language Models for Scientific Reasoning
AUTHORS: YUBO MA et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning.

64, TITLE: Understanding The Impact of Long-Term Memory on Self-Disclosure with Large Language Model-Driven Chatbots for Public Health Intervention
AUTHORS: Eunkyung Jo ; Yuin Jeong ; SoHyun Park ; Daniel A. Epstein ; Young-Ho Kim
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CL, H.5.2; I.2.7]
HIGHLIGHT: We examine the case of CareCall -- an LLM-driven voice chatbot with LTM -- through the analysis of 1,252 call logs and interviews with nine users.

65, TITLE: Numerical Claim Detection in Finance: A New Financial Dataset, Weak-Supervision Model, and Market Analysis
AUTHORS: AGAM SHAH et. al.
CATEGORY: cs.CL [cs.CL, cs.LG, q-fin.CP]
HIGHLIGHT: In this paper, we investigate the influence of claims in analyst reports and earnings calls on financial market returns, considering them as significant quarterly events for publicly traded companies.

66, TITLE: Extensible Embedding: A Flexible Multipler For LLM's Context Length
AUTHORS: Ninglu Shao ; Shitao Xiao ; Zheng Liu ; Peitian Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose Extensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness.

67, TITLE: Computing Voting Rules with Elicited Incomplete Votes
AUTHORS: Daniel Halpern ; Safwan Hossain ; Jamie Tucker-Foltz
CATEGORY: cs.GT [cs.GT, cs.AI]
HIGHLIGHT: Motivated by the difficulty of specifying complete ordinal preferences over a large set of $m$ candidates, we study voting rules that are computable by querying voters about $t < m$ candidates.

68, TITLE: The Male CEO and The Female Assistant: Probing Gender Biases in Text-To-Image Models Through Paired Stereotype Test
AUTHORS: Yixin Wan ; Kai-Wei Chang
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CY]
HIGHLIGHT: Potential biases in this setting remain unexplored, leading to fairness-related risks in usage. To study these underlying facets of gender biases in T2I models, we propose a novel Paired Stereotype Test (PST) bias evaluation framework.

69, TITLE: EmoBench: Evaluating The Emotional Intelligence of Large Language Models
AUTHORS: SAHAND SABOUR et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We propose EmoBench, a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI, including Emotional Understanding and Emotional Application.

70, TITLE: Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking Dialogs
AUTHORS: ARIAN ASKARI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we focus on leveraging LLMs for zero-shot generation of large-scale, open-domain, and intent-aware information-seeking dialogs.

71, TITLE: Contrastive Instruction Tuning
AUTHORS: TIANYI YAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Accordingly, we propose Contrastive Instruction Tuning, which maximizes the similarity between the hidden representations of semantically equivalent instruction-instance pairs while minimizing the similarity between semantically different ones.

72, TITLE: GNNavi: Navigating The Information Flow in Large Language Models By Graph Neural Network
AUTHORS: Shuzhou Yuan ; Ercong Nie ; Michael F�rber ; Helmut Schmid ; Hinrich Sch�tze
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Prompt-based fine-tuning proves to be an effective fine-tuning method in low-data scenarios, but high demands on computing resources limit its practicality. We address this issue by introducing a prompt-based parameter-efficient fine-tuning (PEFT) approach.

73, TITLE: MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization
AUTHORS: Yasaman Jafari ; Dheeraj Mekala ; Rose Yu ; Taylor Berg-Kirkpatrick
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we adapt several techniques for multi-objective optimization to RL-based discrete prompt optimization -- two that consider volume of the Pareto reward surface, and another that chooses an update direction that benefits all rewards simultaneously.

74, TITLE: Speculative Streaming: Fast LLM Inference Without Auxiliary Models
AUTHORS: NIKHIL BHENDAWADE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: We propose Speculative Streaming, a single-model speculative decoding method that fuses drafting into the target model by changing the fine-tuning objective from next token prediction to future n-gram prediction.

75, TITLE: TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs
AUTHORS: Siheng Xiong ; Yuan Yang ; Faramarz Fekri ; James Clayton Kerce
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose TILP, a differentiable framework for temporal logical rules learning.

76, TITLE: FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence
AUTHORS: SEBASTIAN ANTONY JOSEPH et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment.

77, TITLE: Pan-Mamba: Effective Pan-sharpening with State Space Model
AUTHORS: XUANHUA HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our contribution, Pan-Mamba, represents a novel pansharpening network that leverages the efficiency of the Mamba model in global information modeling.

78, TITLE: Hierarchical Prior-based Super Resolution for Point Cloud Geometry Compression
AUTHORS: Dingquan Li ; Kede Ma ; Jing Wang ; Ge Li
CATEGORY: eess.IV [eess.IV, cs.CV, cs.MM]
HIGHLIGHT: This paper proposes a hierarchical prior-based super resolution method for point cloud geometry compression.

79, TITLE: A Multi-Aspect Framework for Counter Narrative Evaluation Using Large Language Models
AUTHORS: Jaylen Jones ; Lingbo Mo ; Eric Fosler-Lussier ; Huan Sun
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs.

80, TITLE: AFaCTA: Assisting The Annotation of Factual Claim Detection with Reliable LLM Annotators
AUTHORS: JINGWEI NI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To address (1), we review the definitions in related work and propose a unifying definition of factual claims that focuses on verifiability.

81, TITLE: Benchmarking Knowledge Boundary for Large Language Model: A Different Perspective on Model Evaluation
AUTHORS: Xunjian Yin ; Xu Zhang ; Jie Ruan ; Xiaojun Wan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To explore the knowledge boundary for a given model, we propose projected gradient descent method with semantic constraints, a new algorithm designed to identify the optimal prompt for each piece of knowledge.

82, TITLE: Are LLM-based Evaluators Confusing NLG Quality Criteria?
AUTHORS: XINYU HU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Inspired by behavioral testing, we elaborately design 18 types of aspect-targeted perturbation attacks for fine-grained analysis of the evaluation behaviors of different LLMs.

83, TITLE: When LLMs Meet Cunning Questions: A Fallacy Understanding Benchmark for Large Language Models
AUTHORS: YINGHUI LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we challenge the reasoning and understanding abilities of LLMs by proposing a FaLlacy Understanding Benchmark (FLUB) containing cunning questions that are easy for humans to understand but difficult for models to grasp.

84, TITLE: Rethinking The Roles of Large Language Models in Chinese Grammatical Error Correction
AUTHORS: YINGHUI LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Recently, Large Language Models (LLMs) have been widely studied by researchers for their roles in various downstream NLP tasks.

85, TITLE: Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large Language Models
AUTHORS: DIDI ZHU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents a comprehensive analysis of catastrophic forgetting in MLLMs and introduces a post-training adjustment method called Model Tailor.

86, TITLE: Is It A Free Lunch for Removing Outliers During Pretraining?
AUTHORS: Baohao Liao ; Christof Monz
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Interestingly, we observed that such an approach leads to performance degradation in full precision. Building on this insight, we enhance the method by ensuring its normalization is invariant to sequence length, a crucial factor for bridging the gap between pretraining and fine-tuning.

87, TITLE: EventRL: Enhancing Event Extraction with Outcome Supervision for Large Language Models
AUTHORS: Jun Gao ; Huan Zhao ; Wei Wang ; Changlong Yu ; Ruifeng Xu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we present EventRL, a reinforcement learning approach developed to enhance event extraction for large language models (LLMs).

88, TITLE: Where It Really Matters: Few-Shot Environmental Conservation Media Monitoring for Low-Resource Languages
AUTHORS: SAMEER JAIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: In this paper, we propose NewsSerow, a method to automatically recognize environmental conservation content in low-resource languages.

89, TITLE: TC-DiffRecon: Texture Coordination MRI Reconstruction Method Based on Diffusion Model and Modified MF-UNet Method
AUTHORS: CHENYAN ZHANG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: In the same vein, some deep learning-based models often suffer from poor generalization performance, meaning their effectiveness is greatly affected by different acceleration factors. To address these challenges, we propose a novel diffusion model-based MRI reconstruction method, named TC-DiffRecon, which does not rely on a specific acceleration factor for training.

90, TITLE: LLM Agents for Psychology: A Study on Gamified Assessments
AUTHORS: QISEN YANG et. al.
CATEGORY: cs.CL [cs.CL, cs.CY, cs.HC, cs.LG, cs.MA]
HIGHLIGHT: In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment.

91, TITLE: Automatic Evaluation for Mental Health Counseling Using LLMs
AUTHORS: ANQI LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Existing methods that rely on self or third-party manual reports to assess the quality of counseling suffer from subjective biases and limitations of time-consuming. To address above challenges, this paper proposes an innovative and efficient automatic approach using large language models (LLMs) to evaluate the working alliance in counseling conversations.

92, TITLE: Unveiling The Secrets of Engaging Conversations: Factors That Keep Users Hooked on Role-Playing Dialog Agents
AUTHORS: SHUAI ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate the factors influencing retention rates in real interactions with roleplaying models.

93, TITLE: A Systematic Comparison of Contextualized Word Embeddings for Lexical Semantic Change
AUTHORS: Francesco Periti ; Nina Tahmasebi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we evaluate state-of-the-art models and approaches for GCD under equal conditions.

94, TITLE: Compression Repair for Feedforward Neural Networks Based on Model Equivalence Evaluation
AUTHORS: Zihao Mo ; Yejiang Yang ; Shuaizheng Lu ; Weiming Xiang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a method of repairing compressed Feedforward Neural Networks (FNNs) based on equivalence evaluation of two neural networks.

95, TITLE: PhySU-Net: Long Temporal Context Transformer for RPPG with Self-Supervised Pre-training
AUTHORS: Marko Savic ; Guoying Zhao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose PhySU-Net, the first long spatial-temporal map rPPG transformer network and a self-supervised pre-training strategy that exploits unlabeled data to improve our model.

96, TITLE: An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection
AUTHORS: Liying Han ; Mani B. Srivastava
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning.

97, TITLE: High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models
AUTHORS: Michela Lorandi ; Anya Belz
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The performance of NLP methods for severely under-resourced languages cannot currently hope to match the state of the art in NLP methods for well resourced languages. We explore the extent to which pretrained large language models (LLMs) can bridge this gap, via the example of data-to-text generation for Irish, Welsh, Breton and Maltese.

98, TITLE: Transformer-based Causal Language Models Perform Clustering
AUTHORS: Xinbo Wu ; Lav R. Varshney
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model.

99, TITLE: What Changed? Converting Representational Interventions to Natural Language
AUTHORS: Matan Avitan ; Ryan Cotterell ; Yoav Goldberg ; Shauli Ravfogel
CATEGORY: cs.CL [cs.CL, cs.CY, cs.LG]
HIGHLIGHT: Interventions targeting the representation space of language models (LMs) have emerged as effective means to influence model behavior. These methods are employed, for example, to eliminate or alter the encoding of demographic information such as gender within the model's representations, creating a counterfactual representation.

100, TITLE: VQAttack: Transferable Adversarial Attacks on Visual Question Answering Via Pre-trained Models
AUTHORS: ZIYI YIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Correspondingly, we propose a novel VQAttack model, which can iteratively generate both image and text perturbations with the designed modules: the large language model (LLM)-enhanced image attack and the cross-modal joint attack module.

101, TITLE: M2K-VDG: Model-Adaptive Multimodal Knowledge Anchor Enhanced Video-grounded Dialogue Generation
AUTHORS: Hongcheng Liu ; Pingjie Wang ; Yu Wang ; Yanfeng Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we reveal via perplexity that different VDG models experience varying hallucinations and exhibit diverse anchor tokens.

102, TITLE: DictLLM: Harnessing Key-Value Data Structures with Large Language Models for Enhanced Medical Diagnostics
AUTHORS: YiQiu Guo ; Yuchen Yang ; Ya Zhang ; Yu Wang ; Yanfeng Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce DictLLM, an innovative framework designed to improve the modeling of key-value structured data, like medical laboratory reports, for generating medical diagnoses.

103, TITLE: WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More
AUTHORS: YUXUAN YUE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We critically analyze the existing quantization approaches, identifying their limitations in balancing the accuracy and efficiency of the quantized LLMs. To advance beyond these limitations, we propose WKVQuant, a PTQ framework especially designed for quantizing weights and the key/value (KV) cache of LLMs.

104, TITLE: Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark
AUTHORS: YIHUA ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: This paper proposes a shift towards BP-free, zeroth-order (ZO) optimization as a solution for reducing memory costs during LLM fine-tuning, building on the initial concept introduced by MeZO.

105, TITLE: Mini-Hes: A Parallelizable Second-order Latent Factor Analysis Model
AUTHORS: Jialiang Wang ; Weiling Li ; Yurong Zhong ; Xin Luo
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: However, with the escalation of data volume, the feasibility of second-order algorithms encounters challenges. To address this pivotal issue, this paper proposes a mini-block diagonal hessian-free (Mini-Hes) optimization for building an LFA model.

106, TITLE: Dissecting Human and LLM Preferences
AUTHORS: JUNLONG LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we dissect the preferences of human and 32 different LLMs to understand their quantitative composition, using annotations from real-world user-model conversations for a fine-grained, scenario-wise analysis.

107, TITLE: Reformatted Alignment
AUTHORS: RUN-ZE FAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Encouragingly, without introducing any additional data or advanced training techniques, and merely by reformatting the response, LLaMA-2-13B's mathematical reasoning ability on GSM8K can be improved from 46.77% to 56.63% in accuracy.

108, TITLE: Grasping The Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction
AUTHORS: Sizhe Zhou ; Yu Meng ; Bowen Jin ; Jiawei Han
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Motivated by the strong synthetic data generation power of LLMs, we propose a framework REPaL which consists of three stages: (1) We utilize LLMs to generate initial seed instances based on relation definitions and an unlabeled corpora.

109, TITLE: How Susceptible Are Large Language Models to Ideological Manipulation?
AUTHORS: Kai Chen ; Zihao He ; Jun Yan ; Taiwei Shi ; Kristina Lerman
CATEGORY: cs.CL [cs.CL, cs.CR, cs.CY]
HIGHLIGHT: In this work, we investigate how effectively LLMs can learn and generalize ideological biases from their instruction-tuning data.

110, TITLE: Visual In-Context Learning for Large Vision-Language Models
AUTHORS: Yucheng Zhou ; Xiang Li ; Qianning Wang ; Jianbing Shen
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In Large Visual Language Models (LVLMs), the efficacy of In-Context Learning (ICL) remains limited by challenges in cross-modal interactions and representation disparities. To overcome these challenges, we introduce a novel Visual In-Context Learning (VICL) method comprising Visual Demonstration Retrieval, Intent-Oriented Image Summarization, and Intent-Oriented Demonstration Composition.

111, TITLE: Mixed Gaussian Flow for Diverse Trajectory Prediction
AUTHORS: Jiahe Chen ; Jinkun Cao ; Dahua Lin ; Kris Kitani ; Jiangmiao Pang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To solve the problem, we propose a flow-based model to transform a mixed Gaussian prior into the future trajectory manifold.

112, TITLE: Citation Amnesia: NLP and Other Academic Fields Are in A Citation Age Recession
AUTHORS: Jan Philip Wahle ; Terry Ruas ; Mohamed Abdalla ; Bela Gipp ; Saif M. Mohammad
CATEGORY: cs.DL [cs.DL, cs.CL]
HIGHLIGHT: This study examines the tendency to cite older work across 20 fields of study over 43 years (1980--2023).

113, TITLE: LoRA+: Efficient Low Rank Adaptation of Large Models
AUTHORS: Soufiane Hayou ; Nikhil Ghosh ; Bin Yu
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, stat.ML]
HIGHLIGHT: In this paper, we show that Low Rank Adaptation (LoRA) as originally introduced in Hu et al. (2021) leads to suboptimal finetuning of models with large width (embedding dimension).

114, TITLE: Exploiting T-norms for Deep Learning in Autonomous Driving
AUTHORS: Mihaela C?t?lina Stoian ; Eleonora Giunchiglia ; Thomas Lukasiewicz
CATEGORY: cs.LG [cs.LG, cs.CV, cs.LO]
HIGHLIGHT: In this paper, we show how it is possible to define memory-efficient t-norm-based losses, allowing for exploiting t-norms for the task of event detection in autonomous driving.

115, TITLE: Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and Improving LLMs
AUTHORS: Siyuan Wang ; Zhongyu Wei ; Yejin Choi ; Xiang Ren
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, their mastery of underlying inferential rules still falls short of human capabilities. To investigate this, we propose a logic scaffolding inferential rule generation framework, to construct an inferential rule base, ULogic, comprising both primitive and compositional rules across five domains.

116, TITLE: Disclosure and Mitigation of Gender Bias in LLMs
AUTHORS: Xiangjue Dong ; Yibo Wang ; Philip S. Yu ; James Caverlee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Hence, we propose an indirect probing framework based on conditional generation.

117, TITLE: RENOVI: A Benchmark Towards Remediating Norm Violations in Socio-Cultural Conversations
AUTHORS: HAOLAN ZHAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We thus harness the power of ChatGPT to generate synthetic training data for our task.

118, TITLE: Amplifying Training Data Exposure Through Fine-Tuning with Pseudo-Labeled Memberships
AUTHORS: Myung Gyo Oh ; Hong Eun Ahn ; Leo Hyun Park ; Taekyoung Kwon
CATEGORY: cs.CL [cs.CL, cs.CR, cs.LG, I.2.7; K.6.5]
HIGHLIGHT: This paper introduces a novel attack scenario wherein an attacker adversarially fine-tunes pre-trained LMs to amplify the exposure of the original training data.

119, TITLE: Why Lift So Heavy? Slimming Large Language Models By Cutting Off The Layers
AUTHORS: Shuzhou Yuan ; Ercong Nie ; Bolei Ma ; Michael F�rber
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Remarkably, in certain cases, models with a single layer outperform their fully layered counterparts. These findings offer valuable insights for future work aimed at mitigating the size constraints of LLMs while preserving their performance, thereby opening avenues for significantly more efficient use of LLMs.

120, TITLE: On The Computation of Equilibria in Discrete First-Price Auctions
AUTHORS: Aris Filos-Ratsikas ; Yiannis Giannakopoulos ; Alexandros Hollender ; Charalampos Kokkalis
CATEGORY: cs.GT [cs.GT, cs.CC]
HIGHLIGHT: In this paper we prove that the problem of deciding their existence is NP-complete, even for approximate equilibria.

121, TITLE: GenAD: Generative End-to-End Autonomous Driving
AUTHORS: Wenzhao Zheng ; Ruiqi Song ; Xianda Guo ; Long Chen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose GenAD, a generative framework that casts autonomous driving into a generative modeling problem.

122, TITLE: Towards Joint Optimization for DNN Architecture and Configuration for Compute-In-Memory Hardware
AUTHORS: Souvik Kundu ; Anthony Sarah ; Vinay Joshi ; Om J Omer ; Sreenivas Subramoney
CATEGORY: cs.AR [cs.AR, cs.AI]
HIGHLIGHT: In this paper, we present CiMNet, a framework that jointly searches for optimal sub-networks and hardware configurations for CiM architectures creating a Pareto optimal frontier of downstream task accuracy and execution metrics (e.g., latency).

123, TITLE: Exploring ChatGPT for Next-generation Information Retrieval: Opportunities and Challenges
AUTHORS: Yizheng Huang ; Jimmy Huang
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: Unlike the traditional supervised learning approach in IR tasks, ChatGPT challenges existing paradigms, bringing forth new challenges and opportunities regarding text quality assurance, model bias, and efficiency. This paper seeks to examine the impact of ChatGPT on IR tasks and offer insights into its potential future developments.

124, TITLE: How Interpretable Are Reasoning Explanations from Prompting Large Language Models?
AUTHORS: Yeo Wei Jie ; Ranjan Satapathy ; Goh Siow Mong ; Erik Cambria
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present a comprehensive and multifaceted evaluation of interpretability, examining not only faithfulness but also robustness and utility across multiple commonsense reasoning benchmarks.

125, TITLE: Multi-Perspective Consistency Enhances Confidence Estimation in Large Language Models
AUTHORS: PEI WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we focus on improving the confidence estimation of large language models.

126, TITLE: PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability
AUTHORS: DAYUAN FU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce $\textbf{PreAct}$, an agent framework that integrates $\textbf{pre}$diction with $\textbf{rea}$soning and $\textbf{act}$ion.

127, TITLE: I Learn Better If You Speak My Language: Enhancing Large Language Model Fine-Tuning with Style-Aligned Response Adjustments
AUTHORS: Xuan Ren ; Biao Wu ; Lingqiao Liu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We found that matching the ground-truth response style with the LLM's inherent style results in better learning outcomes. Building on this insight, we developed a method that minimally alters the LLM's pre-existing responses to correct errors, using these adjusted responses as training targets.

128, TITLE: Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models
AUTHORS: TIANJIE JU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper systematically investigates the possibilities for LLMs to utilize shortcuts based on direct connections between the initial and terminal entities of multi-hop knowledge.

129, TITLE: Acquiring Clean Language Models from Backdoor Poisoned Datasets By Downscaling Frequency Space
AUTHORS: Zongru Wu ; Zhuosheng Zhang ; Pengzhou Cheng ; Gongshen Liu
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR]
HIGHLIGHT: In this paper, we investigate the learning mechanisms of backdoor LMs in the frequency space by Fourier analysis.

130, TITLE: FiT: Flexible Vision Transformer for Diffusion Model
AUTHORS: ZEYU LU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios.

131, TITLE: CodeArt: Better Code Models By Attention Regularization When Symbols Are Lacking
AUTHORS: ZIAN SU et. al.
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: We propose a new method to pre-train general code models when symbols are lacking.

132, TITLE: Unveiling The Magic: Investigating Attention Distillation in Retrieval-augmented Generation
AUTHORS: Zizhong Li ; Haopeng Zhang ; Jiawei Zhang
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: Despite its growing popularity, the detailed mechanisms behind the success of attention distillation remain unexplored, particularly the specific patterns it leverages to benefit training. In this paper, we address this gap by conducting a comprehensive review of attention distillation workflow and identifying key factors influencing the learning quality of retrieval-augmented language models.

133, TITLE: DDIPrompt: Drug-Drug Interaction Event Prediction Based on Graph Prompt Learning
AUTHORS: Yingying Wang ; Yun Xiong ; Xixi Wu ; Xiangguo Sun ; Jiawei Zhang
CATEGORY: q-bio.BM [q-bio.BM, cs.AI, cs.LG]
HIGHLIGHT: In response, we offer DDIPrompt, an innovative panacea inspired by the recent advancements in graph prompting. Our framework aims to address these issues by leveraging the intrinsic knowledge from pre-trained models, which can be efficiently deployed with minimal downstream data.

134, TITLE: Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning
AUTHORS: ZHIYANG XU et. al.
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: In addition, we propose a two-stage instruction tuning framework, in which VLMs are firstly finetuned on Vision-Flan and further tuned on GPT-4 synthesized data. We find this two-stage tuning framework significantly outperforms the traditional single-stage visual instruction tuning framework and achieves the state-of-the-art performance across a wide range of multi-modal evaluation benchmarks.

135, TITLE: Dynamic Planning in Hierarchical Active Inference
AUTHORS: Matteo Priorelli ; Ivilin Peev Stoianov
CATEGORY: cs.AI [cs.AI, cs.LG, cs.RO]
HIGHLIGHT: We start from a simple unit and gradually describe more advanced structures, comparing recently proposed design choices and providing basic examples for each section.

136, TITLE: Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?
AUTHORS: Benjamin Reichman ; Larry Heck
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In this work, we explore DPR-trained models mechanistically by using a combination of probing, layer activation analysis, and model editing.

137, TITLE: AnaloBench: Benchmarking The Identification of Abstract and Long-context Analogies
AUTHORS: XIAO YE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Can language models (LMs) do the same? To answer this question, we propose ANALOBENCH, a benchmark to determine analogical reasoning ability in LMs.

138, TITLE: Evaluating The Effectiveness of Index-Based Treatment Allocation
AUTHORS: NICLAS BOEHMER et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ME, stat.ML]
HIGHLIGHT: This problem occurs, for instance, when allocating scarce medical resources and is often solved using modern ML methods. This paper introduces methods to evaluate index-based allocation policies -- that allocate a fixed number of resources to those who need them the most -- by using data from a randomized control trial.

139, TITLE: Attractor Memory for Long-Term Time Series Forecasting: A Chaos Perspective
AUTHORS: JIAXI HU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, nlin.CD]
HIGHLIGHT: Recognizing the chaotic nature of real-world data, our model, \textbf{\textit{Attraos}}, incorporates chaos theory into LTSF, perceiving real-world time series as observations from unknown high-dimensional chaotic dynamic systems.

140, TITLE: LLM As Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs
AUTHORS: Kai Wang ; Yuwei Xu ; Zhiyong Wu ; Siqiang Luo
CATEGORY: cs.AI [cs.AI, cs.CL, cs.SI]
HIGHLIGHT: One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs).

141, TITLE: Data Distribution Distilled Generative Model for Generalized Zero-Shot Recognition
AUTHORS: Yijie Wang ; Mingjian Hong ; Luwen Huangfu ; Sheng Huang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In the realm of Zero-Shot Learning (ZSL), we address biases in Generalized Zero-Shot Learning (GZSL) models, which favor seen data. To counter this, we introduce an end-to-end generative GZSL framework called D$^3$GZSL.

142, TITLE: Chain-of-Instructions: Compositional Instruction Tuning on Large Language Models
AUTHORS: SHIRLEY ANUGRAH HAYATI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose a novel concept of compositional instructions called chain-of-instructions (CoI), where the output of one instruction becomes an input for the next like a chain.

143, TITLE: Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in Automatic Related Work Composition
AUTHORS: Anna Martin-Boyle ; Aahan Tyagi ; Marti A. Hearst ; Dongyeop Kang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present an analysis of AI-assisted scholarly writing generated with ScholaCite, a tool we built that is designed for organizing literature and composing Related Work sections for academic papers.

144, TITLE: 3D Vascular Segmentation Supervised By 2D Annotation of Maximum Intensity Projection
AUTHORS: Zhanqiang Guo ; Zimeng Tan ; Jianjiang Feng ; Jie Zhou
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Subsequently, taking into account the acquisition method of the 2D labels, we introduce a weakly-supervised network that fuses 2D-3D deep features via MIP to further improve segmentation performance.

145, TITLE: Colorizing Monochromatic Radiance Fields
AUTHORS: YEAN CHENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Since color is necessary in representing the world, reproducing color from monochromatic radiance fields becomes crucial. To achieve this goal, instead of manipulating the monochromatic radiance fields directly, we consider it as a representation-prediction task in the Lab color space.

146, TITLE: Deciphering The Lmpact of Pretraining Data on Large Language Models Through Machine Unlearning
AUTHORS: YANG ZHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: As a result, the organization of the pretraining corpus is still empirical and may deviate from the optimal. To address this issue, we systematically analyze the impact of 48 datasets from 5 major categories of pretraining data of LLMs and measure their impacts on LLMs using benchmarks about nine major categories of model capabilities.

147, TITLE: FIPO: Free-form Instruction-oriented Prompt Optimization with Preference Dataset and Modular Fine-tuning Schema
AUTHORS: JUNRU LU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Contrast to previous model-oriented yet instruction-agnostic Automatic Prompt Optimization methodologies, yielding polished results for predefined target models while suffering rapid degradation with out-of-box models, we present Free-form Instruction-oriented Prompt Optimization (FIPO).

148, TITLE: Controlled Text Generation for Large Language Model with Dynamic Attribute Graphs
AUTHORS: XUN LIANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we introduce a pluggable CTG framework for Large Language Models (LLMs) named Dynamic Attribute Graphs-based controlled text generation (DATG).

149, TITLE: Navigating The Dual Facets: A Comprehensive Evaluation of Sequential Memory Editing in Large Language Models
AUTHORS: ZIHAO LIN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Regrettably, previous studies on ME evaluation have two critical limitations: (i) evaluating LLMs with single edit only, neglecting the need for continuous editing, and (ii) evaluations focusing solely on basic factual triples, overlooking broader LLM capabilities like logical reasoning and reading understanding. This study addresses these limitations with contributions threefold: (i) We explore how ME affects a wide range of fundamental capabilities of LLMs under sequential editing.

150, TITLE: The Colorful Future of LLMs: Evaluating and Improving LLMs As Emotional Supporters for Queer Youth
AUTHORS: SHIR LISSAK et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper aims to comprehensively explore the potential of LLMs to revolutionize emotional support for queers.

151, TITLE: What Do Dialect Speakers Want? A Survey of Attitudes Towards Language Technology for German Dialects
AUTHORS: Verena Blaschke ; Christoph Purschke ; Hinrich Sch�tze ; Barbara Plank
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we focus on dialects and regional languages related to German -- a group of varieties that is heterogeneous in terms of prestige and standardization.

152, TITLE: Stumbling Blocks: Stress Testing The Robustness of Machine-Generated Text Detectors Under Attacks
AUTHORS: YICHEN WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The goal of our study is to stress test the detectors' robustness to malicious attacks under realistic scenarios.

153, TITLE: Event-Based Motion Magnification
AUTHORS: YUTIAN CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a dual-camera system consisting of an event camera and a conventional RGB camera for video motion magnification, containing temporally-dense information from the event stream and spatially-dense data from the RGB images.

154, TITLE: LVCHAT: Facilitating Long Video Comprehension
AUTHORS: Yu Wang ; Zeyuan Zhang ; Julian McAuley ; Zexue He
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: To deal with long videos whose length is beyond videos seen during training, we propose Interleaved Frame Encoding (IFE), repeating positional embedding and interleaving multiple groups of videos to enable long video input, avoiding performance degradation due to overly long videos.

155, TITLE: Supporting Experts with A Multimodal Machine-Learning-Based Tool for Human Behavior Analysis of Conversational Videos
AUTHORS: Riku Arakawa ; Kiyosu Maeda ; Hiromu Yakura
CATEGORY: cs.HC [cs.HC, cs.CV, cs.LG]
HIGHLIGHT: Multimodal scene search of conversations is essential for unlocking valuable insights into social dynamics and enhancing our communication.

156, TITLE: SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network Systems
AUTHORS: Rachmad Vidya Wicaksana Putra ; Muhammad Shafique
CATEGORY: cs.NE [cs.NE, cs.AI, cs.LG]
HIGHLIGHT: These limitations hinder the SNNs from reaching their full potential in accuracy and efficiency. Towards this, we propose SpikeNAS, a novel memory-aware neural architecture search (NAS) framework for SNNs that can quickly find an appropriate SNN architecture with high accuracy under the given memory budgets.

157, TITLE: EndoOOD: Uncertainty-aware Out-of-distribution Detection in Capsule Endoscopy Diagnosis
AUTHORS: Qiaozhi Tan ; Long Bai ; Guankun Wang ; Mobarakol Islam ; Hongliang Ren
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing capsule endoscopy classification methods mostly rely on pre-defined categories, making it challenging to identify and classify out-of-distribution (OOD) data, such as undefined categories or anatomical landmarks. To address this issue, we propose the Endoscopy Out-of-Distribution (EndoOOD) framework, which aims to effectively handle the OOD detection challenge in WCE diagnosis.

158, TITLE: A Lightweight Parallel Framework for Blind Image Quality Assessment
AUTHORS: Qunyue Huang ; Bin Fang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite the significant advancements, these methods remarkably raise the parameter count of the model, thus requiring more training time and computational resources. To tackle the above issues, we propose a lightweight parallel framework (LPF) for BIQA.

159, TITLE: Tasks That Language Models Don't Learn
AUTHORS: Bruce W. Lee ; JaeHyuk Lim
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present an empirical investigation of visual-auditory properties of language through a series of tasks, termed H-TEST.

160, TITLE: When Do LLMs Need Retrieval Augmentation? Mitigating LLMs' Overconfidence Helps Retrieval Augmentation
AUTHORS: Shiyu Ni ; Keping Bi ; Jiafeng Guo ; Xueqi Cheng
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Then, we study how LLMs' certainty about a question correlates with their dependence on external retrieved information. We propose several methods to enhance LLMs' perception of knowledge boundaries and show that they are effective in reducing overconfidence.

161, TITLE: A Novel Framework for Adaptive Stress Testing of Autonomous Vehicles in Highways
AUTHORS: Linh Trinh ; Quang-Hung Luu ; Thai M. Nguyen ; Hai L. Vu
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this paper, we propose a novel framework to systematically explore corner cases that can result in safety concerns in a highway traffic scenario.

162, TITLE: Endowing Pre-trained Graph Models with Provable Fairness
AUTHORS: ZHONGJIAN ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY, cs.SI]
HIGHLIGHT: Moreover, most of them lack a theoretical guarantee, i.e., provable lower bounds on the fairness of model predictions, which directly provides assurance in a practical scenario. To overcome these limitations, we propose a novel adapter-tuning framework that endows pre-trained \textbf{Graph} models with \textbf{P}rovable f\textbf{A}i\textbf{R}ness (called GraphPAR).

163, TITLE: Empirical Study on Updating Key-Value Memories in Transformer Feed-forward Layers
AUTHORS: Zihan Qiu ; Zeyu Huang ; Youcheng Huang ; Jie Fu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we conduct an empirical ablation study on updating keys (the 1st layer in the FFNs layer) or values (the 2nd layer in the FFNs layer).

164, TITLE: Thyroid Ultrasound Diagnosis Improvement Via Multi-view Self-supervised Learning and Two-stage Pre-training
AUTHORS: JIAN WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we proposed a multi-view contrastive self-supervised method to improve thyroid nodule classification and segmentation performance with limited manual labels.

165, TITLE: Reasoning Before Comparison: LLM-Enhanced Semantic Similarity Metrics for Domain Specialized Text Analysis
AUTHORS: SHAOCHEN XU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we leverage LLM to enhance the semantic analysis and develop similarity metrics for texts, addressing the limitations of traditional unsupervised NLP metrics like ROUGE and BLEU.

166, TITLE: Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge
AUTHORS: YUFEI HUANG et. al.
CATEGORY: q-bio.BM [q-bio.BM, cs.AI, cs.LG, physics.chem-ph]
HIGHLIGHT: While deep learning has shown promise, existing methods often depend on holo-protein structures (docked, and not accessible in realistic tasks) or neglect pocket sidechain conformations, leading to limited practical utility and unrealistic conformation predictions. To fill these gaps, we introduce an under-explored task, named flexible docking to predict poses of ligand and pocket sidechains simultaneously and introduce Re-Dock, a novel diffusion bridge generative model extended to geometric manifolds.

167, TITLE: WorldCoder, A Model-Based LLM Agent: Building World Models By Writing Code and Interacting with The Environment
AUTHORS: Hao Tang ; Darren Key ; Kevin Ellis
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: We give a model-based agent that builds a Python program representing its knowledge of the world based on its interactions with the environment.

168, TITLE: Pushing Auto-regressive Models for 3D Shape Generation at Capacity and Scalability
AUTHORS: XUELIN QIAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we extend auto-regressive models to 3D domains, and seek a stronger ability of 3D shape generation by improving auto-regressive models at capacity and scalability simultaneously.

169, TITLE: Human Video Translation Via Query Warping
AUTHORS: Haiming Zhu ; Yangyang Xu ; Shengfeng He
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present QueryWarp, a novel framework for temporally coherent human motion video translation.

170, TITLE: ChatEarthNet: A Global-Scale, High-Quality Image-Text Dataset for Remote Sensing
AUTHORS: Zhenghang Yuan ; Zhitong Xiong ; Lichao Mou ; Xiao Xiang Zhu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Natural language, as a carrier of human knowledge, can be a bridge between common users and complicated satellite imagery. In this context, we introduce a global-scale, high-quality image-text dataset for remote sensing, providing natural language descriptions for Sentinel-2 data to facilitate the understanding of satellite imagery for common users.

171, TITLE: Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations
AUTHORS: Milan Bhan ; Jean-Noel Vittaut ; Nicolas Chesneau ; Marie-Jeanne Lesot
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this work, we propose Self-AMPLIFY to generate automatically rationales from post hoc explanation methods applied to Small Language Models (SLMs) to improve their own performance.

172, TITLE: A Critical Evaluation of AI Feedback for Aligning Large Language Models
AUTHORS: ARCHIT SHARMA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We show that the improvements of the RL step are virtually entirely due to the widespread practice of using a weaker teacher model (e.g. GPT-3.5) for SFT data collection than the critic (e.g., GPT-4) used for AI feedback generation.

173, TITLE: Aligning Large Language Models By On-Policy Self-Judgment
AUTHORS: SANGKYU LEE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we present a novel alignment framework, SELF-JUDGE that is (1) on-policy learning and 2) parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning.

174, TITLE: Interpretable Brain-Inspired Representations Improve RL Performance on Visual Navigation Tasks
AUTHORS: Moritz Lange ; Raphael C. Engelhardt ; Wolfgang Konen ; Laurenz Wiskott
CATEGORY: cs.LG [cs.LG, cs.NE, cs.RO]
HIGHLIGHT: In this work, we show how the method of slow feature analysis (SFA), inspired by neuroscience research, overcomes both limitations by generating interpretable representations of visual data that encode location and heading of an agent.

175, TITLE: Hebbian Learning Based Orthogonal Projection for Continual Learning of Spiking Neural Networks
AUTHORS: Mingqing Xiao ; Qingyan Meng ; Zongpeng Zhang ; Di He ; Zhouchen Lin
CATEGORY: cs.NE [cs.NE, cs.AI, cs.LG]
HIGHLIGHT: In this work, we develop a new method with neuronal operations based on lateral connections and Hebbian learning, which can protect knowledge by projecting activity traces of neurons into an orthogonal subspace so that synaptic weight update will not interfere with old tasks.

176, TITLE: Head-wise Shareable Attention for Large Language Models
AUTHORS: Zouying Cao ; Yifei Yang ; Hai Zhao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a perspective on $\textit{$\textbf{head-wise shareable attention for large language models}$}$.

177, TITLE: Comprehensive Cognitive LLM Agent for Smartphone GUI Automation
AUTHORS: Xinbei Ma ; Zhuosheng Zhang ; Hai Zhao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose \underline{Co}mprehensive \underline{Co}gnitive LLM \underline{Agent}, CoCo-Agent, with two novel approaches, comprehensive environment perception (CEP) and conditional action prediction (CAP), to systematically improve the GUI automation performance.

178, TITLE: LaCo: Large Language Model Pruning Via Layer Collapse
AUTHORS: Yifei Yang ; Zouying Cao ; Hai Zhao
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose a concise layer-wise pruning method called \textit{Layer Collapse (LaCo)}, in which rear model layers collapse into a prior layer, enabling a rapid reduction in model size while preserving the model structure.

179, TITLE: Fine-grained and Explainable Factuality Evaluation for Multimodal Summarization
AUTHORS: Liqiang Jing ; Jingxuan Zuo ; Yue Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To evaluate the factuality of multimodal summarization models, we propose two fine-grained and explainable evaluation frameworks (FALLACIOUS) for different application scenarios, i.e. reference-based factuality evaluation framework and reference-free factuality evaluation framework.

180, TITLE: Machine-generated Text Localization
AUTHORS: Zhongping Zhang ; Wenda Qin ; Bryan A. Plummer
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: A key challenge in our MGT localization task is that short spans of text, e.g., a single sentence, provides little information indicating if it is machine generated due to its short length. To address this, we leverage contextual information, where we predict whether multiple sentences are machine or human written at once.

181, TITLE: Momentor: Advancing Video Large Language Model with Fine-Grained Temporal Reasoning
AUTHORS: LONG QIAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing Video-LLMs can only capture the coarse-grained semantics and are unable to effectively handle tasks related to comprehension or localization of specific video segments. In light of these challenges, we propose Momentor, a Video-LLM capable of accomplishing fine-grained temporal understanding tasks.

182, TITLE: InfuserKI: Enhancing Large Language Models with Knowledge Graphs Via Infuser-Guided Knowledge Integration
AUTHORS: FALI WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Injecting new knowledge poses the risk of forgetting previously acquired knowledge. To tackle this, we propose a novel Infuser-Guided Knowledge Integration (InfuserKI) framework that utilizes transformer internal states to determine whether to enhance the original LLM output with additional information, thereby effectively mitigating knowledge forgetting.

183, TITLE: A Survey on Extractive Knowledge Graph Summarization: Applications, Approaches, Evaluation, and Future Directions
AUTHORS: Xiaxia Wang ; Gong Cheng
CATEGORY: cs.AI [cs.AI, cs.DB, cs.IR, cs.SI]
HIGHLIGHT: Aiming at distilling a compact subgraph with condensed information, it facilitates various downstream KG-based tasks. In this survey paper, we are among the first to provide a systematic overview of its applications and define a taxonomy for existing methods from its interdisciplinary studies.

184, TITLE: Zero Shot VLMs for Hate Meme Detection: Are We There Yet?
AUTHORS: NAQUEE RIZWAN et. al.
CATEGORY: cs.CL [cs.CL, cs.CV, cs.LG]
HIGHLIGHT: Recently, the research community has witnessed the emergence of several visual language models that have exhibited outstanding performance across various tasks. In this study, we aim to investigate the efficacy of these visual language models in handling intricate tasks such as hate meme detection.

185, TITLE: Refining Minimax Regret for Unsupervised Environment Design
AUTHORS: MICHAEL BEUKMAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Although there are possible performance improvements to be made outside of these regret-maximising levels, learning stagnates. In this work, we introduce Bayesian level-perfect MMR (BLP), a refinement of the minimax regret objective that overcomes this limitation.

186, TITLE: Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation
AUTHORS: Kailun Jin ; Chung-Yu Wang ; Hung Viet Pham ; Hadi Hemmati
CATEGORY: cs.SE [cs.SE, cs.AI, cs.LG, I.2.2]
HIGHLIGHT: However, these studies mainly provide evaluations in research settings, which leaves a significant gap in understanding how effectively LLMs can support developers in real-world. To address this, we conducted an empirical analysis of conversations in DevGPT, a dataset collected from developers' conversations with ChatGPT (captured with the Share Link feature on platforms such as GitHub).

187, TITLE: A Note on Bias to Complete
AUTHORS: Jia Xu ; Mona Diab
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Minimizing social bias strengthens societal bonds, promoting shared understanding and better decision-making. We revisit the definition of bias by discovering new bias types (e.g., societal status) in dynamic environments and describe them relative to context, such as culture, region, time, and personal background.

188, TITLE: Key Patch Proposer: Key Patches Contain Rich Information
AUTHORS: Jing Xu ; Beiwen Tian ; Hao Zhao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a novel algorithm named Key Patch Proposer (KPP) designed to select key patches in an image without additional training.

189, TITLE: Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark for Deception Reasoning
AUTHORS: Kang Chen ; Zheng Lian ; Haiyang Sun ; Bin Liu ; Jianhua Tao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To address data scarcity, this paper proposes a new data collection pipeline.

190, TITLE: Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents
AUTHORS: WENKAI YANG et. al.
CATEGORY: cs.CR [cs.CR, cs.AI, cs.CL]
HIGHLIGHT: In this work, we take the first step to investigate one of the typical safety threats, backdoor attack, to LLM-based agents.

191, TITLE: Bridging Causal Discovery and Large Language Models: A Comprehensive Survey of Integrative Approaches and Future Directions
AUTHORS: Guangya Wan ; Yuqi Wu ; Mengxuan Hu ; Zhixuan Chu ; Sheng Li
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper presents a comprehensive survey of the integration of LLMs, such as GPT4, into CD tasks.

192, TITLE: Large Language Models Fall Short: Understanding Complex Relationships in Detective Narratives
AUTHORS: RUNCONG ZHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Existing datasets for narrative understanding often fail to represent the complexity and uncertainty of relationships in real-life social scenarios. To address this gap, we introduce a new benchmark, Conan, designed for extracting and analysing intricate character relation graphs from detective narratives.

193, TITLE: SoLA: Solver-Layer Adaption of LLM for Better Logic Reasoning
AUTHORS: YU ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose a novel solver-layer adaptation (SoLA) method, where we introduce a solver as a new layer of the LLM to differentially guide solutions towards satisfiability.

194, TITLE: Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection
AUTHORS: JIAWEI LIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: The proliferation of face forgery techniques has raised significant concerns within society, thereby motivating the development of face forgery detection methods. These methods aim to distinguish forged faces from genuine ones and have proven effective in practical applications.

195, TITLE: Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness
AUTHORS: CHEN ZHAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY]
HIGHLIGHT: In this paper, to tackle the fairness-aware online learning challenge in evolving settings, we introduce a unique regret measure, FairSAR, by incorporating long-term fairness constraints into a strongly adapted loss regret framework.

196, TITLE: Browse and Concentrate: Comprehending Multimodal Content Via Prior-LLM Context Fusion
AUTHORS: ZIYUE WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: A primary reason for this shortcoming is that the visual features for each images are encoded individually by frozen encoders before feeding into the LLM backbone, lacking awareness of other images and the multimodal instructions. We term this issue as prior-LLM modality isolation and propose a two phase paradigm, browse-and-concentrate, to enable in-depth multimodal context fusion prior to feeding the features into LLMs.

197, TITLE: Groot: Adversarial Testing for Generative Text-to-Image Models with Tree-based Semantic Transformation
AUTHORS: YI LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CR, cs.SE]
HIGHLIGHT: We introduce Groot, the first automated framework leveraging tree-based semantic transformation for adversarial testing of text-to-image models.

198, TITLE: Your Large Language Model Is Secretly A Fairness Proponent and You Should Prompt It Like One
AUTHORS: TIANLIN LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, I.2; J.4]
HIGHLIGHT: In response to this, we validate that prompting LLMs with specific roles can allow LLMs to express diverse viewpoints. Building on this insight and observation, we develop FairThinking, a pipeline designed to automatically generate roles that enable LLMs to articulate diverse perspectives for fair expressions.

199, TITLE: Meta Ranking: Less Capable Language Models Are Capable for Single Response Judgement
AUTHORS: ZIJUN LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: To enable less capable LLMs to effectively judge the reliability of individual responses, we propose a novel method named $\textit{Meta}$ $\textit{Ranking}$ (MR).

200, TITLE: Enhancing Multilingual Capabilities of Large Language Models Through Self-Distillation from Resource-Rich Languages
AUTHORS: YUANCHI ZHANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose SDRRL, a method based on Self-Distillation from Resource-Rich Languages that effectively improve multilingual performance by leveraging the internal capabilities of LLMs on resource-rich languages.

201, TITLE: Scaffolding Coordinates to Promote Vision-Language Coordination in Large Multi-Modal Models
AUTHORS: Xuanyu Lei ; Zonghan Yang ; Xinrui Chen ; Peng Li ; Yang Liu
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this work, we propose Scaffold prompting that scaffolds coordinates to promote vision-language coordination.

202, TITLE: Analysis of Multidomain Abstractive Summarization Using Salience Allocation
AUTHORS: Tohida Rehman ; Raghubir Bose ; Soumik Dey ; Samiran Chattopadhyay
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: The results presented in this paper not only contribute to the evaluation of the SEASON model's effectiveness but also illuminate the intricacies of salience allocation techniques across various types of datasets.

203, TITLE: Towards Cross-Tokenizer Distillation: The Universal Logit Distillation Loss for LLMs
AUTHORS: Nicolas Boizard ; Kevin El-Haddad ; C�line Hudelot ; Pierre Colombo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these methods based on logits often require both teacher and student models to share the same tokenizer, limiting their applicability across different LLM families. In this paper, we introduce Universal Logit Distillation (ULD) loss, grounded in optimal transport, to address this limitation.

204, TITLE: IRFundusSet: An Integrated Retinal Rundus Dataset with A Harmonized Healthy Label
AUTHORS: P. Bilha Githinji ; Keming Zhao ; Jiantao Wang ; Peiwu Qin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present Integrated Retinal Fundus Set (IRFundusSet), a dataset that consolidates, harmonizes and curates several public datasets, facilitating their consumption as a unified whole and with a consistent is_normal label.

205, TITLE: Triple-Encoders: Representations That Fire Together, Wire Together
AUTHORS: Justus-Jonas Erker ; Florian Mai ; Nils Reimers ; Gerasimos Spanakis ; Iryna Gurevych
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While high efficiency is achieved through independently encoding utterances, this ignores the importance of contextualization. To overcome this issue, this study introduces triple-encoders, which efficiently compute distributed utterance mixtures from these independently encoded utterances through a novel hebbian inspired co-occurrence learning objective without using any weights.

206, TITLE: Whose Emotions and Moral Sentiments Do Language Models Reflect?
AUTHORS: Zihao He ; Siyi Guo ; Ashwin Rao ; Kristina Lerman
CATEGORY: cs.CL [cs.CL, cs.CY, cs.SI]
HIGHLIGHT: We define the problem of affective alignment, which measures how LMs' emotional and moral tone represents those of different groups.

207, TITLE: MRKE: The Multi-hop Reasoning Evaluation of LLMs By Knowledge Edition
AUTHORS: Jian Wu ; Linyi Yang ; Manabu Okumura ; Yue Zhang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Thus we introduce an LLM MHQA evaluation benchmark, the first QA benchmark based on the new, unprecedented knowledge by editing the off-the-shelf HotpotQA dataset; Besides, we also annotate and evaluate the reasoning chain in the form of sub-questions and intermediate answers corresponding to the multi-hop questions.

208, TITLE: GenDec: A Robust Generative Question-decomposition Method for Multi-hop Reasoning
AUTHORS: JIAN WU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a \textbf{gen}erative question \textbf{dec}omposition method (GenDec) from the perspective of explainable QA by generating independent and complete sub-questions based on incorporating additional extracted evidence for enhancing LLMs' reasoning ability in RAG.

209, TITLE: FeB4RAG: Evaluating Federated Search in The Context of Retrieval Augmented Generation
AUTHORS: Shuai Wang ; Ekaterina Khramtsova ; Shengyao Zhuang ; Guido Zuccon
CATEGORY: cs.IR [cs.IR, cs.CL]
HIGHLIGHT: However, existing datasets, such as those developed in the past TREC FedWeb tracks, predate the RAG paradigm shift and lack representation of modern information retrieval challenges. To bridge this gap, we present FeB4RAG, a novel dataset specifically designed for federated search within RAG frameworks.

210, TITLE: Large Language Models for Stemming: Promises, Pitfalls and Failures
AUTHORS: Shuai Wang ; Shengyao Zhuang ; Guido Zuccon
CATEGORY: cs.IR [cs.IR, cs.CL]
HIGHLIGHT: However, traditional stemming methods, focusing solely on individual terms, overlook the richness of contextual information. Recognizing this gap, in this paper, we investigate the promising idea of using large language models (LLMs) to stem words by leveraging its capability of context understanding.

211, TITLE: Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning
AUTHORS: SHUAI ZHAO et. al.
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: In this study, we show that PEFT is more susceptible to weight-poisoning backdoor attacks compared to the full-parameter fine-tuning method, with pre-defined triggers remaining exploitable and pre-defined targets maintaining high confidence, even after fine-tuning.

212, TITLE: Metacognitive Retrieval-Augmented Large Language Models
AUTHORS: Yujia Zhou ; Zheng Liu ; Jiajie Jin ; Jian-Yun Nie ; Zhicheng Dou
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: This paper introduces MetaRAG, an approach that combines the retrieval-augmented generation process with metacognition.

213, TITLE: Distilling Large Language Models for Text-Attributed Graph Learning
AUTHORS: Bo Pan ; Zheng Zhang ; Yifei Zhang ; Yuntong Hu ; Liang Zhao
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs to a local graph model on TAG learning.

214, TITLE: Debiased Offline Representation Learning for Fast Online Adaptation in Non-stationary Dynamics
AUTHORS: XINYU ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: A key difficulty arises because the limited offline data makes it hard for the context encoder to differentiate between changes in the environment dynamics and shifts in the behavior policy, often leading to context misassociations. To address this issue, we introduce a novel approach called Debiased Offline Representation for fast online Adaptation (DORA).

215, TITLE: C-ICL: Contrastive In-context Learning for Information Extraction
AUTHORS: YING MO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present c-ICL, a novel few-shot technique that leverages both correct and incorrect sample constructions to create in-context learning demonstrations.

216, TITLE: Cobra Effect in Reference-Free Image Captioning Metrics
AUTHORS: ZHENG MA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Our findings reveal that descriptions guided by these metrics contain significant flaws, e.g. incoherent statements and excessive repetition. Subsequently, we propose a novel method termed Self-Improving to rectify the identified shortcomings within these metrics.

217, TITLE: SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning
AUTHORS: Zhihao Wen ; Jie Zhang ; Yuan Fang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present SIBO, which is a SImple BOoster to enhance PEFT, by injecting an initial residual.

218, TITLE: Understanding The Effects of Noise in Text-to-SQL: An Examination of The BIRD-Bench Benchmark
AUTHORS: Niklas Wretblad ; Fredrik Gordh Riseby ; Rahul Biswas ; Amin Ahmadi ; Oskar Holmstr�m
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study provides an in-depth analysis of the distribution and types of noise in the widely used BIRD-Bench benchmark and the impact of noise on models.

219, TITLE: One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation
AUTHORS: TEJPALSINGH SILEDAR et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We investigate Op-I-Prompt a dimension-independent prompt, and Op-Prompts, a dimension-dependent set of prompts for opinion summary evaluation.

220, TITLE: Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs
AUTHORS: MINH-VUONG NGUYEN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs).

221, TITLE: Centroid-Based Efficient Minimum Bayes Risk Decoding
AUTHORS: HIROYUKI DEGUCHI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose centroid-based MBR (CBMBR) decoding to improve the speed of MBR decoding.

222, TITLE: Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations
AUTHORS: Md Arafat Sultan ; Jatin Ganhotra ; Ram�n Fernandez Astudillo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce a structured chain-of-thought (SCoT) prompting approach to generating content-grounded multi-turn question-answer conversations using a pre-trained large language model (LLM).

223, TITLE: Modelling Political Coalition Negotiations Using LLM-based Agents
AUTHORS: Farhad Moghimifar ; Yuan-Fang Li ; Robert Thomson ; Gholamreza Haffari
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce coalition negotiations as a novel NLP task, and model it as a negotiation between large language model-based agents.

224, TITLE: Metric-Learning Encoding Models Identify Processing Profiles of Linguistic Features in BERT's Representations
AUTHORS: LOUIS JALOUZOT et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce Metric-Learning Encoding Models (MLEMs) as a new approach to understand how neural systems represent the theoretical features of the objects they process.

225, TITLE: MARS: Meaning-Aware Response Scoring for Uncertainty Estimation in Generative LLMs
AUTHORS: YAVUZ FARUK BAKMAN et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this work, we propose Meaning-Aware Response Scoring (MARS) as an alternative to length-normalized scoring for UE methods.

226, TITLE: Perceiving Longer Sequences With Bi-Directional Cross-Attention Transformers
AUTHORS: Markus Hiller ; Krista A. Ehinger ; Tom Drummond
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present a novel bi-directional Transformer architecture (BiXT) which scales linearly with input size in terms of computational cost and memory consumption, but does not suffer the drop in performance or limitation to only one input modality seen with other efficient Transformer-based approaches.

227, TITLE: UncertaintyTrack: Exploiting Detection and Localization Uncertainty in Multi-Object Tracking
AUTHORS: Chang Won Lee ; Steven L. Waslander
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: We introduce UncertaintyTrack, a collection of extensions that can be applied to multiple TBD trackers to account for localization uncertainty estimates from probabilistic object detectors.

228, TITLE: On Good Practices for Task-Specific Distillation of Large Pretrained Models
AUTHORS: Juliette Marrie ; Michael Arbel ; Julien Mairal ; Diane Larlus
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we show that the excellent robustness and versatility of recent pretrained models challenge common practices established in the literature, calling for a new set of optimal guidelines for task-specific distillation.

229, TITLE: Neuromorphic Face Analysis: A Survey
AUTHORS: Federico Becattini ; Lorenzo Berlincioni ; Luca Cultrera ; Alberto Del Bimbo
CATEGORY: cs.CV [cs.CV, cs.ET]
HIGHLIGHT: This survey paper presents a comprehensive overview of capabilities, challenges and emerging applications in the domain of neuromorphic face analysis, to outline promising directions and open issues.

230, TITLE: Interactive Garment Recommendation with User in The Loop
AUTHORS: FEDERICO BECATTINI et. al.
CATEGORY: cs.CV [cs.CV, cs.IR]
HIGHLIGHT: In this paper, we work under the assumption that no prior knowledge is given about a user.

231, TITLE: Search Engines Post-ChatGPT: How Generative Artificial Intelligence Could Make Search Less Reliable
AUTHORS: Shahan Ali Memon ; Jevin D. West
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CY]
HIGHLIGHT: In this commentary, we discuss the evolving nature of search engines, as they begin to generate, index, and distribute content created by generative artificial intelligence (GenAI).

232, TITLE: Cluster Metric Sensitivity to Irrelevant Features
AUTHORS: Miles McCrory ; Spencer A. Thomas
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: In this paper, we investigate the sensitivity of clustering performance noisy uncorrelated variables iteratively added to baseline datasets with well defined clusters.

233, TITLE: Optimizing Warfarin Dosing Using Contextual Bandit: An Offline Policy Learning and Evaluation Method
AUTHORS: Yong Huang ; Charles A. Downs ; Amir M. Rahmani
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Given the wide availability of observational data and safety concerns of decision-making in healthcare, we focused on using exclusively observational data from historical policies as demonstrations to derive new policies; we utilized offline policy learning and evaluation in a contextual bandit setting to establish the optimal personalized dosage strategy.

234, TITLE: Maintaining Adversarial Robustness in Continuous Learning
AUTHORS: XIAOLEI RU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To achieve continuous robust learning, we propose an approach called Double Gradient Projection that projects the gradients for weight updates orthogonally onto two crucial subspaces -- one for stabilizing the smoothed sample gradients and another for stabilizing the final outputs of the neural network.

235, TITLE: Discrete Neural Algorithmic Reasoning
AUTHORS: Gleb Rodionov ; Liudmila Prokhorenkova
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states.

236, TITLE: Learning Conditional Invariances Through Non-Commutativity
AUTHORS: Abhra Chaudhuri ; Serban Georgescu ; Anjan Dutta
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: We show that a provably optimal and sample-efficient way of learning conditional invariances is by relaxing the invariance criterion to be non-commutatively directed towards the target domain.

237, TITLE: Quantum Image Denoising with Machine Learning: A Novel Approach to Improve Quantum Image Processing Quality and Reliability
AUTHORS: Yew Kee Wonga ; Yifan Zhou ; Yan Shing Liang
CATEGORY: quant-ph [quant-ph, cs.AI]
HIGHLIGHT: In this research we propose a novel approach to address the issue of noise in QIP.

238, TITLE: Nonlinear Discrete-Time Observers with Physics-Informed Neural Networks
AUTHORS: Hector Vargas Alvarez ; Gianluca Fabiani ; Ioannis G. Kevrekidis ; Nikolaos Kazantzis ; Constantinos Siettos
CATEGORY: math.NA [math.NA, cs.AI, cs.NA, math.DS, 37N30, 68T05, 93C55, 65D15]
HIGHLIGHT: Integrated within a single-step exact observer linearization framework, the proposed PINN approach aims at learning a nonlinear state transformation map by solving a system of inhomogeneous functional equations.

239, TITLE: Real-World Planning with PDDL+ and Beyond
AUTHORS: Wiktor Piotrowski ; Alexandre Perez
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, the uptake in usage of PDDL+ has been slow and apprehensive, largely due to a general shortage of PDDL+ planning software, and rigid limitations of the few existing planners. To overcome this chasm, we present Nyx, a novel PDDL+ planner built to emphasize lightness, simplicity, and, most importantly, adaptability.

240, TITLE: Discerning and Resolving Knowledge Conflicts Through Adaptive Decoding with Contextual Information-Entropy Constraint
AUTHORS: XIAOWEI YUAN et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This raises a crucial dilemma known as knowledge conflicts, where the contextual knowledge clashes with the However, existing decoding works are specialized in resolving knowledge conflicts and could inadvertently deteriorate performance in absence of conflicts. In this paper, we propose an adaptive decoding method, termed as contextual information-entropy constraint decoding (COIECD), to discern whether the knowledge conflicts occur and resolve them.

241, TITLE: Combinatorial Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing
AUTHORS: Tesfay Zemuy Gebrekidan ; Sebastian Stein ; Timothy J. Norman
CATEGORY: cs.AI [cs.AI, cs.DC, cs.NI, I.2.11]
HIGHLIGHT: We proposed a novel combinatorial client-master MADRL (CCM\_MADRL) algorithm for task offloading in MEC (CCM\_MADRL\_MEC) that enables UDs to decide their resource requirements and the server to make a combinatorial decision based on the requirements of the UDs.

242, TITLE: SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding
AUTHORS: Ruiyi Yang ; Flora D. Salim ; Hao Xue
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Although there are effective spatio-temporal inference methods, they face challenges such as scalability with large datasets and inadequate semantic understanding, which impede their performance. To address these limitations, this paper introduces a novel framework - Simple Spatio-Temporal Knowledge Graph (SSTKG), for constructing and exploring spatio-temporal KGs.

243, TITLE: Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents
AUTHORS: ZENGQING WU et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CY, cs.MA, econ.GN, q-fin.EC]
HIGHLIGHT: However, the potential for LLM agents to spontaneously establish collaborative relationships in the absence of explicit instructions has not been studied. To address this gap, we conduct three case studies, revealing that LLM agents are capable of spontaneously forming collaborations even within competitive settings.

244, TITLE: FGeo-HyperGNet: Geometry Problem Solving Integrating Formal Symbolic System and Hypergraph Neural Network
AUTHORS: XIAOKAI ZHANG et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Geometry problem solving has always been a long-standing challenge in the fields of automated reasoning and artificial intelligence. This is the fifth article in a series of our works, we built a neural-symbolic system to automatically perform human-like geometric deductive reasoning.

245, TITLE: HIP Network: Historical Information Passing Network for Extrapolation Reasoning on Temporal Knowledge Graph
AUTHORS: YONGQUAN HE et. al.
CATEGORY: cs.AI [cs.AI, I.2.4; I.2.6; I.2.7]
HIGHLIGHT: In this paper, we propose the Historical Information Passing (HIP) network to predict future events.

246, TITLE: MultiFIX: An XAI-friendly Feature Inducing Approach to Building Models from Multimodal Data
AUTHORS: Mafalda Malafaia ; Thalea Schlender ; Peter A. N. Bosman ; Tanja Alderliesten
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We propose MultiFIX: a new interpretability-focused multimodal data fusion pipeline that explicitly induces separate features from different data types that can subsequently be combined to make a final prediction.

247, TITLE: Graph-Based Retriever Captures The Long Tail of Biomedical Knowledge
AUTHORS: Julien Delile ; Srayanta Mukherjee ; Anton Van Pamel ; Leonid Zhukov
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In this study, we show that RAG methods leave out a significant proportion of relevant information due to clusters of over-represented concepts in the biomedical literature. We introduce a novel information-retrieval method that leverages a knowledge graph to downsample these clusters and mitigate the information overload problem.

248, TITLE: HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?
AUTHORS: Shubhashis Roy Dipta ; Sadat Shahriar
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose a single model based on contrastive learning, which uses ~40% of the baseline's parameters (149M vs. 355M) but shows a comparable performance on the test dataset (21st out of 137 participants).

249, TITLE: Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding
AUTHORS: HANLING YI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: This research aims to accelerate the inference speed of large language models (LLMs) with billions of parameters.

250, TITLE: BGE Landmark Embedding: A Chunking-Free Embedding Method For Retrieval Augmented Long-Context Large Language Models
AUTHORS: Kun Luo ; Zheng Liu ; Shitao Xiao ; Kang Liu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we proposeExtensible Embedding, which realizes high-quality extension of LLM's context with strong flexibility and cost-effectiveness.

251, TITLE: What's The Plan? Evaluating and Developing Planning-Aware Techniques for LLMs
AUTHORS: Eran Hirsch ; Guy Uziel ; Ateret Anaby-Tavor
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Large language models (LLMs) are increasingly used for applications that require planning capabilities, such as web or embodied agents.

252, TITLE: LEIA: Facilitating Cross-Lingual Knowledge Transfer in Language Models with Entity-based Data Augmentation
AUTHORS: Ikuya Yamada ; Ryokan Ri
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this study, we introduce LEIA, a language adaptation tuning method that utilizes Wikipedia entity names aligned across languages.

253, TITLE: Puzzle Solving Using Reasoning of Large Language Models: A Survey
AUTHORS: Panagiotis Giadikiaroglou ; Maria Lymperaiou ; Giorgos Filandrianos ; Giorgos Stamou
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Through a critical review of relevant datasets and benchmarks, we assess LLMs' performance, identifying significant challenges in complex puzzle scenarios.

254, TITLE: MMMModal -- Multi-Images Multi-Audio Multi-turn Multi-Modal
AUTHORS: Husein Zolkepli ; Aisyah Razak ; Kamarul Adha ; Ariff Nazhan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Our contribution introduces a groundbreaking multimodal large language model designed to comprehend multi-images, multi-audio, and multi-images-multi-audio within a single multiturn session.

255, TITLE: PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation
AUTHORS: Zongxia Li ; Ishani Mondal ; Yijun Liang ; Huy Nghiem ; Jordan Lee Boyd-Graber
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: PANDA (Pedantic ANswer-correctness Determination and Adjudication):Improving Automatic Evaluation for Question Answering and Text Generation

256, TITLE: Modularized Networks for Few-shot Hateful Meme Detection
AUTHORS: Rui Cao ; Roy Ka-Wei Lee ; Jing Jiang
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: In this paper, we address the challenge of detecting hateful memes in the low-resource setting where only a few labeled examples are available.

257, TITLE: Word Embeddings Revisited: Do LLMs Offer Something New?
AUTHORS: Matthew Freestone ; Shubhra Kanti Karmaker Santu
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: Although LLMs have shown remarkable advancement in various NLP tasks, it is still unclear whether the performance improvement is merely because of scale or whether underlying embeddings they produce significantly differ from classical encoding models like Sentence-BERT (SBERT) or Universal Sentence Encoder (USE). This paper systematically investigates this issue by comparing classical word embedding techniques against LLM-based word embeddings in terms of their latent vector semantics.

258, TITLE: Understanding News Thumbnail Representativeness By Counterfactual Text-Guided Contrastive Language-Image Pretraining
AUTHORS: Yejun Yoon ; Seunghyun Yoon ; Kunwoo Park
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: To fill the gap, we propose CFT-CLIP, a counterfactual text-guided contrastive language-image pretraining framework.

259, TITLE: LoRETTA: Low-Rank Economic Tensor-Train Adaptation for Ultra-Low-Parameter Fine-Tuning of Large Language Models
AUTHORS: Yifan Yang ; Jiajun Zhou ; Ngai Wong ; Zheng Zhang
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: However, existing PEFT methods are still limited by the growing number of trainable parameters with the rapid deployment of Large Language Models (LLMs). To address this challenge, we present LoRETTA, an ultra-parameter-efficient framework that significantly reduces trainable parameters through tensor-train decomposition.

260, TITLE: Semantic Textual Similarity Assessment in Chest X-ray Reports Using A Domain-Specific Cosine-Based Metric
AUTHORS: Sayeh Gholipour Picha ; Dawood Al Chanti ; Alice Caplier
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: In this study, we introduce a novel approach designed specifically for assessing the semantic similarity between generated medical reports and the ground truth.

261, TITLE: Mitigating Catastrophic Forgetting in Multi-domain Chinese Spelling Correction By Multi-stage Knowledge Transfer Framework
AUTHORS: PENG XING et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we focus on the key flaw of the CSC model when adapting to multi-domain scenarios: the tendency to forget previously acquired knowledge upon learning new domain-specific knowledge (i.e., catastrophic forgetting). To address this, we propose a novel model-agnostic Multi-stage Knowledge Transfer (MKT) framework, which utilizes a continuously evolving teacher model for knowledge transfer in each domain, rather than focusing solely on new domain knowledge.

262, TITLE: Learning to Edit: Aligning LLMs with Knowledge Editing
AUTHORS: YUXIN JIANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To this end, we propose a Learning to Edit (LTE) framework, focusing on teaching LLMs to apply updated knowledge into input questions, inspired by the philosophy of "Teach a man to fish."

263, TITLE: Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals
AUTHORS: FRANCESCO ORTU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, most existing research in this area focused on analyzing a single mechanism, such as how models copy or recall factual knowledge. In this work, we propose the formulation of competition of mechanisms, which instead of individual mechanisms focuses on the interplay of multiple mechanisms, and traces how one of them becomes dominant in the final prediction.

264, TITLE: Multi-dimensional Evaluation of Empathetic Dialog Responses
AUTHORS: Zhichao Xu ; Jiepu Jiang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In contrast, we propose a multi-dimensional empathy evaluation framework that extends upon existing work to measure both expressed intents from the speaker's perspective and perceived empathy from the listener's perspective.

265, TITLE: Don't Go To Extremes: Revealing The Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection
AUTHORS: Min Zhang ; Jianfeng He ; Taoran Ji ; Chang-Tien Lu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Our evaluation meticulously considers various prompt patterns and mainstream uncertainty estimation methods.

266, TITLE: Team QUST at SemEval-2024 Task 8: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting AI-generated Text
AUTHORS: Xiaoman Xu ; Xiangrun Li ; Taihang Wang ; Jianxiang Tian ; Ye Jiang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper presents the participation of team QUST in Task 8 SemEval 2024.

267, TITLE: Analysis of Levenshtein Transformer's Decoder and Its Variants
AUTHORS: Ruiyang Zhou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this report, we focus on LevT's decoder and analyse the decoding results length, subword generation, and deletion module's capability.

268, TITLE: Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM
AUTHORS: ZIJIN HONG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Thus, the generated SQL of the knowledge-insufficient queries may be inaccurate, which negatively impacts the robustness of the text-to-SQL models. To deal with this situation, we propose the Knowledge-to-SQL framework, which employs tailored Data Expert LLM (DELLM) to provide helpful knowledge for all types of text-to-SQL models.

269, TITLE: Task-Oriented Dialogue with In-Context Learning
AUTHORS: Tom Bocklisch ; Thomas Werkmeister ; Daksh Varshneya ; Alan Nichol
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We describe a system for building task-oriented dialogue systems combining the in-context learning abilities of large language models (LLMs) with the deterministic execution of business logic.

270, TITLE: Grammaticality Illusion or Ambiguous Interpretation? Event-related Potentials Reveal The Nature of The Missing-NP Effect in Mandarin Centre-embedded Structures
AUTHORS: Qihang Yang ; Caimei Yang ; Yu Liao ; Ziman Zhuang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In Experiment 2, providing semantic cues to reduce ambiguity dispelled this illusion, as evidenced by a P600 effect. We interpret the results under garden-path theory and propose that word-order difference may account for this cross-linguistic variation.

271, TITLE: Polarization of Autonomous Generative AI Agents Under Echo Chambers
AUTHORS: Masaya Ohagi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The echo chamber has been viewed as a human-specific problem, but this implicit assumption is becoming less reasonable as large language models, such as ChatGPT, acquire social abilities. In response to this situation, we investigated the potential for polarization to occur among a group of autonomous AI agents based on generative language models in an echo chamber environment.

272, TITLE: KARL: Knowledge-Aware Retrieval and Representations Aid Retention and Learning in Students
AUTHORS: Matthew Shu ; Nishant Balepur ; Shi Feng ; Jordan Boyd-Graber
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Deep Knowledge Tracing (DKT) models can capture semantic relations with language models, but are inefficient, lack content-rich datasets for evaluation, and require robust teaching policies. To address these issues, we design KARL, a DKT-inspired student model that uses retrieval and BERT embeddings for efficient and accurate student recall predictions.

273, TITLE: Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source LLMs in Their Ability to Label Chest X-Ray Reports
AUTHORS: FELIX J. DORFNER et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Conclusion: In this paper, we show that while GPT-4 is superior to open-source models in zero-shot report labeling, the implementation of few-shot prompting can bring open-source models on par with GPT-4.

274, TITLE: Ontology Enhanced Claim Detection
AUTHORS: Zehra Melce H�s�nbeyi ; Tatjana Scheffler
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose an ontology enhanced model for sentence based claim detection.

275, TITLE: Key Ingredients for Effective Zero-shot Cross-lingual Knowledge Transfer in Generative Tasks
AUTHORS: Nadezhda Chirkova ; Vassilina Nikoulina
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work we compare various approaches proposed from the literature in unified settings, also including alternative backbone models, namely mBART and NLLB-200.

276, TITLE: NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms
AUTHORS: Jonathan Zheng ; Alan Ritter ; Wei Xu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Models with later knowledge cutoff dates yield lower perplexities and perform better in downstream tasks.

277, TITLE: BlendFilter: Advancing Retrieval-Augmented Large Language Models Via Query Generation Blending and Knowledge Filtering
AUTHORS: Haoyu Wang ; Tuo Zhao ; Jing Gao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, these methods often face challenges with complex inputs and encounter difficulties due to noisy knowledge retrieval, notably hindering model effectiveness. To address this issue, we introduce BlendFilter, a novel approach that elevates retrieval-augmented LLMs by integrating query generation blending with knowledge filtering.

278, TITLE: Assessing LLMs' Mathematical Reasoning in Financial Document Question Answering
AUTHORS: Pragya Srivastava ; Manuj Malik ; Tanuja Ganu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The results provide insights into LLMs' capabilities and limitations in handling complex mathematical scenarios for semi-structured tables. Ultimately, we introduce a novel prompting technique tailored to semi-structured documents, matching or outperforming other baselines in performance while providing a nuanced understanding of LLMs abilities for such a task.

279, TITLE: Knowledge Graph Assisted Automatic Sports News Writing
AUTHORS: Yang Cao ; Xinyi Chen ; Xin Zhang ; Siying Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a novel method for automatically generating sports news, which employs a unique algorithm that extracts pivotal moments from live text broadcasts and uses them to create an initial draft of the news.

280, TITLE: Language Model Adaptation to Specialized Domains Through Selective Masking Based on Genre and Topical Characteristics
AUTHORS: Anas Belfathi ; Ygor Gallina ; Nicolas Hernandez ; Richard Dufour ; Laura Monceaux
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this article, we introduce an innovative masking approach leveraging genre and topicality information to tailor language models to specialized domains.

281, TITLE: Remember This Event That Year? Assessing Temporal Information and Reasoning in Large Language Models
AUTHORS: Himanshu Beniwal ; Kowsik Nandagopan D ; Mayank Singh
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Remember This Event That Year? Assessing Temporal Information and Reasoning in Large Language Models

282, TITLE: From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings
AUTHORS: AISHIK RAKSHIT et. al.
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this work, we build on the seminal previous work and propose DeepSoftDebias, an algorithm that uses a neural network to perform `soft debiasing'.

283, TITLE: Speech Translation with Speech Foundation Models and Large Language Models: What Is There and What Is Missing?
AUTHORS: Marco Gaido ; Sara Papi ; Matteo Negri ; Luisa Bentivogli
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Among such tasks, this paper focuses on speech-to-text translation (ST). By examining the published papers on the topic, we propose a unified view of the architectural solutions and training strategies presented so far, highlighting similarities and differences among them.

284, TITLE: A Question Answering Based Pipeline for Comprehensive Chinese EHR Information Extraction
AUTHORS: Huaiyuan Ying ; Sheng Yu
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: In this paper, we propose a novel approach that automatically generates training data for transfer learning of QA models.

285, TITLE: KnowTuning: Knowledge-aware Fine-tuning for Large Language Models
AUTHORS: YOUGANG LYU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: These limitations stem from inadequate knowledge awareness of LLMs during vanilla fine-tuning. To address these problems, we propose a knowledge-aware fine-tuning (KnowTuning) method to explicitly and implicitly improve the knowledge awareness of LLMs.

286, TITLE: Compress to Impress: Unleashing The Potential of Compressive Memory in Real-World Long-Term Conversations
AUTHORS: Nuo Chen ; Hongguang Li ; Juhua Huang ; Baoyuan Wang ; Jia Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases.

287, TITLE: In-Context Example Ordering Guided By Label Distributions
AUTHORS: Zhichao Xu ; Daniel Cohen ; Bei Wang ; Vivek Srikumar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we formulate in-context example ordering as an optimization problem.

288, TITLE: Human-AI Interactions in The Communication Era: Autophagy Makes Large Models Achieving Local Optima
AUTHORS: Shu Yang ; Lijie Hu ; Lu Yu ; Muhammad Asif Ali ; Di Wang
CATEGORY: cs.CL [cs.CL, cs.CY, cs.HC]
HIGHLIGHT: Conceptually, we present two realistic models of autophagic ("self-consumption") loops to account for the suppression of human-generated information in the exchange of information between humans and AI systems.

289, TITLE: Evaluating Image Review Ability of Vision Language Models
AUTHORS: SHIGEKI SAITO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.MM]
HIGHLIGHT: Large-scale vision language models (LVLMs) are language models that are capable of processing images and text inputs by a single model.

290, TITLE: A Synthetic Data Approach for Domain Generalization of NLI Models
AUTHORS: Mohammad Javad Hosseini ; Andrey Petrov ; Alex Fabrikant ; Annie Louis
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present an in-depth exploration of the problem of domain generalization of NLI models.

291, TITLE: HunFlair2 in A Cross-corpus Evaluation of Named Entity Recognition and Normalization Tools
AUTHORS: MARIO S�NGER et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: With the exponential growth of the life science literature, biomedical text mining (BTM) has become an essential technology for accelerating the extraction of insights from publications.

292, TITLE: MoRAL: MoE Augmented LoRA for LLMs' Lifelong Learning
AUTHORS: Shu Yang ; Muhammad Asif Ali ; Cheng-Long Wang ; Lijie Hu ; Di Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose MoRAL, i.e., Mixture-of-Experts augmented Low-Rank Adaptation for Lifelong Learning.

293, TITLE: PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering
AUTHORS: Jannat Ara Meem ; Muhammad Shihab Rashid ; Yue Dong ; Vagelis Hristidis
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: PATQA poses unique challenges: (1) large language models (LLMs) may have outdated knowledge, (2) complex temporal relationships (e.g. 'before', 'previous') are hard to reason, (3) multi-hop reasoning may be required, and (4) the gold answers of benchmarks must be continuously updated. To address these challenges, we introduce the PAT-Questions benchmark, which includes single and multi-hop temporal questions.

294, TITLE: Do Large Language Models Understand Logic or Just Mimick Context?
AUTHORS: Junbing Yan ; Chengyu Wang ; Jun Huang ; Wei Zhang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper investigates the reasoning capabilities of LLMs on two logical reasoning datasets by using counterfactual methods to replace context text and modify logical concepts.

295, TITLE: Can Large Language Models Perform Relation-based Argument Mining?
AUTHORS: Deniz Gorur ; Antonio Rago ; Francesca Toni
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: In this paper, we show that general-purpose Large Language Models (LLMs), appropriately primed and prompted, can significantly outperform the best performing (RoBERTa-based) baseline.

296, TITLE: Can LLMs Compute with Reasons?
AUTHORS: HARSHIT SANDILYA et. al.
CATEGORY: cs.CL [cs.CL, 68T50, I.2.7]
HIGHLIGHT: This limitation is further amplified in average Small LangSLMs with limited context and training data. To address this challenge, we propose an "Inductive Learning" approach utilizing a distributed network of SLMs.

297, TITLE: BIDER: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented LLMs Via Key Supporting Evidence
AUTHORS: Jiajie Jin ; Yutao Zhu ; Yujia Zhou ; Zhicheng Dou
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces BIDER, an approach that refines retrieval documents into Key Supporting Evidence (KSE) through knowledge synthesis, supervised fine-tuning (SFT), and preference alignment.

298, TITLE: End-to-end Multilingual Fact-checking at Scale
AUTHORS: Vinay Setty
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this article, we describe how you can perform end-to-end fact-checking in over 100 languages using Factiverse AI models.

299, TITLE: SpeCrawler: Generating OpenAPI Specifications from API Documentation Using Large Language Models
AUTHORS: KOREN LAZAR et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper we introduce SpeCrawler, a comprehensive system that utilizes large language models (LLMs) to generate OpenAPI Specifications from diverse API documentation through a carefully crafted pipeline.

300, TITLE: Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection
AUTHORS: Valeria Pastorino ; Jasivan A. Sivakumar ; Nafise Sadat Moosavi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work contributes to the expanding research on the applicability of LLMs in social sciences by examining the performance of GPT-3.5 Turbo, GPT-4, and Flan-T5 models in detecting framing bias in news headlines through zero-shot, few-shot, and explainable prompting methods.

301, TITLE: In-Context Learning Demonstration Selection Via Influence Analysis
AUTHORS: Vinay M. S. ; Minh-Hao Van ; Xintao Wu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Selecting effective demonstrations for ICL is still an open research challenge. To address this challenge, we propose a demonstration selection method called InfICL which analyzes influences of training samples through influence functions.

302, TITLE: ArtPrompt: ASCII Art-based Jailbreak Attacks Against Aligned LLMs
AUTHORS: FENGQING JIANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose a novel ASCII art-based jailbreak attack and introduce a comprehensive benchmark Vision-in-Text Challenge (ViTC) to evaluate the capabilities of LLMs in recognizing prompts that cannot be solely interpreted by semantics.

303, TITLE: Opening The Black Box of Language Acquisition
AUTHORS: J�r�me Michaud ; Anna Jon-and
CATEGORY: cs.CL [cs.CL, cs.NA, math.NA]
HIGHLIGHT: In this work, we propose an alternative, more transparent and cognitively plausible architecture for learning language.

304, TITLE: Autocorrect for Estonian Texts: Final Report from Project EKTB25
AUTHORS: AGNES LUHTARU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We took into account the existence of the model when adjusting plans and in the report we present a comparison with the ability of GPT4 to improve the Estonian language text.

305, TITLE: PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models
AUTHORS: WENDI CUI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency. To overcome these issues, we present PhaseEvo, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms.

306, TITLE: A Simple Proof That Ricochet Robots Is PSPACE-Complete
AUTHORS: Jose Balanza-Martinez ; Angel A. Cantu ; Robert Schweller ; Tim Wylie
CATEGORY: cs.CC [cs.CC, cs.DS]
HIGHLIGHT: In this paper, we seek to provide a simpler proof that the relocation problem in Ricochet Robots (Lunar Lockout with fixed geometry) is PSPACE-complete via a reduction from Finite Function Generation (FFG).

307, TITLE: Optimal Pseudorandom Generators for Low-Degree Polynomials Over Moderately Large Fields
AUTHORS: Ashish Dwivedi ; Zeyu Guo ; Ben Lee Volk
CATEGORY: cs.CC [cs.CC, cs.SC]
HIGHLIGHT: We construct explicit pseudorandom generators that fool $n$-variate polynomials of degree at most $d$ over a finite field $\mathbb{F}_q$.

308, TITLE: Computational Complexity of The Weisfeiler-Leman Dimension
AUTHORS: Moritz Lichter ; Simon Ra�mann ; Pascal Schweitzer
CATEGORY: cs.CC [cs.CC, cs.DM]
HIGHLIGHT: In this paper, we study the computational complexity of computing the Weisfeiler-Leman dimension.

309, TITLE: Two Online Map Matching Algorithms Based on Analytic Hierarchy Process and Fuzzy Logic
AUTHORS: JEREMY J. LIN et. al.
CATEGORY: cs.CG [cs.CG, cs.AI, cs.CV]
HIGHLIGHT: Our aim of this paper is to develop new map matching algorithms and to improve upon previous work.

310, TITLE: Constrained Boundary Labeling
AUTHORS: Thomas Depian ; Martin N�llenburg ; Soeren Terziadis ; Markus Wallinger
CATEGORY: cs.CG [cs.CG, cs.CC]
HIGHLIGHT: In this paper, we consider grouping and ordering constraints for boundary labeling: Grouping constraints enforce that all labels in a group are placed consecutively on the boundary, and ordering constraints enforce a partial order over the labels.

311, TITLE: When Simple in Near-Optimal in Security Games
AUTHORS: Devansh Jalota ; Michael Ostrovsky ; Marco Pavone
CATEGORY: cs.GT [cs.GT, cs.CC, econ.TH, math.OC]
HIGHLIGHT: However, user fraud is detrimental, as it may compromise safety or impose disproportionate negative externalities on particular population groups. To mitigate the potential harms of user fraud, we study the problem of policing such fraud as a security game between an administrator and users.

312, TITLE: PolypNextLSTM: A Lightweight and Fast Polyp Video Segmentation Network Using ConvNext and ConvLSTM
AUTHORS: DEBAYAN BHATTACHARYA et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: To mirror clinical practices more faithfully, our proposed solution, PolypNextLSTM, leverages video-based deep learning, harnessing temporal information for superior segmentation performance with the least parameter overhead, making it possibly suitable for edge devices.

313, TITLE: SDiT: Spiking Diffusion Model with Transformer
AUTHORS: Shu Yang ; Hanzhi Ma ; Chengting Yu ; Aili Wang ; Er-Ping Li
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we explore a novel diffusion model architecture within spiking neural networks.

314, TITLE: Visual Concept-driven Image Generation with Text-to-Image Diffusion Model
AUTHORS: TANZILA RAHMAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the ability to generate images with multiple interacting concepts, such as human subjects, as well as concepts that may be entangled in one, or across multiple, image illustrations remains illusive. In this work, we propose a concept-driven TTI personalization framework that addresses these core challenges.

315, TITLE: A Novel Fourier Neural Operator Framework for Classification of Multi-sized Images: Application to 3D Digital Porous Media
AUTHORS: Ali Kashefi ; Tapan Mukerji
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Leveraging the advantage of FNOs, we propose a novel deep-learning framework for classifying images with varying sizes.

316, TITLE: Boosting Semi-Supervised 2D Human Pose Estimation By Revisiting Data Augmentation and Consistency Training
AUTHORS: Huayi Zhou ; Mukun Luo ; Fei Jiang ; Yue Ding ; Hongtao Lu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we aim at boosting the accuracy of a pose estimator by excavating extra unlabeled images in a semi-supervised learning (SSL) way.

317, TITLE: Enhancing Surgical Performance in Cardiothoracic Surgery with Innovations from Computer Vision and Artificial Intelligence: A Narrative Review
AUTHORS: Merryn D. Constable ; Hubert P. H. Shum ; Stephen Clark
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Like some other specialities, cardiothoracic surgery has relatively few opportunities to benefit from tools with data capture technology embedded within them (as with robotic-assisted laparoscopic surgery, for example). In such cases, pose estimation techniques that allow for movement tracking across a conventional operating field without using specialist equipment or markers offer considerable potential.

318, TITLE: Dense Matchers for Dense Tracking
AUTHORS: Tom�? Jel�nek ; Jon�? ?er�ch ; Ji?� Matas
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper extends the concept of combining multiple optical flows over logarithmically spaced intervals as proposed by MFT.

319, TITLE: GIM: Learning Generalizable Image Matcher From Internet Videos
AUTHORS: XUELUN SHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: One of the underlying problems is the limited scalability of existing data construction pipelines, which limits the diversity of standard image matching datasets. To address this problem, we propose GIM, a self-training framework for learning a single generalizable model based on any image matching architecture using internet videos, an abundant and diverse data source.

320, TITLE: Modular Graph Extraction for Handwritten Circuit Diagram Images
AUTHORS: Johannes Bayer ; Leo van Waveren ; Andreas Dengel
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: This paper describes a modular end-to-end solution on a larger, public dataset, in which approaches for the individual sub-tasks are evaluated to form a new baseline.

321, TITLE: A Robust Error-Resistant View Selection Method for 3D Reconstruction
AUTHORS: SHAOJIE ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the issue of increased triangulation uncertainty caused by selecting views with small camera baselines in Structure from Motion (SFM) view selection, this paper proposes a robust error-resistant view selection method.

322, TITLE: Challenging The Black Box: A Comprehensive Evaluation of Attribution Maps of CNN Applications in Agriculture and Forestry
AUTHORS: LARS NIERADZIK et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this study, we explore the explainability of neural networks in agriculture and forestry, specifically in fertilizer treatment classification and wood identification.

323, TITLE: Semantically-aware Neural Radiance Fields for Visual Scene Understanding: A Comprehensive Review
AUTHORS: Thang-Anh-Quan Nguyen ; Amine Bourki ; M�ty�s Macudzinski ; Anthony Brunel ; Mohammed Bennamoun
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This review thoroughly examines the role of semantically-aware Neural Radiance Fields (NeRFs) in visual scene understanding, covering an analysis of over 250 scholarly papers.

324, TITLE: A Multispectral Automated Transfer Technique (MATT) for Machine-driven Image Labeling Utilizing The Segment Anything Model (SAM)
AUTHORS: James E. Gallagher ; Aryav Gogia ; Edward J. Oughton
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, SAM is unable to segment and label images outside of the visible light spectrum, for example, for multispectral or hyperspectral imagery. Therefore, this paper outlines a method we call the Multispectral Automated Transfer Technique (MATT).

325, TITLE: AICAttack: Adversarial Image Captioning Attack with Attention-Based Optimization
AUTHORS: Jiyao Li ; Mingze Ni ; Yifei Dong ; Tianqing Zhu ; Wei Liu
CATEGORY: cs.CV [cs.CV, cs.CR, cs.LG]
HIGHLIGHT: In this paper, we present a novel adversarial attack strategy, which we call AICAttack (Attention-based Image Captioning Attack), designed to attack image captioning models through subtle perturbations on images.

326, TITLE: DiffPoint: Single and Multi-view Point Cloud Reconstruction with ViT Based Diffusion Model
AUTHORS: Yu Feng ; Xing Shi ; Mengli Cheng ; Yun Xiong
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We evaluate DiffPoint on both single-view and multi-view reconstruction tasks and achieve state-of-the-art results.

327, TITLE: Separating Common from Salient Patterns with Contrastive Representation Learning
AUTHORS: Robin Louiset ; Edouard Duchesnay ; Antoine Grigis ; Pietro Gori
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose to leverage the ability of Contrastive Learning to learn semantically expressive representations well adapted for Contrastive Analysis.

328, TITLE: A Decoding Scheme with Successive Aggregation of Multi-Level Features for Light-Weight Semantic Segmentation
AUTHORS: Jiwon Yoo ; Jangwon Lee ; Gyeonghwan Kim
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Multi-scale architecture, including hierarchical vision transformer, has been commonly applied to high-resolution semantic segmentation to deal with computational complexity with minimum performance loss. In this paper, we propose a novel decoding scheme for semantic segmentation in this regard, which takes multi-level features from the encoder with multi-scale architecture.

329, TITLE: Hand Biometrics in Digital Forensics
AUTHORS: Asish Bera ; Debotosh Bhattacharjee ; Mita Nasipuri
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Hand Biometrics in Digital Forensics

330, TITLE: Are You Struggling? Dataset and Baselines for Struggle Determination in Assembly Videos
AUTHORS: SHIJIA FENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present a new dataset with three assembly activities and corresponding performance baselines for the determination of struggle from video.

331, TITLE: II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering
AUTHORS: Jihyung Kil ; Farideh Tavazoee ; Dongyeop Kang ; Joo-Kyung Kim
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this paper, we propose II-MMR, a novel idea to identify and improve multi-modal multi-hop reasoning in VQA.

332, TITLE: Surround-View Fisheye Optics in Computer Vision and Simulation: Survey and Challenge
AUTHORS: DANIEL JAKAB et. al.
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: In this paper, we provide a survey on automotive surround-view fisheye optics, with an emphasis on the impact of optical artifacts on computer vision tasks in autonomous driving and ADAS.

333, TITLE: GraphKD: Exploring Knowledge Distillation Towards Document Object Detection with Structured Graph Creation
AUTHORS: Ayan Banerjee ; Sanket Biswas ; Josep Llad�s ; Umapada Pal
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Here we present a graph-based knowledge distillation framework to correctly identify and localize the document objects in a document image.

334, TITLE: Landmark Stereo Dataset for Landmark Recognition and Moving Node Localization in A Non-GPS Battlefield Environment
AUTHORS: Ganesh Sapkota ; Sanjay Madria
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we have proposed a new strategy of using the landmark anchor node instead of a radio-based anchor node to obtain the virtual coordinates (landmarkID, DISTANCE) of moving troops or defense forces that will help in tracking and maneuvering the troops along a safe path within a GPS-denied battlefield environment.

335, TITLE: ISCUTE: Instance Segmentation of Cables Using Text Embedding
AUTHORS: Shir Kozlovsky ; Omkar Joglekar ; Dotan Di Castro
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we propose a foundation model-based DLO instance segmentation technique that is text-promptable and user-friendly.

336, TITLE: MAL: Motion-Aware Loss with Temporal and Distillation Hints for Self-Supervised Depth Estimation
AUTHORS: Yup-Jiang Dong ; Fang-Lue Zhang ; Song-Hai Zhang
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: However, the self-supervised methods often rely on the assumption of a static scene and their performance tends to degrade in dynamic environments. To address this issue, we present Motion-Aware Loss, which leverages the temporal relation among consecutive input frames and a novel distillation scheme between the teacher and student networks in the multi-frame self-supervised depth estimation methods.

337, TITLE: To Use or Not to Use Proprietary Street View Images in (health and Place) Research? That Is The Question
AUTHORS: Marco Helbich ; Matthew Danish ; SM Labib ; Britta Ricker
CATEGORY: cs.CV [cs.CV, stat.AP]
HIGHLIGHT: Interactive web services, particularly Google Street View, play an ever-important role in making imagery data ubiquitous. Despite the technical ease of harnessing millions of Google Street View images, this article questions the current practices in using this proprietary data source.

338, TITLE: Weakly Supervised Object Detection in Chest X-Rays with Differentiable ROI Proposal Networks and Soft ROI Pooling
AUTHORS: Philip M�ller ; Felix Meissen ; Georgios Kaissis ; Daniel Rueckert
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we propose Weakly Supervised ROI Proposal Networks (WSRPN), a new method for generating bounding box proposals on the fly using a specialized region of interest-attention (ROI-attention) module.

339, TITLE: Semi-supervised Medical Image Segmentation Method Based on Cross-pseudo Labeling Leveraging Strong and Weak Data Augmentation Strategies
AUTHORS: YIFEI CHEN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper proposes a semi-supervised model, DFCPS, which innovatively incorporates the Fixmatch concept.

340, TITLE: Occlusion Resilient 3D Human Pose Estimation
AUTHORS: Soumava Kumar Roy ; Ilia Badanin ; Sina Honari ; Pascal Fua
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Temporal consistency has been extensively used to mitigate their impact but the existing algorithms in the literature do not explicitly model them. Here, we apply this by representing the deforming body as a spatio-temporal graph.

341, TITLE: CPN: Complementary Proposal Network for Unconstrained Text Detection
AUTHORS: Longhuang Wu ; Shangxuan Tian ; Youxin Wang ; Pengfei Xiong
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To further enhance the complementarity, we introduce an Interleaved Feature Attention module that enables semantic and geometric features to interact deeply before proposal generation.

342, TITLE: Beyond Literal Descriptions: Understanding and Locating Open-World Objects Aligned with Human Intentions
AUTHORS: WENXUAN WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Thus, in this work, we take a step further to the intention-driven visual-language (V-L) understanding.

343, TITLE: Cross-Attention Fusion of Visual and Geometric Features for Large Vocabulary Arabic Lipreading
AUTHORS: Samar Daou ; Ahmed Rekik ; Achraf Ben-Hamadou ; Abdelaziz Kallel
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: However, employing a simple combination method such as concatenation may not be the most effective approach to get the optimal feature vector. To address this challenge, firstly, we propose a cross-attention fusion-based approach for large lexicon Arabic vocabulary to predict spoken words in videos.

344, TITLE: Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships
AUTHORS: Sebastian Koch ; Narunas Vaskevicius ; Mirco Colosi ; Pedro Hermosilla ; Timo Ropinski
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present Open3DSG, an alternative approach to learn 3D scene graph prediction in an open world without requiring labeled scene graph data.

345, TITLE: Major TOM: Expandable Datasets for Earth Observation
AUTHORS: Alistair Francis ; Mikolaj Czerkawski
CATEGORY: cs.CV [cs.CV, cs.DB]
HIGHLIGHT: Major TOM: Expandable Datasets for Earth Observation

346, TITLE: Towards Explainable LiDAR Point Cloud Semantic Segmentation Via Gradient Based Target Localization
AUTHORS: Abhishek Kuriyal ; Vaibhav Kumar
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This paper introduces pGS-CAM, a novel gradient-based method for generating saliency maps in neural network activation layers.

347, TITLE: CoLLaVO: Crayon Large Language and Vision MOdel
AUTHORS: Byung-Kwan Lee ; Beomchan Park ; Chae Won Kim ; Yong Man Ro
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To enhance object-level image understanding, we propose Crayon Large Language and Vision mOdel (CoLLaVO), which incorporates instruction tuning with crayon prompt as a new visual prompt tuning scheme based on panoptic color maps.

348, TITLE: ICHPro: Intracerebral Hemorrhage Prognosis Classification Via Joint-attention Fusion-based 3d Cross-modal Network
AUTHORS: XINLEI YU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we propose a joint-attention fusion-based 3D cross-modal network termed ICHPro that simulates the ICH prognosis interpretation process utilized by neurosurgeons.

349, TITLE: ReViT: Enhancing Vision Transformers with Attention Residual Connections for Visual Recognition
AUTHORS: Anxhelo Diko ; Danilo Avola ; Marco Cascio ; Luigi Cinque
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, such features can be helpful to accurately represent and identify elements within an image and increase the accuracy and robustness of vision-based recognition systems. Following this rationale, we propose a novel residual attention learning method for improving ViT-based architectures, increasing their visual feature diversity and model robustness.

350, TITLE: FViT: A Focal Vision Transformer with Gabor Filter
AUTHORS: YULONG SHI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Unfortunately, self-attention still faces some challenges in dense prediction tasks, such as the high computational complexity and absence of desirable inductive bias. To address these above issues, we revisit the potential benefits of integrating vision transformer with Gabor filter, and propose a Learnable Gabor Filter (LGF) by using convolution.

351, TITLE: Adversarial Feature Alignment: Balancing Robustness and Accuracy in Deep Learning Via Adversarial Training
AUTHORS: Leo Hyun Park ; Jaeuk Kim ; Myung Gyo Oh ; Jaewoo Park ; Taekyoung Kwon
CATEGORY: cs.CV [cs.CV, cs.CR, cs.LG, I.4.0; K.6.5; D.2.7]
HIGHLIGHT: The necessity for deep learning models to balance both robustness and accuracy for security is obvious, but achieving this balance remains challenging, and the underlying reasons are yet to be clarified. This paper proposes a novel adversarial training method called Adversarial Feature Alignment (AFA), to address these problems.

352, TITLE: Logical Closed Loop: Uncovering Object Hallucinations in Large Vision-Language Models
AUTHORS: JUNFEI WU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this work, we adopt the intuition that the LVLM tends to respond logically consistently for existent objects but inconsistently for hallucinated objects. Therefore, we propose a Logical Closed Loop-based framework for Object Hallucination Detection and Mitigation, namely LogicCheckGPT.

353, TITLE: Examining Monitoring System: Detecting Abnormal Behavior In Online Examinations
AUTHORS: DINH AN NGO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CY]
HIGHLIGHT: This article outlines our methodology and the effectiveness of our system in mitigating the widespread problem of cheating in online exams.

354, TITLE: MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of LiDAR-Camera Fusion for 3D Object Detection
AUTHORS: Till Beemelmanns ; Quan Zhang ; Lutz Eckstein
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Additionally, the integrity of LiDAR and camera data is often compromised by adverse environmental conditions such as inclement weather, leading to occlusions and noise interference. To address this challenge, we introduce MultiCorrupt, a comprehensive benchmark designed to evaluate the robustness of multi-modal 3D object detectors against ten distinct types of corruptions.

355, TITLE: Copyleft for Alleviating AIGC Copyright Dilemma: What-if Analysis, Public Perception and Implications
AUTHORS: Xinwei Guo ; Yujun Li ; Yafeng Peng ; Xuetao Wei
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: In this paper, we take a step further to explore the feasibility of copyleft to alleviate the AIGC copyright dilemma.

356, TITLE: Gauging Public Acceptance of Conditionally Automated Cars in The United States
AUTHORS: Antonios Saravanos
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: In this work we look at an element of smart cities, conditionally automated cars (SAE Level 3), investigating the factors influencing public acceptance in the United States.

357, TITLE: Causal Equal Protection As Algorithmic Fairness
AUTHORS: Marcello Di Bello ; Nicol� Cangiotti ; Michele Loi
CATEGORY: cs.CY [cs.CY, cs.AI, cs.DS, cs.LG]
HIGHLIGHT: Multiple scenarios can be imagined in which - intuitively - a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated.

358, TITLE: The AI Security Pyramid of Pain
AUTHORS: CHRIS M. WARD et. al.
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: We introduce the AI Security Pyramid of Pain, a framework that adapts the cybersecurity Pyramid of Pain to categorize and prioritize AI-specific threats.

359, TITLE: CovRL: Fuzzing JavaScript Engines with Coverage-Guided Reinforcement Learning for LLM-based Mutation
AUTHORS: Jueon Eom ; Seyeon Jeong ; Taekyoung Kwon
CATEGORY: cs.CR [cs.CR, cs.CL, cs.LG, cs.SE, D.4.6; I.2.5; D.2.4]
HIGHLIGHT: This paper presents a novel technique called CovRL (Coverage-guided Reinforcement Learning) that combines Large Language Models (LLMs) with reinforcement learning from coverage feedback.

360, TITLE: Evaluation of ChatGPT's Smart Contract Auditing Capabilities Based on Chain of Thought
AUTHORS: Yuying Du ; Xueyan Tang
CATEGORY: cs.CR [cs.CR, cs.AI, 68, I.2; J.6]
HIGHLIGHT: This study explores the potential of enhancing smart contract security audits using the GPT-4 model.

361, TITLE: To Store or Not to Store: A Graph Theoretical Approach for Dataset Versioning
AUTHORS: ANXIN GUO et. al.
CATEGORY: cs.DS [cs.DS, cs.CC, cs.DB, cs.DC]
HIGHLIGHT: In this work, we study the cost efficient data versioning problem, where the goal is to optimize the storage and reconstruction (retrieval) costs of data versions, given a graph of datasets as nodes and edges capturing edit/delta information.

362, TITLE: Shaping Human-AI Collaboration: Varied Scaffolding Levels in Co-writing with Language Models
AUTHORS: PARAMVEER S. DHILLON et. al.
CATEGORY: cs.HC [cs.HC, cs.CL]
HIGHLIGHT: This paper explores how varying levels of scaffolding from large language models (LLMs) shape the co-writing process.

363, TITLE: Ask Optimal Questions: Aligning Large Language Models with Retriever's Preference in Conversational Search
AUTHORS: CHANWOONG YOON et. al.
CATEGORY: cs.IR [cs.IR, cs.CL]
HIGHLIGHT: The common approach of rewrite-then-retrieve aims to decontextualize questions to be self-sufficient for off-the-shelf retrievers, but most existing methods produce sub-optimal query rewrites due to the limited ability to incorporate signals from the retrieval results. To overcome this limitation, we present a novel framework RetPO (Retriever's Preference Optimization), which is designed to optimize a language model (LM) for reformulating search queries in line with the preferences of the target retrieval systems.

364, TITLE: Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering
AUTHORS: Peijie Sun ; Le Wu ; Kun Zhang ; Xiangzhi Chen ; Meng Wang
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: In response, we propose a solution that treats the collaborative neighbors of the anchor node as positive samples within the final objective loss function.

365, TITLE: Heterogeneity-aware Cross-school Electives Recommendation: A Hybrid Federated Approach
AUTHORS: Chengyi Ju ; Jiannong Cao ; Yu Yang ; Zhen-Qun Yang ; Ho Man Lee
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: In response, we propose HFRec, a heterogeneity-aware hybrid federated recommender system designed for cross-school elective course recommendations.

366, TITLE: Integrating Pre-Trained Language Model with Physical Layer Communications
AUTHORS: Ju-Hyung Lee ; Dong-Ho Lee ; Joohan Lee ; Jay Pujara
CATEGORY: cs.IT [cs.IT, cs.CL, cs.LG, eess.SP, math.IT]
HIGHLIGHT: However, integrating these frameworks with existing wireless systems and effectively managing noise and bit errors pose significant challenges. In this work, we introduce a practical on-device AI communication framework, integrated with physical layer (PHY) communication functions, demonstrated through its performance on a link-level simulator.

367, TITLE: Simplifying Hyperparameter Tuning in Online Machine Learning -- The SpotRiverGUI
AUTHORS: Thomas Bartz-Beielstein
CATEGORY: cs.LG [cs.LG, cs.AI, 90C26, I.2.6; G.1.6]
HIGHLIGHT: The `spotRiver` package provides a framework for hyperparameter tuning of OML models.

368, TITLE: Stochastic Approximation with Delayed Updates: Finite-Time Rates Under Markovian Sampling
AUTHORS: ARMAN ADIBI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.MA, cs.SY, eess.SY, math.OC]
HIGHLIGHT: While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \emph{last iterate} to a ball around the SA operator's fixed point.

369, TITLE: Finite-Time Error Analysis of Online Model-Based Q-Learning with A Relaxed Sampling Model
AUTHORS: Han-Dong Lim ; HyeAnn Lee ; Donghwan Lee
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we delve into the sample complexity of $Q$-learning when integrated with a model-based approach.

370, TITLE: Model Editing By Pure Fine-Tuning
AUTHORS: Govind Gangadhar ; Karl Stratos
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this work, we show that pure fine-tuning can be a viable approach to model editing.

371, TITLE: Training Green AI Models Using Elite Samples
AUTHORS: Mohammed Alswaitti ; Roberto Verdecchia ; Gr�goire Danoy ; Pascal Bouvry ; Johnatan Pecero
CATEGORY: cs.LG [cs.LG, cs.AI, cs.NE]
HIGHLIGHT: This paper presents an evolutionary-based sampling framework aimed at (i) identifying elite training samples tailored for datasets and model pairs, (ii) comparing model performance and energy efficiency gains against typical model training practice, and (iii) investigating the feasibility of this framework for fostering sustainable model training practices.

372, TITLE: Knowledge Distillation Based on Transformed Teacher Matching
AUTHORS: Kaixiang Zheng ; En-Hui Yang
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: To further enhance student's capability to match teacher's power transformed probability distribution, we introduce a sample-adaptive weighting coefficient into TTM, yielding a novel distillation approach dubbed weighted TTM (WTTM).

373, TITLE: OptEx: Expediting First-Order Optimization with Approximately Parallelized Iterations
AUTHORS: Yao Shu ; Jiongfeng Fang ; Ying Tiffany He ; Fei Richard Yu
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: However, their application to complex tasks like neural network training often entails significant inefficiencies due to the need for many sequential iterations for convergence. In response, we introduce first-order optimization expedited with approximately parallelized iterations (OptEx), the first framework that enhances the efficiency of FOO by leveraging parallel computing to mitigate its iterative bottleneck.

374, TITLE: LiGNN: Graph Neural Networks at LinkedIn
AUTHORS: FEDOR BORISYUK et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we present LiGNN, a deployed large-scale Graph Neural Networks (GNNs) Framework.

375, TITLE: Theoretical Foundations for Programmatic Reinforcement Learning
AUTHORS: Guruprerana Shabadi ; Nathana�l Fijalkow ; Th�o Matricon
CATEGORY: cs.LG [cs.LG, cs.LO, cs.PL]
HIGHLIGHT: How can we learn them? The goal of this paper is to give first answers to these questions, initiating a theoretical study of programmatic RL.

376, TITLE: Learning with Imbalanced Noisy Data By Preventing Bias in Sample Selection
AUTHORS: HUAFENG LIU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To this end, we propose a simple yet effective method to address noisy labels in imbalanced datasets.

377, TITLE: Be Persistent: Towards A Unified Solution for Mitigating Shortcuts in Deep Learning
AUTHORS: Hadi M. Dolatabadi ; Sarah M. Erfani ; Christopher Leckie
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Shortcut learning is ubiquitous among many failure cases of neural networks, and traces of this phenomenon can be seen in their generalizability issues, domain shift, adversarial vulnerability, and even bias towards majority groups. In this paper, we argue that this commonality in the cause of various DNN issues creates a significant opportunity that should be leveraged to find a unified solution for shortcut learning.

378, TITLE: Energy-Efficient Edge Learning Via Joint Data Deepening-and-Prefetching
AUTHORS: Sujin Kook ; Won-Yong Shin ; Seong-Lyun Kim ; Seung-Woo Ko
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IT, math.IT]
HIGHLIGHT: However, transmitting high-dimensional and voluminous data from energy-constrained IoT devices poses a significant challenge. To address this limitation, we propose a novel offloading architecture, called joint data deepening-and-prefetching (JD2P), which is feature-by-feature offloading comprising two key techniques.

379, TITLE: Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network
AUTHORS: LIN CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We propose a novel REasoning meta-STRUCTure search (ReStruct) framework that integrates LLM reasoning into the evolutionary procedure.

380, TITLE: Learning to Defer in Content Moderation: The Human-AI Interplay
AUTHORS: Thodoris Lykouris ; Wentao Weng
CATEGORY: cs.LG [cs.LG, cs.AI, cs.GT, cs.HC, cs.PF]
HIGHLIGHT: In this paper, we introduce a model to capture the human-AI interplay in content moderation.

381, TITLE: On The Byzantine-Resilience of Distillation-Based Federated Learning
AUTHORS: Christophe Roux ; Max Zimmer ; Sebastian Pokutta
CATEGORY: cs.LG [cs.LG, cs.AI, cs.DC]
HIGHLIGHT: These methods depart from transmitting model parameters and, instead, communicate information about a learning task by sharing predictions on a public dataset. In this work, we study the performance of such approaches in the byzantine setting, where a subset of the clients act in an adversarial manner aiming to disrupt the learning process.

382, TITLE: Uncertainty Quantification in Fine-tuned LLMs Using LoRA Ensembles
AUTHORS: Oleksandr Balabanov ; Hampus Linander
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, stat.ML]
HIGHLIGHT: Fine-tuning large language models can improve task specific performance, although a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing.

383, TITLE: Generating Survival Interpretable Trajectories and Data
AUTHORS: Andrei V. Konstantinov ; Stanislav R. Kirpichenko ; Lev V. Utkin
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: A new model for generating survival trajectories and data based on applying an autoencoder of a specific structure is proposed.

384, TITLE: Linear Bandits with Polylogarithmic Minimax Regret
AUTHORS: Josep Lumbreras ; Marco Tomamichel
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We study a noise model for linear stochastic bandits for which the subgaussian noise parameter vanishes linearly as we select actions on the unit sphere closer and closer to the unknown vector. We introduce an algorithm for this problem that exhibits a minimax regret scaling as $\log^3(T)$ in the time horizon $T$, in stark contrast the square root scaling of this regret for typical bandit algorithms.

385, TITLE: Class-incremental Learning for Time Series: Benchmark and Evaluation
AUTHORS: ZHONGZHENG QIAO et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Using this framework, we conduct a comprehensive evaluation of various generic and time-series-specific CIL methods in both standard and privacy-sensitive scenarios.

386, TITLE: Minimally Supervised Topological Projections of Self-Organizing Maps for Phase of Flight Identification
AUTHORS: Zimeng Lyu ; Pujan Thapa ; Travis Desell
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: This work investigates the use of a novel method for minimally supervised self-organizing maps (MS-SOMs) which utilize nearest neighbor majority votes in the SOM U-matrix for class estimation.

387, TITLE: Privacy-Preserving Low-Rank Adaptation for Latent Diffusion Models
AUTHORS: ZIHAO LUO et. al.
CATEGORY: cs.LG [cs.LG, cs.CR, cs.CV]
HIGHLIGHT: However, we empirically disclose that PrivateLoRA has the issue of unstable optimization due to the large fluctuation of the gradient scale which impedes adaptation. To mitigate this issue, we propose Stable PrivateLoRA that adapts the LDM by minimizing the ratio of the adaptation loss to the MI gain, which implicitly rescales the gradient and thus stabilizes the optimization.

388, TITLE: A Curious Case of Searching for The Correlation Between Training Data and Adversarial Robustness of Transformer Textual Models
AUTHORS: Cuong Dang ; Dung D. Le ; Thai Le
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CR]
HIGHLIGHT: In this paper, we want to prove that there is also a strong correlation between training data and model robustness.

389, TITLE: Trust Regions for Explanations Via Black-Box Probabilistic Certification
AUTHORS: Amit Dhurandhar ; Swagatam Haldar ; Dennis Wei ; Karthikeyan Natesan Ramamurthy
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we introduce a novel problem of black box (probabilistic) explanation certification.

390, TITLE: Multi-View Conformal Learning for Heterogeneous Sensor Fusion
AUTHORS: Enrique Garcia-Ceja
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: To this end, we build and test multi-view and single-view conformal models for heterogeneous sensor fusion.

391, TITLE: Imbalance in Regression Datasets
AUTHORS: Daniel Kowatsch ; Nicolas M. M�ller ; Kilian Tscharke ; Philip Sperl ; Konstantin B�tinger
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we argue that imbalance in regression is an equally important problem which has so far been overlooked: Due to under- and over-representations in a data set's target distribution, regressors are prone to degenerate to naive models, systematically neglecting uncommon training data and over-representing targets seen often during training.

392, TITLE: Microstructures and Accuracy of Graph Recall By Large Language Models
AUTHORS: Yanbang Wang ; Hejie Cui ; Jon Kleinberg
CATEGORY: cs.LG [cs.LG, cs.CL, cs.IR, cs.SI]
HIGHLIGHT: In this work, we perform the first systematical study of graph recall by LLMs, investigating the accuracy and biased microstructures (local structural patterns) in their recall.

393, TITLE: DualView: Data Attribution from The Dual Perspective
AUTHORS: Galip �mit Yolcu ; Thomas Wiegand ; Wojciech Samek ; Sebastian Lapuschkin
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Local data attribution (or influence estimation) techniques aim at estimating the impact that individual data points seen during training have on particular predictions of an already trained Machine Learning model during test time.

394, TITLE: Towards A Tailored Mixed-precision Sub-8bit Quantization Scheme for Gated Recurrent Units Using Genetic Algorithms
AUTHORS: RICCARDO MICCINI et. al.
CATEGORY: cs.LG [cs.LG, cs.NE, eess.SP]
HIGHLIGHT: In this work, we propose a modular integer quantization scheme for GRUs where the bit width of each operator can be selected independently.

395, TITLE: DART: A Principled Approach to Adversarially Robust Unsupervised Domain Adaptation
AUTHORS: YUNJUAN WANG et. al.
CATEGORY: cs.LG [cs.LG, cs.CV, stat.ML]
HIGHLIGHT: In this work, we study the problem of adversarial robustness under a common setting of distribution shift - unsupervised domain adaptation (UDA).

396, TITLE: Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-tuning
AUTHORS: Mingtian Zhang ; Shawn Lan ; Peter Hayes ; David Barber
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We introduce Model augmented fine-tuning (Mafin) -- a novel approach for fine-tuning a black-box embedding model by augmenting it with a trainable embedding model.

397, TITLE: Learning Discretized Bayesian Networks with GOMEA
AUTHORS: Damy M. F. Ha ; Tanja Alderliesten ; Peter A. N. Bosman
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: In this work, we extend an existing state-of-the-art structure learning approach based on the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) to jointly learn variable discretizations.

398, TITLE: All Language Models Large and Small
AUTHORS: Zhixun Chen ; Yali Du ; David Mguni
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We introduce a novel plug-and-play LM framework named Language Optimising Network Distribution (LONDI) framework.

399, TITLE: In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness
AUTHORS: Liam Collins ; Advait Parulekar ; Aryan Mokhtari ; Sujay Sanghavi ; Sanjay Shakkottai
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We explore the role of softmax attention in an ICL setting where each context encodes a regression task.

400, TITLE: Dynamic Multi-Network Mining of Tensor Time Series
AUTHORS: Kohei Obata ; Koki Kawabata ; Yasuko Matsubara ; Yasushi Sakurai
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IT, math.IT]
HIGHLIGHT: In this paper, we propose a new method, Dynamic Multi-network Mining (DMM), that converts a tensor time series into a set of segment groups of various lengths (i.e., clusters) characterized by a dependency network constrained with l1-norm.

401, TITLE: Revisiting Data Augmentation in Deep Reinforcement Learning
AUTHORS: Jianshu Hu ; Yunpeng Jiang ; Paul Weng
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: This analysis suggests recommendations on how to exploit data augmentation in a more principled way.

402, TITLE: Reinforcement Learning As A Parsimonious Alternative to Prediction Cascades: A Case Study on Image Segmentation
AUTHORS: Bharat Srikishan ; Anika Tabassum ; Srikanth Allu ; Ramakrishnan Kannan ; Nikhil Muralidhar
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: However, we argue that cascaded prediction leads to increased computational cost due to wasteful intermediate computations. To address this, we propose PaSeR (Parsimonious Segmentation with Reinforcement Learning) a non-cascading, cost-aware learning pipeline as an alternative to cascaded architectures.

403, TITLE: Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search
AUTHORS: Kejing Lu ; Chuan Xiao ; Yoshiharu Ishikawa
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.DB, cs.DS]
HIGHLIGHT: Subsequently, we introduce PEOs, a novel approach that efficiently identifies which neighbors in the graph should be considered for exact distance computation, thus significantly improving efficiency in practice.

404, TITLE: Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models Via Reparameterisation and Smoothing
AUTHORS: Dominik Wagner ; Basim Khajwal ; C. -H. Luke Ong
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC]
HIGHLIGHT: We introduce a simple syntactic framework to define non-differentiable functions piecewisely and present a systematic approach to obtain smoothings for which the reparameterisation gradient estimator is unbiased.

405, TITLE: SPML: A DSL for Defending Language Models Against Prompt Attacks
AUTHORS: Reshabh K Sharma ; Vinayak Gupta ; Dan Grossman
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CR, cs.PL]
HIGHLIGHT: This paper presents System Prompt Meta Language (SPML), a domain-specific language for refining prompts and monitoring the inputs to the LLM-based chatbots.

406, TITLE: The Effectiveness of Random Forgetting for Robust Generalization
AUTHORS: Vijaya Raghavan T Ramkumar ; Bahram Zonooz ; Elahe Arani
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called "Forget to Mitigate Overfitting (FOMO)".

407, TITLE: Fair Classification with Partial Feedback: An Exploration-Based Data-Collection Approach
AUTHORS: Vijay Keswani ; Anay Mehrotra ; L. Elisa Celis
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CY, stat.ML]
HIGHLIGHT: We present an approach that trains a classifier using available data and comes with a family of exploration strategies to collect outcome data about subpopulations that otherwise would have been ignored.

408, TITLE: Prospector Heads: Generalized Feature Attribution for Large Models & Data
AUTHORS: GAUTAM MACHIRAJU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, q-bio.QM]
HIGHLIGHT: We introduce prospector heads, an efficient and interpretable alternative to explanation-based methods for feature attribution that can be applied to any encoder and any data modality.

409, TITLE: Generative Kaleidoscopic Networks
AUTHORS: Harsh Shrivastava
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We discovered that the Deep ReLU networks (or Multilayer Perceptron architecture) demonstrate an 'over-generalization' phenomenon.

410, TITLE: Multi-Generative Agent Collective Decision-Making in Urban Planning: A Case Study for Kendall Square Renovation
AUTHORS: Jin Gao ; Hanyong Xu ; Luc Dao
CATEGORY: cs.MA [cs.MA, cs.AI]
HIGHLIGHT: In this study, we develop a multiple-generative agent system to simulate community decision-making for the redevelopment of Kendall Square's Volpe building.

411, TITLE: Fair Resource Allocation in Virtualized O-RAN Platforms
AUTHORS: Fatih Aslan ; George Iosifidis ; Jose A. Ayala-Romero ; Andres Garcia-Saavedra ; Xavier Costa-Perez
CATEGORY: cs.NI [cs.NI, cs.AI, cs.LG]
HIGHLIGHT: This paper presents first a series of experiments which assess the O-Cloud's energy costs and their dependency on the servers' hardware, capacity and data traffic properties which, typically, change over time.

412, TITLE: TDE-3: An Improved Prior for Optical Flow Computation in Spiking Neural Networks
AUTHORS: Matthew Yedutenko ; Federico Paredes-Valles ; Lyes Khacef ; Guido C. H. E. De Croon
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: Here we propose an augmented 3-point TDE (TDE-3) with additional inhibitory input that makes TDE-3 direction-selectivity robust in textured environments.

413, TITLE: An Enhanced Teaching-Learning-Based Optimization (TLBO) with Grey Wolf Optimizer (GWO) for Text Feature Selection and Clustering
AUTHORS: Mahsa Azarshab ; Mohammad Fathian ; Babak Amiri
CATEGORY: cs.NE [cs.NE, cs.CL, cs.LG]
HIGHLIGHT: By proposing a hybrid of TLBO, Grey Wolf Optimizer (GWO), and Genetic Algorithm (GA) operators, this paper suggests a filter-based FS algorithm (TLBO-GWO).

414, TITLE: Surpassing Legacy Approaches and Human Intelligence with Hybrid Single- and Multi-objective Reinforcement Learning-based Optimization and Interpretable AI to Enable The Economic Operation of The US Nuclear Fleet
AUTHORS: Paul Seurin ; Koroush Shirvan
CATEGORY: cs.NE [cs.NE, cs.LG, physics.soc-ph]
HIGHLIGHT: In this paper, we rigorously compare our RL-based approach against the most commonly used SO-based methods, namely Genetic Algorithm (GA), Simulated Annealing (SA), and Tabu Search (TS).

415, TITLE: LTL Learning on GPUs
AUTHORS: Mojtaba Valizadeh ; Nathana�l Fijalkow ; Martin Berger
CATEGORY: cs.PL [cs.PL, cs.AI, 68, D.3]
HIGHLIGHT: We implement the first GPU-based LTL learner using a novel form of enumerative program synthesis.

416, TITLE: Weak-Linear Types
AUTHORS: Hector Gramaglia
CATEGORY: cs.PL [cs.PL, F.3.2; F.3.3; D.3.3]
HIGHLIGHT: In this work we propose a new alternative, whose virtue is to preserve the simplicity and elegance of the original system.

417, TITLE: Solving Data-centric Tasks Using Large Language Models
AUTHORS: SHRADDHA BARKE et. al.
CATEGORY: cs.PL [cs.PL, cs.AI, cs.SE]
HIGHLIGHT: But how do we decide how much data and which data to include in the prompt? This paper makes two contributions towards answering this question.

418, TITLE: A Cartesian Closed Category for Random Variables
AUTHORS: Pietro Di Gianantonio ; Abbas Edalat
CATEGORY: cs.PL [cs.PL, F.3.2]
HIGHLIGHT: We present a novel, yet rather simple construction within the traditional framework of Scott domains to provide semantics to probabilistic programming, thus obtaining a solution to a long-standing open problem in this area.

419, TITLE: Verifiably Following Complex Robot Instructions with Foundation Models
AUTHORS: Benedict Quartey ; Eric Rosen ; Stefanie Tellex ; George Konidaris
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: We propose Language Instruction grounding for Motion Planning (LIMP), a system that leverages foundation models and temporal logics to generate instruction-conditioned semantic maps that enable robots to verifiably follow expressive and long-horizon instructions with open vocabulary referents and complex spatiotemporal constraints.

420, TITLE: Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with The Tabletop Robot Haru
AUTHORS: Zining Wang ; Paul Reisert ; Eric Nichols ; Randy Gomez
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CL]
HIGHLIGHT: We introduce a fully-automated conversation system that leverages LLMs to generate robot responses with expressive behaviors, congruent with the robot's personality.

421, TITLE: From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data
AUTHORS: Naman Shah ; Jayesh Nagpal ; Pulkit Verma ; Siddharth Srivastava
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories.

422, TITLE: Developing Autonomous Robot-Mediated Behavior Coaching Sessions with Haru
AUTHORS: Matou? Jel�nek ; Eric Nichols ; Randy Gomez
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CL]
HIGHLIGHT: This study presents an empirical investigation into the design and impact of autonomous dialogues in human-robot interaction for behavior change coaching.

423, TITLE: DIO: Dataset of 3D Mesh Models of Indoor Objects for Robotics and Computer Vision Applications
AUTHORS: Nillan Nimal ; Wenbin Li ; Ronald Clark ; Sajad Saeedi
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: This paper documents the different methods employed for generating a database of mesh models of real-world objects. These methods address the tedious and time-intensive process of manually generating the models using CAD software.

424, TITLE: LiRaFusion: Deep Adaptive LiDAR-Radar Fusion for 3D Object Detection
AUTHORS: Jingyu Song ; Lingjun Zhao ; Katherine A. Skinner
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We propose LiRaFusion to tackle LiDAR-radar fusion for 3D object detection to fill the performance gap of existing LiDAR-radar detectors.

425, TITLE: Hysteresis Compensation of Flexible Continuum Manipulator Using RGBD Sensing and Temporal Convolutional Network
AUTHORS: Junhyun Park ; Seonghyeok Jang ; Hyojae Park ; Seongjun Bae ; Minho Hwang
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: These effects are difficult to model due to nonlinearity and the difficulties become even more evident when dealing with long and multi-segmented manipulator. This paper proposes a data-driven approach based on recurrent neural networks to capture these nonlinear and previous states-dependent characteristics of cable actuation.

426, TITLE: Bridging or Breaking: Impact of Intergroup Interactions on Religious Polarization
AUTHORS: Rochana Chaturvedi ; Sugat Chaturvedi ; Elena Zheleva
CATEGORY: cs.SI [cs.SI, cs.CL, physics.soc-ph]
HIGHLIGHT: We introduce a new measure for an individual's group conformity based on contextualized embeddings of tweet text, which helps us assess polarization between religious groups.

427, TITLE: Low-power SNN-based Audio Source Localisation Using A Hilbert Transform Spike Encoding Scheme
AUTHORS: Saeid Haghighatshoar ; Dylan R Muir
CATEGORY: cs.SD [cs.SD, cs.NE, eess.AS]
HIGHLIGHT: We use a novel short-time Hilbert transform (STHT) to remove the need for demanding band-pass filtering of audio, and introduce a new accompanying method for audio encoding with spiking events.

428, TITLE: Structure of Activity in Multiregion Recurrent Neural Networks
AUTHORS: David G. Clark ; Manuel Beiran
CATEGORY: q-bio.NC [q-bio.NC, cond-mat.dis-nn, cs.NE]
HIGHLIGHT: These networks exhibit two interacting forms of dynamics: high-dimensional fluctuations within regions and low-dimensional signal transmission between regions. To characterize this interaction, we develop a dynamical mean-field theory to analyze such networks in the limit where each region contains infinitely many neurons, with cross-region currents as key order parameters.

429, TITLE: Transformer-based De Novo Peptide Sequencing for Data-independent Acquisition Mass Spectrometry
AUTHORS: Shiva Ebrahimi ; Xuan Guo
CATEGORY: q-bio.QM [q-bio.QM, cs.AI]
HIGHLIGHT: In this paper, we introduce Casanovo-DIA, a deep-learning model based on transformer architecture.

430, TITLE: Kernel KMeans Clustering Splits for End-to-end Unsupervised Decision Trees
AUTHORS: Louis Ohl ; Pierre-Alexandre Mattei ; Micka�l Leclercq ; Arnaud Droit ; Fr�d�ric Precioso
CATEGORY: stat.ML [stat.ML, cs.AI, cs.LG, 62h30, G.3]
HIGHLIGHT: As most works focus on interpreting with trees the result of another clustering algorithm, we present here a novel end-to-end trained unsupervised binary tree for clustering: Kauri.

431, TITLE: Regularization By Denoising: Bayesian Model and Langevin-within-split Gibbs Sampling
AUTHORS: Elhadji C. Faye ; Mame Diarra Fall ; Nicolas Dobigeon
CATEGORY: stat.ML [stat.ML, cs.CV, cs.LG]
HIGHLIGHT: This paper introduces a Bayesian framework for image inversion by deriving a probabilistic counterpart to the regularization-by-denoising (RED) paradigm.

432, TITLE: Statistical Test for Generated Hypotheses By Diffusion Models
AUTHORS: Teruyuki Katsuoka ; Tomohiro Shiraishi ; Daiki Miwa ; Vo Nguyen Le Duy ; Ichiro Takeuchi
CATEGORY: stat.ML [stat.ML, cs.CV, cs.LG]
HIGHLIGHT: However, when employing AI-generated hypotheses for critical decisions, such as medical diagnoses, verifying their reliability is crucial. In this study, we consider a medical diagnostic task using generated images by diffusion models, and propose a statistical test to quantify its reliability.

433, TITLE: Underestimation of Lung Regions on Chest X-ray Segmentation Masks Assessed By Comparison with Total Lung Volume Evaluated on Computed Tomography
AUTHORS: PRZEMYS?AW BOMBI?SKI et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this study, we assess the underestimation of lung regions on chest X-ray segmentation masks created according to the current state-of-the-art method, by comparison with total lung volume evaluated on computed tomography (CT).

434, TITLE: Training-free Image Style Alignment for Self-adapting Domain Shift on Handheld Ultrasound Devices
AUTHORS: HONGYE ZENG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this study, we propose the Training-free Image Style Alignment (TISA) framework to align the style of handheld device data to those of standard devices.

435, TITLE: Evaluating Adversarial Robustness of Low Dose CT Recovery
AUTHORS: Kanchana Vaishnavi Gandikota ; Paramanand Chandramouli ; Hannah Droege ; Michael Moeller
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we evaluate the robustness of different deep learning approaches and classical methods for CT recovery.

436, TITLE: A Spatiotemporal Illumination Model for 3D Image Fusion in Optical Coherence Tomography
AUTHORS: STEFAN PLONER et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We present a new illumination model that exploits continuity in orthogonally raster-scanned volume data.

437, TITLE: Robustness and Exploration of Variational and Machine Learning Approaches to Inverse Problems: An Overview
AUTHORS: Alexander Auras ; Kanchana Vaishnavi Gandikota ; Hannah Droege ; Michael Moeller
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG, cs.NA, math.NA]
HIGHLIGHT: This paper attempts to provide an overview of current approaches for solving inverse problems in imaging using variational methods and machine learning.

438, TITLE: FOD-Swin-Net: Angular Super Resolution of Fiber Orientation Distribution Using A Transformer-based Deep Model
AUTHORS: Mateus Oliveira da Silva ; Caio Pinheiro Santana ; Diedre Santos do Carmo ; Let�cia Rittner
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG, q-bio.NC]
HIGHLIGHT: However, obtaining robust orientation estimates demands high-resolution data, leading to lengthy acquisitions that are not always clinically available. In this work, we explore the use of automated angular super resolution from faster acquisitions to overcome this challenge.
