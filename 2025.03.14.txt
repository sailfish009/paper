1, TITLE: Distilling Diversity and Control in Diffusion Models
AUTHORS: Rohit Gandikota ; David Bau
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: Distilled diffusion models suffer from a critical limitation: reduced sample diversity compared to their base counterparts. In this work, we uncover that despite this diversity loss, distilled models retain the fundamental concept representations of base models.

2, TITLE: Piece It Together: Part-Based Concepting with IP-Priors
AUTHORS: Elad Richardson ; Kfir Goldberg ; Yuval Alaluf ; Daniel Cohen-Or
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In many cases, these elements represent only fragments of a potential concept-such as an uniquely structured wing, or a specific hairstyle-serving as inspiration for the artist to explore how they can come together creatively into a coherent whole. Recognizing this need, we introduce a generative framework that seamlessly integrates a partial set of user-provided visual components into a coherent composition while simultaneously sampling the missing parts needed to generate a plausible and complete concept.

3, TITLE: Studying Classifier(-Free) Guidance From A Classifier-Centric Perspective
AUTHORS: Xiaoming Zhao ; Alexander G. Schwing
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this work, we carry out an empirical study to provide a fresh perspective on classifier-free guidance.

4, TITLE: VisualWebInstruct: Scaling Up Multimodal Instruction Data Through Web Search
AUTHORS: YIMING JIA et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this work, we aim to address the scarcity issue of reasoning-focused multimodal datasets.

5, TITLE: The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation
AUTHORS: Ho Kei Cheng ; Alexander Schwing
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: This gap between training and testing leads to a subpar performance. To bridge this gap, we propose conditional optimal transport C^2OT that adds a conditional weighting term in the cost matrix when computing the optimal transport assignment.

6, TITLE: BiasConnect: Investigating Bias Interactions in Text-to-Image Models
AUTHORS: PUSHKAR SHUKLA et. al.
CATEGORY: cs.CV [cs.CV, cs.CL, cs.LG]
HIGHLIGHT: Understanding these interdependencies is crucial for designing fairer generative models, yet measuring such effects quantitatively remains a challenge. In this paper, we aim to address these questions by introducing BiasConnect, a novel tool designed to analyze and quantify bias interactions in TTI models.

7, TITLE: Long Context Tuning for Video Generation
AUTHORS: YUWEI GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce Long Context Tuning (LCT), a training paradigm that expands the context window of pre-trained single-shot video diffusion models to learn scene-level consistency directly from data.

8, TITLE: Post-disaster Building Indoor Damage and Survivor Detection Using Autonomous Path Planning and Deep Learning with Unmanned Aerial Vehicles
AUTHORS: Xiao Pan ; Sina Tavasoli ; T. Y. Yang ; Sina Poorghasem
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This paper proposed an autonomous inspection approach for structural damage inspection and survivor detection in the post-disaster building indoor scenario, which incorporates an autonomous navigation method, deep learning-based damage and survivor detection method, and a customized low-cost micro aerial vehicle (MAV) with onboard sensors.

9, TITLE: GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding
AUTHORS: RUI HU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, advancements in this domain are currently constrained by limitations inherent in existing datasets, including limited object categories, insufficient textual diversity, and a scarcity of high-quality annotations. To mitigate these limitations, we introduce GroundingSuite, which comprises: (1) an automated data annotation framework leveraging multiple Vision-Language Model (VLM) agents; (2) a large-scale training dataset encompassing 9.56 million diverse referring expressions and their corresponding segmentations; and (3) a meticulously curated evaluation benchmark consisting of 3,800 images.

10, TITLE: Towards Fast, Memory-based and Data-Efficient Vision-Language Policy
AUTHORS: Haoxuan Li ; Sixu Yan ; Yuhan Li ; Xinggang Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose LiteVLP, a lightweight, memory-based, and general-purpose vision-language policy generation model.

11, TITLE: LHM: Large Animatable Human Reconstruction Model from A Single Image in Seconds
AUTHORS: LINGTENG QIU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Motivated by the emergence of large reconstruction models for efficient static reconstruction, we propose LHM (Large Animatable Human Reconstruction Model) to infer high-fidelity avatars represented as 3D Gaussian splatting in a feed-forward pass.

12, TITLE: VMBench: A Benchmark for Perception-Aligned Video Motion Generation
AUTHORS: XINRANG LING et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Specifically, there are two key issues: 1) current motion metrics do not fully align with human perceptions; 2) the existing motion prompts are limited. Based on these findings, we introduce VMBench--a comprehensive Video Motion Benchmark that has perception-aligned motion metrics and features the most diverse types of motion.

13, TITLE: DiT-Air: Revisiting The Efficiency of Diffusion Model Architecture Design in Text to Image Generation
AUTHORS: CHEN CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we empirically study Diffusion Transformers (DiTs) for text-to-image generation, focusing on architectural choices, text-conditioning strategies, and training protocols.

14, TITLE: Siege: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search
AUTHORS: Andy Zhou
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CR]
HIGHLIGHT: We introduce Siege, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective.

15, TITLE: Compositional Subspace Representation Fine-tuning for Adaptive Large Language Models
AUTHORS: Andy Zhou
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While methods such as LoRA impose orthogonality constraints at the weight level, they do not fully address interference in hidden-state representations. We propose Compositional Subspace Representation Fine-tuning (CS-ReFT), a novel representation-based approach that learns multiple orthonormal subspace transformations, each specializing in a distinct skill, and composes them via a lightweight router.

16, TITLE: LuciBot: Automated Robot Policy Learning from Generated Videos
AUTHORS: XIAOWEN QIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This limitation arises because LLMs struggle to interpret complex scenes compressed into text or code due to their restricted input modality, while VLM-based rewards, though better at visual perception, remain limited by their less expressive output modality. To address these challenges, we leverage the imagination capability of general-purpose video generation models.

17, TITLE: World Modeling Makes A Better Planner: Dual Preference Optimization for Embodied Task Planning
AUTHORS: SIYIN WANG et. al.
CATEGORY: cs.CL [cs.CL, cs.CV, cs.RO]
HIGHLIGHT: We propose Dual Preference Optimization (D$^2$PO), a new learning framework that jointly optimizes state prediction and action selection through preference learning, enabling LVLMs to understand environment dynamics for better planning.

18, TITLE: Solving Bayesian Inverse Problems with Diffusion Priors and Off-policy RL
AUTHORS: LUCA SCIMECA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: This paper presents a practical application of Relative Trajectory Balance (RTB), a recently introduced off-policy reinforcement learning (RL) objective that can asymptotically solve Bayesian inverse problems optimally.

19, TITLE: Identifying Trustworthiness Challenges in Deep Learning Models for Continental-Scale Water Quality Prediction
AUTHORS: XIAOBO XIA et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we present the first comprehensive evaluation of trustworthiness in a continental-scale multi-task LSTM model predicting 20 water quality variables (encompassing physical/chemical processes, geochemical weathering, and nutrient cycling) across 482 U.S. basins.

20, TITLE: VisualPRM: An Effective Process Reward Model for Multimodal Reasoning
AUTHORS: WEIYUN WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: We introduce VisualPRM, an advanced multimodal Process Reward Model (PRM) with 8B parameters, which improves the reasoning abilities of existing Multimodal Large Language Models (MLLMs) across different model scales and families with Best-of-N (BoN) evaluation strategies.

21, TITLE: Temporal Difference Flows
AUTHORS: JESSE FAREBROTHER et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods.

22, TITLE: GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing
AUTHORS: RONGYAO FANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present Generation Chain-of-Thought (GoT), a novel paradigm that enables generation and editing through an explicit language reasoning process before outputting images.

23, TITLE: CameraCtrl II: Dynamic Scene Exploration Via Camera-controlled Video Diffusion Models
AUTHORS: HAO HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces CameraCtrl II, a framework that enables large-scale dynamic scene exploration through a camera-controlled video diffusion model.

24, TITLE: From TOWER to SPIRE: Adding The Speech Modality to A Text-Only LLM
AUTHORS: KSHITIJ AMBILDUKE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we extend an existing LLM to the speech modality via speech discretization and continued pre-training.

25, TITLE: UniGoal: Towards Universal Zero-shot Goal-oriented Navigation
AUTHORS: HANG YIN et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: In this paper, we propose a general framework for universal zero-shot goal-oriented navigation.

26, TITLE: TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention
AUTHORS: JINHAO DUAN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: Moreover, (2) different LVLMs encode universal patterns of hallucinations in common latent subspaces, indicating that there exist "generic truthful directions" shared by various LVLMs. Based on these discoveries, we propose Truthful-Guided Pre-Intervention (TruthPrInt) that first learns the truthful direction of LVLM decoding and then applies truthful-guided inference-time intervention during LVLM decoding.

27, TITLE: Why Does Your CoT Prompt (Not) Work? Theoretical Analysis of Prompt Space Complexity, Its Interaction with Answer Space During CoT Reasoning with LLMs: A Recurrent Perspective
AUTHORS: Xiang Zhang ; Juntai Cao ; Jiaqi Wei ; Chenyu You ; Dujian Ding
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we provide a rigorous theoretical analysis of the complexity and interplay between two crucial spaces: the prompt space (the space of potential prompt structures) and the answer space (the space of reasoning solutions generated by LLMs) in CoT reasoning.

28, TITLE: Exploring Mutual Empowerment Between Wireless Networks and RL-based LLMs: A Survey
AUTHORS: Yu Qiao ; Phuong-Nam Tran ; Ji Su Yoon ; Loc X. Nguyen ; Choong Seon Hong
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.ET]
HIGHLIGHT: We then discuss the progress of RL-based LLMs, focusing on key technologies for LLM training, challenges, and potential solutions. Subsequently, we explore the mutual empowerment between these two fields, highlighting key motivations, open challenges, and potential solutions.

29, TITLE: Unlock The Power of Unlabeled Data in Language Driving Model
AUTHORS: Chaoqun Wang ; Jie Yang ; Xiaobin Hong ; Ruimao Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, such promotion is extremely dependent on large-scale high-quality annotated data, which is costly and labor-intensive. To address this issue, we propose unlocking the value of abundant yet unlabeled data to improve the language-driving model in a semi-supervised learning manner.

30, TITLE: Semantic-Supervised Spatial-Temporal Fusion for LiDAR-based 3D Object Detection
AUTHORS: Chaoqun Wang ; Xiaobin Hong ; Wenzhong Li ; Ruimao Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel Semantic-Supervised Spatial-Temporal Fusion (ST-Fusion) method, which introduces a novel fusion module to relieve the spatial misalignment caused by the object motion over time and a feature-level semantic supervision to sufficiently unlock the capacity of the proposed fusion module.

31, TITLE: AI-assisted Early Detection of Pancreatic Ductal Adenocarcinoma on Contrast-enhanced CT
AUTHORS: Han Liu ; Riqiang Gao ; Sasa Grbic
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we develop a coarse-to-fine approach to detect PDAC on contrast-enhanced CT scans.

32, TITLE: DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation
AUTHORS: WENHAO HU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This makes them vulnerable to memorization during training, where LLMs recall specific test cases instead of generalizing to new problems, leading to data contamination and unreliable evaluation results. To address these issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that overcomes the limitations of static datasets.

33, TITLE: Unveiling The Invisible: Reasoning Complex Occlusions Amodally with AURA
AUTHORS: Zhixuan Li ; Hyunse Yoon ; Sanghoon Lee ; Weisi Lin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While methods like LISA integrate multi-modal large language models (LLMs) with segmentation for reasoning tasks, they are limited to predicting only visible object regions and face challenges in handling complex occlusion scenarios. To address these limitations, we propose a novel task named amodal reasoning segmentation, aiming to predict the complete amodal shape of occluded objects while providing answers with elaborations based on user text input.

34, TITLE: Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection
AUTHORS: ZHEN QU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, these methods face several challenges: 1) handcrafted prompts require extensive expert knowledge and trial-and-error; 2) single-form learnable prompts struggle to capture complex anomaly semantics; and 3) an unconstrained prompt space limit generalization to unseen categories. To address these issues, we propose Bayesian Prompt Flow Learning (Bayes-PFL), which models the prompt space as a learnable probability distribution from a Bayesian perspective.

35, TITLE: RealGeneral: Unifying Visual Generation Via Temporal In-Context Learning with Video Models
AUTHORS: Yijing Lin ; Mengqi Huang ; Shuhan Zhuang ; Zhendong Mao
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we explore video models as a foundation for unified image generation, leveraging their inherent ability to model temporal correlations.

36, TITLE: Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature Alignment
AUTHORS: LUYANG FANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Automatic scoring of student responses enhances efficiency in education, but deploying a separate neural network for each task increases storage demands, maintenance efforts, and redundant computations. To address these challenges, this paper introduces the Gromov-Wasserstein Scoring Model Merging (GW-SMM) method, which merges models based on feature distribution similarities measured via the Gromov-Wasserstein distance.

37, TITLE: Charting and Navigating Hugging Face's Model Atlas
AUTHORS: Eliahu Horwitz ; Nitzan Kurer ; Jonathan Kahana ; Liel Amar ; Yedid Hoshen
CATEGORY: cs.LG [cs.LG, cs.CL, cs.CV]
HIGHLIGHT: It provides stunning visualizations of the model landscape and evolution. We demonstrate several applications of this atlas including predicting model attributes (e.g., accuracy), and analyzing trends in computer vision models.

38, TITLE: VisTai: Benchmarking Vision-Language Models for Traditional Chinese in Taiwan
AUTHORS: Zhi Rui Tam ; Ya-Ting Pai ; Yen-Wei Lee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a comprehensive evaluation benchmark for Visual Language Models (VLM) in Traditional Chinese.

39, TITLE: An Expanded Massive Multilingual Dataset for High-Performance Language Technologies
AUTHORS: LAURIE BURCHELL et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we present HPLT v2, a collection of high-quality multilingual monolingual and parallel corpora.

40, TITLE: KVQ: Boosting Video Quality Assessment Via Saliency-guided Local Perception
AUTHORS: YUNPENG QU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Inspired by the Human Visual System (HVS) that links global quality to the local texture of different regions and their visual saliency, we propose a Kaleidoscope Video Quality Assessment (KVQ) framework, which aims to effectively assess both saliency and local texture, thereby facilitating the assessment of global quality.

41, TITLE: V2Edit: Versatile Video Diffusion Editor for Videos and 3D Scenes
AUTHORS: Yanming Zhang ; Jun-Kun Chen ; Jipeng Lyu ; Yu-Xiong Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper introduces V$^2$Edit, a novel training-free framework for instruction-guided video and 3D scene editing.

42, TITLE: 4D LangSplat: 4D Language Gaussian Splatting Via Multimodal Large Language Models
AUTHORS: WANHUA LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Building a precise 4D language field necessitates obtaining pixel-aligned, object-wise video features, which current vision models struggle to achieve. To address these challenges, we propose 4D LangSplat, which learns 4D language fields to handle time-agnostic or time-sensitive open-vocabulary queries in dynamic scenes efficiently.

43, TITLE: CoSTA$\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing
AUTHORS: Advait Gupta ; NandaKiran Velaga ; Dang Nguyen ; Tianyi Zhou
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Can we combine the strengths of both LLMs and graph search to find cost-efficient tool paths?

44, TITLE: Communication-Efficient Language Model Training Scales Reliably and Robustly: Scaling Laws for DiLoCo
AUTHORS: ZACHARY CHARLES et. al.
CATEGORY: cs.LG [cs.LG, cs.CL, cs.DC]
HIGHLIGHT: In this work, we study the scaling law behavior of DiLoCo when training LLMs under a fixed compute budget.

45, TITLE: V2X-ReaLO: An Open Online Framework and Dataset for Cooperative Perception in Reality
AUTHORS: HAO XIANG et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: In this work, we introduce V2X-ReaLO, an open online cooperative perception framework deployed on real vehicles and smart infrastructure that integrates early, late, and intermediate fusion methods within a unified pipeline and provides the first practical demonstration of online intermediate fusion's feasibility and performance under genuine real-world conditions.

46, TITLE: ImageScope: Unifying Language-Guided Image Retrieval Via Large Multimodal Model Collective Reasoning
AUTHORS: PENGFEI LUO et. al.
CATEGORY: cs.IR [cs.IR, cs.AI, cs.MM]
HIGHLIGHT: To this end, we propose ImageScope, a training-free, three-stage framework that leverages collective reasoning to unify LGIR tasks.

47, TITLE: Source-primed Multi-turn Conversation Helps Large Language Models Translate Documents
AUTHORS: Hanxu Hu ; Jannis Vamvas ; Rico Sennrich
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we study a simple method for handling document-level machine translation, by leveraging previous contexts in a multi-turn conversational manner.

48, TITLE: MaterialMVP: Illumination-Invariant Material Generation Via Multi-view PBR Diffusion
AUTHORS: ZEBIN HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present MaterialMVP, a novel end-to-end model for generating PBR textures from 3D meshes and image prompts, addressing key challenges in multi-view material synthesis.

49, TITLE: Finetuning Generative Trajectory Model with Reinforcement Learning from Human Feedback
AUTHORS: DERUN LI et. al.
CATEGORY: cs.RO [cs.RO, cs.CV, cs.LG]
HIGHLIGHT: While generative models have shown promise in synthesizing feasible trajectories, they often fail to capture the nuanced variability of human driving styles due to dataset biases and distributional shifts. To address this, we introduce TrajHF, a human feedback-driven finetuning framework for generative trajectory models, designed to align motion planning with diverse driving preferences.

50, TITLE: ROODI: Reconstructing Occluded Objects with Denoising Inpainters
AUTHORS: Yeonjin Chang ; Erqun Dong ; Seunghyeon Seo ; Nojun Kwak ; Kwang Moo Yi
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a novel object extraction method based on two key principles: (1) being object-centric by pruning irrelevant primitives; and (2) leveraging generative inpainting to compensate for missing observations caused by occlusions.

51, TITLE: RoCo-Sim: Enhancing Roadside Collaborative Perception Through Foreground Simulation
AUTHORS: YUWEN DU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To significantly enhance roadside collaborative perception and address critical data issues, we present the first simulation framework RoCo-Sim for road-side collaborative perception.

52, TITLE: StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes Through Tree-of-Error
AUTHORS: SHU-XUN YANG et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: However, existing evaluation methods often focus solely on final answers, resulting in highly inaccurate and uninterpretable evaluation outcomes, as well as their failure to assess proof or open-ended problems. To address these issues, we propose a novel mathematical process evaluation agent based on Tree-of-Error, called StepMathAgent.

53, TITLE: KV-Distill: Nearly Lossless Learnable Context Compression for LLMs
AUTHORS: Vivek Chari ; Guanghui Qin ; Benjamin Van Durme
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We introduce KV-Distill, a Transformer compression framework that distills long context KV caches into significantly shorter representations in a question-independent fashion.

54, TITLE: IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification
AUTHORS: Yuhao Wang ; Yongfeng Lv ; Pingping Zhang ; Huchuan Lu
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: To be specific, we propose a standardized multi-modal caption generation pipeline for structured and concise text annotations with Multi-modal Large Language Models (MLLMs).

55, TITLE: Media and Responsible AI Governance: A Game-theoretic and LLM Analysis
AUTHORS: NATALIYA BALABANOVA et. al.
CATEGORY: cs.AI [cs.AI, cs.GT, cs.MA, nlin.CD]
HIGHLIGHT: This paper investigates the complex interplay between AI developers, regulators, users, and the media in fostering trustworthy AI systems. Using evolutionary game theory and large language models (LLMs), we model the strategic interactions among these actors under different regulatory regimes.

56, TITLE: Compute Optimal Scaling of Skills: Knowledge Vs Reasoning
AUTHORS: Nicholas Roberts ; Niladri Chatterji ; Sharan Narang ; Mike Lewis ; Dieuwke Hupkes
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this work, we ask whether compute-optimal scaling behaviour can be skill-dependent.

57, TITLE: A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against The Strong Black-box Models of GPT-4.5/4o/o1
AUTHORS: Zhaoyi Li ; Xiaohan Zhao ; Dong-Dong Wu ; Jiacheng Cui ; Zhiqiang Shen
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: This insight motivates our approach that refines semantic clarity by encoding explicit semantic details within local regions, thus ensuring interoperability and capturing finer-grained features, and by concentrating modifications on semantically rich areas rather than applying them uniformly. To achieve this, we propose a simple yet highly effective solution: at each optimization step, the adversarial image is cropped randomly by a controlled aspect ratio and scale, resized, and then aligned with the target image in the embedding space.

58, TITLE: UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?
AUTHORS: YUANXIN LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To evaluate the performance of automatic metrics in unified AIGV evaluation, we introduce a benchmark called UVE-Bench.

59, TITLE: MoFlow: One-Step Flow Matching for Human Trajectory Forecasting Via Implicit Maximum Likelihood Estimation Based Distillation
AUTHORS: Yuxiang Fu ; Qi Yan ; Lele Wang ; Ke Li ; Renjie Liao
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we address the problem of human trajectory forecasting, which aims to predict the inherently multi-modal future movements of humans based on their past trajectories and other contextual cues.

60, TITLE: OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer
AUTHORS: Jinyang Li ; En Yu ; Sijia Chen ; Wenbing Tao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose OVTR (End-to-End Open-Vocabulary Multiple Object Tracking with TRansformer), the first end-to-end open-vocabulary tracker that models motion, appearance, and category simultaneously.

61, TITLE: The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory
AUTHORS: Robin Schmucker ; Steven Moore
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY]
HIGHLIGHT: However, their relationship to IRT parameters remains underexplored. To address this gap, we conducted a study involving over 7,000 multiple-choice questions across various STEM subjects (e.g., math and biology).

62, TITLE: Attention Reveals More Than Tokens: Training-Free Long-Context Reasoning with Attention-guided Retrieval
AUTHORS: Yuwei Zhang ; Jayanth Srinivasa ; Gaowen Liu ; Jingbo Shang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Interestingly, we observe that the internal attention weights from the generated CoT tokens can effectively ground implicit facts, even when these facts are not explicitly recalled. Building on this insight, we propose a novel training-free algorithm, Attrieval, which leverages attention weights to retrieve relevant facts from the long context and incorporates them into the reasoning process.

63, TITLE: HybridVLA: Collaborative Diffusion and Autoregression in A Unified Vision-Language-Action Model
AUTHORS: JIAMING LIU et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: Meanwhile, some VLA methods incorporate an additional diffusion head to predict continuous actions, relying solely on VLM-extracted features, which limits their reasoning capabilities. In this paper, we introduce HybridVLA, a unified framework that seamlessly integrates the strengths of both autoregressive and diffusion policies within a single large language model, rather than simply connecting them.

64, TITLE: Revisiting Semi-supervised Learning in The Era of Foundation Models
AUTHORS: Ping Zhang ; Zheda Mai ; Quang-Huy Nguyen ; Wei-Lun Chao
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: To overcome the notorious issue of noisy pseudo-labels, we propose ensembling multiple PEFT approaches and VFM backbones to produce more robust pseudo-labels.

65, TITLE: Hybrid Agents for Image Restoration
AUTHORS: Bingchen Li ; Xin Li ; Yiting Lu ; Zhibo Chen
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: In this work, we present HybridAgent, intending to incorporate multiple restoration modes into a unified image restoration model and achieve intelligent and efficient user interaction through our proposed hybrid agents.

66, TITLE: Towards Constraint-Based Adaptive Hypergraph Learning for Solving Vehicle Routing: An End-to-End Solution
AUTHORS: Zhenwei Wang ; Ruibin Bai ; Tiehua Zhang
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: This study introduces a novel end-to-end framework that combines constraint-oriented hypergraphs with reinforcement learning to address vehicle routing problems.

67, TITLE: TIME: Temporal-sensitive Multi-dimensional Instruction Tuning and Benchmarking for Video-LLMs
AUTHORS: YUNXIAO WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In order to reduce reliance on costly temporal annotations, we introduce a multi-task prompt fine-tuning approach that seamlessly integrates temporal-sensitive tasks into existing instruction datasets without requiring additional annotations.

68, TITLE: Transformers Without Normalization
AUTHORS: Jiachen Zhu ; Xinlei Chen ; Kaiming He ; Yann LeCun ; Zhuang Liu
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.CV]
HIGHLIGHT: We introduce Dynamic Tanh (DyT), an element-wise operation $DyT($x$) = \tanh(\alpha $x$)$, as a drop-in replacement for normalization layers in Transformers.

69, TITLE: "Well, Keep Thinking": Enhancing LLM Reasoning with Adaptive Injection Decoding
AUTHORS: Hyunbin Jin ; Je Won Yeom ; Seunghyun Bae ; Taesup Kim
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we unlock the reasoning capabilities of LLMs without explicit prompting.

70, TITLE: SciVerse: Unveiling The Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems
AUTHORS: ZIYU GUO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we introduce SciVerse, a multi-modal scientific evaluation benchmark to thoroughly assess LMMs across 5,735 test instances in five distinct versions.

71, TITLE: Information Density Principle for MLLM Benchmarks
AUTHORS: CHUNYI LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: For developers of MLLMs, questions remain about which benchmark to use and whether the test results meet their requirements. Therefore, we propose a critical principle of Information Density, which examines how much insight a benchmark can provide for the development of MLLMs.

72, TITLE: Image Quality Assessment: From Human to Machine Preference
AUTHORS: CHUNYI LI et. al.
CATEGORY: cs.CV [cs.CV, cs.MM, eess.IV]
HIGHLIGHT: Considering the huge gap between human and machine visual systems, this paper proposes the topic: Image Quality Assessment for Machine Vision for the first time.

73, TITLE: G-Boost: Boosting Private SLMs with General LLMs
AUTHORS: YIJIANG FAN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Specifically, we propose the G-Boost framework where a private SLM adaptively performs collaborative inference with a general LLM under the guide of process reward.

74, TITLE: Using Context to Improve Word Segmentation
AUTHORS: Stephanie Hu ; Xiaolu Guo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We implemented two of their models, a unigram and bigram model, to examine how context can improve statistical word segmentation.

75, TITLE: VicaSplat: A Single Run Is All You Need for 3D Gaussian Splatting and Camera Estimation from Unposed Video Frames
AUTHORS: Zhiqi Li ; Chengrui Dong ; Yiming Chen ; Zhangchi Huang ; Peidong Liu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present VicaSplat, a novel framework for joint 3D Gaussians reconstruction and camera pose estimation from a sequence of unposed video frames, which is a critical yet underexplored task in real-world 3D applications.

76, TITLE: Cosh-DiT: Co-Speech Gesture Video Synthesis Via Hybrid Audio-Visual Diffusion Transformers
AUTHORS: YASHENG SUN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Co-speech gesture video synthesis is a challenging task that requires both probabilistic modeling of human gestures and the synthesis of realistic images that align with the rhythmic nuances of speech. To address these challenges, we propose Cosh-DiT, a Co-speech gesture video system with hybrid Diffusion Transformers that perform audio-to-motion and motion-to-video synthesis using discrete and continuous diffusion modeling, respectively.

77, TITLE: 6D Object Pose Tracking in Internet Videos for Robotic Manipulation
AUTHORS: GEORGY PONIMATKIN et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This is a challenging set-up for current 6D pose estimation methods due to uncontrolled capturing conditions, subtle but dynamic object motions, and the fact that the exact mesh of the manipulated object is not known. To address these challenges, we present the following contributions. First, we develop a new method that estimates the 6D pose of any object in the input image without prior knowledge of the object itself.

78, TITLE: I2V3D: Controllable Image-to-video Generation with 3D Guidance
AUTHORS: Zhiyuan Zhang ; Dongdong Chen ; Jing Liao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present I2V3D, a novel framework for animating static images into dynamic videos with precise 3D control, leveraging the strengths of both 3D geometry guidance and advanced generative models.

79, TITLE: EFC++: Elastic Feature Consolidation with Prototype Re-balancing for Cold Start Exemplar-free Incremental Learning
AUTHORS: Simone Magistri ; Tomaso Trinci ; Albin Soutif-Cormerais ; Joost van de Weijer ; Andrew D. Bagdanov
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we consider the challenging Cold Start scenario in which insufficient data is available in the first task to learn a high-quality backbone.

80, TITLE: Speedy MASt3R
AUTHORS: JINGXING LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: On an A40 GPU, latency per image pair is 198.16 ms, mainly due to computational overhead from the ViT encoder-decoder and Fast Reciprocal Nearest Neighbor (FastNN) matching. To address this, we introduce Speedy MASt3R, a post-training optimization framework that enhances inference efficiency while maintaining accuracy.

81, TITLE: Emotion Recognition with CLIP and Sequential Learning
AUTHORS: Weiwei Zhou ; Chenkun Ling ; Zefeng Cai
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present our innovative methodology for tackling the Valence-Arousal (VA) Estimation Challenge, the Expression Recognition Challenge, and the Action Unit (AU) Detection Challenge, all within the framework of the 8th Workshop and Competition on Affective Behavior Analysis in-the-wild (ABAW).

82, TITLE: Dream-IF: Dynamic Relative EnhAnceMent for Image Fusion
AUTHORS: Xingxin Xu ; Bing Cao ; Yinan Xia ; Pengfei Zhu ; Qinghua Hu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Traditional fusion methods generally treat image enhancement and fusion as separate processes, overlooking the inherent correlation between them; notably, the dominant regions in one modality of a fused image often indicate areas where the other modality might benefit from enhancement. Inspired by this observation, we introduce the concept of dominant regions for image enhancement and present a Dynamic Relative EnhAnceMent framework for Image Fusion (Dream-IF).

83, TITLE: CleverDistiller: Simple and Spatially Consistent Cross-modal Distillation
AUTHORS: HARIPRASATH GOVINDARAJAN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.RO]
HIGHLIGHT: In this work, we propose CleverDistiller, a self-supervised, cross-modal 2D-to-3D KD framework introducing a set of simple yet effective design choices: Unlike contrastive approaches relying on complex loss design choices, our method employs a direct feature similarity loss in combination with a multi layer perceptron (MLP) projection head to allow the 3D network to learn complex semantic dependencies throughout the projection.

84, TITLE: Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?
AUTHORS: Subhajit Maity ; Killian Hitsman ; Xin Li ; Aritra Dutta
CATEGORY: cs.LG [cs.LG, cs.CV, 68T07, I.2.6; I.5.1; I.5.5; I.5.4; I.4.10]
HIGHLIGHT: In this paper, we are the first to design a general learnable Kolmogorov-Arnold Attention (KArAt) for vanilla ViTs that can operate on any choice of basis.

85, TITLE: Deep Learning for Time Series Forecasting: A Survey
AUTHORS: XIANGJIE KONG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, existing surveys have not provided a unified summary of the wide range of model architectures in this field, nor have they given detailed summaries of works in feature extraction and datasets. To address this gap, in this review, we comprehensively study the previous works and summarize the general paradigms of Deep Time Series Forecasting (DTSF) in terms of model architectures.

86, TITLE: ETCH: Generalizing Body Fitting to Clothed Humans Via Equivariant Tightness
AUTHORS: Boqian Li ; Haiwen Feng ; Zeyu Cai ; Michael J. Black ; Yuliang Xiu
CATEGORY: cs.CV [cs.CV, cs.AI, cs.GR]
HIGHLIGHT: We propose Equivariant Tightness Fitting for Clothed Humans, or ETCH, a novel pipeline that estimates cloth-to-body surface mapping through locally approximate SE(3) equivariance, encoding tightness as displacement vectors from the cloth surface to the underlying body.

87, TITLE: Learning Interpretable Logic Rules from Deep Vision Models
AUTHORS: CHUQIN GENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a general framework called VisionLogic to extract interpretable logic rules from deep vision models, with a focus on image classification tasks.

88, TITLE: Do We Always Need The Simplicity Bias? Looking for Optimal Inductive Biases in The Wild
AUTHORS: Damien Teney ; Liangze Jiang ; Florin Gogianu ; Ehsan Abbasnejad
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Building on recent findings that the simplicity bias stems from ReLU activations [96], we introduce a method to meta-learn new activation functions and inductive biases better suited to specific tasks.

89, TITLE: Multi-Modal Mamba Modeling for Survival Prediction (M4Survive): Adapting Joint Foundation Model Representations
AUTHORS: Ho Hin Lee ; Alberto Santamaria-Pang ; Jameson Merkov ; Matthew Lungren ; Ivan Tarapov
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we introduce M4Survive (Multi-Modal Mamba Modeling for Survival Prediction), a novel framework that learns joint foundation model representations using efficient adapter networks.

90, TITLE: GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for Geometrically Consistent Rendering and Reconstruction
AUTHORS: JIANHENG LIU et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We propose a unified LiDAR-visual system that synergizes Gaussian splatting with a neural signed distance field.

91, TITLE: Interactive Multimodal Fusion with Temporal Modeling
AUTHORS: Jun Yu ; Yongqi Wang ; Lei Wang ; Yang Zheng ; Shengfan Xu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents our method for the estimation of valence-arousal (VA) in the 8th Affective Behavior Analysis in-the-Wild (ABAW) competition.

92, TITLE: Dual-Stage Cross-Modal Network with Dynamic Feature Fusion for Emotional Mimicry Intensity Estimation
AUTHORS: JUN YU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To address the limitations of existing methods in insufficient exploitation of modal synergistic effects, noise sensitivity, and limited fine-grained alignment capabilities, this paper proposes a dual-stage cross-modal alignment framework.

93, TITLE: KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation
AUTHORS: Zixian Liu ; Mingtong Zhang ; Yunzhu Li
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this work, we introduce KUDA, an open-vocabulary manipulation system that integrates dynamics learning and visual prompting through keypoints, leveraging both VLMs and learning-based neural dynamics models.

94, TITLE: Siamese Foundation Models for Crystal Structure Prediction
AUTHORS: LIMING WU et. al.
CATEGORY: cond-mat.mtrl-sci [cond-mat.mtrl-sci, cs.AI]
HIGHLIGHT: In this paper, we propose Siamese foundation models specifically designed to address CSP.

95, TITLE: AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents
AUTHORS: ARMAN ZHARMAGAMBETOV et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this work, we propose one way to address that potential risk, by training AI agents to better satisfy the privacy principle of data minimization.

96, TITLE: Enhancing Facial Privacy Protection Via Weakening Diffusion Purification
AUTHORS: Ali Salar ; Qing Liu ; Yingli Tian ; Guoying Zhao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Enhancing Facial Privacy Protection Via Weakening Diffusion Purification

97, TITLE: SVIP: Semantically Contextualized Visual Patches for Zero-Shot Learning
AUTHORS: Zhi Chen ; Zecheng Zhao ; Jingcai Guo ; Jingjing Li ; Zi Huang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we introduce Semantically contextualized VIsual Patches (SVIP) for ZSL, a transformer-based framework designed to enhance visual-semantic alignment.

98, TITLE: OmniSTVG: Toward Spatio-Temporal Omni-Object Video Grounding
AUTHORS: JIALI YAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose spatio-temporal omni-object video grounding, dubbed OmniSTVG, a new STVG task that aims at localizing spatially and temporally all targets mentioned in the textual query from videos.

99, TITLE: Improving Diffusion-based Inverse Algorithms Under Few-Step Constraint Via Learnable Linear Extrapolation
AUTHORS: Jiawei Zhang ; Ziyuan Liu ; Leon Yan ; Gen Li ; Yuantao Gu
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Inspired by the linear subspace search strategy in the design of high-order diffusion ODE solvers, we propose the Learnable Linear Extrapolation (LLE) method, a lightweight approach that universally enhances the performance of any diffusion-based inverse algorithm that fits the proposed canonical form.

100, TITLE: MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation
AUTHORS: WEIHAO XUAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Traditional benchmarks struggle to evaluate increasingly sophisticated language models in multilingual and culturally diverse contexts. To address this gap, we introduce MMLU-ProX, a comprehensive multilingual benchmark covering 13 typologically diverse languages with approximately 11,829 questions per language.

101, TITLE: MouseGPT: A Large-scale Vision-Language Model for Mouse Behavior Analysis
AUTHORS: TENG XU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Here, we introduce MouseGPT, a Vision-Language Model (VLM) that integrates visual cues with natural language to revolutionize mouse behavior analysis.

102, TITLE: DFLMoE: Decentralized Federated Learning Via Mixture of Experts for Medical Data Analysis
AUTHORS: LUYUAN XIE et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Besides, the centralized approach also creates a dependency on the central server, which may affect training stability if the server malfunctions or connections are unstable. To address these issues, we propose a decentralized federated learning framework named dFLMoE.

103, TITLE: Interpretable Image Classification Via Non-parametric Part Prototype Learning
AUTHORS: Zhijie Zhu ; Lei Fan ; Maurice Pagnucco ; Yang Song
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Leveraging recent advances in prototype learning, we present a framework for part-based interpretable image classification that learns a set of semantically distinctive object parts for each class, and provides diverse and comprehensive explanations.

104, TITLE: Uncertainty in Action: Confidence Elicitation in Embodied Agents
AUTHORS: TIANJIAO YU et. al.
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: We introduce Elicitation Policies, which structure confidence assessment across inductive, deductive, and abductive reasoning, along with Execution Policies, which enhance confidence calibration through scenario reinterpretation, action sampling, and hypothetical reasoning.

105, TITLE: A Hierarchical Semantic Distillation Framework for Open-Vocabulary Object Detection
AUTHORS: SHENGHAO FU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a hierarchical semantic distillation framework named HD-OVD to construct a comprehensive distillation process, which exploits generalizable knowledge from the CLIP model in three aspects.

106, TITLE: Streaming Generation of Co-Speech Gestures Via Accelerated Rolling Diffusion
AUTHORS: Evgeniia Vu ; Andrei Boiarov ; Dmitry Vetrov
CATEGORY: cs.LG [cs.LG, cs.CV, cs.HC]
HIGHLIGHT: We introduce Accelerated Rolling Diffusion, a novel framework for streaming gesture generation that extends rolling diffusion models with structured progressive noise scheduling, enabling seamless long-sequence motion synthesis while preserving realism and diversity.

107, TITLE: Poly-MgNet: Polynomial Building Blocks in Multigrid-Inspired ResNets
AUTHORS: Antonia van Betteray ; Matthias Rottmann ; Karsten Kahl
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we introduce a novel neural network building block inspired by polynomial smoothers from MG theory.

108, TITLE: Nash Equilibrium Constrained Auto-bidding With Bi-level Reinforcement Learning
AUTHORS: ZHIYU MOU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.GT]
HIGHLIGHT: However, the NCB problem presents significant challenges due to its constrained bi-level structure and the typically large number of advertisers involved. To address these challenges, we propose a \emph{Bi-level Policy Gradient} (BPG) framework with theoretical guarantees.

109, TITLE: Singular Value Fine-tuning for Few-Shot Class-Incremental Learning
AUTHORS: ZHIWU WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While catastrophic forgetting has been extensively studied, overfitting in FSCIL, especially with large foundation models, has received less attention. To fill this gap, we propose the Singular Value Fine-tuning for FSCIL (SVFCL) and compared it with existing approaches for adapting foundation models to FSCIL, which primarily build on Parameter Efficient Fine-Tuning (PEFT) methods like prompt tuning and Low-Rank Adaptation (LoRA).

110, TITLE: One-Shot Federated Unsupervised Domain Adaptation with Scaled Entropy Attention and Multi-Source Smoothed Pseudo Labeling
AUTHORS: Ali Abedi ; Q. M. Jonathan Wu ; Ning Zhang ; Farhad Pourpanah
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Moreover, FL methods often require high communication overhead due to multiple rounds of model updates between clients and the server. We propose a one-shot Federated Unsupervised Domain Adaptation (FUDA) method to address these limitations.

111, TITLE: CINEMA: Coherent Multi-Subject Video Generation Via MLLM-Based Guidance
AUTHORS: YUFAN DENG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose CINEMA, a novel framework for coherent multi-subject video generation by leveraging Multimodal Large Language Model (MLLM).

112, TITLE: VideoMerge: Towards Training-free Long Video Generation
AUTHORS: Siyang Zhang ; Harry Yang ; Ser-Nam Lim
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose VideoMerge, a training-free method that can be seamlessly adapted to merge short videos generated by pretrained text-to-video diffusion model.

113, TITLE: Foundation X: Integrating Classification, Localization, and Segmentation Through Lock-Release Pretraining Strategy for Chest X-ray Analysis
AUTHORS: NAHID UL ISLAM et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To this end, we introduce nFoundation X, an end-to-end framework that utilizes diverse expert-level annotations from numerous public datasets to train a foundation model capable of multiple tasks including classification, localization, and segmentation.

114, TITLE: Retrieval-Augmented Generation with Hierarchical Knowledge
AUTHORS: HAOYU HUANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce a new RAG approach, called HiRAG, which utilizes hierarchical knowledge to enhance the semantic understanding and structure capturing capabilities of RAG systems in the indexing and retrieval processes.

115, TITLE: Resolution Invariant Autoencoder
AUTHORS: Ashay Patel ; Michela Antonelli ; Sebastien Ourselin ; M. Jorge Cardoso
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: We introduce a resolution-invariant autoencoder that adapts spatial resizing at each layer in the network via a learned variable resizing process, replacing fixed spatial down/upsampling at the traditional factor of 2.

116, TITLE: TokenCarve: Information-Preserving Visual Token Compression in Multimodal Large Language Models
AUTHORS: XUDONG TAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this study, we reveal that the performance degradation of MLLM closely correlates with the accelerated loss of information in the attention output matrix.

117, TITLE: ExtremeAIGC: Benchmarking LMM Vulnerability to AI-Generated Extremist Content
AUTHORS: Bhavik Chandna ; Mariam Aboujenane ; Usman Naseem
CATEGORY: cs.CR [cs.CR, cs.CL]
HIGHLIGHT: However, existing datasets for evaluating LMM robustness offer limited exploration of extremist content, often lacking AI-generated images, diverse image generation models, and comprehensive coverage of historical events, which hinders a complete assessment of model vulnerabilities. To fill this gap, we introduce ExtremeAIGC, a benchmark dataset and evaluation framework designed to assess LMM vulnerabilities against such content.

118, TITLE: ES-Parkour: Advanced Robot Parkour with Bio-inspired Event Camera and Spiking Neural Network
AUTHORS: QIANG ZHANG et. al.
CATEGORY: cs.RO [cs.RO, cs.CV, cs.LG]
HIGHLIGHT: Additionally, deep neural networks in sensor and control systems increase computational demands. To address these issues, we introduce spiking neural networks (SNNs) and event cameras to perform a challenging quadruped parkour task.

119, TITLE: A Multi-Modal Federated Learning Framework for Remote Sensing Image Classification
AUTHORS: Bar?? B�y�kta? ; Gencer Sumbul ; Beg�m Demir
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To effectively exploit decentralized and unshared multi-modal RS data, our paper introduces a novel multi-modal FL framework for RS image classification problems.

120, TITLE: OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary
AUTHORS: YIFENG YANG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We propose OODD, a novel test-time OOD detection method that dynamically maintains and updates an OOD dictionary without fine-tuning.

121, TITLE: Optimizing Fire Safety: Reducing False Alarms Using Advanced Machine Learning Techniques
AUTHORS: MUHAMMAD HASSAN JAMAL et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents a precise and efficient Weighted ensemble model for decreasing false alarms.

122, TITLE: How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game
AUTHORS: ZIYUE WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Less attention is given to comprehensively and quantitatively analyzing reasoning process in multimodal environments, which is crucial for understanding model behaviors and underlying reasoning mechanisms beyond merely task success. To address this, we introduce MM-Escape, an extensible benchmark for investigating multimodal reasoning, inspired by real-world escape games.

123, TITLE: Vi-LAD: Vision-Language Attention Distillation for Socially-Aware Robot Navigation in Dynamic Environments
AUTHORS: MOHAMED ELNOOR et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: We introduce Vision-Language Attention Distillation (Vi-LAD), a novel approach for distilling socially compliant navigation knowledge from a large Vision-Language Model (VLM) into a lightweight transformer model for real-time robotic navigation.

124, TITLE: PyGDA: A Python Library for Graph Domain Adaptation
AUTHORS: Zhen Zhang ; Meihan Liu ; Bingsheng He
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, there is still no unified library that brings together existing techniques and simplifies their implementation. To fill this gap, we introduce PyGDA, an open-source Python library tailored for graph domain adaptation.

125, TITLE: Leveraging Semantic Attribute Binding for Free-Lunch Color Control in Diffusion Models
AUTHORS: H�CTOR LARIA et. al.
CATEGORY: cs.GR [cs.GR, cs.CV, cs.LG]
HIGHLIGHT: In this work, we introduce ColorWave, a novel training-free approach that achieves exact RGB-level color control in diffusion models without fine-tuning.

126, TITLE: CoStoDet-DDPM: Collaborative Training of Stochastic and Deterministic Models Improves Surgical Workflow Anticipation and Recognition
AUTHORS: Kaixiang Yang ; Xin Li ; Qiang Li ; Zhiwei Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing methods rely on deterministic decision-making, struggling to generalize across the large anatomical and procedural variations inherent in real-world surgeries.In this paper, we introduce an innovative framework that incorporates stochastic modeling through a denoising diffusion probabilistic model (DDPM) into conventional deterministic learning for surgical workflow analysis. At the heart of our approach is a collaborative co-training paradigm: the DDPM branch captures procedural uncertainties to enrich feature representations, while the task branch focuses on predicting surgical phases and instrument usage.Theoretically, we demonstrate that this mutual refinement mechanism benefits both branches: the DDPM reduces prediction errors in uncertain scenarios, and the task branch directs the DDPM toward clinically meaningful representations.

127, TITLE: DreamInsert: Zero-Shot Image-to-Video Object Insertion from A Single Image
AUTHORS: Qi Zhao ; Zhan Ma ; Pan Zhou
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose DreamInsert, which achieves Image-to-Video Object Insertion in a training-free manner for the first time.

128, TITLE: Deep Learning-Based Direct Leaf Area Estimation Using Two RGBD Datasets for Model Development
AUTHORS: Namal Jayasuriya ; Yi Guo ; Wen Hu ; Oula Ghannoum
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Some studies have used hand-held cameras, image processing 3D reconstruction and unsupervised learning-based methods to estimate the leaf area in plant images.

129, TITLE: PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction
AUTHORS: Han Wan ; Qi Wang ; Hao Sun
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Existing methods often neglect the effective utilization of multi-scale data, leading to suboptimal robustness in predictions. To address these issues, we propose a novel multi-scale learning framework, namely, the Physics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively leverage multi-scale data for spatiotemporal dynamics prediction.

130, TITLE: Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions
AUTHORS: JIANI FAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: Existing surveys in the AML literature broadly review machine learning approaches for money laundering detection, but they often lack an in-depth exploration of advanced deep learning techniques - an emerging field with significant potential. To address this gap, this paper conducts a comprehensive review of deep learning solutions and the challenges associated with their use in AML.

131, TITLE: R1-Onevision: Advancing Generalized Multimodal Reasoning Through Cross-Modal Formalization
AUTHORS: YI YANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce R1-Onevision, a multimodal reasoning model designed to bridge the gap between visual perception and deep reasoning.

132, TITLE: SmartWay: Enhanced Waypoint Prediction and Backtracking for Zero-Shot Vision-and-Language Navigation
AUTHORS: XIANGYU SHI et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We propose a zero-shot VLN-CE framework integrating an enhanced waypoint predictor with a Multi-modal Large Language Model (MLLM)-based navigator.

133, TITLE: Efficient Federated Fine-Tuning of Large Language Models with Layer Dropout
AUTHORS: Shilong Wang ; Jianchun Liu ; Hongli Xu ; Jiaming Yan ; Xianjun Gao
CATEGORY: cs.LG [cs.LG, cs.AI, cs.DC]
HIGHLIGHT: This work proposes DropPEFT, an innovative federated PEFT framework that employs a novel stochastic transformer layer dropout method, enabling devices to deactivate a considerable fraction of LLMs layers during training, thereby eliminating the associated computational load and memory footprint.

134, TITLE: MACS: Multi-source Audio-to-image Generation with Contextual Significance and Semantic Alignment
AUTHORS: Hao Zhou ; Xiaobao Guo ; Yuzhe Zhu ; Adams Wai-Kin Kong
CATEGORY: cs.SD [cs.SD, cs.CV, cs.GR, eess.AS]
HIGHLIGHT: However, previous works only focus on single-source audio inputs for image generation, ignoring the multi-source characteristic in natural auditory scenes, thus limiting the performance in generating comprehensive visual content. To bridge this gap, a method called MACS is proposed to conduct multi-source audio-to-image generation.

135, TITLE: Category Prompt Mamba Network for Nuclei Segmentation and Classification
AUTHORS: YE ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the Mamba orientation-based scanning method lacks account for category-specific features, resulting in sub-optimal performance in scenarios with imbalanced class distributions. To address these challenges, this paper introduces a novel scanning strategy based on category probability sorting, which independently ranks and scans features for each category according to confidence from high to low.

136, TITLE: StableFusion: Continual Video Retrieval Via Frame Adaptation
AUTHORS: Zecheng Zhao ; Zhi Chen ; Zi Huang ; Shazia Sadiq ; Tong Chen
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Our analysis reveals that current TVR methods based on pre-trained models struggle to retain plasticity when adapting to new tasks, while existing continual learning approaches experience catastrophic forgetting, resulting in semantic misalignment between historical queries and stored video features. To address these challenges, we propose StableFusion, a novel CTVR framework comprising two main components: the Frame Fusion Adapter (FFA), which captures temporal dynamics in video content while preserving model flexibility, and the Task-Aware Mixture-of-Experts (TAME), which maintains consistent semantic alignment between queries across tasks and the stored video features.

137, TITLE: RoMA: Scaling Up Mamba-based Foundation Models for Remote Sensing
AUTHORS: FENGXIANG WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: While the linear-complexity Mamba architecture offers a promising alternative, existing RS applications of Mamba remain limited to supervised tasks on small, domain-specific datasets. To address these challenges, we propose RoMA, a framework that enables scalable self-supervised pretraining of Mamba-based RS foundation models using large-scale, diverse, unlabeled data.

138, TITLE: LVAgent: Long Video Understanding By Multi-Round Dynamical Collaboration of MLLM Agents
AUTHORS: BOYU CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In order to better address long video tasks, we introduce LVAgent, the first framework enabling multi-round dynamic collaboration of MLLM agents in long video understanding.

139, TITLE: OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model
AUTHORS: Bowen Zhang ; Pengcheng Luo
CATEGORY: cs.AI [cs.AI, math.OC]
HIGHLIGHT: We propose OR-LLM-Agent, the first AI agent that enables end-to-end automation for solving real-world OR problems.

140, TITLE: PiSA: A Self-Augmented Data Engine and Training Strategy for 3D Understanding with Large Models
AUTHORS: ZILU GUO et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: To this end, we introduce PiSA-Engine (Point-Self-Augmented-Engine), a new framework for generating instruction point-language datasets enriched with 3D spatial semantics.

141, TITLE: EEdit : Rethinking The Spatial and Temporal Redundancy for Efficient Image Editing
AUTHORS: ZEXUAN YAN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we rethink that the redundancy in inversion-based image editing exists in both the spatial and temporal dimensions, such as the unnecessary computation in unedited regions and the redundancy in the inversion progress. To tackle these challenges, we propose a practical framework, named EEdit, to achieve efficient image editing.

142, TITLE: Geometric Parameter Estimations of Perovskite Solar Cells Based on Optical Simulations
AUTHORS: Junhao Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents a non-invasive approach to estimate the layer thicknesses of perovskite solar cells.

143, TITLE: MASQUE: A Text-Guided Diffusion-Based Framework for Localized and Customized Adversarial Makeup
AUTHORS: Youngjin Kwon ; Xiao Zhang
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: To counteract, various anti-facial recognition techniques have been proposed for privacy protection by adversarially perturbing face images, among which generative makeup-based approaches are the most popular.

144, TITLE: Object-Aware DINO (Oh-A-Dino): Enhancing Self-Supervised Representations for Multi-Object Instance Retrieval
AUTHORS: Stefan Sylvius Wagner ; Stefan Harmeling
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Our findings reveal that DINO representations excel at capturing global object attributes such as object shape and size, but struggle with object-level details like colour, whereas slot-based representations struggle at both global and object-level understanding. To address this, we propose a method that combines global and local features by augmenting DINO representations with object-centric latent vectors from a Variational Autoencoder trained on segmented image patches that are extracted from the DINO features.

145, TITLE: BeamLLM: Vision-Empowered MmWave Beam Prediction with Large Language Models
AUTHORS: Can Zheng ; Jiguang He ; Guofa Cai ; Zitong Yu ; Chung G. Kang
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: In this paper, we propose BeamLLM, a vision-aided millimeter-wave (mmWave) beam prediction framework leveraging large language models (LLMs) to address the challenges of high training overhead and latency in mmWave communication systems.

146, TITLE: Understanding The Logical Capabilities of Large Language Models Via Out-of-Context Representation Learning
AUTHORS: Jonathan Shaki ; Emanuele La Malfa ; Michael Wooldridge ; Sarit Kraus
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We propose an alternative to in-context learning that trains only the representations of newly introduced tokens, namely out-of-context representation learning.

147, TITLE: AudioX: Diffusion Transformer for Anything-to-Audio Generation
AUTHORS: ZEYUE TIAN et. al.
CATEGORY: cs.MM [cs.MM, cs.CV, cs.LG, cs.SD, eess.AS]
HIGHLIGHT: In this work, we propose AudioX, a unified Diffusion Transformer model for Anything-to-Audio and Music Generation.

148, TITLE: Low Complexity Point Tracking of The Myocardium in 2D Echocardiography
AUTHORS: ARTEM CHERNYSHOV et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Deep learning methods for point tracking are applicable in 2D echocardiography, but do not yet take advantage of domain specifics that enable extremely fast and efficient configurations.

149, TITLE: Unlocking Generalization Power in LiDAR Point Cloud Registration
AUTHORS: ZHENXUAN ZENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, current methods fall short in achieving this level of generalization. To address these limitations, we propose UGP, a pruned framework designed to enhance generalization power for LiDAR point cloud registration.

150, TITLE: FourierSR: A Fourier Token-based Plugin for Efficient Image Super-Resolution
AUTHORS: Wenjie Li ; Heng Guo ; Yuefeng Hou ; Zhanyu Ma
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, commonly used units in SR, like convolutions and window-based Transformers, have limited receptive fields, making it challenging to apply them to improve SR under extremely limited computational cost. To address this issue, inspired by modeling convolution theorem through token mix, we propose a Fourier token-based plugin called FourierSR to improve SR uniformly, which avoids the instability or inefficiency of existing token mix technologies when applied as plug-ins.

151, TITLE: Dual-domain Modulation Network for Lightweight Image Super-Resolution
AUTHORS: Wenjie Li ; Heng Guo ; Yuefeng Hou ; Guangwei Gao ; Zhanyu Ma
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this paper, we show introducing both wavelet and Fourier information allows our model to consider both high-frequency features and overall SR structure reconstruction while reducing costs.

152, TITLE: Proxy-Tuning: Tailoring Multimodal Autoregressive Models for Subject-Driven Image Generation
AUTHORS: YI WU et. al.
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: Despite their strong performance in general T2I tasks, our research reveals that these models initially struggle with subject-driven image generation compared to dominant diffusion models. To address this limitation, we introduce Proxy-Tuning, leveraging diffusion models to enhance AR models' capabilities in subject-specific image generation.

153, TITLE: CPLOYO: A Pulmonary Nodule Detection Model with Multi-Scale Feature Fusion and Nonlinear Feature Learning
AUTHORS: Meng Wang ; Zi Yang ; Ruifeng Zhao ; Yaoting Jiang
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: CPLOYO: A Pulmonary Nodule Detection Model with Multi-Scale Feature Fusion and Nonlinear Feature Learning

154, TITLE: GaussHDR: High Dynamic Range Gaussian Splatting Via Learning Unified 3D and 2D Local Tone Mapping
AUTHORS: Jinfeng Liu ; Lingtong Kong ; Bo Li ; Dan Xu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Additionally, the global tone mapper used in existing methods can impede the learning of both HDR and LDR representations. To address these challenges, we present GaussHDR, which unifies 3D and 2D local tone mapping through 3D Gaussian splatting.

155, TITLE: Flow-NeRF: Joint Learning of Geometry, Poses, and Dense Flow Within Unified Neural Representations
AUTHORS: Xunzhi Zheng ; Dan Xu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present Flow-NeRF, a unified framework that simultaneously optimizes scene geometry, camera poses, and dense optical flow all on-the-fly.

156, TITLE: MetricGrids: Arbitrary Nonlinear Approximation with Elementary Metric Grids Based Implicit Neural Representation
AUTHORS: SHU WANG et. al.
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: This paper presents MetricGrids, a novel grid-based neural representation that combines elementary metric grids in various metric spaces to approximate complex nonlinear signals.

157, TITLE: NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval
AUTHORS: ZENGRONG LIN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we directly mitigate hubness during training and introduce NeighborRetr, a novel method that effectively balances the learning of hubs and adaptively adjusts the relations of various kinds of neighbors.

158, TITLE: Reference-Free 3D Reconstruction of Brain Dissection Photographs with Machine Learning
AUTHORS: LIN TIAN et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: Here we propose RefFree, a dissection photograph reconstruction method without external reference.

159, TITLE: Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding
AUTHORS: JINZE LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: To this end, we theoretically demonstrate that initial tokens in the draft sequence are more important than later ones. Building on this insight, we propose Gumiho, a hybrid model combining serial and parallel heads.

160, TITLE: Autoregressive Image Generation with Randomized Parallel Decoding
AUTHORS: Haopeng Li ; Jinyue Yang ; Guoqi Li ; Huan Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce ARPG, a novel visual autoregressive model that enables randomized parallel generation, addressing the inherent limitations of conventional raster-order approaches, which hinder inference efficiency and zero-shot generalization due to their sequential, predefined token generation order.

161, TITLE: SASNet: Spatially-Adaptive Sinusoidal Neural Networks
AUTHORS: Haoan Feng ; Diana Aldana ; Tiago Novello ; Leila De Floriani
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: They enable high-frequency signal reconstruction and smooth manifold modeling; however, they often suffer from spectral bias, training instability, and overfitting. To address these challenges, we propose SASNet, Spatially-Adaptive SNNs that robustly enhance the capacity of compact INRs to fit detailed signals.

162, TITLE: 3D Student Splatting and Scooping
AUTHORS: Jialin Zhu ; Jiangbei Yue ; Feixiang He ; He Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We subsequently propose a new mixture model consisting of flexible Student's t distributions, with both positive (splatting) and negative (scooping) densities.

163, TITLE: Revisiting Backdoor Attacks on Time Series Classification in The Frequency Domain
AUTHORS: Yuanmin Huang ; Mi Zhang ; Zhaoxiang Wang ; Wenxuan Li ; Min Yang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: In this work, we analyze the limitations of existing attacks and introduce an enhanced method, FreqBack.

164, TITLE: Do I Look Like A `cat.n.01` to You? A Taxonomy Image Generation Benchmark
AUTHORS: VIKTOR MOSKVORETSKII et. al.
CATEGORY: cs.CL [cs.CL, cs.CV]
HIGHLIGHT: While text-based methods for taxonomy enrichment are well-established, the potential of the visual dimension remains unexplored. To address this, we propose a comprehensive benchmark for Taxonomy Image Generation that assesses models' abilities to understand taxonomy concepts and generate relevant, high-quality images.

165, TITLE: Modeling Thousands of Human Annotators for Generalizable Text-to-Image Person Re-identification
AUTHORS: JIAYU JIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, the captions produced by MLLMs lack diversity in description styles. To address this issue, we propose a Human Annotator Modeling (HAM) approach to enable MLLMs to mimic the description styles of thousands of human annotators.

166, TITLE: GroomLight: Hybrid Inverse Rendering for Relightable Human Hair Appearance Modeling
AUTHORS: YANG ZHENG et. al.
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: We present GroomLight, a novel method for relightable hair appearance modeling from multi-view images.

167, TITLE: TARS: Traffic-Aware Radar Scene Flow Estimation
AUTHORS: Jialong Wu ; Marco Braun ; Dominic Spata ; Matthias Rottmann
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we present a novel $\textbf{T}$raffic-$\textbf{A}$ware $\textbf{R}$adar $\textbf{S}$cene flow estimation method, named $\textbf{TARS}$, which utilizes the motion rigidity at the traffic level.

168, TITLE: TGP: Two-modal Occupancy Prediction with 3D Gaussian and Sparse Points for 3D Environment Awareness
AUTHORS: MU CHEN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: However, existing occupancy prediction tasks are primarily modeled using voxel or point cloud-based approaches: voxel-based network structures often suffer from the loss of spatial information due to the voxelization process, while point cloud-based methods, although better at retaining spatial location information, face limitations in representing volumetric structural details. To address this issue, we propose a dual-modal prediction method based on 3D Gaussian sets and sparse points, which balances both spatial location and volumetric structural information, achieving higher accuracy in semantic occupancy prediction.

169, TITLE: Learning Richness Modulates Equality Reasoning in Neural Networks
AUTHORS: William L. Tong ; Cengiz Pehlevan
CATEGORY: cs.LG [cs.LG, cs.NE]
HIGHLIGHT: Following observations in comparative psychology, we propose a spectrum of behavior that ranges from conceptual to perceptual outcomes.

170, TITLE: PRISM: Preference Refinement Via Implicit Scene Modeling for 3D Vision-Language Preference-Based Reinforcement Learning
AUTHORS: Yirong Sun ; Yanjun Chen
CATEGORY: cs.CL [cs.CL, cs.RO]
HIGHLIGHT: We propose PRISM, a novel framework designed to overcome the limitations of 2D-based Preference-Based Reinforcement Learning (PBRL) by unifying 3D point cloud modeling and future-aware preference refinement.

171, TITLE: Mamba-VA: A Mamba-based Approach for Continuous Emotion Recognition in Valence-Arousal Space
AUTHORS: Yuheng Liang ; Zheyu Wang ; Feng Liu ; Mingzhou Liu ; Yu Yao
CATEGORY: cs.CV [cs.CV, I.4.6; H.5.2]
HIGHLIGHT: However, existing methods still face challenges in handling long-term dependencies and capturing complex temporal dynamics. To address these issues, this paper proposes a novel emotion recognition model, Mamba-VA, which leverages the Mamba architecture to efficiently model sequential emotional variations in video frames.

172, TITLE: Uncertainty-aware Long-tailed Weights Model The Utility of Pseudo-labels for Semi-supervised Learning
AUTHORS: Jiaqi Wu ; Junbiao Pang ; Qingming Huang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we propose an Uncertainty-aware Ensemble Structure (UES) to assess the utility of pseudo-labels for unlabeled samples.

173, TITLE: AhaRobot: A Low-Cost Open-Source Bimanual Mobile Manipulator for Embodied AI
AUTHORS: Haiqin Cui ; Yifu Yuan ; Yan Zheng ; Jianye Hao
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: The high cost of commercial mobile manipulation robots significantly limits research in real-world scenes. To address this issue, we propose AhaRobot, a low-cost and fully open-source dual-arm mobile manipulation robot system with a hardware cost of only $1,000 (excluding optional computational resources), which is less than 1/15 of the cost of popular mobile robots.

174, TITLE: Semantic Latent Motion for Portrait Video Generation
AUTHORS: QIYUAN ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing methods rely heavily on human priors and pre-trained generation models, which may introduce unrealistic motion and lead to inefficient inference. To address these challenges, we propose Semantic Latent Motion (SeMo), a compact and expressive motion representation.

175, TITLE: Constrained Language Generation with Discrete Diffusion Models
AUTHORS: MICHAEL CARDEI et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Constraints are critical in text generation as LLM outputs are often unreliable when it comes to ensuring generated outputs adhere to user defined instruction or general safety guidelines. To address this gap, we present Constrained Discrete Diffusion (CDD), a novel method for enforcing constraints on natural language by integrating discrete diffusion models with differentiable optimization.

176, TITLE: Enhancing Adversarial Example Detection Through Model Explanation
AUTHORS: Qian Ma ; Ziping Ye
CATEGORY: cs.CR [cs.CR, cs.CV, cs.LG]
HIGHLIGHT: We looked at AmI, a method proposed by a NeurIPS 2018 spotlight paper that uses model explanations to detect adversarial examples. Our study shows that while AmI is a promising idea, its performance is too dependent on specific settings (e.g., hyperparameter) and external factors such as the operating system and the deep learning framework used, and such drawbacks limit AmI's practical usage.

177, TITLE: ConsisLoRA: Enhancing Content and Style Consistency for LoRA-based Style Transfer
AUTHORS: BOLIN CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we comprehensively analyze the limitations of the standard diffusion parameterization, which learns to predict noise, in the context of style transfer.

178, TITLE: MuDG: Taming Multi-modal Diffusion with Gaussian Splatting for Urban Scene Reconstruction
AUTHORS: YINGSHUANG ZOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Nevertheless, critical limitations persist: reconstruction-based methods exhibit substantial performance deterioration under significant viewpoint deviations from training trajectories, while generation-based techniques struggle with temporal coherence and precise scene controllability. To overcome these challenges, we present MuDG, an innovative framework that integrates Multi-modal Diffusion model with Gaussian Splatting (GS) for Urban Scene Reconstruction.

179, TITLE: Have LLMs Made Active Learning Obsolete? Surveying The NLP Community
AUTHORS: Julia Romberg ; Christopher Schr�der ; Julius Gonsior ; Katrin Tomanek ; Fredrik Olsson
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: We conduct an online survey in the NLP community to collect previously intangible insights on the perceived relevance of data annotation, particularly focusing on active learning, including best practices, obstacles and expected future developments.

180, TITLE: Improving Medical Waste Classification with Hybrid Capsule Networks
AUTHORS: Bennet van den Broek ; Javad Pourmostafa Roshan Sharami
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: We explore the integration of capsule networks with a pretrained DenseNet model to improve medical waste classification.

181, TITLE: HSEmotion Team at ABAW-8 Competition: Audiovisual Ambivalence/Hesitancy, Emotional Mimicry Intensity and Facial Expression Recognition
AUTHORS: Andrey V. Savchenko
CATEGORY: cs.CV [cs.CV, 68T10, I.4.9]
HIGHLIGHT: This article presents our results for the eighth Affective Behavior Analysis in-the-Wild (ABAW) competition.

182, TITLE: Channel-wise Noise Scheduled Diffusion for Inverse Rendering in Indoor Scenes
AUTHORS: JUNYONG CHOI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a diffusion-based inverse rendering framework that decomposes a single RGB image into geometry, material, and lighting.

183, TITLE: Hoi2Anomaly: An Explainable Anomaly Detection Approach Guided By Human-Object Interaction
AUTHORS: Yuhan Wang ; Cheng Liu ; Daou Zhang ; Weichao Wu
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this thesis, we propose a novel approach to anomaly detection, termed Hoi2Anomaly, which aims to achieve precise discrimination and localization of anomalies.

184, TITLE: ConceptGuard: Continual Personalized Text-to-Image Generation with Forgetting and Confusion Mitigation
AUTHORS: Zirun Guo ; Tao Jin
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we investigate concept forgetting and concept confusion in the continual customization.

185, TITLE: A Rule Based Solution to Co-reference Resolution in Clinical Text
AUTHORS: Ping Chen ; David Hinote ; Guoqing Chen
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Objective: The aim of this study was to build an effective co-reference resolution system tailored for the biomedical domain.

186, TITLE: Exploring Position Encoding in Diffusion U-Net for Training-free High-resolution Image Generation
AUTHORS: Feng Zhou ; Pu Cao ; Yiyang Ma ; Lu Yang ; Jianqin Yin
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Through comprehensive analysis of position encoding in U-Net, we attribute it to inconsistent position encoding, sourced by the inadequate propagation of position information from zero-padding to latent features in convolution layers as resolution increases. To address this issue, we propose a novel training-free approach, introducing a Progressive Boundary Complement (PBC) method.

187, TITLE: DTA: Dual Temporal-channel-wise Attention for Spiking Neural Networks
AUTHORS: Minje Kim ; Minjun Kim ; Xu Yang
CATEGORY: cs.CV [cs.CV, cs.AI, cs.NE]
HIGHLIGHT: To leverage the strengths of both operations, we propose a novel Dual Temporal-channel-wise Attention (DTA) mechanism that integrates both identical/non-identical attention strategies.

188, TITLE: SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence
AUTHORS: CHANG HAN LOW et. al.
CATEGORY: cs.AI [cs.AI, cs.RO]
HIGHLIGHT: Although Chain-of-Thought (CoT) can structure reasoning more effectively, current approaches rely on self-generated CoT steps, which often exacerbate inherent domain gaps and hallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent framework that delivers transparent, interpretable insights for most tasks in robotic-assisted surgery.

189, TITLE: Predicting Chemical Reaction Outcomes Based on Electron Movements Using Machine Learning
AUTHORS: Shuan Chen ; Kye Sung Park ; Taewan Kim ; Sunkyu Han ; Yousung Jung
CATEGORY: physics.chem-ph [physics.chem-ph, cs.AI]
HIGHLIGHT: Here, we present Reactron, the first electron-based machine learning model for general reaction prediction.

190, TITLE: AdvPaint: Protecting Images from Inpainting Manipulation Via Adversarial Attention Disruption
AUTHORS: Joonsung Jeon ; Woo Jae Kim ; Suhyeon Ha ; Sooel Son ; Sung-eui Yoon
CATEGORY: cs.CV [cs.CV, cs.CR]
HIGHLIGHT: To mitigate inpainting abuses, we propose ADVPAINT, a novel defensive framework that generates adversarial perturbations that effectively disrupt the adversary's inpainting tasks.

191, TITLE: Take Off The Training Wheels Progressive In-Context Learning for Effective Alignment
AUTHORS: ZHENYU LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We find that the transformer embeds the task function learned from demonstrations into the separator token representation, which plays an important role in the generation of prior response tokens. Once the prior response tokens are determined, the demonstrations become redundant.Motivated by this finding, we propose an efficient Progressive In-Context Alignment (PICA) method consisting of two stages.

192, TITLE: Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model
AUTHORS: QIYUAN DENG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we hypothesize that during off-policy training, while the ranking order of output generated by policy changes, their overall distribution remains relatively stable.

193, TITLE: Adaptive Inner Speech-Text Alignment for LLM-based Speech Translation
AUTHORS: HENGLYU LIU et. al.
CATEGORY: cs.CL [cs.CL, cs.SD, eess.AS]
HIGHLIGHT: Existing methods primarily focus on aligning inputs and outputs across modalities while overlooking deeper semantic alignment within model representations. To address this limitation, we propose an Adaptive Inner Speech-Text Alignment (AI-STA) method to bridge the modality gap by explicitly aligning speech and text representations at selected layers within LLMs.

194, TITLE: A New Benchmark for Few-Shot Class-Incremental Learning: Redefining The Upper Bound
AUTHORS: Shiwon Kim ; Dongjun Hwang ; Sungwon Woo ; Rita Singh
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: In this work, we introduce a new joint training benchmark tailored for FSCIL by integrating imbalance-aware techniques, effectively bridging the performance gap between base and incremental classes.

195, TITLE: DeclareAligner: A Leap Towards Efficient Optimal Alignments for Declarative Process Model Conformance Checking
AUTHORS: Jacobo Casas-Ramos ; Manuel Lama ; Manuel Mucientes
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper introduces DeclareAligner, a novel algorithm that uses the A* search algorithm, an established AI pathfinding technique, to tackle the problem from a fresh perspective leveraging the flexibility of declarative models.

196, TITLE: RSR-NF: Neural Field Regularization By Static Restoration Priors for Dynamic Imaging
AUTHORS: Berk Iskender ; Sushan Nakarmi ; Nitin Daphalapurkar ; Marc L. Klasky ; Yoram Bresler
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: Moreover, ground-truth dynamic data is usually either unavailable or too scarce to be used for supervised learning techniques. To tackle this problem, we propose RSR-NF, which uses a neural field (NF) to represent the dynamic object and, using the Regularization-by-Denoising (RED) framework, incorporates an additional static deep spatial prior into a variational formulation via a learned restoration operator.

197, TITLE: PanoGen++: Domain-Adapted Text-Guided Panoramic Environment Generation for Vision-and-Language Navigation
AUTHORS: SEN WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.MM, cs.RO]
HIGHLIGHT: However, the scarcity of training data impedes progress in this field. This paper introduces PanoGen++, a novel framework that addresses this limitation by generating varied and pertinent panoramic environments for VLN tasks.

198, TITLE: DRESS: Disentangled Representation-based Self-Supervised Meta-Learning for Diverse Tasks
AUTHORS: Wei Cui ; Tongzi Wu ; Jesse C. Cresswell ; Yi Sui ; Keyvan Golestan
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: We propose DRESS, a task-agnostic Disentangled REpresentation-based Self-Supervised meta-learning approach that enables fast model adaptation on highly diversified few-shot learning tasks.

199, TITLE: PluralLLM: Pluralistic Alignment in LLMs Via Federated Learning
AUTHORS: Mahmoud Srewa ; Tianyu Zhao ; Salma Elmalaki
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We introduce PluralLLM a federated learning-based approach that enables multiple user groups to collaboratively train a transformer-based preference predictor without sharing sensitive data, which can also serve as a reward model for aligning LLMs.

200, TITLE: Un-Straightening Generative AI: How Queer Artists Surface and Challenge The Normativity of Generative AI Models
AUTHORS: JORDAN TAYLOR et. al.
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: We found our participants struggled to use these models due to various normative values embedded in their designs, such as hyper-positivity and anti-sexuality. We describe various strategies our participants developed to overcome these models' limitations and how, nevertheless, our participants found value in these highly-normative technologies.

201, TITLE: Style Evolving Along Chain-of-Thought for Unknown-Domain Object Detection
AUTHORS: Zihao Zhang ; Aming Wu ; Yahong Han
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: The one-step prompt method may not effectively synthesize combined information involving various styles. To address this limitation, we propose a new method, i.e., Style Evolving along Chain-of-Thought, which aims to progressively integrate and expand style information along the chain of thought, enabling the continual evolution of styles.

202, TITLE: Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for Mental Health Prediction Via Online Text
AUTHORS: Avinash Patil ; Amardeep Kour Gedhu
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Large Language Models (LLMs) have demonstrated potential in predicting mental health outcomes from online text, yet traditional classification methods often lack interpretability and robustness.

203, TITLE: LUMOS: Language-Conditioned Imitation Learning with World Models
AUTHORS: IMAN NEMATOLLAHI et. al.
CATEGORY: cs.RO [cs.RO, cs.CV, cs.LG]
HIGHLIGHT: We introduce LUMOS, a language-conditioned multi-task imitation learning framework for robotics.

204, TITLE: MoEdit: On Learning Quantity Perception for Multi-object Image Editing
AUTHORS: YANFENG LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing methods often struggle to consider each object both individually and part of the whole image editing, both of which are crucial for ensuring consistent quantity perception, resulting in suboptimal perceptual performance. To address these challenges, we propose MoEdit, an auxiliary-free multi-object image editing framework.

205, TITLE: Finding The Muses: Identifying Coresets Through Loss Trajectories
AUTHORS: Manish Nagaraj ; Deepak Ravikumar ; Efstathia Soufleri ; Kaushik Roy
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Deep learning models achieve state-of-the-art performance across domains but face scalability challenges in real-time or resource-constrained scenarios. To address this, we propose Loss Trajectory Correlation (LTC), a novel metric for coreset selection that identifies critical training samples driving generalization.

206, TITLE: Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework
AUTHORS: NATHAN DRENKOW et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: We present a data modality-agnostic auditing framework for generating targeted hypotheses about sources of bias which we refer to as Generalized Attribute Utility and Detectability-Induced bias Testing (G-AUDIT) for datasets.

207, TITLE: New Trends for Modern Machine Translation with Large Reasoning Models
AUTHORS: SINUO LIU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We identify three foundational shifts: 1) contextual coherence, where LRMs resolve ambiguities and preserve discourse structure through explicit reasoning over cross-sentence and complex context or even lack of context; 2) cultural intentionality, enabling models to adapt outputs by inferring speaker intent, audience expectations, and socio-linguistic norms; 3) self-reflection, LRMs can perform self-reflection during the inference time to correct the potential errors in translation especially extremely noisy cases, showing better robustness compared to simply mapping X->Y translation.

208, TITLE: PlanGen: Towards Unified Layout Planning and Image Generation in Auto-Regressive Vision Language Models
AUTHORS: RUNZE HE et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a unified layout planning and image generation model, PlanGen, which can pre-plan spatial layout conditions before generating images.

209, TITLE: Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in Neural Architecture Search
AUTHORS: Matteo Gambella ; Fabrizio Pittorino ; Manuel Roveri
CATEGORY: cs.LG [cs.LG, cond-mat.dis-nn, cs.CV]
HIGHLIGHT: In this paper, we investigate the geometric properties of neural architecture spaces commonly used in differentiable NAS methods, specifically NAS-Bench-201 and DARTS.

210, TITLE: Multi-Agent Q-Learning Dynamics in Random Networks: Convergence Due to Exploration and Sparsity
AUTHORS: Aamal Hussain ; Dan Leonte ; Francesco Belardinelli ; Raphael Huser ; Dario Paccagnan
CATEGORY: cs.MA [cs.MA, cs.AI, cs.GT, math.DS, 93A16, 91A26, 91A68, 58K35, G.3; J.4; F.2.2]
HIGHLIGHT: In this paper, we study Q-learning dynamics in network polymatrix games where the network structure is drawn from classical random graph models.

211, TITLE: Bidirectional Learned Facial Animation Codec for Low Bitrate Talking Head Videos
AUTHORS: Riku Takahashi ; Ryugo Morita ; Fuma Kimishima ; Kosuke Iwama ; Jinjia Zhou
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this paper, we propose a novel bidirectional learned animation codec that generates natural facial videos using past and future keyframes.

212, TITLE: DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding
AUTHORS: AYESHA ISHAQ et. al.
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: Moreover, existing methods lack a comprehensive framework for evaluating step-by-step reasoning in realistic driving scenarios. To address this gap, we propose DriveLMM-o1, a new dataset and benchmark specifically designed to advance step-wise visual reasoning for autonomous driving.

213, TITLE: Hierarchical Self-Supervised Adversarial Training for Robust Vision Models in Histopathology
AUTHORS: Hashmat Shadab Malik ; Shahina Kunhimon ; Muzammal Naseer ; Fahad Shahbaz Khan ; Salman Khan
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Existing self-supervised adversarial training methods overlook the hierarchical structure of histopathology images, where patient-slide-patch relationships provide valuable discriminative signals. To address this, we propose Hierarchical Self-Supervised Adversarial Training (HSAT), which exploits these properties to craft adversarial examples using multi-level contrastive learning and integrate it into adversarial training for enhanced robustness.

214, TITLE: Why The Brain Cannot Be A Digital Computer: History-Dependence and The Computational Limits of Consciousness
AUTHORS: Andrew Knight
CATEGORY: physics.hist-ph [physics.hist-ph, cs.AI, q-bio.NC]
HIGHLIGHT: This paper presents a novel information-theoretic proof demonstrating that the human brain as currently understood cannot function as a classical digital computer.

215, TITLE: Through The Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding
AUTHORS: Shunqi Mao ; Chaoyi Zhang ; Weidong Cai
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this work, we propose the Perception Magnifier (PM), a novel visual decoding method that iteratively isolates relevant visual tokens based on attention and magnifies the corresponding regions, spurring the model to concentrate on fine-grained visual details during decoding.

216, TITLE: FDCT: Frequency-Aware Decomposition and Cross-Modal Token-Alignment for Multi-Sensor Target Classification
AUTHORS: Shoaib Meraj Sami ; Md Mahedi Hasan ; Nasser M. Nasrabadi ; Raghuveer Rao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In addition, the multi-sensor images can be misaligned due to intricate background clutters, fluctuating illumination conditions, and uncontrolled sensor settings. In this paper, to overcome these issues, we decompose, align, and fuse multiple image sensor data for target classification.

217, TITLE: Hyper3D: Efficient 3D Representation Via Hybrid Triplane and Octree Feature for Enhanced 3D Shape Variational Auto-Encoders
AUTHORS: JINGYU GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Although recent work explores 3D latent representations, their large scale hinders high-resolution encoding and efficient training. Given these challenges, we introduce Hyper3D, which enhances VAE reconstruction through efficient 3D representation that integrates hybrid triplane and octree features.

218, TITLE: GBSVR: Granular Ball Support Vector Regression
AUTHORS: Reshma Rastogi ; Ankush Bisht ; Sanjay Kumar ; Suresh Chandra
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IR]
HIGHLIGHT: We propose Granular Ball Support Vector Regression (GBSVR) to tackle problem of regression by using granular ball concept.

219, TITLE: Automatic Quality Control in Multi-centric Fetal Brain MRI Super-resolution Reconstruction
AUTHORS: THOMAS SANCHEZ et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we focus on automated quality control of super-resolution reconstruction (SRR) volumes of fetal brain MRI, an important processing step where multiple stacks of thick 2D slices are registered together and combined to build a single, isotropic and artifact-free T2 weighted volume.

220, TITLE: SeqSAM: Autoregressive Multiple Hypothesis Prediction for Medical Image Segmentation Using SAM
AUTHORS: Benjamin Towle ; Xin Chen ; Ke Zhou
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: We introduce SeqSAM, a sequential, RNN-inspired approach to generating multiple masks, which uses a bipartite matching loss for ensuring the clinical relevancy of each mask, and can produce an arbitrary number of masks.

221, TITLE: Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking
AUTHORS: Xinglong Sun ; Haijiang Sun ; Shan Jiang ; Jiacheng Wang ; Jiasong Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a novel target-aware Bidirectional Fusion transformer (BFTrans) for UAV tracking.

222, TITLE: Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping
AUTHORS: Phoebe Koundouri ; Conrad Landis ; Georgios Feretzakis
CATEGORY: cs.AI [cs.AI, cs.CL, 68T50, I.2.7]
HIGHLIGHT: This research introduces a comprehensive system based on state-of-the-art natural language processing, semantic embedding, and efficient search techniques for retrieving similarities and thus generating actionable insights from raw textual information.

223, TITLE: Probing LLMs for Multilingual Discourse Generalization Through A Unified Label Set
AUTHORS: Florian Eichin ; Yang Janet Liu ; Barbara Plank ; Michael A. Hedderich
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work investigates whether large language models (LLMs) capture discourse knowledge that generalizes across languages and frameworks.

224, TITLE: Unveiling Hidden Pivotal Players with GoalNet: A GNN-Based Soccer Player Evaluation System
AUTHORS: Jacky Hao Jiang ; Jerry Cai ; Anastasios Kyrillidis
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC]
HIGHLIGHT: In this work, we introduce a GNN-based framework that assigns individual credit for changes in expected threat (xT), thus capturing overlooked yet vital contributions in soccer.

225, TITLE: OSMa-Bench: Evaluating Open Semantic Mapping Under Varying Lighting Conditions
AUTHORS: Maxim Popov ; Regina Kurkova ; Mikhail Iumanov ; Jaafar Mahmoud ; Sergey Kolyubin
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.RO]
HIGHLIGHT: This paper introduces a dynamically configurable and highly automated LLM/LVLM-powered pipeline for evaluating OSM solutions called OSMa-Bench (Open Semantic Mapping Benchmark).

226, TITLE: Label Unbalance in High-frequency Trading
AUTHORS: Zijian Zhao ; Xuming Chen ; Jiayu Wen ; Mingwen Liu ; Xiaoteng Ma
CATEGORY: cs.LG [cs.LG, cs.AI, q-fin.CP]
HIGHLIGHT: Label Unbalance in High-frequency Trading

227, TITLE: Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond
AUTHORS: LIANG WEN et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper presents our work on the Light-R1 series, with models, data, and code all released.

228, TITLE: Investigating and Improving Counter-Stereotypical Action Relation in Text-to-Image Diffusion Models
AUTHORS: Sina Malakouti ; Adriana Kovashka
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Through systematic investigation, we discover this limitation stems from distributional biases rather than inherent model constraints. Our key insight reveals that while models fail on rare compositions when their inversions are common, they can successfully generate similar intermediate compositions (e.g., "mouse chasing boy").

229, TITLE: Local Look-Ahead Guidance Via Verifier-in-the-Loop for Automated Theorem Proving
AUTHORS: Sara Rajaee ; Kumar Pratik ; Gabriele Cesa ; Arash Behboodi
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG, cs.LO]
HIGHLIGHT: In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process.

230, TITLE: MinorBench: A Hand-built Benchmark for Content-based Risks for Children
AUTHORS: Shaun Khoo ; Gabriel Chua ; Rachel Shong
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Large Language Models (LLMs) are rapidly entering children's lives - through parent-driven adoption, schools, and peer networks - yet current AI ethics and safety research do not adequately address content-related risks specific to minors. In this paper, we highlight these gaps with a real-world case study of an LLM-based chatbot deployed in a middle school setting, revealing how students used and sometimes misused the system.

231, TITLE: Generative AI for Named Entity Recognition in Low-Resource Language Nepali
AUTHORS: Sameer Neupane ; Jeevan Chapagain ; Nobal B. Niraula ; Diwa Koirala
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This paper investigates the application of state-of-the-art LLMs for Nepali NER, conducting experiments with various prompting techniques to assess their effectiveness.

232, TITLE: CountPath: Automating Fragment Counting in Digital Pathology
AUTHORS: ANA BEATRIZ VIEIRA et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, I.2; I.4]
HIGHLIGHT: Quality control of medical images is a critical component of digital pathology, ensuring that diagnostic images meet required standards. A pre-analytical task within this process is the verification of the number of specimen fragments, a process that ensures that the number of fragments on a slide matches the number documented in the macroscopic report.

233, TITLE: Consistent Multi-animal Pose Estimation in Cattle Using Dynamic Kalman Filter Based Tracking
AUTHORS: Maarten Perneel ; Ines Adriaens ; Ben Aernouts ; Jan Verwaeren
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this perspective, pose-estimation in combination with animal tracking offers opportunities to yield a higher level representation capturing both the spatial and temporal component of animal behaviour.

234, TITLE: How Good Are Deep Learning Methods for Automated Road Safety Analysis Using Video Data? An Experimental Study
AUTHORS: Qingwu Liu ; Nicolas Saunier ; Guillaume-Alexandre Bilodeau
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Inspired by the success of deep learning in MOD and MOT, we investigate three MOT methods, including one based on a stereo-camera, using the annotated KITTI traffic video dataset.

235, TITLE: Multiplicative Learning
AUTHORS: Han Kim ; Hyungjoon Soh ; Vipul Periwal ; Junghyo Jo
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this study, we introduce Expectation Reflection (ER), a novel learning approach that updates weights multiplicatively based on the ratio of observed to predicted outputs.

236, TITLE: Generative Binary Memory: Pseudo-Replay Class-Incremental Learning on Binarized Embeddings
AUTHORS: Yanis Basso-Bert ; Anca Molnos ; Romain Lemaire ; William Guicquero ; Antoine Dupret
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: This paper introduces Generative Binary Memory (GBM), a novel CIL pseudo-replay approach which generates synthetic binary pseudo-exemplars.

237, TITLE: Red Teaming Contemporary AI Models: Insights from Spanish and Basque Perspectives
AUTHORS: MIGUEL ROMERO-ARJONA et. al.
CATEGORY: cs.SE [cs.SE, cs.CL]
HIGHLIGHT: In response to these global trends, the Spanish government has proposed ALIA, a public and transparent AI infrastructure incorporating small language models designed to support Spanish and co-official languages such as Basque. This paper presents the results of Red Teaming sessions, where ten participants applied their expertise and creativity to manually test three of the latest models from these initiatives$\unicode{x2013}$OpenAI o3-mini, DeepSeek R1, and ALIA Salamandra$\unicode{x2013}$focusing on biases and safety concerns.

238, TITLE: Whisper Speaker Identification: Leveraging Pre-Trained Multilingual Transformers for Robust Speaker Embeddings
AUTHORS: Jakaria Islam Emon ; Md Abu Salek ; Kazi Tamanna Alam
CATEGORY: cs.SD [cs.SD, cs.AI, eess.AS, I.2]
HIGHLIGHT: In this paper, we propose WSI (Whisper Speaker Identification), a framework that repurposes the encoder of the Whisper automatic speech recognition model pre trained on extensive multilingual data to generate robust speaker embeddings via a joint loss optimization strategy that leverages online hard triplet mining and self supervised Normalized Temperature-scaled Cross Entropy loss.

239, TITLE: Rapid Analysis of Point-contact Andreev Reflection Spectra Via Machine Learning with Adaptive Data Augmentation
AUTHORS: DONGIK LEE et. al.
CATEGORY: cond-mat.supr-con [cond-mat.supr-con, cs.AI, cs.LG]
HIGHLIGHT: In this study, we employ a convolutional neural network (CNN) algorithm to create models for rapid and automated analysis of PCAR spectra of various superconductors with different pairing symmetries (conventional $s$-wave, chiral $p_x+ip_y$-wave, and $d_{x^2-y^2}$-wave).

240, TITLE: Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM
AUTHORS: MOHD ARIFUL HAQUE et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Human-designed tools are inflexible and restricted to solutions within the scope of pre-existing tools created by experts. To address this problem, we propose ATLASS, an advanced tool learning and selection system designed as a closed-loop framework.

241, TITLE: Parallelizing Multi-objective A* Search
AUTHORS: Saman Ahmadi ; Nathan R. Sturtevant ; Andrea Raith ; Daniel Harabor ; Mahdi Jalili
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper presents a novel search framework that allows efficient parallelization of MOA* with different objective orders.

242, TITLE: Adaptive Preference Aggregation
AUTHORS: Benjamin Heymann
CATEGORY: cs.AI [cs.AI, cs.GT]
HIGHLIGHT: Leveraging insights from a recently published urn process, this work introduces a preference aggregation strategy that adapts to the user's context and that inherits the good properties of the maximal lottery, a Condorcet-consistent solution concept.

243, TITLE: LLM Agents Display Human Biases But Exhibit Distinct Learning Patterns
AUTHORS: Idan Horowitz ; Ori Plonsky
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We investigate the choice patterns of Large Language Models (LLMs) in the context of Decisions from Experience tasks that involve repeated choice and learning from feedback, and compare their behavior to human participants.

244, TITLE: Review GIDE -- Restaurant Review Gastrointestinal Illness Detection and Extraction with Large Language Models
AUTHORS: TIMOTHY LAURENCE et. al.
CATEGORY: cs.CL [cs.CL, cs.LG, 68T50]
HIGHLIGHT: In this study, we introduce a novel annotation schema, developed with experts in GI illness, applied to the Yelp Open Dataset of reviews.

245, TITLE: Wikipedia Is Not A Dictionary, Delete! Text Classification As A Proxy for Analysing Wiki Deletion Discussions
AUTHORS: Hsuvas Borkakoty ; Luis Espinosa-Anke
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Wikipedia Is Not A Dictionary, Delete! Text Classification As A Proxy for Analysing Wiki Deletion Discussions

246, TITLE: Assessing The Validity of New Paradigmatic Complexity Measures As Criterial Features for Proficiency in L2 Writings in English
AUTHORS: CYRIEL MALLART et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Using the EFCAMDAT as a gold standard and a corpus of French learners as an external test set, we employ a supervised learning framework to operationalise and evaluate seven microsystems.

247, TITLE: R.U.Psycho? Robust Unified Psychometric Testing of Language Models
AUTHORS: Julian Schelb ; Orr Borin ; David Garcia ; Andreas Spitz
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Generative language models are increasingly being subjected to psychometric questionnaires intended for human testing, in efforts to establish their traits, as benchmarks for alignment, or to simulate participants in social science experiments.

248, TITLE: ARLED: Leveraging LED-based ARMAN Model for Abstractive Summarization of Persian Long Documents
AUTHORS: Samira Zangooei ; Amirhossein Darmani ; Hossein Farahmand Nezhad ; Laya Mahmoudi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The paper provides a comprehensive overview of related work, discusses the methodology, presents the experimental results, and concludes with future research directions.

249, TITLE: Developing and Evaluating An AI-Assisted Prediction Model for Unplanned Intensive Care Admissions Following Elective Neurosurgery Using Natural Language Processing Within An Electronic Healthcare Record System
AUTHORS: JULIA IVE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Methods: This study analysed the EHRs of elective neurosurgery patients from University College London Hospital (UCLH) using NLP.

250, TITLE: Statistical Analysis of Sentence Structures Through ASCII, Lexical Alignment and PCA
AUTHORS: Abhijeet Sahdev
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While utilizing syntactic tools such as parts-of-speech (POS) tagging has helped us understand sentence structures and their distribution across diverse corpora, it is quite complex and poses a challenge in natural language processing (NLP). This study focuses on understanding sentence structure balance - usages of nouns, verbs, determiners, etc - harmoniously without relying on such tools.

251, TITLE: LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions
AUTHORS: Gaurav Kumar Gupta ; Pranal Pande
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses.

252, TITLE: What's In Your Field? Mapping Scientific Research with Knowledge Graphs and Large Language Models
AUTHORS: Abhipsha Das ; Nicholas Lourie ; Siavash Golkar ; Mariel Pettee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Structured representations offer a natural complement -- enabling systematic analysis across the whole corpus. Recent work enhances LLMs with unstructured or semistructured representations of scientific concepts; to complement this, we try extracting structured representations using LLMs.

253, TITLE: A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent Document Summarization
AUTHORS: Nevidu Jayatilleke ; Ruvan Weerasinghe
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Embodying extractive and abstractive text summarization methodologies into a hybrid framework, this study proposes a system for efficiently creating abstractive summaries of patent records.

254, TITLE: Who Are You Behind The Screen? Implicit MBTI and Gender Detection Using Artificial Intelligence
AUTHORS: Kourosh Shahnazari ; Seyed Moein Ayyoubzadeh
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This study emphasizes practical issues in balancing accuracy and data coverage as Transformer-based models show their efficiency in implicit personality and gender prediction tasks from conversational texts.

255, TITLE: Computational Complexity and Integer Programming Formulation of The Oredango Puzzle
AUTHORS: Takuma Takahata ; Norito Minamikawa ; Takayuki Okuno
CATEGORY: cs.CC [cs.CC]
HIGHLIGHT: In this paper, we show NP- and ASP-completeness of Oredango by constructing a reduction from the 1-in-3SAT problem.

256, TITLE: OCCUQ: Exploring Efficient Uncertainty Quantification for 3D Occupancy Prediction
AUTHORS: Severin Heidrich ; Till Beemelmanns ; Alexey Nekrasov ; Bastian Leibe ; Lutz Eckstein
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose an efficient adaptation of an uncertainty estimation technique for 3D occupancy prediction.

257, TITLE: Fourier Decomposition for Explicit Representation of 3D Point Cloud Attributes
AUTHORS: Donghyun Kim ; Hyunah Ko ; Chanyoung Kim ; Seong Jae Hwang
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: While existing methods handle these attributes separately on a per-point basis, this leads to a limited receptive field and restricted ability to capture relationships across multiple points. To address this, we pioneer a point cloud encoding methodology that leverages 3D Fourier decomposition to disentangle color and geometric features while extending the receptive field through spectral-domain operations.

258, TITLE: ST-FlowNet: An Efficient Spiking Neural Network for Event-Based Optical Flow Estimation
AUTHORS: HONGZE SUN et. al.
CATEGORY: cs.CV [cs.CV, cs.NE, q-bio.NC]
HIGHLIGHT: However, the performance of SNN models is often constrained, limiting their application in real-world scenarios. In this work, we address this gap by proposing a novel neural network architecture, ST-FlowNet, specifically tailored for optical flow estimation from event-based data.

259, TITLE: Enhancing Multi-Agent Systems Via Reinforcement Learning with LLM-based Planner and Graph-based Policy
AUTHORS: Ziqi Jia ; Junjie Li ; Xiaoyang Qu ; Jianzong Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: The introduction of Large Language Models (LLMs) has brought stronger reasoning and cognitive abilities to MAS, but existing LLM-based systems struggle to respond quickly and accurately in dynamic environments. To address these challenges, we propose LLM-based Graph Collaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and MARL.

260, TITLE: Learning Disease State from Noisy Ordinal Disease Progression Labels
AUTHORS: Gustav Schmidt ; Holger Heidrich ; Philipp Berens ; Sarah M�ller
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we ask whether ordinal disease progression labels (better, worse, or stable) can be used to learn a representation allowing to classify disease state.

261, TITLE: Lightweight Models for Emotional Analysis in Video
AUTHORS: Quoc-Tien Nguyen ; Hong-Hai Nguyen ; Van-Thong Huynh
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this study, we present an approach for efficient spatiotemporal feature extraction using MobileNetV4 and a multi-scale 3D MLP-Mixer-based temporal aggregation module.

262, TITLE: A PyTorch-Enabled Tool for Synthetic Event Camera Data Generation and Algorithm Development
AUTHORS: JOSEPH L. GREENE et. al.
CATEGORY: cs.CV [cs.CV, physics.optics]
HIGHLIGHT: However, their adoption in domain-specific research tasks is hindered in part by limited commercial availability, lack of existing datasets, and challenges related to predicting the impact of their nonlinear optical encoding, unique noise model and tensor-based data processing requirements. To address these challenges, we introduce Synthetic Events for Neural Processing and Integration (SENPI) in Python, a PyTorch-based library for simulating and processing event camera data.

263, TITLE: A Siamese Network to Detect If Two Iris Images Are Monozygotic
AUTHORS: Yongle Yuan ; Kevin W. Bowyer
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we employ a Siamese network architecture and contrastive learning to categorize a pair of iris images as coming from monozygotic or non-monozygotic irises.

264, TITLE: NIL: No-data Imitation Learning By Leveraging Pre-trained Video Diffusion Models
AUTHORS: MERT ALBABA et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, cs.RO]
HIGHLIGHT: Video diffusion models, on the other hand, are capable of generating realistic videos of various morphologies, from humans to ants. Leveraging this capability, we propose a data-independent approach for skill acquisition that learns 3D motor skills from 2D-generated videos, with generalization capability to unconventional and non-human forms.

265, TITLE: A Multimodal Fusion Model Leveraging MLP Mixer and Handcrafted Features-based Deep Learning Networks for Facial Palsy Detection
AUTHORS: Heng Yim Nicole Oo ; Min Hun Lee ; Jeong Hoon Lim
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we present a multimodal fusion-based deep learning model that utilizes an MLP mixer-based model to process unstructured data (i.e. RGB images or images with facial line segments) and a feed-forward neural network to process structured data (i.e. facial landmark coordinates, features of facial expressions, or handcrafted features) for detecting facial palsy.

266, TITLE: Isolated Channel Vision Transformers: From Single-Channel Pretraining to Multi-Channel Finetuning
AUTHORS: Wenyi Lian ; Joakim Lindblad ; Patrick Micke ; Nata?a Sladoje
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we introduce a simple yet effective pretraining framework for large-scale MCI datasets.

267, TITLE: Object Detection Characteristics in A Learning Factory Environment Using YOLOv8
AUTHORS: Toni Schneidereit ; Stefan Gohrenz ; Michael Breu�
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we present a systematic investigation of background influences and different features of the object to be detected.

268, TITLE: On The Limitations of Vision-Language Models in Understanding Image Transforms
AUTHORS: Ahmad Mustafa Anis ; Hasnain Ali ; Saquib Sarfraz
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, I.4, I.2.10, I.2.7]
HIGHLIGHT: Vision Language Models (VLMs) have demonstrated significant potential in various downstream tasks, including Image/Video Generation, Visual Question Answering, Multimodal Chatbots, and Video Understanding.

269, TITLE: Eye on The Target: Eye Tracking Meets Rodent Tracking
AUTHORS: EMIL MEDEDOVIC et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we propose a novel pipeline that utilizes eye-tracking data from Aria glasses to generate prompt points, which are then used to produce segmentation masks via a fast zero-shot segmentation model.

270, TITLE: Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis
AUTHORS: CHENJUN LI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we present a novel method that integrates graph representation learning with vision-language models (VLMs) to deliver explainable DR diagnosis.

271, TITLE: Evaluating The Impact of Synthetic Data on Object Detection Tasks in Autonomous Driving
AUTHORS: Enes �zeren ; Arka Bhowmick
CATEGORY: cs.CV [cs.CV, I.2.9; I.2.10; I.4.8]
HIGHLIGHT: We compare models trained on real, synthetic, and mixed datasets, analyzing their robustness and generalization capabilities.

272, TITLE: AI Rivalry As A Craft: How Resisting and Embracing Generative AI Reshape Writing Professions
AUTHORS: Rama Adithya Varanasi ; Batia Mishan Wiesenfeld ; Oded Nov
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: Recent studies explore GAI adoption experiences of creative practitioners, but we know little about how these experiences evolve into established practices and how GAI resistance alters these practices. To address this gap, we conducted 25 semi-structured interviews with writing professionals who adopted and/or resisted GAI.

273, TITLE: Training Human-Robot Teams By Improving Transparency Through A Virtual Spectator Interface
AUTHORS: SEAN DALLAS et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, cs.RO, H.5.2; I.2.9]
HIGHLIGHT: Traditional AAR between human teammates may not be satisfactory for human-robot teams. To address this limitation, we propose a new training review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance human-robot team performance and situational awareness (SA) in a simulated search mission.

274, TITLE: Conformal Prediction Sets for Deep Generative Models Via Reduction to Conformal Regression
AUTHORS: Hooman Shahrokhi ; Devjeet Raj Roy ; Yan Yan ; Venera Arnaoudova ; Janaradhan Rao Doppa
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We consider the problem of generating valid and small prediction sets by sampling outputs (e.g., software code and natural language text) from a black-box deep generative model for a given input (e.g., textual prompt).

275, TITLE: Robustness Tokens: Towards Adversarial Robustness of Transformers
AUTHORS: Brian Pulfer ; Yury Belousov ; Slava Voloshynovskiy
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: In this work, we propose Robustness Tokens, a novel approach specific to the transformer architecture that fine-tunes a few additional private tokens with low computational requirements instead of tuning model parameters as done in traditional adversarial training.

276, TITLE: The Spectral Bias of Shallow Neural Network Learning Is Shaped By The Choice of Non-linearity
AUTHORS: Justin Sahs ; Ryan Pyle ; Fabio Anselmi ; Ankit Patel
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This unexpected property is attributed to the network's so-called implicit bias, which describes its propensity to converge to solutions that generalize effectively, among the many possible that correctly label the training data. The aim of our research is to explore this bias from a new perspective, focusing on how non-linear activation functions contribute to shaping it.

277, TITLE: EXpLogic: Explaining Logic Types and Patterns in DiffLogic Networks
AUTHORS: Stephen Wormald ; David Koblah ; Matheus Kunzler Maldaner ; Domenic Forte ; Damon L. Woodard
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Inspired by principles of circuit analysis from computer engineering, this work presents an algorithm (eXpLogic) for producing saliency maps which explain input patterns that activate certain functions.

278, TITLE: Language Models, Graph Searching, and Supervision Adulteration: When More Supervision Is Less and How to Make More More
AUTHORS: Arvid Frydenlund
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, I.2.7; I.2.8; I.5.0]
HIGHLIGHT: Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to a learned shortcut that absorbs training supervision. We show how this pathology is caused by excess supervision and we present a series of solutions demonstrating that the task is solvable via decoder-only LMs.

279, TITLE: Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning
AUTHORS: Duc Kien Doan ; Bang Giang Le ; Viet Cuong Ta
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we aim to learn an efficient state representation to balance the exploration and safety-prefer action in a sparse-reward environment.

280, TITLE: Adding Numbers with Spiking Neural Circuits on Neuromorphic Hardware
AUTHORS: OSKAR VON SEELER et. al.
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: We describe the time complexity, neuron and synaptic resources, as well as constraints on the bit width of the numbers that can be added with the current implementations.

281, TITLE: Super-Linear Speedup By Generalizing Runtime Repeated Recursion Unfolding in Prolog
AUTHORS: Thom Fruehwirth
CATEGORY: cs.PL [cs.PL, cs.DS, cs.PF, cs.SC, D.1.6; D.3.3]
HIGHLIGHT: So far, the method was restricted to single linear direct recursive rules in the programming language Constraint Handling Rules (CHR). In this companion paper, we generalize the technique to multiple recursion and to multiple recursive rules and provide an implementation of the generalized method in the logic programming language Prolog.

282, TITLE: CODEI: Resource-Efficient Task-Driven Co-Design of Perception and Decision Making for Mobile Robots Applied to Autonomous Vehicles
AUTHORS: Dejan Milojevic ; Gioele Zardini ; Miriam Elser ; Andrea Censi ; Emilio Frazzoli
CATEGORY: cs.RO [cs.RO, cs.AI, cs.AR, cs.CV, cs.SY, eess.SY, I.2.9; I.2.10; I.2.8; I.4.8]
HIGHLIGHT: This paper discusses the integration challenges and strategies for designing mobile robots, by focusing on the task-driven, optimal selection of hardware and software to balance safety, efficiency, and minimal usage of resources such as costs, energy, computational requirements, and weight.

283, TITLE: Quantization for OpenAI's Whisper Models: A Comparative Analysis
AUTHORS: Allison Andreyev
CATEGORY: cs.SD [cs.SD, cs.CL, cs.LG, eess.AS, 68T50, 68T10, I.2.7; I.5.4; H.5.1]
HIGHLIGHT: This study analyzes the similarities and differences between three Whisper models, qualitatively examining their distinct capabilities.

284, TITLE: Explainable Bayesian Deep Learning Through Input-skip Latent Binary Bayesian Neural Networks
AUTHORS: Eirik H�yheim ; Lars Skaaret-Lund ; Solve S�b� ; Aliaksandr Hubin
CATEGORY: stat.ML [stat.ML, cs.AI, cs.LG, stat.CO, stat.ME, 62-02, 62-09, 62F07, 62F15, 62J12, 62J05, 62J99, 62M05, 05A16, 60J22, 92D20, 90C27, 90C59, G.1.2; G.1.6; G.2.1; G.3; I.2.0; I.2.6; I.2.8; I.5.1; I.6; I.6.4]
HIGHLIGHT: This article advances LBBNNs by enabling covariates to skip to any succeeding layer or be excluded, simplifying networks and clarifying input impacts on predictions.

285, TITLE: How Should We Evaluate Uncertainty in Accelerated MRI Reconstruction?
AUTHORS: Luca Trautmann ; Peter Wijeratne ; Itamar Ronen ; Ivor Simpson
CATEGORY: eess.IV [eess.IV, cs.CV, physics.med-ph]
HIGHLIGHT: In this paper, we propose a new approach to evaluating reconstruction variability based on apparent anatomical changes in the reconstruction, which is more tightly related to common downstream tasks.

286, TITLE: Markerless Tracking-Based Registration for Medical Image Motion Correction
AUTHORS: LUISA NEUBIG et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We introduce a novel motion correction pipeline that effectively removes disruptive motion while preserving swallowing dynamics and surpassing competitive registration techniques.

287, TITLE: PS3C: An Ensemble-Based Two-Step Framework for Classification of Pep Smear Cell Images
AUTHORS: Theo Di Piazza ; Loic Boussel
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we propose a two-stage ensemble approach: first, a neural network determines whether an image is rubbish or not.

288, TITLE: QuickDraw: Fast Visualization, Analysis and Active Learning for Medical Image Segmentation
AUTHORS: DANIEL SYOMICHEV et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.HC]
HIGHLIGHT: Despite significant advances in medical image analysis in recent years, many of the latest models are never applied in clinical settings because state-of-the-art models do not easily interface with existing medical image viewers. To address these limitations, we propose QuickDraw, an open-source framework for medical image visualization and analysis that allows users to upload DICOM images and run off-the-shelf models to generate 3D segmentation masks.
