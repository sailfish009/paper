1, TITLE: ScriptViz: A Visualization Tool to Aid Scriptwriting Based on A Large Movie Database
AUTHORS: Anyi Rao ; Jean-Pe�c Chou ; Maneesh Agrawala
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CV, cs.GR]
HIGHLIGHT: In this paper, we develop ScriptViz to provide external visualization based on a large movie database for the screenwriting process.

2, TITLE: Estimating Body and Hand Motion in An Ego-sensed World
AUTHORS: BRENT YI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We present EgoAllo, a system for human motion estimation from a head-mounted device.

3, TITLE: ALR$^2$: A Retrieve-then-Reason Framework for Long-context Question Answering
AUTHORS: HUAYANG LI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We find that modern LLMs struggle to accurately retrieve relevant facts and instead, often hallucinate "retrieved facts", resulting in flawed reasoning and the production of incorrect answers. To address these issues, we introduce ALR$^2$, a method that augments the long-context reasoning capability of LLMs via an explicit two-stage procedure, i.e., aligning LLMs with the objectives of both retrieval and reasoning.

4, TITLE: Diffusion State-Guided Projected Gradient for Inverse Problems
AUTHORS: Rayhan Zirvi ; Bahareh Tolooshams ; Anima Anandkumar
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: To enhance the performance and robustness of diffusion models in solving inverse problems, we propose Diffusion State-Guided Projected Gradient (DiffStateGrad), which projects the measurement gradient onto a subspace that is a low-rank approximation of an intermediate state of the diffusion process.

5, TITLE: Margin Matching Preference Optimization: Enhanced Model Alignment with Granular Feedback
AUTHORS: Kyuyoung Kim ; Ah Jeong Seo ; Hao Liu ; Jinwoo Shin ; Kimin Lee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Despite their success, existing methods typically rely on simple binary labels, such as those indicating preferred outputs in pairwise preferences, which fail to capture the subtle differences in relative quality between pairs. To address this limitation, we introduce an approach called Margin Matching Preference Optimization (MMPO), which incorporates relative quality margins into optimization, leading to improved LLM policies and reward models.

6, TITLE: Gradient-based Jailbreak Images for Multimodal Fusion Models
AUTHORS: Javier Rando ; Hannah Korevaar ; Erik Brinkman ; Ivan Evtimov ; Florian Tram�r
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: In this work, we introduce the notion of a tokenizer shortcut that approximates tokenization with a continuous function and enables continuous optimization.

7, TITLE: Efficiently Identifying Watermarked Segments in Mixed-Source Texts
AUTHORS: Xuandong Zhao ; Chenwen Liao ; Yu-Xiang Wang ; Lei Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Drawing inspiration from plagiarism detection systems, we propose two novel methods for partial watermark detection.

8, TITLE: AuroraCap: Efficient, Performant Video Detailed Captioning and A New Benchmark
AUTHORS: WENHAO CHAI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose AuroraCap, a video captioner based on a large multimodal model.

9, TITLE: Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification
AUTHORS: Gary Murphy ; Raghubir Singh
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This study introduces a novel and accurate approach to breast cancer classification using histopathology images.

10, TITLE: Tutor CoPilot: A Human-AI Approach for Scaling Real-Time Expertise
AUTHORS: Rose E. Wang ; Ana T. Ribeiro ; Carly D. Robinson ; Susanna Loeb ; Dora Demszky
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This challenge disproportionately harms students from under-served communities, who stand to gain the most from high-quality education. We introduce Tutor CoPilot, a novel Human-AI approach that leverages a model of expert thinking to provide expert-like guidance to tutors as they tutor.

11, TITLE: What Matters for Model Merging at Scale?
AUTHORS: PRATEEK YADAV et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: We evaluate the merged models on both held-in tasks, i.e., the expert's training tasks, and zero-shot generalization to unseen held-out tasks.

12, TITLE: Can Watermarked LLMs Be Identified By Users Via Crafted Prompts?
AUTHORS: AIWEI LIU et. al.
CATEGORY: cs.CR [cs.CR, cs.CL, 68T50, I.2.7]
HIGHLIGHT: Finally, we propose that the key to enhancing the imperceptibility of watermarked LLMs is to increase the randomness of watermark key selection. Based on this, we introduce the Water-Bag strategy, which significantly improves watermark imperceptibility by merging multiple watermark keys.

13, TITLE: Better Instruction-Following Through Minimum Bayes Risk
AUTHORS: IAN WU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We find that MBR decoding with reference-based LLM judges substantially improves over greedy decoding, best-of-N decoding with reference-free judges and MBR decoding with lexical and embedding-based metrics on AlpacaEval and MT-Bench.

14, TITLE: NNetscape Navigator: Complex Demonstrations for Web Agents Without A Demonstrator
AUTHORS: Shikhar Murty ; Dzmitry Bahdanau ; Christopher D. Manning
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce NNetscape Navigator (NNetnav), a method for training web agents entirely through synthetic demonstrations.

15, TITLE: Image First or Text First? Optimising The Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks
AUTHORS: Grant Wardle ; Teo Susnjak
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: This paper examines how the sequencing of images and text within multi-modal prompts influences the reasoning performance of large language models (LLMs).

16, TITLE: A Tutorial on The Design, Experimentation and Application of Metaheuristic Algorithms to Real-World Optimization Problems
AUTHORS: ENEKO OSABA et. al.
CATEGORY: cs.NE [cs.NE, cs.AI]
HIGHLIGHT: A clear example stems from the scarce replicability of works dealing with metaheuristics used for optimization, which is often infeasible due to ambiguity and lack of detail in the presentation of the methods to be reproduced.

17, TITLE: MLP-KAN: Unifying Deep Representation and Function Learning
AUTHORS: Yunhong He ; Yifeng Xie ; Zhengqing Yuan ; Lichao Sun
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: However, the effective integration of these paradigms poses a significant challenge, particularly in cases where users must manually decide whether to apply a representation learning or function learning model based on dataset characteristics. To address this issue, we introduce MLP-KAN, a unified method designed to eliminate the need for manual model selection.

18, TITLE: Autoregressive Large Language Models Are Computationally Universal
AUTHORS: Dale Schuurmans ; Hanjun Dai ; Francesco Zanini
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We show that autoregressive decoding of a transformer-based language model can realize universal computation, without external intervention or modification of the model's weights.

19, TITLE: CounterQuill: Investigating The Potential of Human-AI Collaboration in Online Counterspeech Writing
AUTHORS: XIAOHAN DING et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CY]
HIGHLIGHT: Existing counterspeech methods often face challenges such as fear of retaliation and skill-related barriers. To address these challenges, we introduce CounterQuill, an AI-mediated system that assists users in composing effective and empathetic counterspeech.

20, TITLE: Deliberate Reasoning for LLMs As Structure-aware Planning with Accurate World Model
AUTHORS: Siheng Xiong ; Ali Payani ; Yuan Yang ; Faramarz Fekri
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions. Inspired by this, we propose a novel multi-step reasoning framework for LLMs, referred to as Structure-aware Planning with Accurate World Model (SWAP).

21, TITLE: Frame-Voyager: Learning to Query Frames for Video Large Language Models
AUTHORS: SICHENG YU et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In this paper, we propose Frame-Voyager that learns to query informative frame combinations, based on the given textual queries in the task.

22, TITLE: Img2CAD: Conditioned 3D CAD Model Generation from Single Image with Structured Visual Geometry
AUTHORS: TIANRUN CHEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose Img2CAD, the first approach to our knowledge that uses 2D image inputs to generate CAD models with editable parameters.

23, TITLE: Scaling Parameter-Constrained Language Models with Quality Data
AUTHORS: ERNIE CHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we extend the conventional understanding of scaling law by offering a microscopic view of data quality within the original formulation -- effective training tokens -- which we posit to be a critical determinant of performance for parameter-constrained language models.

24, TITLE: LoRC: Low-Rank Compression for LLMs KV Cache with A Progressive Compression Strategy
AUTHORS: RONGZHI ZHANG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, I.2]
HIGHLIGHT: This paper introduces an orthogonal approach to KV cache compression.

25, TITLE: Redefining Temporal Modeling in Video Diffusion: The Vectorized Timestep Approach
AUTHORS: YAOFANG LIU et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: However, current video diffusion models~(VDMs) rely on a scalar timestep variable applied at the clip level, which limits their ability to model complex temporal dependencies needed for various tasks like image-to-video generation. To address this limitation, we propose a frame-aware video diffusion model~(FVDM), which introduces a novel vectorized timestep variable~(VTV).

26, TITLE: Transforming Teachers' Roles and Agencies in The Era of Generative AI: Perceptions, Acceptance, Knowledge, and Practices
AUTHORS: Xiaoming Zhai
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: This paper explores the transformative impact of Generative Artificial Intelligence (GenAI) on teachers' roles and agencies in education, presenting a comprehensive framework that addresses teachers' perceptions, knowledge, acceptance, and practices of GenAI.

27, TITLE: Are Expert-Level Language Models Expert-Level Annotators?
AUTHORS: Yu-Min Tseng ; Wei-Lin Chen ; Chung-Chi Chen ; Hsin-Hsi Chen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we investigate comprehensive approaches across three highly specialized domains and discuss practical suggestions from a cost-effectiveness perspective.

28, TITLE: Towards An Improved Metric for Evaluating Disentangled Representations
AUTHORS: Sahib Julka ; Yashu Wang ; Michael Granitzer
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We propose a new framework for quantifying disentanglement, introducing a metric entitled \emph{EDI}, that leverages the intuitive concept of \emph{exclusivity} and improved factor-code relationship to minimize ad-hoc decisions.

29, TITLE: ToolGen: Unified Tool Retrieval and Calling Via Generation
AUTHORS: RENXI WANG et. al.
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: We introduce ToolGen, a paradigm shift that integrates tool knowledge directly into the LLM's parameters by representing each tool as a unique token.

30, TITLE: Aligning LLMs with Individual Preferences Via Interaction
AUTHORS: SHUJIN WU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.HC]
HIGHLIGHT: As large language models (LLMs) demonstrate increasingly advanced capabilities, aligning their behaviors with human values and preferences becomes crucial for their wide adoption.

31, TITLE: Towards A Benchmark for Large Language Models for Business Process Management Tasks
AUTHORS: Kiran Busch ; Henrik Leopold
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: The analysis aims to identify task-specific performance variations, compare the effectiveness of open-source versus commercial models, and assess the impact of model size on BPM task performance.

32, TITLE: How Much Can We Forget About Data Contamination?
AUTHORS: Sebastian Bordt ; Suraj Srinivas ; Valentyn Boreiko ; Ulrike von Luxburg
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this work, we use experimental evidence and theoretical estimates to challenge the common assumption that small-scale contamination renders benchmark evaluations invalid.

33, TITLE: Geometric Representation Condition Improves Equivariant Molecule Generation
AUTHORS: Zian Li ; Cai Zhou ; Xiyuan Wang ; Xingang Peng ; Muhan Zhang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we introduce GeoRCG, a general framework to enhance the performance of molecular generative models by integrating geometric representation conditions.

34, TITLE: Steering Large Language Models Between Code Execution and Textual Reasoning
AUTHORS: Yongchao Chen ; Harsh Jhamtani ; Srinagesh Sharma ; Chuchu Fan ; Chi Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We also discover that results from LLM written code are not always better than using textual reasoning, even if the task could be solved through code. To mitigate the above issues, we propose three methods to better steer LLM code/text generation and achieve a notable improvement.

35, TITLE: FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech Language Model
AUTHORS: Yichen Lu ; Jiaqi Song ; Chao-Han Huck Yang ; Shinji Watanabe
CATEGORY: eess.AS [eess.AS, cs.AI, cs.CL]
HIGHLIGHT: In this study, we aim to explore Multitask Speech Language Model (SpeechLM) efficient inference via token reduction.

36, TITLE: TICKing All The Boxes: Generated Checklists Improve LLM Evaluation and Generation
AUTHORS: Jonathan Cook ; Tim Rockt�schel ; Jakob Foerster ; Dennis Aumiller ; Alex Wang
CATEGORY: cs.AI [cs.AI, cs.CL, cs.HC, cs.LG]
HIGHLIGHT: In this work, we propose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated, interpretable evaluation protocol that structures evaluations with LLM-generated, instruction-specific checklists.

37, TITLE: On Uncertainty In Natural Language Processing
AUTHORS: Dennis Ulmer
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: On Uncertainty In Natural Language Processing

38, TITLE: RIPPLECOT: Amplifying Ripple Effect of Knowledge Editing in Language Models Via Chain-of-Thought In-Context Learning
AUTHORS: Zihao Zhao ; Yuchen Yang ; Yijiang Li ; Yinzhi Cao
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: As a result of these design limitations, the challenge remains, with the highest accuracy being only 33.8% on the MQuAKE-cf benchmarks for Vicuna-7B. To address this, we propose RippleCOT, a novel ICL editing approach integrating Chain-of-Thought (COT) reasoning.

39, TITLE: A Probabilistic Perspective on Unlearning and Alignment for Large Language Models
AUTHORS: Yan Scholten ; Stephan G�nnemann ; Leo Schwinn
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This is particularly problematic in critical contexts such as unlearning and alignment, where precise model evaluations are crucial. To remedy this, we introduce the first formal probabilistic evaluation framework in LLMs.

40, TITLE: MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction
AUTHORS: Han Jiang ; Junwen Duan ; Zhe Qu ; Jianxin Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we propose a Multi-Aspect Rationale Extractor (MARE) to explain and predict multiple aspects simultaneously.

41, TITLE: Disentangling Textual and Acoustic Features of Neural Speech Representations
AUTHORS: Hosein Mohebbi ; Grzegorz Chrupa?a ; Willem Zuidema ; Afra Alishahi ; Ivan Titov
CATEGORY: cs.CL [cs.CL, cs.LG, cs.SD, eess.AS]
HIGHLIGHT: In this paper, we build upon the Information Bottleneck principle to propose a disentanglement framework that separates complex speech representations into two distinct components: one encoding content (i.e., what can be transcribed as text) and the other encoding acoustic features relevant to a given downstream task.

42, TITLE: How Language Models Prioritize Contextual Grammatical Cues?
AUTHORS: Hamidreza Amirzadeh ; Afra Alishahi ; Hosein Mohebbi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we investigate how language models handle gender agreement when multiple gender cue words are present, each capable of independently disambiguating a target gender pronoun.

43, TITLE: AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML
AUTHORS: Patara Trirat ; Wonyong Jeong ; Sung Ju Hwang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.MA]
HIGHLIGHT: This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment.

44, TITLE: Unraveling Cross-Modality Knowledge Conflict in Large Vision-Language Models
AUTHORS: Tinghui Zhu ; Qin Liu ; Fei Wang ; Zhengzhong Tu ; Muhao Chen
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: However, these models are prone to parametric knowledge conflicts, which arise from inconsistencies of represented knowledge between their vision and language components. In this paper, we formally define the problem of $\textbf{cross-modality parametric knowledge conflict}$ and present a systematic approach to detect, interpret, and mitigate them.

45, TITLE: SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric Groups
AUTHORS: Yongxing Zhang ; Donglin Yang ; Renjie Liao
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV]
HIGHLIGHT: In this paper, we introduce SymmetricDiffusers, a novel discrete diffusion model that simplifies the task of learning a complicated distribution over $S_n$ by decomposing it into learning simpler transitions of the reverse diffusion using deep neural networks.

46, TITLE: Is Your Paper Being Reviewed By An LLM? Investigating AI Text Detectability in Peer Review
AUTHORS: Sungduk Yu ; Man Luo ; Avinash Madasu ; Vasudev Lal ; Phillip Howard
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we investigate the ability of existing AI text detection algorithms to distinguish between peer reviews written by humans and different state-of-the-art LLMs.

47, TITLE: DocKD: Knowledge Distillation from LLMs for Open-World Document Understanding Models
AUTHORS: SUNGNYUN KIM et. al.
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: In response, we present a new framework (called DocKD) that enriches the data generation process by integrating external document knowledge.

48, TITLE: Selective Transformer for Hyperspectral Image Classification
AUTHORS: Yichu Xu ; Di Wang ; Lefei Zhang ; Liangpei Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing Transformer models face two key challenges when dealing with HSI scenes characterized by diverse land cover types and rich spectral information: (1) fixed receptive field representation overlooks effective contextual information; (2) redundant self-attention feature representation. To address these limitations, we propose a novel Selective Transformer (SFormer) for HSI classification.

49, TITLE: Generating Equivalent Representations of Code By A Self-Reflection Approach
AUTHORS: Jia Li ; Ge Li ; Lecheng Wang ; Hao Zhu ; Zhi Jin
CATEGORY: cs.CL [cs.CL, cs.PL, cs.SE]
HIGHLIGHT: In this paper, we propose a self-reflection approach to generating ERs of code.

50, TITLE: Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting
AUTHORS: Marcel Kollovieh ; Marten Lienen ; David L�dke ; Leo Schwinn ; Stephan G�nnemann
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We introduce TSFlow, a conditional flow matching (CFM) model for time series that simplifies the generative problem by combining Gaussian processes, optimal transport paths, and data-dependent prior distributions.

51, TITLE: Showing LLM-Generated Code Selectively Based on Confidence of LLMs
AUTHORS: Jia Li ; Yuqi Zhu ; Yongmin Li ; Ge Li ; Zhi Jin
CATEGORY: cs.SE [cs.SE, cs.CL]
HIGHLIGHT: Showing these erroneous programs to developers will waste developers' energies and introduce security risks to software. To address the above limitations, we propose HonestCoder, a novel LLM-based code generation approach.

52, TITLE: Visual-O1: Understanding Ambiguous Instructions Via Multi-modal Multi-turn Chain-of-thoughts Reasoning
AUTHORS: Minheng Ni ; Yutao Fan ; Lei Zhang ; Wangmeng Zuo
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, even highly intelligent large models exhibit significant performance limitations on ambiguous instructions, where weak reasoning abilities of disambiguation can lead to catastrophic errors. To address this issue, this paper proposes Visual-O1, a multi-modal multi-turn chain-of-thought reasoning framework.

53, TITLE: FactCheckmate: Preemptively Detecting and Mitigating Hallucinations in LMs
AUTHORS: Deema Alnuhait ; Neeraja Kirtane ; Muhammad Khalifa ; Hao Peng
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We introduce FactCheckMate, which preemptively detects hallucinations by learning a classifier that predicts whether the LM will hallucinate, based on the model's hidden states produced over the inputs, before decoding begins.

54, TITLE: An X-Ray Is Worth 15 Features: Sparse Autoencoders for Interpretable Radiology Report Generation
AUTHORS: AHMED ABDULAAL et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We introduce SAE-Rad, which uses sparse autoencoders (SAEs) to decompose latent representations from a pre-trained vision transformer into human-interpretable features.

55, TITLE: Integrating Natural Language Prompting Tasks in Introductory Programming Courses
AUTHORS: CHRIS KERSLAKE et. al.
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module.

56, TITLE: Permissive Information-Flow Analysis for Large Language Models
AUTHORS: SHOAIB AHMED SIDDIQUI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose a novel, more permissive approach to propagate information flow labels through LLM queries.

57, TITLE: GenSim2: Scaling Robot Data Generation with Multi-modal and Reasoning LLMs
AUTHORS: PU HUA et. al.
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: Simulation-trained policies also face scalability issues as many sim-to-real methods focus on a single task. To address these challenges, this work proposes GenSim2, a scalable framework that leverages coding LLMs with multi-modal and reasoning capabilities for complex and realistic simulation task creation, including long-horizon tasks with articulated objects.

58, TITLE: Enhancing Data Quality Through Simple De-duplication: Navigating Responsible Computational Social Science Research
AUTHORS: Yida Mu ; Mali Jin ; Xingyi Song ; Nikolaos Aletras
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we conduct an in-depth examination of 20 datasets extensively used in NLP for CSS to comprehensively examine data quality.

59, TITLE: Geometry Is All You Need: A Unified Taxonomy of Matrix and Tensor Factorization for Compression of Generative Language Models
AUTHORS: Mingxue Xu ; Sadia Sharmin ; Danilo P. Mandic
CATEGORY: cs.CL [cs.CL, cs.LG, cs.NA, math.NA]
HIGHLIGHT: To this end, we propose a unified taxonomy, which bridges the matrix/tensor compression approaches and model compression concepts in ML and NLP research.

60, TITLE: Images Speak Volumes: User-Centric Assessment of Image Generation for Accessible Communication
AUTHORS: Miriam Ansch�tz ; Tringa Sylaj ; Georg Groh
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: However, the images available in online databases are not tailored toward the respective texts, and the creation of customized images is expensive. In this large-scale study, we investigated whether text-to-image generation models can close this gap by providing customizable images quickly and easily.

61, TITLE: Guided Stream of Search: Learning to Better Search with Language Models Via Optimal Path Guidance
AUTHORS: Seungyong Moon ; Bumsoo Park ; Hyun Oh Song
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: In this work, we explore how to leverage optimal solutions to enhance the search and planning abilities of language models.

62, TITLE: Fine-Tuning Language Models with Differential Privacy Through Adaptive Noise Allocation
AUTHORS: Xianzhi Li ; Ran Zmigrod ; Zhiqiang Ma ; Xiaomo Liu ; Xiaodan Zhu
CATEGORY: cs.AI [cs.AI, cs.CL, cs.CR, cs.LG]
HIGHLIGHT: However, this overlooks the distinct sensitivities and contributions of individual parameters in privacy protection and often results in suboptimal models. To address these limitations, we propose ANADP, a novel algorithm that adaptively allocates additive noise based on the importance of model parameters.

63, TITLE: Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models
AUTHORS: XIN ZOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the aforementioned challenge, we follow a common cognitive process - when one's initial memory of critical on-sight details fades, it is intuitive to look at them a second time to seek a factual and accurate answer. Therefore, we introduce Memory-space Visual Retracing (MemVR), a novel hallucination mitigation paradigm that without the need for external knowledge retrieval or additional fine-tuning.

64, TITLE: Dynamic Diffusion Transformer
AUTHORS: WANGBO ZHAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Specifically, we introduce a Timestep-wise Dynamic Width (TDW) approach that adapts model width conditioned on the generation timesteps.

65, TITLE: Table Question Answering for Low-resourced Indic Languages
AUTHORS: Vaishali Pal ; Evangelos Kanoulas ; Andrew Yates ; Maarten de Rijke
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We incorporate our data generation method on two Indic languages, Bengali and Hindi, which have no tableQA datasets or models.

66, TITLE: Can Transformers Learn $n$-gram Language Models?
AUTHORS: Anej Svete ; Nadav Borenstein ; Mike Zhou ; Isabelle Augenstein ; Ryan Cotterell
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Much theoretical work has described the ability of transformers to represent formal languages.

67, TITLE: Entanglement-induced Provable and Robust Quantum Learning Advantages
AUTHORS: Haimeng Zhao ; Dong-Ling Deng
CATEGORY: quant-ph [quant-ph, cs.CC, cs.LG]
HIGHLIGHT: Here, we rigorously establish a noise-robust, unconditional quantum learning advantage in terms of expressivity, inference speed, and training efficiency, compared to commonly-used classical machine learning models.

68, TITLE: On Unsupervised Prompt Learning for Classification with Black-box Language Models
AUTHORS: Zhen-Yu Zhang ; Jiandong Zhang ; Huaxiu Yao ; Gang Niu ; Masashi Sugiyama
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose unsupervised prompt learning for classification with black-box LLMs, where the learning parameters are the prompt itself and the pseudo labels of unlabeled data.

69, TITLE: Zero-Shot Fact Verification Via Natural Logic and Large Language Models
AUTHORS: Marek Strong ; Rami Aly ; Andreas Vlachos
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Despite these advancements, such systems often rely on a large amount of training data annotated with natural logic. To address this issue, we propose a zero-shot method that utilizes the generalization capabilities of instruction-tuned large language models.

70, TITLE: Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs
AUTHORS: Pritom Saha Akash ; Kevin Chen-Chuan Chang
CATEGORY: cs.CL [cs.CL, cs.IR]
HIGHLIGHT: Therefore, existing approaches, whether probabilistic or neural, frequently struggle to extract meaningful patterns from such data, resulting in incoherent topics. To address this challenge, we propose a novel approach that leverages large language models (LLMs) to extend short texts into more detailed sequences before applying topic modeling.

71, TITLE: Audio-Agent: Leveraging LLMs For Audio Generation, Editing and Composition
AUTHORS: Zixuan Wang ; Yu-Wing Tai ; Chi-Keung Tang
CATEGORY: cs.SD [cs.SD, cs.CV, cs.LG, eess.AS]
HIGHLIGHT: We introduce Audio-Agent, a multimodal framework for audio generation, editing and composition based on text or video inputs.

72, TITLE: EBES: Easy Benchmarking for Event Sequences
AUTHORS: Dmitry Osin ; Igor Udovichenko ; Viktor Moskvoretskii ; Egor Shvetsov ; Evgeny Burnaev
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We introduce EBES, a comprehensive benchmarking tool with standardized evaluation scenarios and protocols, focusing on regression and classification problems with sequence-level targets.

73, TITLE: Position: LLM Unlearning Benchmarks Are Weak Measures of Progress
AUTHORS: PRATIKSHA THAKER et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we find that existing benchmarks provide an overly optimistic and potentially misleading view on the effectiveness of candidate unlearning methods.

74, TITLE: GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction
AUTHORS: SHIJIN DUAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Our theoretical analysis indicates that self-correlation generally falls short in accurately representing specific graph features such as islands, symmetrical structures, and directional edges, particularly in smaller or multiple graph contexts. To address these limitations, we introduce a cross-correlation mechanism that significantly enhances the GAE representational capabilities.

75, TITLE: FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator
AUTHORS: Sunny Gupta ; Nikita Jangid ; Amit Sethi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.DC, I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2; I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10]
HIGHLIGHT: While previous research has primarily addressed the issue of skewed label distribution across clients, this study focuses on the less explored challenge of multi-domain FL, where client data originates from distinct domains with varying feature distributions. We introduce a novel method designed to address these challenges FedStein: Enhancing Multi-Domain Federated Learning Through the James-Stein Estimator.

76, TITLE: Generative Artificial Intelligence for Navigating Synthesizable Chemical Space
AUTHORS: Wenhao Gao ; Shitong Luo ; Connor W. Coley
CATEGORY: cs.LG [cs.LG, cs.AI, physics.chem-ph, q-bio.BM]
HIGHLIGHT: We introduce SynFormer, a generative modeling framework designed to efficiently explore and navigate synthesizable chemical space.

77, TITLE: Kiss Up, Kick Down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas
AUTHORS: SEUNGJONG SUN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study is the first to explore whether multi-modal large language models (LLMs) can align their behaviors with visual personas, addressing a significant gap in the literature that predominantly focuses on text-based personas. We developed a novel dataset of 5K fictional avatar images for assignment as visual personas to LLMs, and analyzed their negotiation behaviors based on the visual traits depicted in these images, with a particular focus on aggressiveness.

78, TITLE: Multilingual Topic Classification in X: Dataset and Analysis
AUTHORS: Dimosthenis Antypas ; Asahi Ushio ; Francesco Barbieri ; Jose Camacho-Collados
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce X-Topic, a multilingual dataset featuring content in four distinct languages (English, Spanish, Japanese, and Greek), crafted for the purpose of tweet topic classification.

79, TITLE: Quo Vadis, Motion Generation? From Large Language Models to Large Motion Models
AUTHORS: YE WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Despite some progress, current state-of-the-art works remain far from achieving truly generalist models, largely due to the lack of large-scale, high-quality motion data. To address this, we present MotionBase, the first million-level motion generation benchmark, offering 15 times the data volume of the previous largest dataset, and featuring multimodal data with hierarchically detailed text descriptions.

80, TITLE: SELU: Self-Learning Embodied MLLMs in Unknown Environments
AUTHORS: BOYU LI et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: To fully unleash the self-learning potential of MLLMs, we propose a novel actor-critic self-learning paradigm, dubbed SELU, inspired by the actor-critic paradigm in reinforcement learning.

81, TITLE: Media Framing Through The Lens of Event-Centric Narratives
AUTHORS: Rohan Das ; Aditya Chandra ; I-Ta Lee ; Maria Leonor Pacheco
CATEGORY: cs.CL [cs.CL, cs.SI]
HIGHLIGHT: In this work, we argue that to explain framing devices we have to look at the way narratives are constructed.

82, TITLE: Surgical, Cheap, and Flexible: Mitigating False Refusal in Language Models Via Single Vector Ablation
AUTHORS: Xinpeng Wang ; Chengzhi Hu ; Paul R�ttger ; Barbara Plank
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a simple and surgical method for mitigating false refusal in language models via single vector ablation.

83, TITLE: Autoregressive Action Sequence Learning for Robotic Manipulation
AUTHORS: Xinyu Zhang ; Yuhan Liu ; Haonan Chang ; Liam Schramm ; Abdeslam Boularias
CATEGORY: cs.RO [cs.RO, cs.AI, cs.LG]
HIGHLIGHT: In this work, we design a simple yet effective autoregressive architecture for robotic manipulation tasks.

84, TITLE: Classification-Denoising Networks
AUTHORS: Louis Thiry ; Florentin Guth
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Image classification and denoising suffer from complementary issues of lack of robustness or partially ignoring conditioning information. We argue that they can be alleviated by unifying both tasks through a model of the joint probability of (noisy) images and class labels.

85, TITLE: Safeguard Is A Double-edged Sword: Denial-of-service Attack on Large Language Models
AUTHORS: Qingzhao Zhang ; Ziyang Xiong ; Z. Morley Mao
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Safeguard Is A Double-edged Sword: Denial-of-service Attack on Large Language Models

86, TITLE: In-context Learning in Presence of Spurious Correlations
AUTHORS: Hrayr Harutyunyan ; Rafayel Darbinyan ; Samvel Karapetyan ; Hrant Khachatrian
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Moreover, when the meta-training dataset includes instances of only one task, the conventional approach leads to task memorization and fails to produce a model that leverages context for predictions. Based on these observations, we propose a novel technique to train such a learner for a given classification task.

87, TITLE: Scalable Frame-based Construction of Sociocultural NormBases for Socially-Aware Dialogues
AUTHORS: SHILIN QU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR, cs.LG]
HIGHLIGHT: We propose a scalable approach for constructing a Sociocultural Norm (SCN) Base using Large Language Models (LLMs) for socially aware dialogues.

88, TITLE: Re-examining Sexism and Misogyny Classification with Annotator Attitudes
AUTHORS: Aiqi Jiang ; Nikolas Vitsakis ; Tanvi Dinkar ; Gavin Abercrombie ; Ioannis Konstas
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We revisit two important stages in the moderation pipeline for GBV: (1) manual data labelling; and (2) automated classification.

89, TITLE: Differentiation and Specialization of Attention Heads Via The Refined Local Learning Coefficient
AUTHORS: George Wang ; Jesse Hoogland ; Stan van Wingerden ; Zach Furman ; Daniel Murfet
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We introduce refined variants of the Local Learning Coefficient (LLC), a measure of model complexity grounded in singular learning theory, to study the development of internal structure in transformer language models during training.

90, TITLE: Combing Text-based and Drag-based Editing for Precise and Flexible Image Editing
AUTHORS: Ziqi Jiang ; Zhen Wang ; Long Chen
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we choose the two most common editing approaches (ie text-based editing and drag-based editing) and analyze their drawbacks.

91, TITLE: CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written By LLM-Assisted Crowds
AUTHORS: Min-Hsuan Yeh ; Ruyuan Wan ; Ting-Hao 'Kenneth' Huang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces CoCoLoFa, the largest known logical fallacy dataset, containing 7,706 comments for 648 news articles, with each comment labeled for fallacy presence and type.

92, TITLE: How Hard Is This Test Set? NLI Characterization By Exploiting Training Dynamics
AUTHORS: Adrian Cosma ; Stefan Ruseti ; Mihai Dascalu ; Cornelia Caragea
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Natural Language Inference (NLI) evaluation is crucial for assessing language understanding models; however, popular datasets suffer from systematic spurious correlations that artificially inflate actual model performance. To address this, we propose a method for the automated creation of a challenging test set without relying on the manual construction of artificial and unrealistic examples.

93, TITLE: Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models
AUTHORS: HAIBO WANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: In this paper, we introduce Grounded-VideoLLM, a novel Video-LLM adept at perceiving and reasoning over specific video moments in a fine-grained manner.

94, TITLE: An Explainable Approach to Detect Case Law on Housing and Eviction Issues Within The HUDOC Database
AUTHORS: Mohammad Mohammadi ; Martijn Wieling ; Michel Vols
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this study, we focus on the right to adequate housing and aim to build models to detect cases related to housing and eviction issues.

95, TITLE: A General Framework for Producing Interpretable Semantic Text Embeddings
AUTHORS: Yiqun Sun ; Qiang Huang ; Yixuan Tang ; Anthony K. H. Tung ; Jun Yu
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Recent approaches have improved interpretability by leveraging domain-expert-crafted or LLM-generated questions, but these methods rely heavily on expert input or well-prompt design, which restricts their generalizability and ability to generate discriminative questions across a wide range of tasks. To address these challenges, we introduce \algo{CQG-MBQA} (Contrastive Question Generation - Multi-task Binary Question Answering), a general framework for producing interpretable semantic text embeddings across diverse tasks.

96, TITLE: RSA: Resolving Scale Ambiguities in Monocular Depth Estimators Through Language Descriptions
AUTHORS: ZIYAO ZENG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose a method for metric-scale monocular depth estimation.

97, TITLE: Cogs in A Machine, Doing What They're Meant to Do -- The AMI Submission to The WMT24 General Translation Task
AUTHORS: Atli Jasonarson ; Hinrik Hafsteinsson ; Bjarki �rmannsson ; Stein��r Steingr�msson
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents the submission of the \'Arni Magnusson Institute's team to the WMT24 General translation task.

98, TITLE: Exploring The Benefit of Activation Sparsity in Pre-training
AUTHORS: ZHENGYAN ZHANG et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Our examination reveals that Transformers exhibit sparse activation throughout the majority of the pre-training process while the activation correlation keeps evolving as training progresses. Leveraging this observation, we propose Switchable Sparse-Dense Learning (SSD).

99, TITLE: PRF: Parallel Resonate and Fire Neuron for Long Sequence Learning in Spiking Neural Networks
AUTHORS: YULONG HUANG et. al.
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: In this work, we address the efficiency and performance challenges of long sequence learning in SNNs simultaneously.

100, TITLE: Computational Modeling of Artistic Inspiration: A Framework for Predicting Aesthetic Preferences in Lyrical Lines Using Linguistic and Stylistic Features
AUTHORS: Gaurav Sahu ; Olga Vechtomova
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work proposes a novel framework for computationally modeling artistic preferences in different individuals through key linguistic and stylistic properties, with a focus on lyrical content.

101, TITLE: Influence-oriented Personalized Federated Learning
AUTHORS: Yue Tan ; Guodong Long ; Jing Jiang ; Chengqi Zhang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.DC]
HIGHLIGHT: Hence, their effectiveness in heterogeneous data contexts is limited. To address this problem, we propose an influence-oriented federated learning framework, namely FedC^2I, which quantitatively measures Client-level and Class-level Influence to realize adaptive parameter aggregation for each client.

102, TITLE: One2set + Large Language Model: Best Partners for Keyphrase Generation
AUTHORS: LIANGYING SHAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Given these observations, we introduce a generate-then-select framework decomposing KPG into two steps, where we adopt a one2set-based model as generator to produce candidates and then use an LLM as selector to select keyphrases from these candidates. Particularly, we make two important improvements on our generator and selector: 1) we design an Optimal Transport-based assignment strategy to address the above improper assignments; 2) we model the keyphrase selection as a sequence labeling task to alleviate redundant selections.

103, TITLE: Generative Edge Detection with Stable Diffusion
AUTHORS: CAIXIA ZHOU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Thus motivated, we propose a novel approach, named Generative Edge Detector (GED), by fully utilizing the potential of the pre-trained stable diffusion model.

104, TITLE: F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI
AUTHORS: XU ZHENG et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We propose Fine-tuned Fidelity F-Fidelity, a robust evaluation framework for XAI, which utilizes i) an explanation-agnostic fine-tuning strategy, thus mitigating the information leakage issue and ii) a random masking operation that ensures that the removal step does not generate an OOD input.

105, TITLE: LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences
AUTHORS: Zhenxiao Fu ; Fan Chen ; Shan Zhou ; Haitong Li ; Lei Jiang
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL, cs.CY]
HIGHLIGHT: We introduce \coo, a graph neural network (GNN)-based model that greatly improves the accuracy of LLM inference carbon footprint predictions compared to previous methods.

106, TITLE: AIME: AI System Optimization Via Multiple LLM Evaluators
AUTHORS: BHRIJ PATEL et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: We then theoretically prove that a linear combination of multiple evaluators can approximate this optimal policy. From this insight, we propose AI system optimization via Multiple LLM Evaluators (AIME).

107, TITLE: X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale
AUTHORS: HAORAN XU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we prioritize quality over scaling number of languages, with a focus on multilingual machine translation task, and introduce X-ALMA, a model designed with a commitment to ensuring top-tier performance across 50 diverse languages, regardless of their resource levels.

108, TITLE: Visual Editing with LLM-based Tool Chaining: An Efficient Distillation Approach for Real-Time Applications
AUTHORS: Oren Sultan ; Alex Khasin ; Guy Shiran ; Asnat Greenstein-Messica ; Dafna Shahaf
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present a practical distillation approach to fine-tune LLMs for invoking tools in real-time applications.

109, TITLE: Enhance Reasoning By Learning from Mistakes: Peer-Review Knowledge Distillation from Multiple Large Language Models
AUTHORS: Zhuochun Li ; Yuelyu Ji ; Rui Meng ; Daqing He
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we introduce a novel Mistake-Aware Peer-Review Distillation (MAPD) approach: 1) Instead of merely obtaining gold rationales from teachers, our method asks teachers to identify and explain the student's mistakes, providing customized instruction learning data.

110, TITLE: Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample Optimization
AUTHORS: ZICHEN MIAO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we present an algorithm named pairwise sample optimization (PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled diffusion model.

111, TITLE: Is Safer Better? The Impact of Guardrails on The Argumentative Strength of LLMs in Hate Speech Countering
AUTHORS: HELENA BONALDI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we focus on two aspects of counterspeech generation to produce more cogent responses.

112, TITLE: Asymptotic Inapproximability of Reconfiguration Problems: Maxmin $k$-Cut and Maxmin E$k$-SAT
AUTHORS: Shuichi Hirahara ; Naoto Ohsaka
CATEGORY: cs.CC [cs.CC, cs.DM, cs.DS]
HIGHLIGHT: In this paper, we present the following hardness-of-approximation results and approximation algorithms for Maxmin $k$-Cut Reconfiguration and Maxmin E$k$-SAT Reconfiguration: $\bullet$ For every $k \geq 2$, Maxmin $k$-Cut Reconfiguration is PSPACE-hard to approximate within a factor of $1 - \Omega\left(\frac{1}{k}\right)$, whereas it can be approximated within a factor of $1-\frac{2}{k}$.

113, TITLE: ARB-LLM: Alternating Refined Binarizations for Large Language Models
AUTHORS: ZHITENG LI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: However, current binarization methods struggle to narrow the distribution gap between binarized and full-precision weights, while also overlooking the column deviation in LLM weight distribution. To tackle these issues, we propose ARB-LLM, a novel 1-bit post-training quantization (PTQ) technique tailored for LLMs.

114, TITLE: ECHOPulse: ECG Controlled Echocardio-grams Video Generation
AUTHORS: YIWEI LI et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: However, existing models often face high computational costs, slow inference, and rely on complex conditional prompts that require experts' annotations. To address these challenges, we propose ECHOPULSE, an ECG-conditioned ECHO video generation model.

115, TITLE: How Toxicity Classifiers and Large Language Models Respond to Ableism
AUTHORS: Mahika Phutane ; Ananya Seelam ; Aditya Vashistha
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: While online platforms use machine learning models to moderate online harm, there is little research investigating how these models interact with ableism. In this paper, we curated a dataset of 100 social media comments targeted towards PwD, and recruited 160 participants to rate and explain how toxic and ableist these comments were.

116, TITLE: Streamlining Conformal Information Retrieval Via Score Refinement
AUTHORS: YOTAM INTRATOR et. al.
CATEGORY: cs.IR [cs.IR, cs.AI, cs.LG]
HIGHLIGHT: In this work, we introduce a score refinement method that applies a simple monotone transformation to retrieval scores, leading to significantly smaller conformal sets while maintaining their statistical guarantees.

117, TITLE: MMP: Towards Robust Multi-Modal Learning with Masked Modality Projection
AUTHORS: Niki Nezakati ; Md Kaykobad Reza ; Ameya Patil ; Mashhour Solh ; M. Salman Asif
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this paper, we propose Masked Modality Projection (MMP), a method designed to train a single model that is robust to any missing modality scenario.

118, TITLE: On The Hardness of Learning One Hidden Layer Neural Networks
AUTHORS: Shuchen Li ; Ilias Zadik ; Manolis Zampetakis
CATEGORY: cs.LG [cs.LG, cs.CC, math.ST, stat.ML, stat.TH]
HIGHLIGHT: In this work, we consider the problem of learning one hidden layer ReLU neural networks with inputs from $\mathbb{R}^d$.

119, TITLE: Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need
AUTHORS: XIANLONG WANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: With more 3D point cloud data containing sensitivity information, unauthorized usage of this new type data has also become a serious concern. To address this, we propose the first integral unlearnable framework for 3D point clouds including two processes: (i) we propose an unlearnable data protection scheme, involving a class-wise setting established by a category-adaptive allocation strategy and multi-transformations assigned to samples; (ii) we propose a data restoration scheme that utilizes class-wise inverse matrix transformation, thus enabling authorized-only training for unlearnable data.

120, TITLE: Understanding Decision Subjects' Engagement with and Perceived Fairness of AI Models When Opportunities of Qualification Improvement Exist
AUTHORS: Meric Altug Gemalmaz ; Ming Yin
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: We explore how an AI model's decision fairness affects people's engagement with and perceived fairness of the model if they are subject to its decisions, but could repeatedly and strategically respond to these decisions.

121, TITLE: Investigating and Mitigating Object Hallucinations in Pretrained Vision-Language (CLIP) Models
AUTHORS: Yufang Liu ; Tao Ji ; Changzhi Sun ; Yuanbin Wu ; Aimin Zhou
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: We unveil that even in isolation, the CLIP model is prone to object hallucinations, suggesting that the hallucination problem is not solely due to the interaction between vision and language modalities. To address this, we propose a counterfactual data augmentation method by creating negative samples with a variety of hallucination issues.

122, TITLE: CPFD: Confidence-aware Privileged Feature Distillation for Short Video Classification
AUTHORS: JINGHAO SHI et. al.
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In industrial applications, prioritizing end-to-end multi-modal features, can enhance efficiency but often leads to the loss of valuable information from historical privileged dense features.To integrate both features while maintaining efficiency and manageable resource costs, we present Confidence-aware Privileged Feature Distillation (CPFD), which empowers features of an end-to-end multi-modal model by adaptively distilling privileged features during training.Unlike existing privileged feature distillation (PFD) methods, which apply uniform weights to all instances during distillation, potentially causing unstable performance across different business scenarios and a notable performance gap between teacher model (Dense Feature enhanced multimodal-model DF-X-VLM) and student model (multimodal-model only X-VLM), our CPFD leverages confidence scores derived from the teacher model to adaptively mitigate the performance variance with the student model.We conducted extensive offline experiments on five diverse tasks demonstrating that CPFD improves the video classification F1 score by 6.76% compared with end-to-end multimodal-model (X-VLM) and by 2.31% with vanilla PFD on-average.

123, TITLE: Predicting Perturbation Targets with Causal Differential Networks
AUTHORS: Menghua Wu ; Umesh Padia ; Sean H. Murphy ; Regina Barzilay ; Tommi Jaakkola
CATEGORY: cs.LG [cs.LG, cs.AI, q-bio.QM]
HIGHLIGHT: In this work, we propose a causality-inspired approach for predicting perturbation targets that decouples the two search steps.

124, TITLE: VEDIT: Latent Prediction Architecture For Procedural Video Representation Learning
AUTHORS: HAN LIN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we show that a strong off-the-shelf frozen pretrained visual encoder, along with a well designed prediction model, can achieve state-of-the-art (SoTA) performance in forecasting and procedural planning without the need for pretraining the prediction model, nor requiring additional supervision from language or ASR.

125, TITLE: Understanding Reasoning in Chain-of-Thought from The Hopfieldian View
AUTHORS: LIJIE HU et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: However, existing research primarily focuses on improving performance, lacking a comprehensive framework to explain and understand the fundamental factors behind CoT's success. To bridge this gap, we introduce a novel perspective grounded in the Hopfieldian view of cognition in cognitive neuroscience.

126, TITLE: Killing Two Flies with One Stone: An Attempt to Break LLMs Using English->Icelandic Idioms and Proper Names
AUTHORS: Bjarki �rmannsson ; Hinrik Hafsteinsson ; Atli Jasonarson ; Stein��r Steingr�msson
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents the submission of the \'Arni Magn\'usson Institute's team to the WMT24 test suite subtask, focusing on idiomatic expressions and proper names for the English->Icelandic translation direction.

127, TITLE: Horizon-Length Prediction: Advancing Fill-in-the-Middle Capabilities for Code Generation with Lookahead Planning
AUTHORS: YIFENG DING et. al.
CATEGORY: cs.LG [cs.LG, cs.CL, cs.SE]
HIGHLIGHT: We hypothesize that NTP alone is insufficient for models to learn effective planning conditioned on the distant right context, a critical factor for successful code infilling. To overcome this, we propose Horizon-Length Prediction (HLP), a novel training objective that teaches models to predict the number of remaining middle tokens (i.e., horizon length) at each step.

128, TITLE: Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram Dataset of Over Half A Million Posts for Multilingual Sentiment Analysis
AUTHORS: Nirmalya Thakur
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CY, cs.LG, cs.SI, I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6]
HIGHLIGHT: The work presented in this paper makes three scientific contributions with a specific focus on mining and analysis of COVID-19-related posts on Instagram.

129, TITLE: Autonomous Character-Scene Interaction Synthesis from Text Instruction
AUTHORS: NAN JIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: These requirements pose challenges for current models, leading to a notable gap in automating the animation of characters from simple human inputs. This paper addresses this challenge by introducing a comprehensive framework for synthesizing multi-stage scene-aware interaction motions directly from a single text instruction and goal location.

130, TITLE: Task-unaware Lifelong Robot Learning with Retrieval-based Weighted Local Adaptation
AUTHORS: PENGZHI YANG et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Storing all past data to prevent forgetting is impractical due to storage and privacy concerns. To address this, we propose a method that efficiently restores a robot's proficiency in previously learned tasks over its lifespan.

131, TITLE: Harm Ratio: A Novel and Versatile Fairness Criterion
AUTHORS: Soroush Ebadian ; Rupert Freeman ; Nisarg Shah
CATEGORY: cs.GT [cs.GT, cs.AI]
HIGHLIGHT: In this work, we propose a novel fairness criterion, individual harm ratio, which is inspired by envy-freeness but applies to a broad range of collective decision-making settings.

132, TITLE: SiMilarity-Enhanced Homophily for Multi-View Heterophilous Graph Clustering
AUTHORS: JIANPENG CHEN et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In reality, this assumption does not always hold; a moderately or even mildly homophilous graph is more common than a fully homophilous one due to inevitable heterophilous information in the graph. To address this issue, in this paper, we propose a novel SiMilarity-enhanced Homophily for Multi-view Heterophilous Graph Clustering (SMHGC) approach.

133, TITLE: HRVMamba: High-Resolution Visual State Space Model for Dense Prediction
AUTHORS: HAO ZHANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: By leveraging the multi-resolution parallel design proposed in HRNet, we introduce High-Resolution Visual State Space Model (HRVMamba) based on the DVSS block, which preserves high-resolution representations throughout the entire process while promoting effective multi-scale feature learning.

134, TITLE: MBDS: A Multi-Body Dynamics Simulation Dataset for Graph Networks Simulators
AUTHORS: Sheng Yang ; Fengge Wu ; Junsuo Zhao
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The datasets employed for training and evaluating physical simulation techniques are typically generated by researchers themselves, often resulting in limited data volume and quality.

135, TITLE: Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models
AUTHORS: Yan Chen ; Cheng Liu
CATEGORY: cs.LG [cs.LG, cs.AI, eess.SP]
HIGHLIGHT: Traditional methods, based on small-scale deep learning or physical/statistical models, often struggle with complex, multidimensional sensor data and varying operating conditions, limiting their generalization capabilities. To address these challenges, this paper introduces an innovative regression framework utilizing large language models (LLMs) for RUL prediction.

136, TITLE: ProcBench: Benchmark for Multi-Step Reasoning and Following Procedure
AUTHORS: IPPEI FUJISAWA et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose a benchmark that focuses on a specific aspect of reasoning ability: the direct evaluation of multi-step inference.

137, TITLE: Should Cross-Lingual AMR Parsing Go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing
AUTHORS: Jeongwoo Kang ; Maximin Coavoux ; C�dric Lopez ; Didier Schwab
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We empirically study our method by comparing it to classical joint learning.

138, TITLE: CommonIT: Commonality-Aware Instruction Tuning for Large Language Models Via Data Partitions
AUTHORS: JUN RAO et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Drawing inspiration from the human learning process, where it is generally easier to master solutions to similar topics through focused practice on a single type of topic, we introduce a novel instruction tuning strategy termed CommonIT: Commonality-aware Instruction Tuning.

139, TITLE: RAFT: Realistic Attacks to Fool Text Detectors
AUTHORS: James Wang ; Ran Li ; Junfeng Yang ; Chengzhi Mao
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we present RAFT: a grammar error-free black-box attack against existing LLM detectors.

140, TITLE: Characterizing Context Influence and Hallucination in Summarization
AUTHORS: James Flemings ; Wanrong Zhang ; Bo Jiang ; Zafar Takhirov ; Murali Annavaram
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: To this end, we comprehensively characterize the influence and hallucination of contextual information during summarization.

141, TITLE: Variational Bayes Gaussian Splatting
AUTHORS: Toon Van de Maele ; Ozan Catal ; Alexander Tschantz ; Christopher L. Buckley ; Tim Verbelen
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: The predominant optimization method for these models relies on backpropagating gradients through a differentiable rendering pipeline, which struggles with catastrophic forgetting when dealing with continuous streams of data. To address this limitation, we propose Variational Bayes Gaussian Splatting (VBGS), a novel approach that frames training a Gaussian splat as variational inference over model parameters.

142, TITLE: CLIP-Clique: Graph-based Correspondence Matching Augmented By Vision Language Models for Object-based Global Localization
AUTHORS: Shigemichi Matsuzaki ; Kazuhito Tanaka ; Kazuhiro Shintani
CATEGORY: cs.CV [cs.CV, cs.RO]
HIGHLIGHT: This letter proposes a method of global localization on a map with semantic object landmarks.

143, TITLE: Adaptive Masking Enhances Visual Grounding
AUTHORS: Sen Jia ; Lei Li
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we propose IMAGE, Interpretative MAsking with Gaussian radiation modEling, aimed at enhancing vocabulary grounding in low-shot learning scenarios without necessitating an increase in dataset size.

144, TITLE: The Role of Deductive and Inductive Reasoning in Large Language Models
AUTHORS: CHENGKUN CAI et. al.
CATEGORY: cs.AI [cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose the Deductive and InDuctive(DID) method, which enhances LLM reasoning by dynamically integrating both deductive and inductive reasoning within the prompt construction process.

145, TITLE: Self-supervised Spatio-Temporal Graph Mask-Passing Attention Network for Perceptual Importance Prediction of Multi-point Tactility
AUTHORS: Dazhong He ; Qian Liu
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: In fact, differences in tactile perceptual importance are not limited to conventional frequency and time domains, but also encompass differences in the spatial locations on the skin unique to tactile perception. For the most frequently used tactile information, vibrotactile texture perception, we have developed a model to predict its perceptual importance at multiple points, based on self-supervised learning and Spatio-Temporal Graph Neural Network.

146, TITLE: UNComp: Uncertainty-Aware Long-Context Compressor for Efficient Large Language Model Inference
AUTHORS: JING XIONG et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we propose UNComp, an uncertainty-aware compression scheme that leverages matrix entropy to estimate model uncertainty across layers and heads at the token sequence level.

147, TITLE: Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in Finetuning Pretrained Language Models
AUTHORS: Gunjan Balde ; Soumyadeep Roy ; Mainack Mondal ; Niloy Ganguly
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we show a fundamental limitation in vocabulary adaptation approaches that use Byte-Pair Encoding (BPE) tokenization scheme for fine-tuning pretrained language models (PLMs) to expert domains.

148, TITLE: Structure-Enhanced Protein Instruction Tuning: Towards General-Purpose Protein Understanding
AUTHORS: WEI WU et. al.
CATEGORY: cs.CL [cs.CL, q-bio.BM]
HIGHLIGHT: However, the fine-tuned model is tailored for particular downstream prediction task, and achieving general-purpose protein understanding remains a challenge. In this paper, we introduce Structure-Enhanced Protein Instruction Tuning (SEPIT) framework to bridge this gap.

149, TITLE: Solving The Phase Ordering Problem $\ne$ Generating The Globally Optimal Code
AUTHORS: Yu Wang ; Hongyu Chen ; Ke Wang
CATEGORY: cs.PL [cs.PL]
HIGHLIGHT: The fundamental reason that applying the optimal phase ordering may still result in suboptimal code is the exclusion of programs of less efficiency during the optimization process. Motivated by this insight, we propose a theoretical approach, called \textit{infinitive iterative bi-directional optimizations} (\textit{IIBO}), which is guaranteed to converge to the globally optimal code for any input program.

150, TITLE: CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios
AUTHORS: ZETIAN OUYANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: (ii) Several general-domain LLMs demonstrate substantial potential in medical clinics, while the limited input capacity of many medical LLMs hinders their practical use. These findings reveal both the strengths and limitations of LLMs in clinical scenarios and offer critical insights for medical research.

151, TITLE: Auto-GDA: Automatic Domain Adaptation for Efficient Grounding Verification in Retrieval Augmented Generation
AUTHORS: TOBIAS LEEMANN et. al.
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: Additionally, the lack of labeled instances in the target domain makes supervised domain adaptation, e.g., through fine-tuning, infeasible. To address these challenges, we introduce Automatic Generative Domain Adaptation (Auto-GDA).

152, TITLE: Not All Diffusion Model Activations Have Been Evaluated As Discriminative Features
AUTHORS: Benyuan Meng ; Qianqian Xu ; Zitai Wang ; Xiaochun Cao ; Qingming Huang
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: After careful analysis, we discover three properties universal among diffusion models, enabling this study to go beyond specific models. On top of this, we present effective feature selection solutions for several popular diffusion models.

153, TITLE: LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning
AUTHORS: DI ZHANG et. al.
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: This paper presents an advanced mathematical problem-solving framework, LLaMA-Berry, for enhancing the mathematical reasoning ability of Large Language Models (LLMs).

154, TITLE: Comparing Zero-shot Self-explanations with Human Rationales in Multilingual Text Classification
AUTHORS: Stephanie Brandl ; Oliver Eberle
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Instruction-tuned LLMs are able to provide an explanation about their output to users by generating self-explanations that do not require gradient computations or the application of possibly complex XAI methods. In this paper, we analyse whether this ability results in a good explanation by evaluating self-explanations in the form of input rationales with respect to their plausibility to humans as well as their faithfulness to models.

155, TITLE: SAG: Style-Aligned Article Generation Via Model Collaboration
AUTHORS: Chenning Xu ; Fangxun Shu ; Dian Jin ; Jinghao Wei ; Hao Jiang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a novel collaborative training framework that leverages the strengths of both LLMs and SLMs for style article generation, surpassing the performance of either model alone.

156, TITLE: Deep Image-based Adaptive BRDF Measure
AUTHORS: Wen Cao
CATEGORY: cs.GR [cs.GR, cs.AI]
HIGHLIGHT: This paper presents a novel method for minimizing the number of samples required for high quality BRDF capture using a gonio-reflectometer setup.

157, TITLE: Bridging The Gap Between Text, Audio, Image, and Any Sequence: A Novel Approach Using Gloss-based Annotation
AUTHORS: Sen Fang ; Yalin Feng ; Sizhou Chen ; Xiaofeng Zhang ; Teik Toe Teoh
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper presents an innovative approach called BGTAI to simplify multimodal understanding by utilizing gloss-based annotation as an intermediate step in aligning Text and Audio with Images.

158, TITLE: Generalizable Prompt Tuning for Vision-Language Models
AUTHORS: Qian Zhang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Additionally, prior research has predominantly concentrated on the textual modality, with very few studies attempting to explore the prompt's generalization potential from the visual modality. Keeping these limitations in mind, we investigate how to prompt tuning to obtain both a competitive downstream performance and generalization.

159, TITLE: Intrinsic Evaluation of RAG Systems for Deep-Logic Questions
AUTHORS: Junyi Hu ; You Zhou ; Jie Wang
CATEGORY: cs.AI [cs.AI, I.2.7]
HIGHLIGHT: We introduce the Overall Performance Index (OPI), an intrinsic metric to evaluate retrieval-augmented generation (RAG) mechanisms for applications involving deep-logic queries.

160, TITLE: EmojiHeroVR: A Study on Facial Expression Recognition Under Partial Occlusion from Head-Mounted Displays
AUTHORS: Thorben Ortmann ; Qi Wang ; Larissa Putzar
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, facial expressions are rarely used to recognize users' emotions, as Head-Mounted Displays (HMDs) occlude the upper half of the face. To address this issue, we conducted a study with 37 participants who played our novel affective VR game EmojiHeroVR.

161, TITLE: Analysis and Detection of Differences in Spoken User Behaviors Between Autonomous and Wizard-of-Oz Systems
AUTHORS: Mikey Elmers ; Koji Inoue ; Divesh Lala ; Keiko Ochi ; Tatsuya Kawahara
CATEGORY: cs.CL [cs.CL, cs.HC, cs.RO]
HIGHLIGHT: This study examined users' behavioral differences in a large corpus of Japanese human-robot interactions, comparing interactions between a tele-operated robot and an autonomous dialogue system.

162, TITLE: AirLetters: An Open Video Dataset of Characters Drawn in The Air
AUTHORS: Rishit Dagli ; Guillaume Berger ; Joanna Materzynska ; Ingo Bax ; Roland Memisevic
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We introduce AirLetters, a new video dataset consisting of real-world videos of human-generated, articulated motions.

163, TITLE: Revealing The Unseen: Guiding Personalized Diffusion Models to Expose Training Data
AUTHORS: Xiaoyu Wu ; Jiaru Zhang ; Steven Wu
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: Moreover, concerns regarding copyright violations arise when unauthorized data is used during fine-tuning. In this paper, we ask: "Can training data be extracted from these fine-tuned DMs shared online?"

164, TITLE: DiffKillR: Killing and Recreating Diffeomorphisms for Cell Annotation in Dense Microscopy Images
AUTHORS: CHEN LIU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, accurately annotating densely packed information in these images remains a major challenge. To address this, we introduce DiffKillR, a novel framework that reframes cell annotation as the combination of archetype matching and image registration tasks.

165, TITLE: SPINE: Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments
AUTHORS: Zachary Ravichandran ; Varun Murali ; Mariliza Tzes ; George J. Pappas ; Vijay Kumar
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: However, existing LLM planners typically do not consider online planning or complex missions; rather, relevant subtasks are provided by a pre-built map or a user. We address these limitations via SPINE (online Semantic Planner for missions with Incomplete Natural language specifications in unstructured Environments).

166, TITLE: Semantic Segmentation Based Quality Control of Histopathology Whole Slide Images
AUTHORS: ABHIJEET PATIL et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: We developed a software pipeline for quality control (QC) of histopathology whole slide images (WSIs) that segments various regions, such as blurs of different levels, tissue regions, tissue folds, and pen marks.

167, TITLE: LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding
AUTHORS: DOOHYUK JANG et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: While speculative decoding has proven effective for accelerating LLMs by generating multiple tokens in a single forward, its application in visual AR models remains largely unexplored. In this work, we identify a challenge in this setting, which we term \textit{token selection ambiguity}, wherein visual AR models frequently assign uniformly low probabilities to tokens, hampering the performance of speculative decoding.

168, TITLE: Towards Reproducible LLM Evaluation: Quantifying Uncertainty in LLM Benchmark Scores
AUTHORS: Robert E. Blackwell ; Jon Barry ; Anthony G. Cohn
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We suggest a simple method for cost-effectively quantifying the uncertainty of a benchmark score and make recommendations concerning reproducible LLM evaluation.

169, TITLE: F�rdXel: An Expert System for Danish Traffic Law
AUTHORS: Lu�s Cruz-Filipe ; Jonas Vistrup
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We present f{\ae}rdXel, a tool for symbolic reasoning in the domain of Danish traffic law.

170, TITLE: System 2 Reasoning Capabilities Are Nigh
AUTHORS: Scott C. Lowe
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: In this work, we review the current state of the literature and describe the remaining steps to achieve a neural model which can perform System 2 reasoning analogous to a human.

171, TITLE: Enriching Ontologies with Disjointness Axioms Using Large Language Models
AUTHORS: ELIAS CRUM et. al.
CATEGORY: cs.AI [cs.AI, cs.LO]
HIGHLIGHT: In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms.

172, TITLE: Precision, Stability, and Generalization: A Comprehensive Assessment of RNNs Learnability Capability for Classifying Counter and Dyck Languages
AUTHORS: Neisarg Dave ; Daniel Kifer ; Lee Giles ; Ankur Mali
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Remarkably, even a basic single-layer classifier using RNN embeddings performed better than chance. To evaluate generalization, we trained models on strings up to a length of 40 and tested them on strings from lengths 41 to 500, using 10 unique seeds to ensure statistical robustness.

173, TITLE: Sm: Enhanced Localization in Multiple Instance Learning for Medical Imaging Classification
AUTHORS: Francisco M. Castro-Mac�as ; Pablo Morales-�lvarez ; Yunan Wu ; Rafael Molina ; Aggelos K. Katsaggelos
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: Motivated by a simple observation -- that neighboring instances are likely to have the same label -- we propose a novel, principled, and flexible mechanism to model local dependencies.

174, TITLE: AutoPenBench: Benchmarking Generative Agents for Penetration Testing
AUTHORS: LUCA GIOACCHINI et. al.
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: We present a comprehensive framework that includes 33 tasks, each representing a vulnerable system that the agent has to attack.

175, TITLE: EB-NeRD: A Large-Scale Dataset for News Recommendation
AUTHORS: JOHANNES KRUSE et. al.
CATEGORY: cs.IR [cs.IR, cs.AI, cs.LG]
HIGHLIGHT: However, several domain specific challenges have held back adoption of recommender systems in news publishing. To address these challenges, we introduce the Ekstra Bladet News Recommendation Dataset (EB-NeRD).

176, TITLE: Ward: Provable RAG Dataset Inference Via LLM Watermarks
AUTHORS: Nikola Jovanovi? ; Robin Staab ; Maximilian Baader ; Martin Vechev
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: Despite its importance, the challenge of detecting such unauthorized usage remains underexplored, with existing datasets and methodologies from adjacent fields being ill-suited for its study. In this work, we take several steps to bridge this gap.

177, TITLE: Machine Learning for Asymptomatic Ratoon Stunting Disease Detection With Freely Available Satellite Based Multispectral Imaging
AUTHORS: Ethan Kane Waters ; Carla Chia-ming Chen ; Mostafa Rahimi Azghadi
CATEGORY: cs.LG [cs.LG, cs.CV, eess.IV, I.4; I.2]
HIGHLIGHT: This study employed various machine learning techniques to detect the presence of RSD in different sugarcane varieties, using vegetation indices derived from freely available satellite-based spectral data.

178, TITLE: Autoregressive Moving-average Attention Mechanism for Time Series Forecasting
AUTHORS: Jiecheng Lu ; Xu Han ; Yan Sun ; Shihao Yang
CATEGORY: cs.LG [cs.LG, cs.AI, stat.ML]
HIGHLIGHT: We propose an Autoregressive (AR) Moving-average (MA) attention structure that can adapt to various linear attention mechanisms, enhancing their ability to capture long-range and local temporal patterns in time series.

179, TITLE: Lost in Tracking: Uncertainty-guided Cardiac Cine MRI Segmentation at Right Ventricle Base
AUTHORS: Yidong Zhao ; Yi Zhang ; Orlando Simonetti ; Yuchi Han ; Qian Tao
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: In this work, we propose to address the currently unsolved issues in CMR segmentation, specifically at the RV base, with two strategies: first, we complemented the public resource by reannotating the RV base in the ACDC dataset, with refined delineation of the right ventricle outflow tract (RVOT), under the guidance of an expert cardiologist.

180, TITLE: AiBAT: Artificial Intelligence/Instructions for Build, Assembly, and Test
AUTHORS: BENJAMIN NUERNBERGER et. al.
CATEGORY: cs.AI [cs.AI, cs.AR, cs.ET, cs.HC]
HIGHLIGHT: This paper presents an overview of the AiBAT system, including promising preliminary results and discussion on future work.

181, TITLE: Beyond Film Subtitles: Is YouTube The Best Approximation of Spoken Vocabulary?
AUTHORS: ADAM NOHEJL et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We demonstrate that frequencies extracted from carefully processed YouTube subtitles provide an approximation comparable to, and often better than, the best currently available resources.

182, TITLE: Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments
AUTHORS: Omar Sharif ; Joseph Gatto ; Madhusudan Basak ; Sarah M. Preum
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Prior works formulate the extraction of event-specific arguments as a span extraction problem, where event arguments are explicit -- i.e. assumed to be contiguous spans of text in a document. In this study, we revisit this definition of Event Extraction (EE) by introducing two key argument types that cannot be modeled by existing EE frameworks.

183, TITLE: Generating Bilingual Example Sentences with Large Language Models As Lexicography Assistants
AUTHORS: Raphael Merx ; Ekaterina Vylomova ; Kemal Kurniawan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We present a study of LLMs' performance in generating and rating example sentences for bilingual dictionaries across languages with varying resource levels: French (high-resource), Indonesian (mid-resource), and Tetun (low-resource), with English as the target language.

184, TITLE: Parallel Corpus Augmentation Using Masked Language Models
AUTHORS: Vibhuti Kumari ; Narayana Murthy Kavi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper we propose a novel method of augmenting parallel text corpora which promises good quality and is also capable of producing many fold larger corpora than the seed corpus we start with.

185, TITLE: Cross-lingual Transfer for Automatic Question Generation By Learning Interrogative Structures in Target Languages
AUTHORS: Seonjeong Hwang ; Yunsu Kim ; Gary Geunbae Lee
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a simple and efficient XLT-QG method that operates without the need for monolingual, parallel, or labeled data in the target language, utilizing a small language model.

186, TITLE: PersoBench: Benchmarking Personalized Response Generation in Large Language Models
AUTHORS: Saleh Afzoon ; Usman Naseem ; Amin Beheshti ; Zahra Jamali
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Although recent benchmarks automatically evaluate persona consistency in role-playing contexts using LLM-based judgment, the evaluation of personalization in response generation remains underexplored. To address this gap, we present a new benchmark, PersoBench, to evaluate the personalization ability of LLMs in persona-aware dialogue generation within a zero-shot setting.

187, TITLE: Unlocking Structured Thinking in Language Models with Cognitive Prompting
AUTHORS: Oliver Kramer ; Jill Baumann
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose cognitive prompting as a novel approach to guide problem-solving in large language models (LLMs) through structured, human-like cognitive operations such as goal clarification, decomposition, filtering, abstraction, and pattern recognition.

188, TITLE: Coal Mining Question Answering with LLMs
AUTHORS: Antonio Carlos Rivera ; Anthony Moore ; Steven Robinson
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we present a novel approach to coal mining question answering (QA) using large language models (LLMs) combined with tailored prompt engineering techniques.

189, TITLE: Context and System Fusion in Post-ASR Emotion Recognition with Large Language Models
AUTHORS: Pavel Stepachev ; Pinzhen Chen ; Barry Haddow
CATEGORY: cs.CL [cs.CL, eess.AS]
HIGHLIGHT: Large language models (LLMs) have started to play a vital role in modelling speech and text.

190, TITLE: Exploring Learnability in Memory-Augmented Recurrent Neural Networks: Precision, Stability, and Empirical Insights
AUTHORS: Shrabon Das ; Ankur Mali
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This study explores the learnability of memory-less and memory-augmented RNNs, which are theoretically equivalent to Pushdown Automata.

191, TITLE: Towards Linguistically-Aware and Language-Independent Tokenization for Large Language Models (LLMs)
AUTHORS: Abrar Rahman ; Garry Bowlin ; Binit Mohanty ; Sean McGunigal
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper presents a comprehensive study on the tokenization techniques employed by state-of-the-art large language models (LLMs) and their implications on the cost and availability of services across different languages, especially low resource languages.

192, TITLE: Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification
AUTHORS: Sudipta Singha Roy ; Xindi Wang ; Robert E. Mercer ; Frank Rudzicz
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Existing methods often struggle with token limits and fail to adequately model hierarchical relationships within documents. To address these constraints, we propose a novel model leveraging a graph-tree structure.

193, TITLE: Learning Semantic Structure Through First-Order-Logic Translation
AUTHORS: Akshay Chaturvedi ; Nicholas Asher
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we study whether transformer-based language models can extract predicate argument structure from simple sentences.

194, TITLE: Team MTS @ AutoMin 2021: An Overview of Existing Summarization Approaches and Comparison to Unsupervised Summarization Techniques
AUTHORS: Olga Iakovenko ; Anna Andreeva ; Anna Lapidus ; Liana Mikaelyan
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In particular, in this paper we analyze existing approaches to text and speech summarization, propose an unsupervised summarization technique based on clustering and provide a pipeline that includes an adapted automatic speech recognition block able to run on real-life recordings.

195, TITLE: NLIP_Lab-IITH Low-Resource MT System for WMT24 Indic MT Shared Task
AUTHORS: Pramit Sahoo ; Maharaj Brahma ; Maunendra Sankar Desarkar
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we describe our system for the WMT 24 shared task of Low-Resource Indic Language Translation.

196, TITLE: Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges
AUTHORS: Nguyen Van Dinh ; Thanh Chi Dang ; Luan Thanh Nguyen ; Kiet Van Nguyen
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Despite the existence of various speech recognition datasets, none of them has provided a fine-grained classification of the 63 dialects specific to individual provinces of Vietnam. To address this gap, we introduce Vietnamese Multi-Dialect (ViMD) dataset, a novel comprehensive dataset capturing the rich diversity of 63 provincial dialects spoken across Vietnam.

197, TITLE: Consultation on Industrial Machine Faults with Large Language Models
AUTHORS: Apiradee Boonmee ; Kritsada Wongsuwan ; Pimchanok Sukjai
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces a novel approach leveraging Large Language Models (LLMs), specifically through a structured multi-round prompting technique, to improve fault diagnosis accuracy.

198, TITLE: A Multi-task Learning Framework for Evaluating Machine Translation of Emotion-loaded User-generated Content
AUTHORS: Shenbin Qian ; Constantin Or?san ; Diptesh Kanojia ; F�lix do Carmo
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We extend it with sentence-level evaluation scores and word-level labels, leading to a dataset suitable for sentence- and word-level translation evaluation and emotion classification, in a multi-task setting. We propose a new architecture to perform these tasks concurrently, with a novel combined loss function, which integrates different loss heuristics, like the Nash and Aligned losses.

199, TITLE: CoCoHD: Congress Committee Hearing Dataset
AUTHORS: Arnav Hiray ; Yunsong Liu ; Mingxiao Song ; Agam Shah ; Sudheer Chava
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Despite their importance, there is a lack of comprehensive datasets for analyzing these discourses. To address this, we propose the Congress Committee Hearing Dataset (CoCoHD), covering hearings from 1997 to 2024 across 86 committees, with 32,697 records.

200, TITLE: What Do Large Language Models Need for Machine Translation Evaluation?
AUTHORS: SHENBIN QIAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we explore what translation information, such as the source, reference, translation errors and annotation guidelines, is needed for LLMs to evaluate MT quality.

201, TITLE: Group Fairness in Peer Review
AUTHORS: Haris Aziz ; Evi Micha ; Nisarg Shah
CATEGORY: cs.GT [cs.GT, cs.AI, cs.SI, physics.soc-ph]
HIGHLIGHT: We tackle this challenge by introducing a notion of group fairness, called the core, which requires that every possible community (subset of researchers) to be treated in a way that prevents them from unilaterally benefiting by withdrawing from a large conference. We study a simple peer review model, prove that it always admits a reviewing assignment in the core, and design an efficient algorithm to find one such assignment.

202, TITLE: Fully Automated CTC Detection, Segmentation and Classification for Multi-Channel IF Imaging
AUTHORS: EVAN SCHWAB et. al.
CATEGORY: cs.CV [cs.CV, q-bio.QM]
HIGHLIGHT: To assist clinicians, we have developed a fully automated machine learning-based production-level pipeline to efficiently detect, segment and classify CTCs in multi-channel IF images.

203, TITLE: Looking Into Concept Explanation Methods for Diabetic Retinopathy Classification
AUTHORS: Andrea M. Stor�s ; Josefine V. Sundgaard
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: This work investigates and compares two concept-based explanation techniques for explaining deep neural networks developed for automatic diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation Vectors and Concept Bottleneck Models.

204, TITLE: Action Selection Learning for Multi-label Multi-view Action Recognition
AUTHORS: Trung Thanh Nguyen ; Yasutomo Kawanishi ; Takahiro Komamizu ; Ichiro Ide
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We propose the method named MultiASL (Multi-view Action Selection Learning), which leverages action selection learning to enhance view fusion by selecting the most useful information from different viewpoints.

205, TITLE: Lightning UQ Box: A Comprehensive Framework for Uncertainty Quantification in Deep Learning
AUTHORS: NILS LEHMANN et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this paper, we provide a theoretical and quantitative comparison of the wide range of state-of-the-art UQ methods implemented in our toolbox.

206, TITLE: Task-Decoupled Image Inpainting Framework for Class-specific Object Remover
AUTHORS: Changsuk Oh ; H. Jin Kim
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, image inpainting networks often generate unsatisfactory removal results. In this work, we find that the current training approach which encourages a single image inpainting model to handle both object removal and restoration tasks is one of the reasons behind such unsatisfactory result.

207, TITLE: Does SpatioTemporal Information Benefit Two Video Summarization Benchmarks?
AUTHORS: Aashutosh Ganesh ; Mirela Popa ; Daan Odijk ; Nava Tintarev
CATEGORY: cs.CV [cs.CV, cs.MM]
HIGHLIGHT: In this paper we inquire if similar spurious relationships might influence the task of video summarization.

208, TITLE: Dessie: Disentanglement for Articulated 3D Horse Shape and Pose Estimation from Images
AUTHORS: CI LI et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: While progress has been made for humans, it's more challenging for animals due to limited annotated data. To address this, we introduce the first method using synthetic data generation and disentanglement to learn to regress 3D shape and pose.

209, TITLE: CLoSD: Closing The Loop Between Simulation and Diffusion for Multi-task Character Control
AUTHORS: GUY TEVET et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this work, we present a method that combines their respective strengths.

210, TITLE: Mamba in Vision: A Comprehensive Survey of Techniques and Applications
AUTHORS: MD MAKLACHUR RAHMAN et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In contrast, ViTs effectively model global relationships but suffer from high computational costs due to the quadratic complexity of their self-attention mechanisms. Mamba addresses these limitations by leveraging Selective Structured State Space Models to effectively capture long-range dependencies with linear computational complexity.

211, TITLE: A Multimodal Framework for Deepfake Detection
AUTHORS: KASHISH GANDHI et. al.
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG, cs.LO]
HIGHLIGHT: Using our proposed models for video and audio classification i.e. Artificial Neural Network and VGG19, the overall sample is classified as deepfake if either component is identified as such.

212, TITLE: PixelShuffler: A Simple Image Translation Through Pixel Rearrangement
AUTHORS: Omar Zamzam
CATEGORY: cs.CV [cs.CV, eess.IV]
HIGHLIGHT: In this paper, we propose a novel pixel shuffle method that addresses the image-to-image translation problem generally with a specific demonstrative application in style transfer.

213, TITLE: Dynamic Sparse Training Versus Dense Training: The Unexpected Winner in Image Corruption Robustness
AUTHORS: BOQIAN WU et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: At the same time, Dense Training is widely accepted as being the "de facto" approach to train artificial neural networks if one would like to maximize their robustness against image corruption. In this paper, we question this general practice.

214, TITLE: Strategic Insights from Simulation Gaming of AI Race Dynamics
AUTHORS: Ross Gruetzemacher ; Shahar Avin ; James Fox ; Alexander K Saeri
CATEGORY: cs.CY [cs.CY, cs.AI]
HIGHLIGHT: We present insights from "Intelligence Rising", a scenario exploration exercise about possible AI futures.

215, TITLE: Label-Free Subjective Player Experience Modelling Via Let's Play Videos
AUTHORS: Dave Goel ; Athar Mahmoudi-Nejad ; Matthew Guzdial
CATEGORY: cs.HC [cs.HC, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose a novel PEM development approach, approximating player experience from gameplay video.

216, TITLE: Cognitive Biases in Large Language Models for News Recommendation
AUTHORS: Yougang Lyu ; Xiaoyu Zhang ; Zhaochun Ren ; Maarten de Rijke
CATEGORY: cs.IR [cs.IR, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we explore the potential impact of multiple cognitive biases on LLM-based news recommender systems, including anchoring bias, framing bias, status quo bias and group attribution bias.

217, TITLE: EXAQ: Exponent Aware Quantization For LLMs Acceleration
AUTHORS: MORAN SHKOLNIK et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.PF]
HIGHLIGHT: We propose an analytical approach to determine the optimal clipping value for the input to the softmax function, enabling sub-4-bit quantization for LLMs inference.

218, TITLE: Enhanced Transformer Architecture for In-context Learning of Dynamical Systems
AUTHORS: Matteo Rufolo ; Dario Piga ; Gabriele Maroni ; Marco Forgione
CATEGORY: cs.LG [cs.LG, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: In this paper, we enhance the original meta-modeling framework through three key innovations: by formulating the learning task within a probabilistic framework; by managing non-contiguous context and query windows; and by adopting recurrent patching to effectively handle long context sequences.

219, TITLE: Mitigating Adversarial Perturbations for Deep Reinforcement Learning Via Vector Quantization
AUTHORS: Tung M. Luu ; Thanh Nguyen ; Tee Joshua Tian Jin ; Sungwoon Kim ; Chang D. Yoo
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we instead study an input transformation-based defense for RL.

220, TITLE: Make Interval Bound Propagation Great Again
AUTHORS: Patryk Krukowski ; Daniel Wilczak ; Jacek Tabor ; Anna Bielawska ; Przemys?aw Spurek
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We adapt two classical approaches dedicated to strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate the wrapping effect in neural networks.

221, TITLE: No Need to Talk: Asynchronous Mixture of Language Models
AUTHORS: Anastasiia Filippova ; Angelos Katharopoulos ; David Grangier ; Ronan Collobert
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: We introduce SmallTalk LM, an innovative method for training a mixture of language models in an almost asynchronous manner.

222, TITLE: MELODI: Exploring Memory Compression for Long Contexts
AUTHORS: YINPENG CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: We present MELODI, a novel memory architecture designed to efficiently process long documents using short context windows.

223, TITLE: Mathematical Formalism for Memory Compression in Selective State Space Models
AUTHORS: Siddhanth Bhat
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CC]
HIGHLIGHT: In this paper, we develop a rigorous mathematical framework for understanding memory compression in selective state space models.

224, TITLE: Training on More Reachable Tasks for Generalisation in Reinforcement Learning
AUTHORS: Max Weltevrede ; Caroline Horsch ; Matthijs T. J. Spaan ; Wendelin B�hmer
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we introduce the concept of reachability in multi-task reinforcement learning and show that an initial exploration phase increases the number of reachable tasks the agent is trained on.

225, TITLE: Cayley Graph Propagation
AUTHORS: JJ Wilson ; Maya Bechler-Speicher ; Petar Veli?kovi?
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this work, we show that truncation is detrimental to the coveted expansion properties.

226, TITLE: Vulnerability Detection Via Topological Analysis of Attention Maps
AUTHORS: Pavel Snopov ; Andrey Nikolaevich Golubinskiy
CATEGORY: cs.LG [cs.LG, cs.AI, math.AT]
HIGHLIGHT: In this study, we explore a novel approach to vulnerability detection utilizing the tools from topological data analysis (TDA) on the attention matrices of the BERT model.

227, TITLE: Test-time Adaptation for Regression By Subspace Alignment
AUTHORS: Kazuki Adachi ; Shin'ya Yamaguchi ; Atsutoshi Kumagai ; Tomoki Hamagami
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: For an effective feature alignment in TTA for regression, we propose Significant-subspace Alignment (SSA).

228, TITLE: A System for Critical Facility and Resource Optimization in Disaster Management and Planning
AUTHORS: EMMANUEL TUNG et. al.
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: This study proposes optimization models for patient reallocation and the strategic placement of temporary medical facilities to bolster the resilience of the critical care system, with a focus on equitable outcomes.

229, TITLE: Comparative Study of Regression Vs Pairwise Models for Surrogate-based Heuristic Optimisation
AUTHORS: Pablo S. Naharro ; Pablo Toharia ; Antonio LaTorre ; Jos�-Mar�a Pe�a
CATEGORY: cs.NE [cs.NE, cs.AI]
HIGHLIGHT: The pairwise approach can be directly exploited by some algorithms, such as Differential Evolution, in which the fitness value is not actually needed to drive the search, and it is sufficient to know whether a solution is better than another one or not. Based on these modelling approaches, we have conducted a multidimensional analysis of surrogate models under different configurations: different machine learning algorithms (regularised regression, neural networks, decision trees, boosting methods, and random forests), different surrogate strategies (encouraging diversity or relaxing prediction thresholds), and compare them for both surface and pairwise surrogate models.

230, TITLE: Multi-Robot Motion Planning with Diffusion Models
AUTHORS: Yorai Shaoul ; Itamar Mishani ; Shivam Vats ; Jiaoyang Li ; Maxim Likhachev
CATEGORY: cs.RO [cs.RO, cs.AI, cs.MA]
HIGHLIGHT: In this paper, we propose a method for generating collision-free multi-robot trajectories that conform to underlying data distributions while using only single-robot data.

231, TITLE: Enhancing Autonomous Navigation By Imaging Hidden Objects Using Single-Photon LiDAR
AUTHORS: AARON YOUNG et. al.
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We present a novel approach that leverages Non-Line-of-Sight (NLOS) sensing using single-photon LiDAR to improve visibility and enhance autonomous navigation.

232, TITLE: Real-World Cooking Robot System from Recipes Based on Food State Recognition Using Foundation Models and PDDL
AUTHORS: Naoaki Kanazawa ; Kento Kawaharazuka ; Yoshiki Obinata ; Kei Okada ; Masayuki Inaba
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this study, we propose a robot system that integrates real-world executable robot cooking behaviour planning using the Large Language Model (LLM) and classical planning of PDDL descriptions, and food ingredient state recognition learning from a small number of data using the Vision-Language model (VLM).

233, TITLE: Latent Action Priors From A Single Gait Cycle Demonstration for Online Imitation Learning
AUTHORS: Oliver Hausd�rfer ; Alexander von Rohr ; �ric Lefort ; Angela Schoellig
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: We propose an additional inductive bias for robot learning: latent actions learned from expert demonstration as priors in the action space.

234, TITLE: A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle Development
AUTHORS: Jesper Knapp ; Klas Moberg ; Yuchuan Jin ; Simin Sun ; Miroslaw Staron
CATEGORY: cs.SE [cs.SE, cs.AI]
HIGHLIGHT: This paper presents and evaluates a pipeline that allows searching for specific scenarios in log collections using natural language descriptions instead of SQL.

235, TITLE: SoundSignature: What Type of Music Do You Like?
AUTHORS: Brandon James Carone ; Pablo Ripoll�s
CATEGORY: cs.SD [cs.SD, cs.AI, cs.IR, eess.AS]
HIGHLIGHT: . In this paper, we highlight the application's innovative features and educational potential, and present findings from a pilot user study that evaluates its efficacy and usability.

236, TITLE: Individuation of 3D Perceptual Units from Neurogeometry of Binocular Cells
AUTHORS: Maria Virginia Bolelli ; Giovanna Citti ; Alessandro Sarti ; Steven W. Zucker
CATEGORY: q-bio.NC [q-bio.NC, cs.CV, math.DG]
HIGHLIGHT: A new framework for correspondence is introduced that integrates a neural-based algorithm to achieve stereo correspondence locally while, simultaneously, organizing the corresponding points into global perceptual units.

237, TITLE: MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech
AUTHORS: Taejun Bak ; Youngsik Eom ; SeungJae Choi ; Young-Sun Joo
CATEGORY: eess.AS [eess.AS, cs.AI, cs.SD]
HIGHLIGHT: However, these systems have certain limitations: they require a large amount of training data, which increases costs, and often overlook prosody similarity. To address these issues, we propose MultiVerse, a zero-shot multi-task TTS system that is able to perform TTS or speech style transfer in zero-shot and cross-lingual conditions.

238, TITLE: Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope
AUTHORS: Yasaman Torabi ; Shahram Shirani ; James P. Reilly
CATEGORY: eess.AS [eess.AS, cs.AI, cs.LG, eess.SP]
HIGHLIGHT: Recent improvements in stethoscope technology have made it possible to capture patient sounds with enhanced precision. In this dataset, we used a digital stethoscope to capture both heart and lung sounds, including individual and mixed recordings.

239, TITLE: HyperCMR: Enhanced Multi-Contrast CMR Reconstruction with Eagle Loss
AUTHORS: Ruru Xu ; Caner �zer ; Ilkay Oksuz
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This paper presents HyperCMR, a novel framework designed to accelerate the reconstruction of multi-contrast cardiac magnetic resonance (CMR) images.

240, TITLE: An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging
AUTHORS: BILL CASSIDY et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: This paper presents an improved HarDNet segmentation architecture which integrates a contrast-eliminating component in the initial layers of the network to enhance feature learning.

241, TITLE: GABIC: Graph-based Attention Block for Image Compression
AUTHORS: GABRIELE SPADARO et. al.
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: This work proposes a Graph-based Attention Block for Image Compression (GABIC), a method to reduce feature redundancy based on a k-Nearest Neighbors enhanced attention mechanism.

242, TITLE: 3D Segmentation of Neuronal Nuclei and Cell-Type Identification Using Multi-channel Information
AUTHORS: Antonio LaTorre ; Lidia Alonso-Nanclares ; Jos� Mar�a Pe�a ; Javier De Felipe
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: New method We present a method to improve the 3D reconstruction of neuronal nuclei that allows their segmentation, excluding the nuclei of non-neuronal cell types.

243, TITLE: Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery
AUTHORS: KARL-PHILIPPE BEAUDET et. al.
CATEGORY: eess.IV [eess.IV, cs.AI, cs.CV]
HIGHLIGHT: We propose a patient-specific approach using preoperative 3D ultrasound liver volume to train a deep learning model for real-time identification of portal tree and branch structures.
