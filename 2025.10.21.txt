1, TITLE: Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation
AUTHORS: Collin Zhang; Fei Huang; Chenhan Yuan; Junyang Lin
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Abstract: Large language models (LLMs) often experience language confusion, which isthe unintended mixing of languages during text generation. Current solutions tothis problem either ...

2, TITLE: A Comparative User Evaluation of XRL Explanations Using Goal Identification
AUTHORS: Mark Towers; Yali Du; Christopher Freeman; Timothy J. Norman
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Debugging is a core application of explainable reinforcement learning (XRL)algorithms; however, limited comparative evaluations have been conducted tounderstand their relative performance. We propose a novel evaluationmethodology to test whether users can identify an agent's goal from anexplanation of its decision-making.

3, TITLE: SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents
AUTHORS: Qiusi Zhan; Angeline Budiman-Chan; Abdelrahman Zayed; Xingzhi Guo; Daniel Kang; Joo-Kyung Kim
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present SafeSearch, a multi-objective reinforcementlearning approach that couples a final-output safety/utility reward with anovel query-level shaping term that penalizes unsafe queries and rewards safeones.

4, TITLE: FineVision: Open Data Is All You Need
AUTHORS: Luis Wiedmann; Orr Zohar; Amir Mahla; Xiaohan Wang; Rui Li; Thibaud Frere; Leandro von Werra; Aritra Roy Gosthipaty; Andrés Marafioti
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: The advancement of vision-language models (VLMs) is hampered by a fragmentedlandscape of inconsistent and contaminated public datasets. We introduceFineVision, a meticulously ...

5, TITLE: A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting
AUTHORS: Cristian J. Vaca-Rubio; Roberto Pereira; Luis Blanco; Engin Zeydan; Màrius Caus
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This work introduces Probabilistic Kolmogorov-Arnold Network (P-KAN), a novelprobabilistic extension of Kolmogorov-Arnold Networks (KANs) for time seriesforecasting.

6, TITLE: RL Makes MLLMs See Better Than SFT
AUTHORS: Junha Song; Sangdoo Yun; Dongyoon Han; Jaegul Choo; Byeongho Heo
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address this, we first investigate the impact oftraining strategies on MLLMs, where RL shows a clear advantage over SFT instrongly vision-related VQA benchmarks. Motivated by this, we conduct acritical yet under-explored analysis of the vision encoder of MLLMs throughdiverse and in-depth experiments, ranging from ImageNet classification andsegmentation to gradient visualization.

7, TITLE: UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action
AUTHORS: Yuhao Yang; Zhen Yang; Zi-Yi Dou; Anh Nguyen; Keen You; Omar Attia; Andrew Szot; Michael Feng; Ram Ramrakhya; Alexander Toshev; Chao Huang; Yinfei Yang; Zhe Gan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Multimodal agents for computer use rely exclusively on primitive actions(click, type, scroll) that require accurate visual grounding and lengthyexecution chains, leading to ...

8, TITLE: Enrich and Detect: Video Temporal Grounding with Multimodal LLMs
AUTHORS: Shraman Pramanick; Effrosyni Mavroudi; Yale Song; Rama Chellappa; Lorenzo Torresani; Triantafyllos Afouras
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce ED-VTG, a method for fine-grained video temporal groundingutilizing multi-modal large language models.

9, TITLE: SimBench: Benchmarking The Ability of Large Language Models to Simulate Human Behaviors
AUTHORS: Tiancheng Hu; Joachim Baumann; Lorenzo Lupo; Nigel Collier; Dirk Hovy; Paul Röttger
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: By making progress measurable, we aim toaccelerate the development of more faithful LLM simulators.

10, TITLE: QueST: Incentivizing LLMs to Generate Difficult Problems
AUTHORS: Hanxu Hu; Xingxing Zhang; Jannis Vamvas; Rico Sennrich; Furu Wei
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose QueST,a novel framework which combines difficulty-aware graph sampling anddifficulty-aware rejection fine-tuning that directly optimizes specializedgenerators to create challenging coding problems.

11, TITLE: The Ends Justify The Thoughts: RL-Induced Motivated Reasoning in LLMs
AUTHORS: Nikolaus Howe; Micah Carroll
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: WARNING: someexamples in this paper may be upsetting.

12, TITLE: SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes
AUTHORS: Xiongkun Linghu; Jiangyong Huang; Ziyu Zhu; Baoxiong Jia; Siyuan Huang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paperbridges the gap by presenting a novel framework.

13, TITLE: Instant Personalized Large Language Model Adaptation Via Hypernetwork
AUTHORS: Zhaoxuan Tan; Zixuan Zhang; Haoyang Wen; Zheng Li; Rongzhi Zhang; Pei Chen; Fengran Mo; Zheyuan Liu; Qingkai Zeng; Qingyu Yin; Meng Jiang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce Profile-to-PEFT, a scalable framework that employs ahypernetwork, trained end-to-end, to map a user's encoded profile directly to afull set of adapter parameters (e.g., LoRA), eliminating per-user training atdeployment.

14, TITLE: Prompt-MII: Meta-Learning Instruction Induction for LLMs
AUTHORS: Emily Xiao; Yixiao Zeng; Ada Chen; Chin-Jou Li; Amanda Bertsch; Graham Neubig
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: A popular method to adapt large language models (LLMs) to new tasks isin-context learning (ICL), which is effective but incurs high inference costsas context length grows. In this paper we propose a method to performinstruction induction, where we take training examples and reduce them to acompact but descriptive prompt that can achieve performance comparable to ICLover the full training set.

15, TITLE: Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics
AUTHORS: Akshara Prabhakar; Roshan Ram; Zixiang Chen; Silvio Savarese; Frank Wang; Caiming Xiong; Huan Wang; Weiran Yao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present EnterpriseDeep Research (EDR), a multi-agent system that integrates (1) a Master PlanningAgent for adaptive query decomposition, (2) four specialized search agents(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based toolecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) aVisualization Agent for data-driven insights, and (5) a reflection mechanismthat detects knowledge gaps and updates research direction with optionalhuman-in-the-loop steering guidance.

16, TITLE: From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models
AUTHORS: Zefan Cai; Haoyi Qiu; Haozhe Zhao; Ke Wan; Jiachen Li; Jiuxiang Gu; Wen Xiao; Nanyun Peng; Junjie Hu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: While these methods improve visualquality, they can unintentionally encode and amplify social biases. Tosystematically trace how such biases evolve throughout the alignment pipeline,we introduce VideoBiasEval, a comprehensive diagnostic framework for evaluatingsocial representation in video generation.

17, TITLE: DeepAnalyze: Agentic Large Language Models for Autonomous Data Science
AUTHORS: Shaolei Zhang; Ju Fan; Meihao Fan; Guoliang Li; Xiaoyong Du
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we introduce DeepAnalyze-8B,the first agentic LLM designed for autonomous data science, capable ofautomatically completing the end-toend pipeline from data sources toanalyst-grade deep research reports.

18, TITLE: Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models
AUTHORS: Katie Luo; Jingwei Ji; Tong He; Runsheng Xu; Yichen Xie; Dragomir Anguelov; Mingxing Tan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our method leverages the zero-shot reasoning capabilities ofMLLMs to achieve significant improvements in motion prediction performance,while requiring no fine-tuning -- making it practical to adopt.

19, TITLE: Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback
AUTHORS: Zongjian Li; Zheyuan Liu; Qihui Zhang; Bin Lin; Feize Wu; Shenghai Yuan; Zhiyuan Yan; Yang Ye; Wangbo Yu; Yuwei Niu; Shaodong Wang; Xinhua Cheng; Li Yuan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To this end, we introduce Edit-R1, a novel post-trainingframework for instruction-based image editing based on policy optimization.Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), alikelihood-free policy optimization method consistent with the flow matchingforward process, thereby enabling the use of higher-order samplers and moreefficient training.

20, TITLE: Train for Truth, Keep The Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations
AUTHORS: Tong Chen; Akari Asai; Luke Zettlemoyer; Hannaneh Hajishirzi; Faeze Brahman
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Existingmitigation approaches often degrade performance on open-ended generation anddownstream tasks, limiting their practical utility. We propose an onlinereinforcement learning method using a novel binary retrieval-augmented reward(RAR) to address this tradeoff.

21, TITLE: TokenAR: Multiple Subject Generation Via Autoregressive Token-level Enhancement
AUTHORS: Haiyue Sun; Qingdong He; Jinlong Peng; Peng Tang; Jiangning Zhang; Junwei Zhu; Xiaobin Hu; Shuicheng Yan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, wepropose the TokenAR framework, specifically focused on a simple but effectivetoken-level enhancement mechanism to address reference identity confusionproblem.

22, TITLE: MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More Than Outcomes
AUTHORS: Yu Ying Chiu; Michael S. Lee; Rachel Calcott; Brandon Handoko; Paul de Font-Reaulx; Paula Rodriguez; Chen Bo Calvin Zhang; Ziwen Han; Udari Madhushani Sehwag; Yash Maurya; Christina Q Knight; Harry R. Lloyd; Florence Bacus; Mantas Mazeika; Bing Liu; Yejin Choi; Mitchell L Gordon; Sydney Levine
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Reasoning language models, which provide bothfinal responses and (partially transparent) intermediate thinking traces,present a timely opportunity to study AI procedural reasoning.

23, TITLE: VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents
AUTHORS: Kangrui Wang; Pingyue Zhang; Zihan Wang; Yaning Gao; Linjie Li; Qineng Wang; Hanyang Chen; Chi Wan; Yiping Lu; Zhengyuan Yang; Lijuan Wang; Ranjay Krishna; Jiajun Wu; Li Fei-Fei; Yejin Choi; Manling Li
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Our investigation into how agents represent internal beliefsreveals that the optimal representation is task-dependent: Natural Languageexcels at capturing semantic relationships in general tasks, while Structuredformats are indispensable for precise manipulation and control. Building onthese insights, we design a World Modeling Reward that provides dense,turn-level supervision for accurate state prediction, and introduce Bi-LevelGeneral Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.Through this form of visual state reasoning, a 3B-parameter model achieves ascore of 0.82 across five diverse agent benchmarks, representing a 3$\times$improvement over its untrained counterpart (0.21) and outperforming proprietaryreasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5(0.62).

24, TITLE: Bombardier Beetle Optimizer: A Novel Bio-Inspired Algorithm for Global Optimization
AUTHORS: Hisham A. Shehadeh; Mohd Yamani Idna Idris; Iqbal H. Jebril
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: In this paper, a novel bio-inspired optimization algorithm is proposed,called Bombardier Beetle Optimizer (BBO).

25, TITLE: Vocab Diet: Reshaping The Vocabulary of LLMs with Vector Arithmetic
AUTHORS: Yuval Reif; Guy Kaplan; Roy Schwartz
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, standardtokenization algorithms treat these variations as distinct tokens -- fillingthe size-capped vocabulary with surface form variants (e.g., "walk", "walking","Walk"), at the expense of less frequent words and multilingual coverage. Weshow that many of these variations can be captured by transformation vectors --additive offsets that yield the appropriate word's representation when appliedto the base form word embedding -- in both the input and output spaces.Building on this, we propose a compact reshaping of the vocabulary: rather thanassigning unique tokens to each surface form, we compose them from shared baseform and transformation vectors (e.g., "walked" = "walk" + past tense).

26, TITLE: Agentic Inequality
AUTHORS: Matthew Sharp; Omer Bilgin; Iason Gabriel; Lewis Hammond
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: This paper introduces andexplores "agentic inequality" - the potential disparities in power,opportunity, and outcomes stemming from differential access to, andcapabilities of, AI agents.

27, TITLE: Detecting Adversarial Fine-tuning with Auditing Agents
AUTHORS: Sarah Egler; John Schulman; Nicholas Carlini
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: We introduce the concept of a fine-tuningauditing agent and show it can detect harmful fine-tuning prior to modeldeployment.

28, TITLE: Annotation-Efficient Universal Honesty Alignment
AUTHORS: Shiyu Ni; Keping Bi; Jiafeng Guo; Minghao Tang; Jingtong Wu; Zengxin Han; Xueqi Cheng
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To support a large-scale study, we release HonestyBench, abenchmark covering ten free-form QA datasets with 560k training and 70kevaluation instances annotated with correctness and self-consistency signals.Experiments show that EliCal achieves near-optimal alignment with only 1kcorrectness annotations (0.18% of full supervision) and better alignmentperformance on unseen MMLU tasks than the calibration-only baseline, offering ascalable solution toward universal honesty alignment in LLMs.

29, TITLE: Language Over Content: Tracing Cultural Understanding in Multilingual Large Language Models
AUTHORS: Seungho Cho; Changgeon Ko; Eui Jun Hwang; Junmyeong Lee; Huije Lee; Jong C. Park
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we traceLLMs' internal cultural understanding mechanisms by measuring activation pathoverlaps when answering semantically equivalent questions under two conditions:varying the target country while fixing the question language, and varying thequestion language while fixing the country.

30, TITLE: FinSight: Towards Real-World Financial Deep Research
AUTHORS: Jiajie Jin; Yuyao Zhang; Yimeng Xu; Hongjin Qian; Yutao Zhu; Zhicheng Dou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Generating professional financial reports is a labor-intensive andintellectually demanding process that current AI systems struggle to fullyautomate. To address this challenge, we introduce FinSight (Financial InSight),a novel multi agent framework for producing high-quality, multimodal financialreports.

31, TITLE: Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation
AUTHORS: Chenghao Zhang; Guanting Dong; Xinyu Yang; Zhicheng Dou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To this end, we propose Nyx, a unifiedmixed-modal to mixed-modal retriever tailored for URAG scenarios.

32, TITLE: Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization
AUTHORS: Tianxin Wei; Yifan Chen; Xinrui He; Wenxuan Bao; Jingrui He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: On the model side, to better embed the unseen testdomains, we propose model anchoring to exploit the intra-class connectivity inpre-trained representations and complement the anchoring with generativetransformation loss.

33, TITLE: Navigating The Alignment-Calibration Trade-off: A Pareto-Superior Frontier Via Model Merging
AUTHORS: Tiancheng Hu; Benjamin Minixhofer; Nigel Collier
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We show that thistrade-off can be navigated effectively via a simple post-hoc intervention:interpolating between a model's weights before and after alignment.

34, TITLE: SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion
AUTHORS: George Ma; Anurag Koul; Qi Chen; Yawen Wu; Sachit Kuhar; Yu Yu; Aritra Sengupta; Varun Kumar; Murali Krishna Ramanathan
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: The low inference-time latencybudget affects either retrieval quality or the added latency adversely impactsuser experience. We address this limitation with SpecAgent, an agent thatimproves both latency and code-generation quality by proactively exploringrepository files during indexing and constructing speculative context thatanticipates future edits in each file.

35, TITLE: Deep Self-Evolving Reasoning
AUTHORS: Zihan Liu; Shun Zheng; Xumeng Wen; Yang Wang; Jiang Bian; Mao Yang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model.

36, TITLE: MuseTok: Symbolic Music Tokenization for Generation and Semantic Understanding
AUTHORS: Jingyue Huang; Zachary Novack; Phillip Long; Yupeng Hou; Ke Chen; Taylor Berg-Kirkpatrick; Julian McAuley
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Discrete representation learning has shown promising results across variousdomains, including generation and understanding in image, speech and language.Inspired by these advances, we propose MuseTok, a tokenization method forsymbolic music, and investigate its effectiveness in both music generation andunderstanding tasks.

37, TITLE: Executable Knowledge Graphs for Replicating AI Research
AUTHORS: Yujie Luo; Zhuoyun Yu; Xuehai Wang; Yuqi Zhu; Ningyu Zhang; Lanning Wei; Lun Du; Da Zheng; Huajun Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Furthermore, previous approachestend to overlook valuable implementation-level code signals and lack structuredknowledge representations that support multi-granular retrieval and reuse. Toovercome these challenges, we propose Executable Knowledge Graphs (xKG), amodular and pluggable knowledge base that automatically integrates technicalinsights, code snippets, and domain-specific knowledge extracted fromscientific literature.

38, TITLE: TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework
AUTHORS: Shuzheng Gao; Eric John Li; Man Ho Lam; Jingyu Xiao; Yuxuan Wan; Chaozheng Wang; Ng Man Tik; Michael R. Lyu
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: Existingbenchmarks suffer from limited task scope and fail to incorporate criticalevaluation aspects such as the robustness and reliability of models. To bridgethis gap, we present an evaluation framework called TREAT (Code LLMsTrustworthiness / Reliability Evaluation And Testing) that provides a holisticassessment of model performance in code intelligence tasks.

39, TITLE: SoftMimic: Learning Compliant Whole-body Control from Examples
AUTHORS: Gabriel B. Margolis; Michelle Wang; Nolan Fey; Pulkit Agrawal
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: We introduce SoftMimic, a framework for learning compliant whole-body controlpolicies for humanoid robots from example motions.

40, TITLE: Beyond Pipelines: A Survey of The Paradigm Shift Toward Model-Native Agentic AI
AUTHORS: Jitao Sang; Jinlin Xiao; Jiarun Han; Jilin Chen; Xiaoyi Chen; Shuyu Wei; Yongjie Sun; Yuhang Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: The rapid evolution of agentic AI marks a new phase in artificialintelligence, where Large Language Models (LLMs) no longer merely respond butact, reason, and adapt.

41, TITLE: Online Learning Defense Against Iterative Jailbreak Attacks Via Prompt Optimization
AUTHORS: Masahiro Kaneko; Zeerak Talat; Timothy Baldwin
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Despite being an effective attack strategyagainst LLMs and their safety mechanisms, existing defenses do not proactivelydisrupt this dynamic trial-and-error cycle. In this study, we propose a novelframework that dynamically updates its defense strategy through online learningin response to each new prompt from iterative jailbreak methods.

42, TITLE: Bits Leaked Per Query: Information-Theoretic Bounds on Adversarial Attacks Against LLMs
AUTHORS: Masahiro Kaneko; Timothy Baldwin
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: We fill thisgap with an information-theoretic framework that computes how much informationcan be safely disclosed, and enables auditors to gauge how close their methodscome to the fundamental limit.

43, TITLE: RAVEN: Robust Advertisement Video Violation Temporal Grounding Via Reinforcement Reasoning
AUTHORS: Deyi Ji; Yuekui Yang; Haiyang Wu; Shaoping Ma; Tianrun Chen; Lanyun Zhu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We propose RAVEN, anovel framework that integrates curriculum reinforcement learning withmultimodal large language models (MLLMs) to enhance reasoning and cognitivecapabilities for violation detection.

44, TITLE: ReefNet: A Large Scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification
AUTHORS: Yahia Battach; Abdulwahab Felemban; Faizan Farooq Khan; Yousef A. Radwan; Xiang Li; Fabio Marchese; Sara Beery; Burton H. Jones; Francesca Benzoni; Mohamed Elhoseiny
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose two evaluation settings: (i) a within-sourcebenchmark that partitions each source's images for localized evaluation, and(ii) a cross-source benchmark that withholds entire sources to test domaingeneralization.

45, TITLE: Demeter: A Parametric Model of Crop Plant Morphology from The Real World
AUTHORS: Tianhang Cheng; Albert J. Zhai; Evan Z. Chen; Rui Zhou; Yawen Deng; Zitong Li; Kejie Zhao; Janice Shiu; Qianyu Zhao; Yide Xu; Xinlei Wang; Yuan Shen; Sheng Wang; Lisa Ainsworth; Kaiyu Guan; Shenlong Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we present Demeter, a data-driven parametric model thatencodes key factors of a plant morphology, including topology, shape,articulation, and deformation into a compact learned representation.

46, TITLE: TabR1: Taming GRPO for Tabular Reasoning LLMs
AUTHORS: Pengxiang Cai; Zihao Gao; Jintai Chen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This paper presents TabR1, the first reasoning LLM for tabular predictionwith multi-step reasoning.

47, TITLE: Natural Language Processing for Cardiology: A Narrative Review
AUTHORS: Kailai Yang; Yan Leng; Xin Zhang; Tianlin Zhang; Paul Thompson; Bernard Keavney; Maciej Tomaszewski; Sophia Ananiadou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To the best of ourknowledge, this review represents the most comprehensive synthesis of NLPresearch in cardiology to date.

48, TITLE: Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains
AUTHORS: Austin Xu; Xuan-Phi Nguyen; Yilun Zhou; Chien-Sheng Wu; Caiming Xiong; Shafiq Joty
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we focuson data scaling, curating a set of 2.5M samples spanning five unique evaluationtasks (pairwise, step-level, reference-free and reference-based verification,and single rating) and multiple domains focused on reasoning evaluation.

49, TITLE: DETree: DEtecting Human-AI Collaborative Texts Via Tree-Structured Hierarchical Representation Learning
AUTHORS: Yongxin He; Shan Zhang; Yixuan Cao; Lei Ma; Ping Luo
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Weobserve that representations of texts generated through different processesexhibit inherent clustering relationships. Therefore, we propose DETree, anovel approach that models the relationships among different processes as aHierarchical Affinity Tree structure, and introduces a specialized lossfunction that aligns text representations with this tree.

50, TITLE: What Can String Probability Tell Us About Grammaticality?
AUTHORS: Jennifer Hu; Ethan Gotlieb Wilcox; Siyuan Song; Kyle Mahowald; Roger P. Levy
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present a theoretical analysis of the relationshipbetween grammar, meaning, and string probability, based on simple assumptionsabout the generative process of corpus data.

51, TITLE: Are LLMs Court-Ready? Evaluating Frontier Models on Indian Legal Reasoning
AUTHORS: Kush Juvekar; Arghya Bhattacharya; Sai Khadloya; Utkarsh Saxena
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: Our work shows that while frontier systems consistently clearhistorical cutoffs and often match or exceed recent top-scorer bands onobjective exams, none surpasses the human topper on long-form reasoning.

52, TITLE: Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?
AUTHORS: Junchi Yu; Yujie Liu; Jindong Gu; Philip Torr; Dongzhan Zhou
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However, existing KG-based RAG methods struggle to retrieve accurateand diverse information from text-rich KGs for complex real-world queries.Process Reward Models (PRMs) offer a way to align the retrieval process ofKG-based RAG with query-specific knowledge requirements, but they heavily relyon process-level supervision signals that are expensive and hard to obtain onKGs. To address this challenge, we propose GraphFlow, a framework thatefficiently retrieves accurate and diverse knowledge required for real-worldqueries from text-rich KGs.

53, TITLE: Training-free Online Video Step Grounding
AUTHORS: Luca Zanella; Massimiliano Mancini; Yiming Wang; Alessio Tonioni; Elisa Ricci
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Thus, in this work, we explore how to perform VSG online and withouttraining.

54, TITLE: Universal Spectral Tokenization Via Self-Supervised Panchromatic Representation Learning
AUTHORS: Jeff Shen; Francois Lanusse; Liam Holden Parker; Ollie Liu; Tom Hehir; Leopoldo Sarra; Lucas Meyer; Micah Bowles; Sebastian Wagner-Carena; Sebastian Wagner-Carena; Helen Qu; Siavash Golkar; Alberto Bietti; Hatim Bourfoune; Nathan Cassereau; Pierre Cornette; Keiya Hirashima; Geraud Krawezik; Ruben Ohana; Nicholas Lourie; Michael McCabe; Rudy Morel; Payel Mukhopadhyay; Mariel Pettee; Bruno Régaldo-Saint Blancard; Kyunghyun Cho; Miles Cranmer; Shirley Ho
CATEGORY: arxiv-astro-ph.IM [IM]
HIGHLIGHT: We present a deep learning modelthat jointly learns from heterogeneous spectra in a self-supervised manner.

55, TITLE: Glyph: Scaling Context Windows Via Visual-Text Compression
AUTHORS: Jiale Cheng; Yusen Liu; Xinyu Zhang; Yulin Fei; Wenyi Hong; Ruiliang Lyu; Weihan Wang; Zhe Su; Xiaotao Gu; Xiao Liu; Yushi Bai; Jie Tang; Hongning Wang; Minlie Huang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Large language models (LLMs) increasingly rely on long-context modeling fortasks such as document understanding, code analysis, and multi-step reasoning.However, scaling context windows to the million-token level brings prohibitivecomputational and memory costs, limiting the practicality of long-context LLMs.In this work, we take a different perspective-visual context scaling-to tacklethis challenge. Instead of extending token-based sequences, we propose Glyph, aframework that renders long texts into images and processes them withvision-language models (VLMs).

56, TITLE: The Formalism-Implementation Gap in Reinforcement Learning Research
AUTHORS: Pablo Samuel Castro
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This paper argues two points:(i) RL research should stop focusing solely on demonstrating agentcapabilities, and focus more on advancing the science and understanding ofreinforcement learning; and (ii) we need to be more precise on how ourbenchmarks map to the underlying mathematical formalisms.

57, TITLE: Xiaoice: Training-Free Video Understanding Via Self-Supervised Spatio-Temporal Clustering of Semantic Features
AUTHORS: Shihao Ji; Zihui Song
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our core idea is to reframe videounderstanding as a self-supervised spatio-temporal clustering problem within ahigh-dimensional semantic feature space.

58, TITLE: Publication Trend Analysis and Synthesis Via Large Language Model: A Case Study of Engineering in PNAS
AUTHORS: Mason Smetana; Lev Khazanovich
CATEGORY: arxiv-cs.DL [DL]
HIGHLIGHT: Scientific literature is increasingly siloed by complex language, staticdisciplinary structures, and potentially sparse keyword systems, making itcumbersome to capture the dynamic nature of modern science. This studyaddresses these challenges by introducing an adaptable large language model(LLM)-driven framework to quantify thematic trends and map the evolvinglandscape of scientific knowledge.

59, TITLE: Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats
AUTHORS: Simeon Adebola; Chung Min Kim; Justin Kerr; Shuangyu Xie; Prithvi Akella; Jose Luis Susa Rincon; Eugen Solowjow; Ken Goldberg
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this paper, we present Botany-Bot, asystem for building detailed "annotated digital twins" of living plants usingtwo stereo cameras, a digital turntable inside a lightbox, an industrial robotarm, and 3D segmentated Gaussian Splat models.

60, TITLE: Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts
AUTHORS: Tong Zhang; Ru Zhang; Jianyi Liu; Zhen Yang; Gongshen Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Based on thisinsight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation forContextual Targeting), a dynamic anchor selection framework designed toovercome the limitations of fixed anchors.

61, TITLE: Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation
AUTHORS: Guoqing Luo; Iffat Maab; Lili Mou; Junichi Yamagishi
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, the underlying behaviours of these language models in socialbias scenarios remain underexplored. In this work, we systematicallyinvestigate mechanisms within the thinking process behind this phenomenon anduncover two failure patterns that drive social bias aggregation: 1) stereotyperepetition, where the model relies on social stereotypes as its primaryjustification, and 2) irrelevant information injection, where it fabricates orintroduces new details to support a biased narrative.

62, TITLE: NavQ: Learning A Q-Model for Foresighted Vision-and-Language Navigation
AUTHORS: Peiran Xu; Xicheng Gong; Yadong MU
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work we concentrate on the task of goal-oriented Vision-and-LanguageNavigation (VLN).

63, TITLE: Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling
AUTHORS: Lipeng Xie; Sen Huang; Zhuo Zhang; Anni Zou; Yunpeng Zhai; Dingchao Ren; Kezun Zhang; Haoyuan Hu; Boyin Liu; Haoran Chen; Zhaoyang Liu; Bolin Ding
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We address theselimitations with a novel, training-free framework built on a key assumption:\textit{evaluation rubrics underlying human preferences exhibit significantgeneralization ability across diverse queries}, a property that enablesremarkable data efficiency.

64, TITLE: Uncertainty-Aware Post-Hoc Calibration: Mitigating Confidently Incorrect Predictions Beyond Calibration Metrics
AUTHORS: Hassan Gharoun; Mohammad Sadegh Khorshidi; Kasra Ranjbarigderi; Fang Chen; Amir H. Gandomi
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: The framework employs proximity-based conformal prediction tostratify calibration samples into putatively correct and putatively incorrectgroups based on semantic similarity in feature space.

65, TITLE: Conditional Synthetic Live and Spoof Fingerprint Generation
AUTHORS: Syed Konain Abbas; Sandip Purnapatra; M. G. Sarwar Murshed; Conor Miller-Lynch; Lambert Igene; Soumyabrata Dey; Stephanie Schuckers; Faraz Hussain
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper presents a novel approach for generating syntheticfingerprint images (both spoof and live), addressing concerns related toprivacy, cost, and accessibility in biometric data collection.

66, TITLE: STEM for All Abilities: Unlocking The Potential of Special-Needs and Neurodiverse Students in America's Innovation Pipeline
AUTHORS: Uche Nweje
CATEGORY: International Journal of Science and Research Archive [INTERNATIONAL JOURNAL OF SCIENCE AND RESEARCH ARCHIVE]
HIGHLIGHT: Through comparative analysis of international best practices, the study proposes an integrated framework for inclusive STEM education that aligns policy, institutional infrastructure, and professional development with the goal of fostering cognitive diversity in innovation.

67, TITLE: PLAGUE: Plug-and-play Framework for Lifelong Adaptive Generation of Multi-turn Exploits
AUTHORS: Neeladri Bhuiya; Madhav Aggarwal; Diptanshu Purwar
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Whilesingle-turn attacks have been extensively explored, adaptability, efficiencyand effectiveness continue to remain key challenges for their multi-turncounterparts. To address these gaps, we present PLAGUE, a novel plug-and-playframework for designing multi-turn attacks inspired by lifelong-learningagents.

68, TITLE: Exploring The Design Space of Diffusion and Flow Models for Data Fusion
AUTHORS: Niraj Chaudhari; Manmeet Singh; Naveen Sudharsan; Amit Kumar Srivastava; Harsh Kamath; Dushyant Mahajan; Ayan Paul
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this study, weexplore the design space of diffusion and flow models for data fusion, focusingon the integration of Defense Meteorological Satellite Program's OperationalLinescan System (DMSP-OLS) and Visible Infrared Imaging Radiometer Suite(VIIRS) nighttime lights data.

69, TITLE: Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals Via Vision-Language Models
AUTHORS: Chenrui Tie; Shengxiang Sun; Yudi Lin; Yanbo Wang; Zhongrui Li; Zhouhan Zhong; Jinxuan Zhu; Yiman Pang; Haonan Chen; Junting Chen; Ruihai Wu; Lin Shao
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this paper, we considerconnections as first-class primitives in assembly representation, includingconnector types, specifications, quantities, and placement locations.

70, TITLE: Pursuing Minimal Sufficiency in Spatial Reasoning
AUTHORS: Yejie Guo; Yunzhong Hou; Wufei Ma; Meng Tang; Ming-Hsuan Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce MSSR (MinimalSufficient Spatial Reasoner), a dual-agent framework that implements thisprinciple.

71, TITLE: Scaling Laws for Deepfake Detection
AUTHORS: Wenhao Wang; Longqi Cai; Taihong Xiao; Yuxiao Wang; Ming-Hsuan Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper presents a systematic study of scaling laws for the deepfakedetection task.

72, TITLE: The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in The Age of AI
AUTHORS: Alex Zhavoronkov; Dominika Wilczok; Roman Yampolskiy
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Over time, thiscreates a new threat: the gradual erasure of those with limited digitalpresence, and the amplification of those already prominent, reshapingcollective memory. To address these concerns, this paper presents a concept ofthe Right To Be Remembered (RTBR) which encompasses minimizing the risk ofAI-driven information omission, embracing the right of fair treatment, whileensuring that the generated content would be maximally truthful.

73, TITLE: Vision-Centric 4D Occupancy Forecasting and Planning Via Implicit Residual World Models
AUTHORS: Jianbiao Mei; Yu Yang; Xuemeng Yang; Licheng Wen; Jiajun Lv; Botian Shi; Yong Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: End-to-end autonomous driving systems increasingly rely on vision-centricworld models to understand and predict their environment. However, a commonineffectiveness in these models ...

74, TITLE: EvoSyn: Generalizable Evolutionary Data Synthesis for Verifiable Learning
AUTHORS: He Du; Bowen Li; Aijun Yang; Siyang He; Qipeng Guo; Dacheng Tao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we introduce anevolutionary, task-agnostic, strategy-guided, executably-checkable datasynthesis framework that, from minimal seed supervision, jointly synthesizesproblems, diverse candidate solutions, and verification artifacts, anditeratively discovers strategies via a consistency-based evaluator thatenforces agreement between human-annotated and strategy-induced checks.

75, TITLE: Diagnosis of Fuel Cell Health Status with Deep Sparse Auto-Encoder Neural Network
AUTHORS: Chenyan Fei; Dalin Zhang; Chen Melinda Dang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: However, its online testing is prohibitivelycomplex and costly. This paper employs a deep sparse auto-encoding network forthe prediction and classification of high-frequency impedance in fuel cells,achieving metric of accuracy rate above 92\%.

76, TITLE: Feedback Lunch: Deep Feedback Codes for Wiretap Channels
AUTHORS: Yingyao Zhou; Natasha Devroye; Onur Günlü
CATEGORY: arxiv-cs.IT [IT]
HIGHLIGHT: We consider reversely-degraded wiretap channels, for which the secrecycapacity is zero if there is no channel feedback.

77, TITLE: SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models
AUTHORS: Chih-Kai Yang; Yen-Ting Piao; Tzu-Wen Hsu; Szu-Wei Fu; Zhehuai Chen; Ke-Han Lu; Sung-Feng Huang; Chao-Han Huck Yang; Yu-Chiang Frank Wang; Yun-Nung Chen; Hung-yi Lee
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: We introduce SAKE, the first benchmark specificallydesigned for editing auditory attribute knowledge in Large Audio-LanguageModels (LALMs).

78, TITLE: Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations
AUTHORS: Bo-Han Feng; Chien-Feng Liu; Yu-Hsuan Li Liang; Chih-Kai Yang; Szu-Wei Fu; Zhehuai Chen; Ke-Han Lu; Sung-Feng Huang; Chao-Han Huck Yang; Yu-Chiang Frank Wang; Yun-Nung Chen; Hung-yi Lee
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Large audio-language models (LALMs) extend text-based LLMs with auditoryunderstanding, offering new opportunities for multimodal applications.

79, TITLE: Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence
AUTHORS: Qiongyan Wang; Xingchen Zou; Yutian Jiang; Haomin Wen; Jiaheng Wei; Qingsong Wen; Yuxuan Liang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To this end, we propose Urban-R1, a reinforcementlearning-based post-training framework that aligns MLLMs with the objectives ofUGI.

80, TITLE: DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition
AUTHORS: Fo Hu; Can Wang; Qinxu Zheng; Xusheng Yang; Bin Zhou; Gang Li; Yu Sun; Wen-an Zhang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose a distribution-awaremulti-source domain adaptation network (DAMSDAN).

81, TITLE: SSL4RL: Revisiting Self-supervised Learning As Intrinsic Reward for Visual-Language Reasoning
AUTHORS: Xiaojun Guo; Runyu Zhou; Yifei Wang; Qi Zhang; Chenheng Zhang; Stefanie Jegelka; Xiaohan Wang; Jiajun Chai; Guojun Yin; Wei Lin; Yisen Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, they often fail to utilizevisual evidence adequately, either depending on linguistic priors invision-centric tasks or resorting to textual shortcuts during reasoning.Although reinforcement learning (RL) can align models with desired behaviors,its application to VLMs has been hindered by the lack of scalable and reliablereward mechanisms. To overcome this challenge, we propose SSL4RL, a novelframework that leverages self-supervised learning (SSL) tasks as a source ofverifiable rewards for RL-based fine-tuning.

82, TITLE: LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs
AUTHORS: Ang Li; Yifei Wang; Zhihang Yuan; Stefanie Jegelka; Yisen Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Across mathematical reasoningbenchmarks, LANPO enables 7B and 14B models to significantly outperform strongbaselines trained with GRPO in test accuracy.

83, TITLE: Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense
AUTHORS: Zhehao Zhang; Weijie Xu; Shixian Cui; Chandan K. Reddy
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we identify and systematicallyanalyze a critical vulnerability we term reasoning distraction, where LRMs arediverted from their primary objective by irrelevant yet complex tasksmaliciously embedded in the prompt.

84, TITLE: Fit for Purpose? Deepfake Detection in The Real World
AUTHORS: Guangyu Lin; Li Lin; Christina P. Walker; Daniel S. Schiff; Shu Hu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, weintroduce the first systematic benchmark based on the Political DeepfakesIncident Database, a curated collection of real-world political deepfakesshared on social media since 2018.

85, TITLE: MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems
AUTHORS: Qingyao Ai; Yichen Tang; Changyue Wang; Jianming Long; Weihang Su; Yiqun Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Therefore,we propose a user feedback simulation framework and a comprehensive benchmarkcovering multiple domains, languages, and types of tasks to evaluate thecontinual learning abilities of LLMsys.

86, TITLE: From Charts to Code: A Hierarchical Benchmark for Multimodal Models
AUTHORS: Jiahao Tang; Henry Hengyuan Zhao; Lijian Wu; Yifei Tao; Dongxing Mao; Yang Wan; Jingru Tan; Min Zeng; Min Li; Alex Jinpeng Wang
CATEGORY: arxiv-cs.SE [SE]
HIGHLIGHT: We introduce Chart2Code, a new benchmark for evaluating the chartunderstanding and code generation capabilities of large multimodal models(LMMs).

87, TITLE: Enhancing Language Agent Strategic Reasoning Through Self-Play in Adversarial Games
AUTHORS: Yikai Zhang; Ye Rong; Siyu Yuan; Jiangjie Chen; Jian Xie; Yanghua Xiao
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we propose a Step-level poliCyOptimization method through Play-And-Learn, SCO-PAL.

88, TITLE: Exploring The Missing Semantics In Event Modality
AUTHORS: Jingqian Wu; Shengpeng Xu; Yunbo Jia; Edmund Y. Lam
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Further, semantic information plays acrucial role in video and frame reconstruction, yet is often overlooked byexisting E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2Vframework that explores the missing visual semantic knowledge in event modalityand leverages it to enhance event-to-video reconstruction.

89, TITLE: GSPlane: Concise and Accurate Planar Reconstruction Via Structured Representation
AUTHORS: Ruitong Gan; Junran Peng; Yang Liu; Chuanchen Luo; Qing Li; Zhaoxiang Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However,even state-of-the-art GS representations often struggle to reconstruct planarregions with sufficient smoothness and precision. To address this issue, wepropose GSPlane, which recovers accurate geometry and produces clean andwell-structured mesh connectivity for plane regions in the reconstructed scene.By leveraging off-the-shelf segmentation and normal prediction models, GSPlaneextracts robust planar priors to establish structured representations forplanar Gaussian coordinates, which help guide the training process by enforcinggeometric consistency.

90, TITLE: On-the-Fly OVD Adaptation with FLAME: Few-shot Localization Via Active Marginal-Samples Exploration
AUTHORS: Yehonathan Refael; Amit Aides; Aviad Barzilai; George Leifman; Genady Beryozkin; Vered Silverman; Bolous Jaber; Tomer Shekel
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: For instance, an OVD model may struggle to distinguishbetween fine-grained classes such as "fishing boat" and "yacht" since theirembeddings are similar and often inseparable. This can hamper specific usergoals, such as monitoring illegal fishing, by producing irrelevant detections.To address this, we propose a cascaded approach that couples the broadgeneralization of a large pre-trained OVD model with a lightweight few-shotclassifier.

91, TITLE: SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving
AUTHORS: Peiru Zheng; Yun Zhao; Zhan Gong; Hong Zhu; Shaohua Wu
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In this paper,we propose SimpleVSF (Simple VLM-ScoringFusion), a novel framework that enhances end-to-end planning by leveraging thecognitive capabilities of Vision-Language Models (VLMs) and advanced trajectoryfusion techniques.

92, TITLE: How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design
AUTHORS: Mohd Ruhul Ameen; Akif Islam; Abu Saleh Musa Miah; Ayesha Siddiqua; Jungpil Shin
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: The findings reveal a cleardominance of negative emotions, particularly anger, fear, and disappointment,and significant variation in how similar stories are emotionally portrayedacross outlets. Based on these insights, we propose design ideas for ahuman-centered news aggregator that visualizes emotional cues and helps readersrecognize hidden affective framing in daily news.

93, TITLE: From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh
AUTHORS: M Saifuzzaman Rafat; Mohd Ruhul Ameen; Akif Islam; Abu Saleh Musa Miah; Jungpil Shin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To track this slow-motion catastrophe has, until now,been a Herculean task for human analysts. Here we show how a powerfulgeneral-purpose vision model, the Segment Anything Model (SAM), can be adaptedto this task with remarkable precision.

94, TITLE: Forgetting to Forget: Attention Sink As A Gateway for Backdooring LLM Unlearning
AUTHORS: Bingqi Shang; Yiwei Chen; Yihua Zhang; Bingquan Shen; Sijia Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Drawing inspiration from classical backdoor attacks thatembed triggers into training data to enforce specific behaviors, we investigatebackdoor unlearning, where models forget as intended in the clean setting butrecover forgotten knowledge when the trigger appears. We show that designingsuch attacks presents unique challenges, hinging on where triggers are placedand how backdoor training is reinforced.

95, TITLE: Explainability of Large Language Models: Opportunities and Challenges Toward Generating Trustworthy Explanations
AUTHORS: Shahin Atakishiyev; Housam K. B. Babiker; Jiayi Dai; Nawshad Farruque; Teruaki Hayashi; Nafisa Sadaf Hriti; Md Abed Rahman; Iain Smith; Mi-Young Kim; Osmar R. Zaïane; Randy Goebel
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Motivated by thisgap, this paper investigates local explainability and mechanisticinterpretability within Transformer-based large language models to foster trustin such models. In this regard, our paper aims to make three key contributions.First, we present a review of local explainability and mechanisticinterpretability approaches and insights from relevant studies in theliterature.

96, TITLE: Predicting Life Satisfaction Using Machine Learning and Explainable AI
AUTHORS: Alif Elham Khan; Mohammad Junayed Hasan; Humayra Anjum; Nabeel Mohammed; Sifat Momen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Using featurelearning techniques, 27 significant questions for assessing contentment wereextracted, making the study highly reproducible, simple, and easilyinterpretable.

97, TITLE: WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale
AUTHORS: Yuxuan Lu; Jing Huang; Hui Liu; Jiri Gesi; Yan Han; Shihan Fu; Tianqi Zheng; Dakuo Wang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose WEBSERV, an environment thatincludes 1) a compact, site-agnostic browser environment that balances contextand action complexity, and 2) a scalable RL environment via efficient launchingand resetting web-servers to enable scalable RL training and evaluation.

98, TITLE: Which LLM Multi-Agent Protocol to Choose?
AUTHORS: Hongyi Du; Jiaqi Su; Jisen Li; Lijie Ding; Yingxuan Yang; Peixuan Han; Xiangru Tang; Kunlun Zhu; Jiaxuan You
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: As large-scale multi-agent systems evolve, the communication protocol layerhas become a critical yet under-evaluated factor shaping performance andreliability. Despite the ...

99, TITLE: AcademicEval: Live Long-Context LLM Benchmark
AUTHORS: Haozhen Zhang; Tao Feng; Pengrui Han; Jiaxuan You
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: However, current long-context LLM benchmarks arelimited by rigid context length, labor-intensive annotation, and the pressingchallenge of label leakage issues during LLM training. Therefore, we propose\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-contextgeneration tasks.

100, TITLE: Leave It to The Experts: Detecting Knowledge Distillation Via MoE Expert Signatures
AUTHORS: Pingzhi Li; Morris Yu-Chao Huang; Zhen Tan; Qingquan Song; Jie Peng; Kai Zou; Yu Cheng; Kaidi Xu; Tianlong Chen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Knowledge Distillation (KD) accelerates training of large language models(LLMs) but poses intellectual property protection and LLM diversity risks.Existing KD detection methods based on self-identity or output similarity canbe easily evaded through prompt engineering.

101, TITLE: Agree, Disagree, Explain: Decomposing Human Label Variation in NLI Through The Lens of Explanations
AUTHORS: Pingjun Hong; Beiduo Chen; Siyao Peng; Marie-Catherine de Marneffe; Benjamin Roth; Barbara Plank
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Natural Language Inference datasets often exhibit human label variation. Tobetter understand these variations, explanation-based approaches analyze theunderlying reasoning behind annotators' decisions.

102, TITLE: Improving Model Representation and Reducing KV Cache Via Skip Connections with First Value Heads
AUTHORS: Zhoutong Wu; Yuan Zhang; Yiming Dong; Chenheng Zhang; Cong Fang; Kun Yuan; Zhouchen Lin
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we propose SkipV1Former, a Transformervariant that uses skip connections from the first layer's Value heads tostrengthen model representation and reduce KV cache.

103, TITLE: Agentic Reinforcement Learning for Search Is Unsafe
AUTHORS: Yushi Yang; Shreyansh Padarha; Andrew Lee; Adam Mahdi
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: These models excel at multi-step reasoning tasks, but their safetyproperties are not well understood. In this study, we show that RL-trainedsearch models inherit refusal from instruction tuning and often deflect harmfulrequests by turning them into safe queries.

104, TITLE: Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory
AUTHORS: Shiqi He; Yue Cui; Xinyu Ma; Yaliang Li; Bolin Ding; Mosharaf Chowdhury
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Abstract: Autonomous web agents powered by large language models (LLMs) show strongpotential for performing goal-oriented tasks such as information retrieval,report generation, and online ...

105, TITLE: Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis
AUTHORS: Chong Chen; Ze Liu; Lingfeng Bao; Yanlin Wang; Ting Chen; Daoyuan Wu; Jiachi Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Dataintegration and analysis are essential for informed investment decisions.Currently, investors use three main approaches: (1) Manual analysis acrossvarious sources, which depends heavily on individual experience and istime-consuming and prone to bias; (2) Data aggregation platforms-limited infunctionality and depth of analysis; (3) Large language model agents-based onstatic pretrained models, lacking real-time data integration and multi-stepreasoning capabilities. To address these limitations, we present Coinvisor, areinforcement learning-based chatbot that provides comprehensive analyticalsupport for cryptocurrency investment through a multi-agent framework.Coinvisor integrates diverse analytical capabilities through specialized tools.Its key innovation is a reinforcement learning-based tool selection mechanismthat enables multi-step planning and flexible integration of diverse datasources.

106, TITLE: ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents
AUTHORS: David Peer; Sebastian Stabinger
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Large Language Models (LLMs) have demonstrated impressive capabilities, yettheir deployment in high-stakes domains is hindered by inherent limitations intrustworthiness, including hallucinations, instability, and a lack oftransparency. To address these challenges, we introduce a genericneuro-symbolic approach, which we call Autonomous Trustworthy Agents (ATA).

107, TITLE: PICABench: How Far Are We from Physically Realistic Image Editing?
AUTHORS: Yuandong Pu; Le Zhuo; Songhao Han; Jinbo Xing; Kaiwen Zhu; Shuo Cao; Bin Fu; Si Liu; Hongsheng Li; Yu Qiao; Wenlong Zhang; Xi Chen; Yihao Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We hope that our benchmark andproposed solutions can serve as a foundation for future work moving from naivecontent editing toward physically consistent realism.

108, TITLE: Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution
AUTHORS: Ivan Molodetskikh; Kirill Malyshev; Mark Mirgaleev; Nikita Zagainov; Evgeney Bogatyrev; Dmitriy Vatolin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Weargue that artifacts should be characterized by their prominence to humanobservers rather than treated as uniform binary defects. Motivated by this, wepresent a novel dataset of 1302 artifact examples from 11 contemporary image-SRmethods, where each artifact is paired with a crowdsourced prominence score.Building on this dataset, we train a lightweight regressor that producesspatial prominence heatmaps and outperforms existing methods at detectingprominent artifacts.

109, TITLE: Seeing But Not Believing: Probing The Disconnect Between Visual Attention and Answer Correctness in VLMs
AUTHORS: Zhining Liu; Ziyi Chen; Hui Liu; Chen Luo; Xianfeng Tang; Suhang Wang; Joy Zeng; Zhenwei Dai; Zhan Shi; Tianxin Wei; Benoit Dumoulin; Hanghang Tong
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Vision-Language Models (VLMs) achieve strong results on multimodal tasks suchas visual question answering, yet they can still fail even when the correctvisual evidence is present. In this work, we systematically investigate whetherthese failures arise from not perceiving the evidence or from not leveraging iteffectively.

110, TITLE: SHIELD: Suppressing Hallucinations In LVLM Encoders Via Bias and Vulnerability Defense
AUTHORS: Yiyang Huang; Liang Shi; Yitian Zhang; Yi Xu; Yun Fu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.However, object hallucination, where models produce plausible but inaccurateobject descriptions, remains a ...

111, TITLE: Patronus: Safeguarding Text-to-Image Models Against White-Box Adversaries
AUTHORS: Xinfeng Li; Shengyuan Pang; Jialin Wu; Jiangyi Deng; Huanlong Zhong; Yanjiao Chen; Jie Zhang; Wenyuan Xu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: This paper presents a novel defensive framework, named Patronus,which equips T2I models with holistic protection to defend against white-boxadversaries.

112, TITLE: Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation
AUTHORS: Navreet Kaur; Hoda Ayad; Hayoung Jung; Shravika Mittal; Munmun De Choudhury; Tanushree Mitra
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We propose CoRUS (COmmunity-driven Roles forUser-centric Question Simulation), a framework for simulating role-basedquestions.

113, TITLE: D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks
AUTHORS: Jundong Zhang; Yuhui Situ; Fanji Zhang; Rongji Deng; Tianqi Wei
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To address this,we propose a reinforcement learning framework that (i) discretizes continuousaction spaces to approximate multimodal distributions, (ii) employsentropy-regularized exploration to improve coverage of risky but rewardingactions, and (iii) introduces a dual-critic architecture for more accuratediscrete value distribution estimation.

114, TITLE: Empowering Real-World: A Survey on The Technology, Practice, and Evaluation of LLM-driven Industry Agents
AUTHORS: Yihong Tang; Kehai Chen; Liang Yue; Jinxin Fan; Caishen Zhou; Xiaoguang Li; Yuyang Zhang; Mingming Zhao; Shixiong Kai; Kaiyang Guo; Xingshan Zeng; Wenjing Cun; Lifeng Shang; Min Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Bycombining technological evolution with industry practices, this review aims toclarify the current state and offer a clear roadmap and theoretical foundationfor understanding and building the next generation of industry agents.

115, TITLE: Structured Interfaces for Automated Reasoning with 3D Scene Graphs
AUTHORS: Aaron Ray; Jacob Arkin; Harel Biggie; Chuchu Fan; Luca Carlone; Nicholas Roy
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we addressthe challenge of using LLMs with 3DSGs to ground natural language.

116, TITLE: SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference
AUTHORS: Samir Khaki; Junxian Guo; Jiaming Tang; Shang Yang; Yukang Chen; Konstantinos N. Plataniotis; Yao Lu; Song Han; Zhijian Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We present SparseVILA, a new paradigm for efficientVLM inference that decouples visual sparsity across the prefilling and decodingstages.

117, TITLE: GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer
AUTHORS: Sayan Deb Sarkar; Sinisa Stekovic; Vincent Lepetit; Iro Armeni
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Beyond showcased scenarios,our method is general and could be extended to different types of diffusionmodels and guidance functions.

118, TITLE: VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models
AUTHORS: Qilin Liao; Anamika Lochab; Ruqi Zhang
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Existing multimodal red-teaming methods largely rely onbrittle templates, focus on single-attack settings, and expose only a narrowsubset of vulnerabilities. To address these limitations, we introduce VERA-V, avariational inference framework that recasts multimodal jailbreak discovery aslearning a joint posterior distribution over paired text-image prompts.

119, TITLE: Uncertain Knowledge Graph Completion Via Semi-Supervised Confidence Distribution Learning
AUTHORS: Tianxing Wu; Shutong Zhu; Jingting Wang; Ning Xu; Guilin Qi; Haofen Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: This causes that the learnt embeddings are insufficient tohigh-quality UKG completion. Thus, in this paper, to address the above issue,we propose a new semi-supervised Confidence Distribution Learning (ssCDL)method for UKG completion, where each triple confidence is transformed into aconfidence distribution to introduce more supervision information of differentconfidences to reinforce the embedding learning process.

120, TITLE: End-to-end Listen, Look, Speak and Act
AUTHORS: Siyin Wang; Wenyi Yu; Xianzhao Chen; Xiaohai Tian; Jun Zhang; Lu Lu; Chao Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We present ELLSA (End-to-end Listen, Look, Speak and Act),which, to our knowledge, is the first full-duplex, end-to-end model thatsimultaneously perceives and generates across vision, text, speech, and actionwithin a single architecture, enabling interaction patterns previously out ofreach, yielding more natural, human-like behaviors.

121, TITLE: Soft-Masked Diffusion Language Models
AUTHORS: Michael Hersche; Samuel Moor-Smith; Thomas Hofmann; Abbas Rahimi
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: To address thislimitation, we introduce soft-masking (SM), a novel method that dynamicallyblends the embedding of the mask token with the embeddings of the top-$k$predicted tokens from the previous decoding step, for each retained mask.

122, TITLE: What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics
AUTHORS: Lennart Wachowiak; Andrew Coles; Gerard Canal; Oya Celiktutan
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: With the growing use of large language models and conversational interfacesin human-robot interaction, robots' ability to answer user questions is moreimportant than ever. We therefore introduce a dataset of 1,893 user questionsfor household robots, collected from 100 participants and organized into 12categories and 70 subcategories.

123, TITLE: ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling
AUTHORS: Shuyuan Zhang; Chenhan Jiang; Zuoou Li; Jiankang Deng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address theselimitations, we represent 3D assets as shape programs and introduce ShapeCraft,a novel multi-agent framework for text-to-3D generation.

124, TITLE: MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues
AUTHORS: Yaning Pan; Zekun Wang; Qianqian Xie; Yongqian Wen; Yuanxing Zhang; Guohui Zhang; Haoxuan Hu; Zhiyu Pan; Yibing Huang; Zhidong Gan; Yonghong Lin; An Ping; Tianhao Peng; Jiaheng Liu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However,existing evaluation benchmarks remain limited to single-turn questionanswering, overlooking the complexity of multi-turn dialogues in real-worldscenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic videounderstanding benchmark for evaluating MLLMs in multi-turn dialogues.Specifically, our MT-Video-Bench mainly assesses six core competencies thatfocus on perceptivity and interactivity, encompassing 987 meticulously curatedmulti-turn dialogues from diverse domains.

125, TITLE: A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications
AUTHORS: Minhua Lin; Zongyu Wu; Zhichao Xu; Hui Liu; Xianfeng Tang; Qi He; Charu Aggarwal; Hui Liu; Xiang Zhang; Suhang Wang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We summarize representativemethods, evaluation protocols, and applications, and discuss open challengesand future directions toward building reliable and scalable RL driven agenticsearch systems.

126, TITLE: WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection
AUTHORS: Nachuan Ma; Zhengfei Song; Qiang Hu; Xiaoyu Tang; Chengxi Zhang; Rui Fan; Lihua Xie
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To further boostdetection performance, we design a path-aware attention module (PAAM) thatfuses high-level semantics from the classifier with low-level structural cuesfrom the reconstructor by modeling spatial and channel-wise dependencies.Additionally, a center-enhanced CAM consistency module (CECCM) is proposed torefine crack CAMs using center Gaussian weighting and consistency constraints,enabling better pseudo-label generation.

127, TITLE: VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs
AUTHORS: Jiaying Zhu; Yurui Zhu; Xin Lu; Wenrui Yan; Dong Li; Kunlin Liu; Xueyang Fu; Zheng-Jun Zha
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To be specific, we propose VisionSelector, a scorermodule decoupled from the MLLM backbone that incorporates a differentiableTop-K mechanism and a curriculum annealing strategy to bridge thetraining-inference gap, enabling efficient and adaptive token selection variousarbitrary compression rates.

128, TITLE: DELULU: Discriminative Embedding Learning Using Latent Units for Speaker-Aware Self-Supervised Speech Foundational Model
AUTHORS: Massa Baali; Rita Singh; Bhiksha Raj
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: Self-supervised speech models have achieved remarkable success oncontent-driven tasks, yet they remain limited in capturingspeaker-discriminative features critical for verification, diarization, andprofiling applications. We introduce DELULU, a speaker-aware self-supervisedfoundational model that addresses this limitation by integrating externalsupervision into the pseudo-label generation process.

129, TITLE: Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition
AUTHORS: Jiahao Huo; Mufhumudzi Muthivhi; Terence L. van Zyl; Fredrik Gustafsson
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose a probability distribution based on an input's distance toits Nearest Class Mean (NCM).

130, TITLE: NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems
AUTHORS: Xiaozhe Li; Xinyu Fang; Shengyuan Ding; Linyang Li; Haodong Duan; Qingwen Liu; Kai Chen
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: However, their ability to solve more complexoptimization problems - particularly NP-hard tasks - remains underexplored. Tobridge this gap, we propose NP-ENGINE, the first comprehensive framework fortraining and evaluating LLMs on NP-hard problems.

131, TITLE: TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model
AUTHORS: Bin Yu; Xinming Wang; Shijie Lian; Haotian Li; Changti Wu; Ruina Hu; Bailing Wang; Yuliang Wei; Kai Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Large language models (LLMs) have shown remarkable progress in complexreasoning tasks, largely enabled by test-time scaling (TTS) paradigms thatallocate additional compute during inference.

132, TITLE: Modeling Expert Interactions in Sparse Mixture of Experts Via Graph Structures
AUTHORS: Minh-Khoi Nguyen-Nhat; Rachel S. Y. Teo; Laziz Abdullaev; Maurice Mok; Viet-Hoang Tran; Tan Minh Nguyen
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work,we introduce SymphonySMoE, a novel family of SMoE that introduces a socialgraph to model interactions among experts.

133, TITLE: Comprehending Spatio-temporal Data Via Cinematic Storytelling Using Large Language Models
AUTHORS: Panos Kalnis. Shuo Shang; Christian S. Jensen
CATEGORY: arxiv-cs.DB [DB]
HIGHLIGHT: Spatio-temporal data captures complex dynamics across both space and time,yet traditional visualizations are complex, require domain expertise and oftenfail to resonate with broader audiences. Here, we propose MapMuse, astorytelling-based framework for interpreting spatio-temporal datasets,transforming them into compelling, narrative-driven experiences.

134, TITLE: The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models
AUTHORS: Shivam Ratnakar; Sanjay Raghavendra
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We introduce two theoretically grounded metrics: theChameleon Score (0-1) that quantifies stance instability, and Source Re-useRate (0-1) that measures knowledge diversity.

135, TITLE: Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models
AUTHORS: Yuefeng Peng; Parnian Afshar; Megan Ganji; Thomas Butler; Amir Houmansadr; Mingxian Wang; Dezhi Hong
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Existingevaluations of unlearning methods focus on (1) the extent of forgetting of thetarget knowledge (forget set) and (2) maintaining performance on the retain set(i.e., utility).

136, TITLE: Disparities in Multilingual LLM-Based Healthcare Q&A
AUTHORS: Ipek Baris Schlicht; Burcu Sayin; Zhixue Zhao; Frederik M. Labonté; Cesare Barbera; Marco Viviani; Paolo Rosso; Lucie Flek
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We systematically examine cross-lingual disparities inpre-training source and factuality alignment in LLM answers for multilingualhealthcare Q&A across English, German, Turkish, Chinese (Mandarin), andItalian.

137, TITLE: VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction
AUTHORS: Djamel Eddine Boukhari
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We evaluate our approach on the benchmark SCUT-FBP5500 dataset.

138, TITLE: Atom-anchored LLMs Speak Chemistry: A Retrosynthesis Demonstration
AUTHORS: Alan Kai Hassen; Andrius Bernatavicius; Antonius P. A. Janssen; Mike Preuss; Gerard J. P. van Westen; Djork-Arné Clevert
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we introduce a framework for molecular reasoning usinggeneral-purpose Large Language Models (LLMs) that operates without requiringlabeled training data.

139, TITLE: A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications
AUTHORS: Lars Niedermeier; Vyom Shah; Jeffrey L. Krichmar
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: Spiking Neural Networks (SNNs) have sparse, event driven processing that canleverage neuromorphic applications. In this work, we introduce amulti-threading kernel that enables neuromorphic applications running at theedge, meaning they process sensory input directly and without any up-link to ordependency on a cloud service.

140, TITLE: One-step Diffusion Models with Bregman Density Ratio Matching
AUTHORS: Yuanzhi Zhu; Eleftherios Tsonis; Lucas Degeorge; Vicky Kalogeiton
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we proposeDi-Bregman, a compact framework that formulates diffusion distillation asBregman divergence-based density-ratio matching.

141, TITLE: A Physics-Guided AI Cascaded Corrector Model Significantly Extends Madden-Julian Oscillation Prediction Skill
AUTHORS: Xiao Zhou; Yuze Sun; Jie Wu; Xiaomeng Huang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: The Madden-Julian Oscillation (MJO) is an important driver of global weatherand climate extremes, but its prediction in operational dynamical modelsremains challenging, with skillful forecasts typically limited to 3-4 weeks.Here, we introduce a novel deep learning framework, the Physics-guided CascadedCorrector for MJO (PCC-MJO), which acts as a universal post-processor tocorrect MJO forecasts from dynamical models.

142, TITLE: RubiSCoT: A Framework for AI-Supported Academic Assessment
AUTHORS: Thorsten Fröhlich; Tim Schlippe
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: The framework includes preliminary assessments,multidimensional assessments, content extraction, rubric-based scoring, anddetailed reporting. We present the design and implementation of RubiSCoT,discussing its potential to optimize academic assessment processes throughconsistent, scalable, and transparent evaluation.

143, TITLE: FrugalPrompt: Reducing Contextual Overhead in Large Language Models Via Token Attribution
AUTHORS: Syed Rifat Raiyan; Md Farhan Ishmam; Abdullah Al Imran; Mohammad Ali Moni
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We evaluate the approach across four NLP tasks: SentimentAnalysis, Commonsense QA, Summarization, and Mathematical Reasoning, using asuite of frontier LLMs.

144, TITLE: Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction
AUTHORS: Ioannis Tsaknakis; Bingqing Song; Shuyu Gan; Dongyeop Kang; Alfredo Garcia; Gaowen Liu; Charles Fleming; Mingyi Hong
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This raises afundamental question: Can LLMs uncover and reason about such latent informationthrough conversation? We address this problem by introducing a unified benchmark for evaluatinglatent information discovery - the ability of LLMs to reveal and utilize hiddenuser attributes through multi-turn interaction.

145, TITLE: BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation
AUTHORS: Shujian Gao; Yuan Wang; Zekuan Yu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To this end, we introduce \textbf{Bilateral Alignmentin Representation and Label spaces (BARL)}, a unified framework that couplestwo collaborative branches and enforces alignment in both spaces.

146, TITLE: Generation Then Reconstruction: Accelerating Masked Autoregressive Models Via Two-Stage Sampling
AUTHORS: Feihong Yan; Peiru Wang; Yao Zhu; Kaiyu Pang; Qingyan Wei; Huiqi Li; Linfeng Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Masked Autoregressive (MAR) models promise better efficiency in visualgeneration than autoregressive (AR) models for the ability of parallelgeneration, yet their acceleration potential remains constrained by themodeling complexity of spatially correlated visual tokens in a single step. Toaddress this limitation, we introduce Generation then Reconstruction (GtR), atraining-free hierarchical sampling strategy that decomposes generation intotwo stages: structure generation establishing global semantic scaffolding,followed by detail reconstruction efficiently completing remaining tokens.Assuming that it is more difficult to create an image from scratch than tocomplement images based on a basic image framework, GtR is designed to achieveacceleration by computing the reconstruction stage quickly while maintainingthe generation quality by computing the generation stage slowly.

147, TITLE: Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition
AUTHORS: Binyuan Huang; Yongdong Luo; Xianda Guo; Xiawu Zheng; Zheng Zhu; Jiahui Pan; Chengju Zhou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, existing methods typicallyuse predefined regions for temporal modeling, with fixed or equivalent temporalscales assigned to different types of regions, which makes it difficult tomodel motion regions that change dynamically over time and adapt to theirspecific patterns. To tackle this problem, we introduce a Region-aware DynamicAggregation and Excitation framework (GaitRDAE) that automatically searches formotion regions, assigns adaptive temporal scales and applies correspondingattention.

148, TITLE: Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis
AUTHORS: Praveenbalaji Rajendran; Mojtaba Safari; Wenfeng He; Mingzhe Hu; Shansong Wang; Jun Zhou; Xiaofeng Yang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Recent advancements in artificial intelligence (AI), particularly foundationmodels (FMs), have revolutionized medical image analysis, demonstrating strongzero- and few-shot ...

149, TITLE: Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement Via Condition Refinement
AUTHORS: Xiaogang Xu; Jian Wang; Yunfan Lu; Ruihang Chu; Ruixing Wang; Jiafei Wu; Bei Yu; Liang Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We identify twoprimary causes of fidelity loss: the absence of suitable conditional latentmodeling and the lack of bidirectional interaction between the conditionallatent and noisy latent in the diffusion process. To address this, we propose anovel optimization strategy for conditioning in pre-trained diffusion models,enhancing fidelity while preserving realism and aesthetics.

150, TITLE: Evaluating Medical LLMs By Levels of Autonomy: A Survey Moving from Benchmarks to Applications
AUTHORS: Xiao Ye; Jacob Dineen; Zhaonan Li; Zhikun Xu; Weiyu Chen; Shijie Lu; Yuxi Huang; Ming Shen; Phu Tran; Ji-Eun Irene Yum; Muhammad Ali Khan; Muhammad Umar Afzal; Irbaz Bin Riaz; Ben Zhou
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Medical Large language models achieve strong scores on standard benchmarks;however, the transfer of those results to safe and reliable performance inclinical workflows remains a challenge.

151, TITLE: Toward Understanding Security Issues in The Model Context Protocol Ecosystem
AUTHORS: Xiaofan Li; Xing Gao
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: In this paper, we present the firstcomprehensive security analysis of the MCP ecosystem.

152, TITLE: Mapping Post-Training Forgetting in Language Models at Scale
AUTHORS: Jackson Harmon; Andreas Hochlehnert; Matthias Bethge; Ameya Prabhu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Hence,we propose a sample-wise paradigm to measure what is forgotten and whenbackward transfer occurs.

153, TITLE: Unbiased Gradient Low-Rank Projection
AUTHORS: Rui Pan; Yang Luo; Yuxing Liu; Yang You; Tong Zhang
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We theoretically prove our method matches theconvergence guarantees of the base Muon algorithm while preserving the memoryefficiency of low-rank techniques.

154, TITLE: DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation Via Decoupled Branch Optimization
AUTHORS: Thanh-Huy Nguyen; Hoang-Thien Nguyen; Vi Vu; Ba-Thinh Lam; Phat Huynh; Tianyang Wang; Xingjian Li; Ulas Bagci; Min Xu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To improve consistency under noisyconditions, we introduce Decoupled Dropout Perturbation, enforcingregularization across branches.

155, TITLE: StripRFNet: A Strip Receptive Field and Shape-Aware Network for Road Damage Detection
AUTHORS: Jianhan Lin; Yuchu Qin; Shuai Gao; Yikang Rui; Jie Liu; Yanjie Lv
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Well-maintained road networks are crucial for achieving SustainableDevelopment Goal (SDG) 11. Road surface damage not only threatens trafficsafety but also hinders sustainable ...

156, TITLE: Towards Automatic Evaluation and Selection of PHI De-identification Models Via Multi-Agent Collaboration
AUTHORS: Guanchen Wu; Zuhui Chen; Yuzhang Xie; Carl Yang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We present TEAM-PHI, a multi-agent evaluation and selectionframework that uses large language models (LLMs) to automatically measurede-identification quality and select the best-performing model without heavyreliance on gold labels.

157, TITLE: Segmentation As A Plug-and-Play Capability for Frozen Multimodal LLMs
AUTHORS: Jiazhen Liu; Long Chen
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To equip MLLMs withpixel-level segmentation abilities, prevailing methods require finetuning themodel to produce specific outputs compatible with a mask decoder. This processtypically alters the model's output space and compromises its intrinsicgeneralization, which undermines the goal of building a unified model.

158, TITLE: LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena
AUTHORS: Qingchuan Yang; Simon Mahns; Sida Li; Anri Gu; Jibang Wu; Haifeng Xu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To this end,we build Prophet Arena, a general evaluation benchmark that continuouslycollects live forecasting tasks and decomposes each task into distinct pipelinestages, in order to support our controlled and large-scale experimentation.

159, TITLE: Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling
AUTHORS: Tingsong Xiao; Yao An Lee; Zelin Xu; Yupu Zhang; Zibo Liu; Yu Huang; Jiang Bian; Serena Jingchuan Guo; Zhe Jiang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: To address theselimitations, we propose Temporally Detailed Hypergraph Neural OrdinaryDifferential Equation (TD-HNODE), which represents disease progression onclinically recognized trajectories as a temporally detailed hypergraph andlearns the continuous-time progression dynamics via a neural ODE framework.TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures theinterdependency of disease complication markers within both intra- andinter-progression trajectories.

160, TITLE: Explainable Heterogeneous Anomaly Detection in Financial Networks Via Adaptive Expert Routing
AUTHORS: Zan Li; Rui Fan
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Three unsolved challenges persist: (1) staticgraph structures cannot adapt when market correlations shift during regimechanges; (2) uniform detection mechanisms miss type-specific signatures acrossmultiple temporal scales while failing to integrate individual behaviors withnetwork contagion; (3) black-box outputs provide no actionable guidance onanomaly mechanisms or their temporal evolution. We address these via adaptive graph learning with specialized expert networksthat provide built-in interpretability.

161, TITLE: Ripple Effect Protocol: Coordinating Agent Populations
AUTHORS: Ayush Chopra; Aman Sharma; Feroz Ahmad; Luca Muscariello; Vijoy Pandey; Ramesh Raskar
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: We introduce theRipple Effect Protocol (REP), a coordination protocol in which agents share notonly their decisions but also lightweight sensitivities - signals expressinghow their choices would change if key environmental variables shifted.

162, TITLE: From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors
AUTHORS: Zhengshen Zhang; Hao Li; Yalun Dai; Zhengbang Zhu; Lei Zhou; Chenchen Liu; Dong Wang; Francis E. H. Tay; Sijin Chen; Ziwei Liu; Yuxiao Liu; Xinghang Li; Pan Zhou
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: Inthis work, we introduce FALCON (From Spatial to Action), a novel paradigm thatinjects rich 3D spatial tokens into the action head.

163, TITLE: Humanoid-inspired Causal Representation Learning for Domain Generalization
AUTHORS: Ze Tao; Jian Zhang; Haowei Li; Xianshuai Li; Yifei Peng; Xiyao Liu; Senzhang Wang; Chao Liu; Sheng Ren; Shichao Zhang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), anovel causal framework inspired by human intelligence, designed to overcome thelimitations of conventional domain generalization models.

164, TITLE: Verification-Aware Planning for Multi-Agent Systems
AUTHORS: Tianyang Xu; Dan Zhang; Kushan Mitra; Estevam Hruschka
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We evaluate VeriMAP on diverse datasets,demonstrating that it outperforms both single- and multi-agent baselines whileenhancing system robustness and interpretability.

165, TITLE: RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile
AUTHORS: Ao Tian; Yunfeng Lu; Xinxin Fan; Changhao Wang; Lanzhi Zhou; Yeyao Zhang; Yanfang Liu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Torealize the long-term memory and behavioral consistency for Language Agents inLLM era, we propose a self-evolving memory framework RGMem, inspired by theideology of classic renormalization group (RG) in physics, this frameworkenables to organize the dialogue history in multiple scales: it first extractssemantics and user insights from episodic fragments, then through hierarchicalcoarse-graining and rescaling operations, progressively forms adynamically-evolved user profile.

166, TITLE: ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion
AUTHORS: Wei Huang; Peining Li; Meiyu Liang; Xu Hou; Junping Du; Yingxia Shao; Guanhua Ye; Wu Liu; Kangkang Lu; Yang Yu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Moreover, applying Multimodal Large Language Models(MLLMs) to the task of MKGC introduces significant challenges: (1) the largenumber of image tokens per entity leads to semantic noise and modalityconflicts, and (2) the high computational cost of processing large tokeninputs. To address these issues, we propose Efficient Lightweight MultimodalLarge Language Models (ELMM) for MKGC.

167, TITLE: A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in The Physical World
AUTHORS: Wei Zhang; Zhanhao Hu; Xiao Li; Xiaopei Zhu; Xiaolin Hu
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To defendagainst these attacks, researchers have proposed various defense methodsagainst adversarial patches, a typical form of physically-realizable attack.However, our experiments showed that simply enlarging the patch size could makethese defense methods fail. Motivated by this, we evaluated various defensemethods against adversarial clothes which have large coverage over the humanbody.

168, TITLE: 4DSegStreamer: Streaming 4D Panoptic Segmentation Via Dual Threads
AUTHORS: Ling Liu; Jun Tian; Li Yi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we introduce4DSegStreamer, a novel framework that employs a Dual-Thread System toefficiently process streaming frames.

169, TITLE: Registration Is A Powerful Rotation-Invariance Learner for 3D Anomaly Detection
AUTHORS: Yuyang Yu; Zhengwei Chen; Xuemiao Xu; Lei Zhang; Haoxin Yang; Yongwei Nie; Shengfeng He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To thisend, we propose a registration-induced, rotation-invariant feature extractionframework that integrates the objectives of point-cloud registration andmemory-based anomaly detection.

170, TITLE: Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation
AUTHORS: Rui Yang; Huining Li; Yiyi Long; Xiaojun Wu; Shengfeng He
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Generating sketches guided by reference styles requires precise transfer ofstroke attributes, such as line thickness, deformation, and texture sparsity,while preserving semantic ...

171, TITLE: WaMaIR: Image Restoration Via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement
AUTHORS: Shengyu Zhu; Fuxuan Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, wepropose WaMaIR, which is a novel framework with a large receptive field forimage perception and improves the reconstruction of texture details in restoredimages.

172, TITLE: Automated C-Arm Positioning Via Conformal Landmark Localization
AUTHORS: Ahmad Arrabi; Jay Hwasung Jung; Jax Luo; Nathan Franssen; Scott Raymond; Safwan Wshah
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we present apipeline that autonomously navigates the C-arm to predefined anatomicallandmarks utilizing X-ray images.

173, TITLE: C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy
AUTHORS: Ahmad Arrabi; Jay hwasung Jung; J Le; A Nguyen; J Reed; E Stahl; Nathan Franssen; Scott Raymond; Safwan Wshah
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work, we introduce a self-supervised framework that classifiesvarious skeletal landmarks using a regression-based pretext task.

174, TITLE: I- RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models
AUTHORS: Giacomo Camposampiero; Michael Hersche; Roger Wattenhofer; Abu Sebastian; Abbas Rahimi
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce I-RAVEN-X, a symbolic benchmark designed to evaluategeneralization and robustness in analogical and mathematical reasoning forLarge Language Models (LLMs) and Large Reasoning Models (LRMs).

175, TITLE: Rewarding The Journey, Not Just The Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning
AUTHORS: Chenwei Tang; Jingyu Xing; Xinyu Liu; Wei Ju; Jiancheng Lv; Deng Xiong; Ziyue Qiao
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We introduce COMPASS (Composite Path and Answer Self-Scoring), a noveltest-time reward mechanism that operates without external supervision.

176, TITLE: Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries
AUTHORS: Cansu Erdogan; Cesar Alan Contreras; Alireza Rastegarpanah; Manolis Chiou; Rustam Stolkin
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: This paper addresses the problem of planning complex manipulation tasks, inwhich multiple robots with different end-effectors and capabilities, informedby computer vision, must plan and execute concatenated sequences of actions ona variety of objects that can appear in arbitrary positions and configurationsin unstructured scenes. We propose an intent-driven planning pipeline which canrobustly construct such action sequences with varying degrees of supervisoryinput from a human using simple language instructions.

177, TITLE: Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards
AUTHORS: Xuan Zhang; Ruixiao Li; Zhijian Zhou; Long Li; Yulei Qin; Ke Li; Xing Sun; Xiaoyu Tan; Chao Qu; Yuan Qi
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this paper, we study the central question of how to designexploration for LLM reasoning and introduce MERCI (Motivating Exploration inLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm thataugments policy optimization with a principled intrinsic reward.

178, TITLE: CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams
AUTHORS: Junhao Zhao; Zishuai Liu; Ruili Fang; Jin Lu; Linghan Zhang; Fei Dou
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We propose ContrastiveAlignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), anend-to-end framework that jointly optimizes representation learning viaSequence-Image Contrastive Alignment (SICA) and classification viacross-entropy, ensuring both cross-representation alignment and task-specificdiscriminability.

179, TITLE: U-Codec: Ultra Low Frame-rate Neural Speech Codec for Fast High-fidelity Speech Generation
AUTHORS: Xusheng Yang; Long Zhou; Wenfu Wang; Kai Hu; Shulin Feng; Chenxing Li; Meng Yu; Dong Yu; Yuexian Zou
CATEGORY: arxiv-cs.SD [SD]
HIGHLIGHT: We propose \textbf{U-Codec}, an \textbf{U}ltra low frame-rate neural speech\textbf{Codec} that achieves high-fidelity reconstruction and fast speechgeneration at an extremely low frame-rate of 5Hz (5 frames per second).

180, TITLE: Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts
AUTHORS: Yongxiang Hua; Haoyu Cao; Zhou Tao; Bocheng Li; Zihao Wu; Chaohu Liu; Linli Xu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose Input Domain Aware MoE,a novel routing framework that leverages a probabilistic mixture model tobetter partition the input space.

181, TITLE: From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display
AUTHORS: Xiangyu Mu; Dongliang Zhou; Jie Hou; Haijun Zhang; Weili Guan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: To address the loss of fine facial details due to latent spacecompression, we introduce a mirror loss applied in pixel space through adenoising diffusion implicit model (DDIM)-based one-step denoising.Additionally, we design a distribution-aware adapter that aligns statisticaldistributions of identity and clothing features to enhance temporal coherence.Extensive experiments on the UBC fashion dataset, our self-constructed ASOSdataset, and the newly collected MannequinVideos dataset captured on-sitedemonstrate that M2HVideo achieves superior performance in terms of clothingconsistency, identity preservation, and video fidelity in comparison tostate-of-the-art methods.

182, TITLE: Quantifying Multimodal Imbalance: A GMM-Guided Adaptive Loss for Audio-Visual Learning
AUTHORS: Zhaocheng Liu; Zhiwen Yu; Xiaoqing Liu
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Current mainstream approaches to addressing multimodal imbalance primarilyfocus on architectural modifications and optimization-based, often overlookinga quantitative analysis of the imbalance degree between modalities. To addressthis gap, our work introduces a novel method for the quantitative analysis ofmulti-modal imbalance, which in turn informs the design of a sample-leveladaptive loss function.We begin by defining the "Modality Gap" as thedifference between the Softmax scores of different modalities (e.g., audio andvisual) for the ground-truth class prediction.

183, TITLE: SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection
AUTHORS: Yang Feng; Xudong Pan
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: Existing defenses often fall short due to reactivedesigns or centralized architectures which may introduce single points offailure. To address these challenges, we propose SentinelNet, the firstdecentralized framework for proactively detecting and mitigating maliciousbehaviors in multi-agent collaboration.

184, TITLE: Diagnosing Representation Dynamics in NER Model Extension
AUTHORS: Xirui Zhang; Philippe de La Chevasnerie; Benoit Fabre
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Extending Named Entity Recognition (NER) models to new PII entities in noisyspoken-language data is a common need.

185, TITLE: Lingua Custodi's Participation at The WMT 2025 Terminology Shared Task
AUTHORS: Jingshu Liu; Raheel Qader; Gaëtan Caillaut; Mariam Nakhlé
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We show that introducing a pre-trained multilinguallanguage model dramatically reduces the amount of parallel training datarequired to achieve good performance by 80%.

186, TITLE: Hallucination Benchmark for Speech Foundation Models
AUTHORS: Alkis Koudounas; Moreno La Quatra; Manuel Giollo; Sabato Marco Siniscalchi; Elena Baralis
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Consequently, there is a critical need for new evaluationframeworks that can effectively identify and assess models with a heightenedpropensity for generating hallucinated content.

187, TITLE: Rethinking Nighttime Image Deraining Via Learnable Color Space Transformation
AUTHORS: Qiyuan Guan; Xiang Chen; Guiyue Jin; Jiyu Jin; Shumin Fan; Tianyu Song; Jinshan Pan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we rethink the task of nighttimeimage deraining and contribute a new high-quality benchmark, HQ-NightRain,which offers higher harmony and realism compared to existing datasets.

188, TITLE: So Much Depends / Upon / A Whitespace: Why Whitespace Matters for Poets and LLMs
AUTHORS: Sriharsh Bhyravajjula; Melanie Walsh; Anna Preus; Maria Antoniak
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Using a corpus of 19k English-language published poems from PoetryFoundation, we investigate how 4k poets have used whitespace in their works.

189, TITLE: Mixed-Precision Quantization for Language Models: Techniques and Prospects
AUTHORS: Mariam Rakka; Marios Fournarakis; Olga Krestinskaya; Jinane Bazzi; Khaled N. Salama; Fadi Kurdahi; Ahmed M. Eltawil; Mohammed E. Fouda
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: The rapid scaling of language models (LMs) has resulted in unprecedentedcomputational, memory, and energy requirements, making their training anddeployment increasingly ...

190, TITLE: KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation
AUTHORS: WenBo Xu; Liu Liu; Li Zhang; Ran Zhang; Hao Wu; Dan Guo; Meng Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Abstract: Articulated objects, such as laptops and drawers, exhibit significantchallenges for 3D reconstruction and pose estimation due to their multi-partgeometries and variable joint ...

191, TITLE: Elastic ViTs from Pretrained Models Without Retraining
AUTHORS: Walter Simoncini; Michael Dorkenwald; Tijmen Blankevoort; Cees G. M. Snoek; Yuki M. Asano
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Our key contributions include an efficient pruningstrategy for pretrained Vision Transformers, a novel evolutionary approximationof Hessian off-diagonal structures, and a self-supervised importance scoringmechanism that maintains strong performance without requiring retraining orlabels.

192, TITLE: Rethinking On-policy Optimization for Query Augmentation
AUTHORS: Zhichao Xu; Shengyao Zhuang; Xueguang Ma; Bingsen Chen; Yijun Tian; Fengran Mo; Jie Cao; Vivek Srikumar
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we present the first systematiccomparison of prompting-based and RL-based query augmentation across diversebenchmarks, including evidence-seeking, ad hoc, and tool retrieval.

193, TITLE: Towards 3D Objectness Learning in An Open World
AUTHORS: Taichi Liu; Zhenyu Wang; Ruofeng Liu; Guang Wang; Desheng Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we delve into learning open-world 3Dobjectness, which focuses on detecting all objects in a 3D scene, includingnovel objects unseen during training.

194, TITLE: GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image
AUTHORS: Yinghui Wang; Xinyu Zhang; Peng Du
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, currentmulti-modal large language models (MLLMs) still struggle with accuratelyinferring 3D geometry from 2D images due to limited spatial reasoningcapabilities. We address this limitation by introducing GACO-CAD, a noveltwo-stage post-training framework.

195, TITLE: Closing The Sim2Real Performance Gap in RL
AUTHORS: Akhil S Anand; Shambhuraj Sawant; Jasper Hoffmann; Dirk Reinhardt; Sebastien Gros
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose a novel framework to address thisissue by directly adapting the simulator parameters based on real-worldperformance.

196, TITLE: The Parameterized Complexity of Computing The VC-Dimension
AUTHORS: Florent Foucaud; Harmender Gahlawat; Fionn Mc Inerney; Prafullkumar Tale
CATEGORY: arxiv-cs.CC [CC]
HIGHLIGHT: In particular, given a hypergraph$\mathcal{H}=(\mathcal{V},\mathcal{E})$, we prove that the naive$2^{\mathcal{O}(|\mathcal{V}|)}$-time algorithm is asymptotically tight underthe Exponential Time Hypothesis (ETH).

197, TITLE: The Burden of Interactive Alignment with Inconsistent Preferences
AUTHORS: Ali Shirali
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: From media platforms to chatbots, algorithms shape how people interact,learn, and discover information.

198, TITLE: Personalized Image Filter: Mastering Your Photographic Style
AUTHORS: Chengxuan Zhu; Shuchen Weng; Jiacong Fang; Peixuan Zhang; Si Li; Chao Xu; Boxin Shi
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Previous works either fail to learn meaningfulphotographic concepts from reference images, or cannot preserve the content ofthe content image. To tackle these issues, we proposed a Personalized ImageFilter (PIF).

199, TITLE: Bridging Accuracy and Interpretability: Deep Learning with XAI for Breast Cancer Detection
AUTHORS: Bishal Chhetri; B. V. Rathish Kumar
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this study, we present an interpretable deep learning framework for theearly detection of breast cancer using quantitative features extracted fromdigitized fine needle aspirate (FNA) images of breast masses.

200, TITLE: SAMOSA: Sharpness Aware Minimization for Open Set Active Learning
AUTHORS: Young In Kim; Andrea Agiollo; Rajiv Khanna
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Abstract: Modern machine learning solutions require extensive data collection wherelabeling remains costly. To reduce this burden, open set active learningapproaches aim to select ...

201, TITLE: CBINNS: Cancer Biology-Informed Neural Network for Unknown Parameter Estimation and Missing Physics Identification
AUTHORS: Bishal Chhetri; B. V. Rathish Kumar
CATEGORY: arxiv-q-bio.QM [QM]
HIGHLIGHT: In this study, we develop acancer biology-informed neural network model(CBINN) to infer the unknownparameters in the system of equations as well as to discover the missingphysics from sparse and noisy measurements.

202, TITLE: Call-Center Staff Scheduling Considering Performance Evolution Under Emotional Stress
AUTHORS: Yujun Zheng; Xinya Chen; Xueqin Lu; Weiguo Sheng; Shengyong Chen
CATEGORY: arxiv-cs.NE [NE]
HIGHLIGHT: We study a call-center staff scheduling problem, which considers theevolution of work performance of staff under emotional stress.

203, TITLE: Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening
AUTHORS: Xin Wang; Yu Wang; Yunchao Liu; Jens Meiler; Tyler Derr
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: Overall, thiswork introduces novel perspectives on effectively enhancing VS by leveraginggenerative augmentations, reranking, and general scaffold-awareness.

204, TITLE: See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models
AUTHORS: Shuo Han; Yukun Cao; Zezhong Ding; Zengyi Gao; S Kevin Zhou; Xike Xie
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: Vision-language models (VLMs) have shown promise in graph understanding, butremain limited by input-token constraints, facing scalability bottlenecks andlacking effective mechanisms to coordinate textual and visual modalities. Toaddress these challenges, we propose GraphVista, a unified framework thatenhances both scalability and modality coordination in graph understanding.

205, TITLE: XDXD: End-to-end Crystal Structure Determination with Low Resolution X-ray Diffraction
AUTHORS: Jiale Zhao; Cong Liu; Yuxuan Zhang; Chengyue Gong; Zhenyi Zhang; Shifeng Jin; Zhenyu Liu
CATEGORY: arxiv-cond-mat.mtrl-sci [MTRL-SCI]
HIGHLIGHT: While recent deep learning models have madebreakthroughs in solving the crystallographic phase problem, the resultinglow-resolution electron density maps are often ambiguous and difficult tointerpret. To overcome this critical bottleneck, we introduce XDXD, to ourknowledge, the first end-to-end deep learning framework to determine a completeatomic model directly from low-resolution single-crystal X-ray diffractiondata.

206, TITLE: Back to Bytes: Revisiting Tokenization Through UTF-8
AUTHORS: Amit Moryossef; Clara Meister; Pavel Stepachev; Desmond Elliott
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: We present UTF8Tokenizer, a minimalist byte-level tokenizer that maps textexactly to IDs corresponding to the bytes underlying the text's UTF-8 encoding(e.g., byte x09 is token ID 9).

207, TITLE: SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation
AUTHORS: Mehdi Zekriyapanah Gashti; Mostafa Mohammadpour; Ghasem Farjamnia
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this paper, we introduce a novelSaliency-Guided Cross-Layer Deep Feature Fusion framework (SG-CLDFF) thattightly integrates saliency-driven preprocessing with multi-scale deep featureaggregation to improve both robustness and interpretability for WBC analysis.SG-CLDFF first computes saliency priors to highlight candidate WBC regions andguide subsequent feature extraction.

208, TITLE: Safire: Similarity Framework for Visualization Retrieval
AUTHORS: Huyen N. Nguyen; Nils Gehlenborg
CATEGORY: arxiv-cs.HC [HC]
HIGHLIGHT: We introduce the Similarity Framework forVisualization Retrieval (Safire), a conceptual model that frames visualizationsimilarity along two dimensions: comparison criteria and representationmodalities.

209, TITLE: LILO: Bayesian Optimization with Interactive Natural Language Feedback
AUTHORS: Katarzyna Kobalczyk; Zhiyuan Jerry Lin; Benjamin Letham; Zhuokai Zhao; Maximilian Balandat; Eytan Bakshy
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We propose a language-in-the-loop framework that uses a largelanguage model (LLM) to convert unstructured feedback in the form of naturallanguage into scalar utilities to conduct BO over a numeric search space.Unlike preferential BO, which only accepts restricted feedback formats andrequires customized models for each domain-specific problem, our approachleverages LLMs to turn varied types of textual feedback into consistent utilitysignals and to easily include flexible user priors without manual kerneldesign.

210, TITLE: DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving Through Metric-Guided Alignment
AUTHORS: Yu Gao; Anqing Jiang; Yiru Wang; Heng Yuwen; Wang Shuo; Sun Hao; Wang Jijun
CATEGORY: arxiv-cs.RO [RO]
HIGHLIGHT: In contrast, Vision-Language-Action (VLA)models leverage world knowledge to handle challenging cases, but their limited3D reasoning capability can lead to physically infeasible actions.

211, TITLE: Zero-Shot Performance Prediction for Probabilistic Scaling Laws
AUTHORS: Viktoria Schram; Markus Hiller; Daniel Beck; Trevor Cohn
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we formulatethe prediction task as a multitask learning problem, where each task's data ismodelled as being organized within a two-layer hierarchy.

212, TITLE: Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model
AUTHORS: Xinwei Zhang; Hu Chen; Zhe Yuan; Sukun Tian; Peng Feng
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: 2) We propose a semantic-guided contrastive learning method to addressthe issue of weak supervision in contrastive learning.

213, TITLE: Disentangling Hyperedges Through The Lens of Category Theory
AUTHORS: Yoonho Lee; Junseok Lee; Sangwoo Seo; Sungwon Kim; Yeongmin Kim; Chanyoung Park
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: This paper presents an analysis of hyperedgedisentanglement from a category-theoretical perspective and proposes a novelcriterion for disentanglement derived from the naturality condition.

214, TITLE: Aria Gen 2 Pilot Dataset
AUTHORS: Chen Kong; James Fort; Aria Kang; Jonathan Wittmer; Simon Green; Tianwei Shen; Yipu Zhao; Cheng Peng; Gustavo Solaira; Andrew Berkovich; Nikhil Raina; Vijay Baiyya; Evgeniy Oleinik; Eric Huang; Fan Zhang; Julian Straub; Mark Schwesinger; Luis Pesqueira; Xiaqing Pan; Jakob Julian Engel; Carl Ren; Mingfei Yan; Richard Newcombe
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Theinitial release features Dia'ane, our primary subject, who records her dailyactivities alongside friends, each equipped with Aria Gen 2 glasses.

215, TITLE: Justitia: Fair and Efficient Scheduling for LLM Applications
AUTHORS: Mingyan Yang; Guanjie Wang; Manqi Luo; Yifei Liu; Chen Chen; Han Zhao; Yu Feng; Quan Chen; Minyi Guo
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this paper, we propose to serve LLM applications in afair and also efficient manner.

216, TITLE: Small Language Models Offer Significant Potential for Science Community
AUTHORS: Jian Zhang
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: A curated corpus ofapproximately 77 million high-quality sentences, extracted from 95 leadingpeer-reviewed geoscience journals such as Geophysical Research Letters andEarth and Planetary Science Letters published during years 2000 to 2024, wasconstructed. MiniLMs enable a computationally efficient approach for extractingrelevant domain-specific information from these corpora through semantic searchtechniques and sentence-level indexing.

217, TITLE: When AI Companions Become Witty: Can Human Brain Recognize AI-generated Irony?
AUTHORS: Xiaohui Rao; Hanlin Wu; Zhenguang G. Cai
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: This study investigates whether people adopt theintentional stance, attributing mental states to explain behavior,toward AIduring irony comprehension.

218, TITLE: Decoding Glycosylation in Neurodegenerative Diseases: Mechanistic Insights and Therapeutic Opportunities
AUTHORS: Haihan Yu; Xing Chen; Yang Yang; Mengke Gu; Kaidi Ren; Ziqing Wei
CATEGORY: The FASEB Journal [THE FASEB JOURNAL]
HIGHLIGHT: This review provides a comprehensive overview of the molecular mechanisms by which the two predominant forms of glycosylation, N‐glycosylation and O‐GlcNAcylation, contribute to protein misfolding, synaptic dysfunction, neuroinflammation, and impaired stress responses in the diseased nervous system.

219, TITLE: LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding
AUTHORS: ZhaoYang Han; Qihan Lin; Hao Liang; Bowen Chen; Zhou Liu; Wentao Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce \textbf{LongInsightBench}, the first benchmark designed toassess models' ability to understand long videos, with a focus on humanlanguage, viewpoints, actions, and other contextual elements, while integrating\textbf{visual, audio, and text} modalities.

220, TITLE: Do Satellite Tasks Need Special Pretraining?
AUTHORS: Ani Vanyan; Alvard Barseghyan; Hakob Tamazyan; Tigran Galstyan; Vahan Huroyan; Naira Hovakimyan; Hrant Khachatrian
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: In this work wesystematically challenge the idea that specific foundation models are moreuseful than general-purpose vision foundation models, at least in the smallscale.

221, TITLE: HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection
AUTHORS: Guang Yang; Yujie Zhu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: Pre-trained language models (PLMs) are increasingly being applied tocode-related tasks.

222, TITLE: CrossGuard: Safeguarding MLLMs Against Joint-Modal Implicit Malicious Attacks
AUTHORS: Xu Zhang; Hao Li; Zhichao Lu
CATEGORY: arxiv-cs.CR [CR]
HIGHLIGHT: We propose ImpForge, an automatedred-teaming pipeline that leverages reinforcement learning with tailored rewardmodules to generate diverse implicit samples across 14 domains.

223, TITLE: Zeroth-Order Sharpness-Aware Learning with Exponential Tilting
AUTHORS: Xuchen Gong; Tian Li
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: We explore new zeroth-order algorithms to solve a softSAM objective parameterized by a tilting parameter $t$.

224, TITLE: Does GenAI Rewrite How We Write? An Empirical Study on Two-Million Preprints
AUTHORS: Minfeng Qi; Zhongmin Cao; Qin Wang; Ningran Li; Tianqing Zhu
CATEGORY: arxiv-cs.CY [CY]
HIGHLIGHT: We introduce amulti-level analytical framework that integrates interrupted time-seriesmodels, collaboration and productivity metrics, linguistic profiling, and topicmodeling to assess changes in volume, authorship, style, and disciplinaryorientation.

225, TITLE: On The Provable Importance of Gradients for Language-Assisted Image Clustering
AUTHORS: Bo Peng; Jie Lu; Guangquan Zhang; Zhen Fang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Existing filtering strategies arepredominantly based on the off-the-shelf feature space learned by CLIP;however, despite being intuitive, these strategies lack a rigorous theoreticalfoundation. To fill this gap, we propose a novel gradient-based framework,termed as GradNorm, which is theoretically guaranteed and shows strongempirical performance.

226, TITLE: GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation
AUTHORS: Junbo Li; Weimin Yuan; Yinuo Wang; Yue Zeng; Shihao Shu; Cai Meng; Xiangzhi Bai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, thesemethods often face difficulties with textureless objects and varyingillumination conditions. To overcome these limitations, we propose GS2POSE, anovel approach for 6D object pose estimation.

227, TITLE: ConsistEdit: Highly Consistent and Precise Training-free Visual Editing
AUTHORS: Zixin Yin; Ling-Hao Chen; Lionel Ni; Xili Dai
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Building on these, we propose ConsistEdit, a novel attentioncontrol method specifically tailored for MM-DiT.

228, TITLE: Token-Level Inference-Time Alignment for Vision-Language Models
AUTHORS: Kejia Chen; Jiawen Zhang; Jiacong Hu; Kewei Gao; Jian Lou; Zunlei Feng; Mingli Song
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Existing alignmentapproaches often rely on expensive fine-tuning with annotated preference dataor sequence-level inference strategies that provide only coarse, delayedfeedback. To overcome these limitations, we present TITA (Token-levelInference-Time Alignment), a lightweight framework that freezes the base VLMand instead trains a reward model to approximate its distribution.

229, TITLE: GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection
AUTHORS: Xin Gao; Jiyao Liu; Guanghao Li; Yueming Lyu; Jianxiong Gao; Weichen Yu; Ningsheng Xu; Liang Wang; Caifeng Shan; Ziwei Liu; Chenyang Si
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, existing approaches typically rely onperturbing text-conditioned embeddings, resulting in semantic instability andinsufficient shift diversity, which limit generalization to realistic OOD. Toaddress these challenges, we propose GOOD, a novel and flexible framework thatdirectly guides diffusion sampling trajectories towards OOD regions usingoff-the-shelf in-distribution (ID) classifiers.

230, TITLE: LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis
AUTHORS: Huiyuan Xie; Chenyang Li; Huining Zhu; Chubin Zhang; Yuxiao Ye; Zhenghao Liu; Zhiyuan Liu
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this work, we present a novelframework for explicitly modeling legal reasoning in the analysis of Chinesetort-related civil cases.

231, TITLE: Select-Then-Decompose: From Empirical Analysis to Adaptive Selection Strategy for Task Decomposition in Large Language Models
AUTHORS: Shuodi Liu; Yingzhuo Liu; Zi Wang; Yusheng Wang; Huijia Wu; Liuyu Xiang; Zhaofeng He
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this study, wefirst conduct a comprehensive investigation on task decomposition, identifyingsix categorization schemes.

232, TITLE: MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning
AUTHORS: Alejandro Guerra-Manzanares; Farah E. Shamout
CATEGORY: arxiv-cs.LG [LG]
HIGHLIGHT: In this work, we present theModality-Informed Learning ratE Scheduler (MILES) for training multimodal jointfusion models in a balanced manner.

233, TITLE: Universal and Transferable Attacks on Pathology Foundation Models
AUTHORS: Yuntian Wang; Xilin Yang; Che-Yung Shen; Nir Pillar; Aydogan Ozcan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce Universal and Transferable Adversarial Perturbations (UTAP) forpathology foundation models that reveal critical vulnerabilities in theircapabilities.

234, TITLE: Expose Camouflage in The Water: Underwater Camouflaged Instance Segmentation and Dataset
AUTHORS: Chuhong Wang; Hua Li; Chongyi Li; Huazhong Liu; Xiongxin Tang; Sam Kwong
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Traditionalcamouflaged instance segmentation methods, trained on terrestrial-dominateddatasets with limited underwater samples, may exhibit inadequate performance inunderwater scenes. To address these issues, we introduce the first underwatercamouflaged instance segmentation (UCIS) dataset, abbreviated as UCIS4K, whichcomprises 3,953 images of camouflaged marine organisms with instance-levelannotations.

235, TITLE: PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception
AUTHORS: Kaichen Zhou; Yuhan Wang; Grace Chen; Xinhai Chang; Gaspard Beaudouin; Fangneng Zhan; Paul Pu Liang; Mengyu Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: However, since they are typically trained on static datasets,these models often struggle in real-world scenarios involving complex dynamicelements, such as moving humans or deformable objects like umbrellas. Toaddress this limitation, we introduce PAGE-4D, a feedforward model that extendsVGGT to dynamic scenes, enabling camera pose estimation, depth prediction, andpoint cloud reconstruction -- all without post-processing.

236, TITLE: Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients
AUTHORS: Shun Huang; Wenlu Xing; Shijia Geng; Hailong Wang; Guangkun Nie; Gongzheng Tang; Chenyang He; Shenda Hong
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: This study aimed to develop ahybrid predictive framework that integrates a large-scale electrocardiogram(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier toimprove both accuracy and interpretability.

237, TITLE: BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction
AUTHORS: Tian Xia; Tianrun Gao; Wenhao Deng; Long Wei; Xiaowei Qian; Yixian Jiang; Chenglei Yu; Tailin Wu
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: While modern LLMs possess broadknowledge and strong reasoning capabilities that make them promising candidatesfor this domain, their construction competencies remain largely unevaluated. Toaddress this gap, we introduce BuildArena, the first physics-alignedinteractive benchmark designed for language-driven engineering construction.

238, TITLE: Multilingual Text-to-Image Person Retrieval Via Bidirectional Relation Reasoning and Aligning
AUTHORS: Min Cao; Xinyu Zhou; Ding Jiang; Bo Du; Mang Ye; Min Zhang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Additionally, current methods areEnglish-centric, restricting their application in multilingual contexts. Toalleviate these issues, we pioneer a multilingual TIPR task by developing amultilingual TIPR benchmark, for which we leverage large language models forinitial translations and refine them by integrating domain-specific knowledge.Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit RelationReasoning and Aligning framework to learn alignment across languages andmodalities.

239, TITLE: StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales
AUTHORS: Nyle Siddiqui; Rohit Gupta; Sirnam Swetha; Mubarak Shah
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Consequently, these modelssuffer from degraded performance when evaluated on videos with spatial andtemporal resolutions unseen during training; a property we call spatio-temporalinflexibility. In the context of action recognition, this severely limits amodel's ability to retain performance across both short- and long-form videos.Therefore, we propose a flexible training method that leverages and improvesthe inherent adaptability of SSMs.

240, TITLE: PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies
AUTHORS: Lukas Selch; Yufang Hou; M. Jehanzeb Mirza; Sivan Doveh; James Glass; Rogerio Feris; Wei Lin
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: We introduce PRISMM-Bench(Peer-Review-sourced Inconsistency Set for Multimodal Models), the firstbenchmark grounded in real reviewer-flagged inconsistencies in scientificpapers.

241, TITLE: Construction and Optimization of Faculty Teams in Vocational Colleges Under The Paradigm of Industry-Education Integration
AUTHORS: Bing Wu; Feiran Li; Xiudong Shao
CATEGORY: Journal of Computer Science and Frontier Technologies [JOURNAL OF COMPUTER SCIENCE AND FRONTIER TECHNOLOGIES]
HIGHLIGHT: Three interlocking barriers were identified—rigid institutional mechanisms, resource scarcity, and cognitive constraints regarding digital and industrial teaching. To address these challenges, the study proposes a Tri-ple-Entity Collaboration and Dual-Drive framework linking full-time teachers, enterprise engineers, and part-time practitioners, supported by policy incen-tives and AI-based capability development.

242, TITLE: A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning
AUTHORS: Anjie Liu; Jianhong Wang; Samuel Kaski; Jun Wang; Mengyue Yang
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work, we employ multi-agentinfluence diagrams (MAIDs) as a graphical framework to address the aboveissues.

243, TITLE: What Limits Agentic Systems Efficiency?
AUTHORS: Song Bian; Minghao Yan; Anand Jayarajan; Gennady Pekhimenko; Shivaram Venkataraman
CATEGORY: arxiv-cs.AI [AI]
HIGHLIGHT: In this work,we present a comprehensive empirical study that identifies efficiencybottlenecks in web-interactive agentic systems.

244, TITLE: Multilingual Clinical NER for Diseases and Medications Recognition in Cardiology Texts Using BERT Embeddings
AUTHORS: Manuela Daniela Danu; George Marica; Constantin Suciu; Lucian Mihai Itu; Oladimeji Farri
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: To bridge thisgap, our study aims to develop multiple deep contextual embedding models toenhance clinical NER in the cardiology domain, as part of the BioASQMultiCardioNER shared task.

245, TITLE: Probing The Hidden Talent of ASR Foundation Models for L2 English Oral Assessment
AUTHORS: Fu-An Chao; Bi-Cheng Yan; Berlin Chen
CATEGORY: arxiv-cs.CL [CL]
HIGHLIGHT: In this paper, we explore the untapped potential of Whisper, awell-established automatic speech recognition (ASR) foundation model, in thecontext of L2 spoken language assessment (SLA).

246, TITLE: Investigating Adversarial Robustness Against Preprocessing Used in Blackbox Face Recognition
AUTHORS: Roland Croft; Brian Du; Darcy Joseph; Sharath Kumar
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Face Recognition (FR) models have been shown to be vulnerable to adversarialexamples that subtly alter benign facial images, exposing blind spots in thesesystems, as well as protecting user privacy.

247, TITLE: Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis Within The Knowledge-to-Action Framework
AUTHORS: Mohammad R. Salmanpour; Sonya Falahati; Amir Hossein Pouria; Amin Mousavi; Somayeh Sadat Mehrnia; Morteza Alizadeh; Arman Gorji; Zeinab Farsangi; Alireza Safarian; Mehdi Maghsudi; Carlos Uribe; Arman Rahmim; Ren Yuan
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Guided by the Knowledge-to-Action framework,this study develops a clinician-in-the-loop DL pipeline to enhancereproducibility, prognostic accuracy, and clinical trust.

248, TITLE: Proactive Scene Decomposition and Reconstruction
AUTHORS: Baicheng Li; Zike Yan; Dong Wu; Hongbin Zha
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: This paper formalizes a new task of proactivescene decomposition and reconstruction, an online approach that leverageshuman-object interactions to iteratively disassemble and reconstruct theenvironment.

249, TITLE: Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis
AUTHORS: Mohammad Javad Ahmadi; Iman Gandomi; Parisa Abdi; Seyed-Farzad Mohammadi; Amirhossein Taslimi; Mehdi Khodaparast; Hassan Hashemi; Mahdi Tavakoli; Hamid D. Taghirad
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Current resources for cataract surgery often lack thediversity and annotation depth needed to train generalizable deep-learningmodels. To address this gap, we present a dataset of 3,000 phacoemulsificationcataract surgery videos from two surgical centers, performed by surgeons with arange of experience levels.

250, TITLE: When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions
AUTHORS: Zhuo Cao; Heming Du; Bingqing Zhang; Xin Yu; Xue Li; Sen Wang
CATEGORY: arxiv-cs.CV [CV]
HIGHLIGHT: Building on existingefforts in MMR, we propose a framework called FlashMMR.

