
1, TITLE: Comparing Hallucination Detection Metrics for Multilingual Generation
AUTHORS: Haoqiang Kang ; Terra Blevins ; Luke Zettlemoyer
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While many automatic hallucination detection techniques have been proposed for English texts, their effectiveness in multilingual contexts remains unexplored. This paper aims to bridge the gap in understanding how these hallucination detection metrics perform on non-English languages.

2, TITLE: RLVF: Learning from Verbal Feedback Without Overgeneralization
AUTHORS: MORITZ STEPHAN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: However, while writing high-level feedback is far simpler than collecting annotations for reinforcement learning from human feedback (RLHF), we find that simply prompting a model with such feedback leads to overgeneralization of the feedback to contexts where it is not relevant. We study the problem of incorporating verbal feedback without such overgeneralization, inspiring a new method Contextualized Critiques with Constrained Preference Optimization (C3PO).

3, TITLE: Control Color: Multimodal Diffusion-based Interactive Image Colorization
AUTHORS: Zhexin Liang ; Zhaochen Li ; Shangchen Zhou ; Chongyi Li ; Chen Change Loy
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Despite the existence of numerous colorization methods, several limitations still exist, such as lack of user interaction, inflexibility in local colorization, unnatural color rendering, insufficient color variation, and color overflow. To solve these issues, we introduce Control Color (CtrlColor), a multi-modal colorization method that leverages the pre-trained Stable Diffusion (SD) model, offering promising capabilities in highly controllable interactive image colorization.

4, TITLE: Assessing The Reasoning Abilities of ChatGPT in The Context of Claim Verification
AUTHORS: John Dougrez-Lewis ; Mahmud Elahi Akhter ; Yulan He ; Maria Liakata
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose the first logical reasoning framework designed to break down any claim or rumor paired with evidence into the atomic reasoning steps necessary for verification.

5, TITLE: Make A Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution Adaptation
AUTHORS: LANQING GUO et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This paper proposes a novel self-cascade diffusion model that leverages the rich knowledge gained from a well-trained low-resolution model for rapid adaptation to higher-resolution image and video generation, employing either tuning-free or cheap upsampler tuning paradigms.

6, TITLE: LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models
AUTHORS: MINSUK KAHNG et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CL, cs.LG]
HIGHLIGHT: In this paper, we present LLM Comparator, a novel visual analytics tool for interactively analyzing results from automatic side-by-side evaluation.

7, TITLE: ToolSword: Unveiling Safety Issues of Large Language Models in Tool Learning Across Three Stages
AUTHORS: JUNJIE YE et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: While current research primarily emphasizes leveraging tools to augment LLMs, it frequently neglects emerging safety considerations tied to their application. To fill this gap, we present $ToolSword$, a comprehensive framework dedicated to meticulously investigating safety issues linked to LLMs in tool learning.

8, TITLE: SPAR: Personalized Content-Based Recommendation Via Long Engagement Attention
AUTHORS: CHIYU ZHANG et. al.
CATEGORY: cs.IR [cs.IR, cs.CL]
HIGHLIGHT: In this paper, we introduce a content-based recommendation framework, SPAR, which effectively tackles the challenges of holistic user interest extraction from the long user engagement history.

9, TITLE: Pedipulate: Enabling Manipulation Skills Using A Quadruped Robot's Leg
AUTHORS: Philip Arm ; Mayank Mittal ; Hendrik Kolvenbach ; Marco Hutter
CATEGORY: cs.RO [cs.RO, cs.AI, cs.SY, eess.SY]
HIGHLIGHT: In this work, we explore pedipulation - using the legs of a legged robot for manipulation.

10, TITLE: Opening The Black Box of Large Language Models: Two Views on Holistic Interpretability
AUTHORS: Haiyan Zhao ; Fan Yang ; Himabindu Lakkaraju ; Mengnan Du
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The top-down view utilizes representation engineering to analyze behaviors through hidden representations. In this paper, we review the landscape around mechanistic interpretability and representation engineering, summarizing approaches, discussing limitations and applications, and outlining future challenges in using these techniques to achieve ethical, honest, and reliable reasoning aligned with human values.

11, TITLE: Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities
AUTHORS: MINGYU JIN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, by comparing LLMs with traditional models, many properties of LLMs in time series prediction are found.

12, TITLE: PointMamba: A Simple State Space Model for Point Cloud Analysis
AUTHORS: DINGKANG LIANG et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, taking inspiration from the success of SSM in NLP, we propose PointMamba, a framework with global modeling and linear complexity.

13, TITLE: DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows
AUTHORS: Ajay Patel ; Colin Raffel ; Chris Callison-Burch
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this paper, we introduce DataDreamer, an open source Python library that allows researchers to write simple code to implement powerful LLM workflows.

14, TITLE: Distillation Enhanced Generative Retrieval
AUTHORS: YONGQI LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR]
HIGHLIGHT: In this work, we identify a viable direction to further enhance generative retrieval via distillation and propose a feasible framework, named DGR.

15, TITLE: Generative Cross-Modal Retrieval: Memorizing Images in Multimodal Language Models for Retrieval and Beyond
AUTHORS: YONGQI LI et. al.
CATEGORY: cs.MM [cs.MM, cs.AI, cs.CL, cs.CV, cs.IR]
HIGHLIGHT: Achieving this target presents notable challenges, including inbuilt visual memory and visual recall schemes within MLLMs. To address these challenges, we introduce a generative cross-modal retrieval framework, which assigns unique identifier strings to represent images and involves two training steps: learning to memorize and learning to retrieve.

16, TITLE: Measuring and Reducing LLM Hallucination Without Gold-Standard Answers Via Expertise-Weighting
AUTHORS: JIAHENG WEI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this work, we propose Factualness Evaluations via Weighting LLMs (FEWL), the first hallucination metric that is specifically designed for the scenario when gold-standard answers are absent.

17, TITLE: Can LLMs Speak For Diverse People? Tuning LLMs Via Debate to Generate Controllable Controversial Statements
AUTHORS: Ming Li ; Jiuhai Chen ; Lichang Chen ; Tianyi Zhou
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we improve the controllability of LLMs in generating statements supporting an argument the user defined in the prompt.

18, TITLE: BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains
AUTHORS: YANIS LABRAK et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central.

19, TITLE: Do Llamas Work in English? On The Latent Language of Multilingual Transformers
AUTHORS: Chris Wendler ; Veniamin Veselovsky ; Giovanni Monea ; Robert West
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: Tracking intermediate embeddings through their high-dimensional space reveals three distinct phases, whereby intermediate embeddings (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an input-language-specific region of the embedding space. We cast these results into a conceptual model where the three phases operate in "input space", "concept space", and "output space", respectively.

20, TITLE: Symbolic Autoencoding for Self-Supervised Sequence Learning
AUTHORS: MOHAMMAD HOSSEIN AMANI et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Traditional language models, adept at next-token prediction in text sequences, often struggle with transduction tasks between distinct symbolic systems, particularly when parallel data is scarce. Addressing this issue, we introduce \textit{symbolic autoencoding} ($\Sigma$AE), a self-supervised framework that harnesses the power of abundant unparallel data alongside limited parallel data.

21, TITLE: Using Left and Right Brains Together: Towards Vision and Language Planning
AUTHORS: JUN CEN et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In contrast, humans utilize both left and right hemispheres of the brain for language and visual planning during the thinking process. Therefore, we introduce a novel vision-language planning framework in this work to perform concurrent visual and language planning for tasks with inputs of any form.

22, TITLE: Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts
AUTHORS: Xiaobo Guo ; Soroush Vosoughi
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Current research largely targets predefined aspects within structured texts, neglecting the complexities of dynamic and disordered environments. Addressing this gap, we introduce Disordered-DABS, a novel benchmark for dynamic aspect-based summarization tailored to unstructured text.

23, TITLE: LongHeads: Multi-Head Attention Is Secretly A Long Context Processor
AUTHORS: YI LU et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: However, these methods introduce new issues such as ignoring the middle context and requiring additional training. To address these problems, we propose LongHeads, a training-free framework that enhances LLM's long context ability by unlocking multi-head attention's untapped potential.

24, TITLE: Universal Prompt Optimizer for Safe Text-to-Image Generation
AUTHORS: Zongyu Wu ; Hongcheng Gao ; Yueze Wang ; Xiang Zhang ; Suhang Wang
CATEGORY: cs.CV [cs.CV, cs.CL]
HIGHLIGHT: Hence, \textit{we propose the first universal prompt optimizer for safe T2I generation in black-box scenario}.

25, TITLE: Humans or LLMs As The Judge? A Study on Judgement Biases
AUTHORS: Guiming Hardy Chen ; Shunian Chen ; Ziche Liu ; Feng Jiang ; Benyou Wang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a novel framework for investigating 5 types of biases for LLM and human judges.

26, TITLE: Efficiency at Scale: Investigating The Performance of Diminutive Language Models in Clinical Tasks
AUTHORS: NIALL TAYLOR et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: We present an investigation into the suitability of different PEFT methods to clinical decision-making tasks, across a range of model sizes, including extremely small models with as few as $25$ million parameters.

27, TITLE: Enhancing ESG Impact Type Identification Through Early Fusion and Multilingual Models
AUTHORS: Hariram Veeramani ; Surendrabikram Thapa ; Usman Naseem
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In the evolving landscape of Environmental, Social, and Corporate Governance (ESG) impact assessment, the ML-ESG-2 shared task proposes identifying ESG impact types. To address this challenge, we present a comprehensive system leveraging ensemble learning techniques, capitalizing on early and late fusion approaches.

28, TITLE: `Keep It Together': Enforcing Cohesion in Extractive Summaries By Simulating Human Memory
AUTHORS: Ronald Cardenas ; Matthias Galle ; Shay B. Cohen
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we aim to enforce cohesion whilst controlling for informativeness and redundancy in summaries, in cases where the input exhibits high redundancy.

29, TITLE: When Is Tree Search Useful for LLM Planning? It Depends on The Discriminator
AUTHORS: ZIRU CHEN et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we examine how large language models (LLMs) solve multi-step problems under a language agent framework with three components: a generator, a discriminator, and a planning method.

30, TITLE: Enhancing Role-playing Systems Through Aggressive Queries: Evaluation and Improvement
AUTHORS: YIHONG TANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we design the Modular ORchestrated Trap-setting Interaction SystEm (MORTISE) to benchmark and improve the role-playing LLMs' performance.

31, TITLE: 3D Diffuser Actor: Policy Diffusion with 3D Scene Representations
AUTHORS: Tsung-Wei Ke ; Nikolaos Gkanatsios ; Katerina Fragkiadaki
CATEGORY: cs.RO [cs.RO, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: Diffusion policies learn the action distribution conditioned on the robot and environment state using conditional diffusion models.

32, TITLE: Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review
AUTHORS: JING SU et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency.

33, TITLE: Semi-weakly-supervised Neural Network Training for Medical Image Registration
AUTHORS: YIWEN LI et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This paper describes a semi-weakly-supervised registration pipeline that improves the model performance, when only a small corresponding-ROI-labelled dataset is available, by exploiting unlabelled image pairs.

34, TITLE: OpenFMNav: Towards Open-Set Zero-Shot Object Navigation Via Vision-Language Foundation Models
AUTHORS: Yuxuan Kuang ; Hai Lin ; Meng Jiang
CATEGORY: cs.CL [cs.CL, cs.RO]
HIGHLIGHT: Aiming to solve the two challenges, in this paper, we propose OpenFMNav, an Open-set Foundation Model based framework for zero-shot object Navigation.

35, TITLE: Random Projection Layers for Multidimensional Time Sires Forecasting
AUTHORS: CHIN-CHIA MICHAEL YEH et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer.

36, TITLE: DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection
AUTHORS: HERUN WAN et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we propose DELL that identifies three key stages in misinformation detection where LLMs could be incorporated as part of the pipeline: 1) LLMs could \emph{generate news reactions} to represent diverse perspectives and simulate user-news interaction networks; 2) LLMs could \emph{generate explanations} for proxy tasks (e.g., sentiment, stance) to enrich the contexts of news articles and produce experts specializing in various aspects of news understanding; 3) LLMs could \emph{merge task-specific experts} and provide an overall prediction by incorporating the predictions and confidence scores of varying experts.

37, TITLE: Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)
AUTHORS: Usha Bhalla ; Alex Oesterling ; Suraj Srinivas ; Flavio P. Calmon ; Himabindu Lakkaraju
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: In this work, we empirically show that CLIP's latent space is highly structured, and consequently that CLIP representations can be decomposed into their underlying semantic components.

38, TITLE: GenRES: Rethinking Evaluation for Generative Relation Extraction in The Era of Large Language Models
AUTHORS: Pengcheng Jiang ; Jiacheng Lin ; Zifeng Wang ; Jimeng Sun ; Jiawei Han
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: This shortfall arises because these metrics rely on exact matching with human-annotated reference relations, while GRE methods often produce diverse and semantically accurate relations that differ from the references. To fill this gap, we introduce GenRES for a multi-dimensional assessment in terms of the topic similarity, uniqueness, granularity, factualness, and completeness of the GRE results.

39, TITLE: Language-Driven Engineering An Interdisciplinary Software Development Paradigm
AUTHORS: BERNHARD STEFFEN et. al.
CATEGORY: cs.SE [cs.SE, cs.PL]
HIGHLIGHT: We illustrate how purpose-specific, graphical modeling enables application experts with different levels of expertise to collaboratively design and then produce complex applications using their individual, purpose-specific modeling language.

40, TITLE: Associative Memories in The Feature Space
AUTHORS: Tommaso Salvatori ; Beren Millidge ; Yuhang Song ; Rafal Bogacz ; Thomas Lukasiewicz
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: An additional drawback of current models is the need of storing the whole dataset in the pixel space, which is often extremely large. We relax this condition and propose a class of memory models that only stores low-dimensional semantic embeddings, and uses them to retrieve similar, but not identical, memories.

41, TITLE: Inference to The Best Explanation in Large Language Models
AUTHORS: Dhairya Dalal ; Marco Valentino ; Andr� Freitas ; Paul Buitelaar
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: This paper proposes IBE-Eval, a framework inspired by philosophical accounts on Inference to the Best Explanation (IBE) to advance the interpretation and evaluation of LLMs' explanations.

42, TITLE: Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL Through Workflow Paradigm
AUTHORS: YUANZHEN XIE et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: To improve the contextual learning capabilities of LLMs in text-to-SQL, a workflow paradigm method is proposed, aiming to enhance the attention and problem-solving scope of LLMs through decomposition.

43, TITLE: BioFusionNet: Deep Learning-Based Survival Risk Stratification in ER+ Breast Cancer Through Multifeature and Multimodal Data Fusion
AUTHORS: Raktim Kumar Mondol ; Ewan K. A. Millar ; Arcot Sowmya ; Erik Meijering
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: Here we present BioFusionNet, a deep learning framework that fuses image-derived features with genetic and clinical data to achieve a holistic patient profile and perform survival risk stratification of ER+ breast cancer patients.

44, TITLE: Physics-informed MeshGraphNets (PI-MGNs): Neural Finite Element Solvers for Non-stationary and Nonlinear Simulations on Arbitrary Meshes
AUTHORS: Tobias W�rth ; Niklas Freymuth ; Clemens Zimmerling ; Gerhard Neumann ; Luise K�rger
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CE]
HIGHLIGHT: This work introduces PI-MGNs, a hybrid approach that combines PINNs and MGNs to quickly and accurately solve non-stationary and nonlinear partial differential equations (PDEs) on arbitrary meshes.

45, TITLE: Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants
AUTHORS: Peter Richt�rik ; Elnur Gasanov ; Konstantin Burlachenko
CATEGORY: cs.LG [cs.LG, cs.AI, math.OC, stat.ML, 90C26, 74Pxx, G.1.6; I.2.11; I.2.m]
HIGHLIGHT: In this work we study a modern form of error feedback called EF21 (Richtarik et al., 2021) which offers the currently best-known theoretical guarantees, under the weakest assumptions, and also works well in practice.

46, TITLE: Quantifying The Persona Effect in LLM Simulations
AUTHORS: Tiancheng Hu ; Nigel Collier
CATEGORY: cs.CL [cs.CL, cs.CY]
HIGHLIGHT: In this study, we delve into the intersection of persona variables and the capability of LLMs to simulate different perspectives.

47, TITLE: When Dataflow Analysis Meets Large Language Models
AUTHORS: CHENGPENG WANG et. al.
CATEGORY: cs.PL [cs.PL, cs.LG, cs.SE, 68N30, 68T01, D.3.0; D.2.4; I.2.5; I.2.6]
HIGHLIGHT: This paper introduces LLMDFA, an LLM-powered dataflow analysis framework that analyzes arbitrary code snippets without requiring a compilation infrastructure and automatically synthesizes downstream applications.

48, TITLE: Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed Up Speech Diffusion Model
AUTHORS: XIANGYU ZHANG et. al.
CATEGORY: eess.AS [eess.AS, cs.AI]
HIGHLIGHT: In this paper, we double the training and inference speed of Speech DDPMs by simply redirecting the generative target to the wavelet domain.

49, TITLE: Generative AI for Controllable Protein Sequence Design: A Survey
AUTHORS: YIHENG ZHU et. al.
CATEGORY: q-bio.BM [q-bio.BM, cs.AI, cs.LG]
HIGHLIGHT: In this survey, we systematically review recent advances in generative AI for controllable protein sequence design.

50, TITLE: Multitask Kernel-based Learning with Logic Constraints
AUTHORS: Michelangelo Diligenti ; Marco Gori ; Marco Maggini ; Leonardo Rigutini
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper presents a general framework to integrate prior knowledge in the form of logic constraints among a set of task functions into kernel machines.

51, TITLE: Jailbreaking Proprietary Large Language Models Using Word Substitution Cipher
AUTHORS: Divij Handa ; Advait Chirmule ; Bimal Gajera ; Chitta Baral
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we present jailbreaking prompts encoded using cryptographic techniques.

52, TITLE: Direct Preference Optimization with An Offset
AUTHORS: Afra Amini ; Tim Vieira ; Ryan Cotterell
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: In this paper, we propose a generalization of DPO, termed DPO with an offset (ODPO), that does not treat every preference pair equally during fine-tuning.

53, TITLE: I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large Language Models
AUTHORS: Wenchao Dong ; Assem Zhunis ; Hyojin Chin ; Jiyoung Han ; Meeyoung Cha
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We explored cultural biases-individualism vs. collectivism-in ChatGPT across three Western languages (i.e., English, German, and French) and three Eastern languages (i.e., Chinese, Japanese, and Korean).

54, TITLE: Human Goal Recognition As Bayesian Inference: Investigating The Impact of Actions, Timing, and Goal Solvability
AUTHORS: Chenyuan Zhang ; Charles Kemp ; Nir Lipovetzky
CATEGORY: cs.HC [cs.HC, cs.AI]
HIGHLIGHT: Our work provides new insight into human goal recognition and takes a step towards more human-like AI models.

55, TITLE: Can We Soft Prompt LLMs for Graph Learning Tasks?
AUTHORS: Zheyuan Liu ; Xiaoxin He ; Yijun Tian ; Nitesh V. Chawla
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Hence, to further investigate LLMs' potential for comprehending graph information, we introduce GraphPrompter, a novel framework designed to align graph information with LLMs via soft prompts.

56, TITLE: GaussianHair: Hair Modeling and Rendering with Light-aware Gaussians
AUTHORS: HAIMIN LUO et. al.
CATEGORY: cs.GR [cs.GR, cs.CV]
HIGHLIGHT: This paper presents GaussianHair, a novel explicit hair representation.

57, TITLE: Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs
AUTHORS: Zae Myung Kim ; Kwang Hee Lee ; Preston Zhu ; Vipul Raheja ; Dongyeop Kang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Introducing a novel methodology, we leverage hierarchical parse trees and recursive hypergraphs to unveil distinctive discourse patterns in texts produced by both LLMs and humans.

58, TITLE: Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of Language Models
AUTHORS: Kang He ; Yinghan Long ; Kaushik Roy
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: In this work, we propose a null-input prompting method to calibrate intrinsic bias encoded in pre-trained LMs.

59, TITLE: Large Language Models As Zero-shot Dialogue State Tracker Through Function Calling
AUTHORS: ZEKUN LI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this work, we propose a novel approach FnCTOD for solving DST with LLMs through function calling.

60, TITLE: Incremental Sequence Labeling: A Tale of Two Shifts
AUTHORS: Shengjie Qiu ; Junhao Zheng ; Zhen Liu ; Yicheng Luo ; Qianli Ma
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This negligence results in a model bias towards classifying new data samples as belonging to the new class during the learning process. To address these challenges, we propose a novel framework, Incremental Sequential Labeling without Semantic Shifts (IS3).

61, TITLE: Real-Time Model-Based Quantitative Ultrasound and Radar
AUTHORS: Tom Sharon ; Yonina C. Eldar
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, current quantitative imaging techniques that estimate physical properties from received signals, such as Full Waveform Inversion, are time-consuming and tend to converge to local minima, making them unsuitable for medical imaging. To address these challenges, we propose a neural network based on the physical model of wave propagation, which defines the relationship between the received signals and physical properties.

62, TITLE: Grounding Language About Belief in A Bayesian Theory-of-Mind
AUTHORS: Lance Ying ; Tan Zhi-Xuan ; Lionel Wong ; Vikash Mansinghka ; Joshua Tenenbaum
CATEGORY: cs.AI [cs.AI, cs.CL]
HIGHLIGHT: What explains this capacity to interpret the hidden epistemic content of other minds? In this paper, we take a step towards an answer by grounding the semantics of belief statements in a Bayesian theory-of-mind: By modeling how humans jointly infer coherent sets of goals, beliefs, and plans that explain an agent's actions, then evaluating statements about the agent's beliefs against these inferences via epistemic logic, our framework provides a conceptual role semantics for belief, explaining the gradedness and compositionality of human belief attributions, as well as their intimate connection with goals and plans.

63, TITLE: Masked Attention Is All You Need for Graphs
AUTHORS: David Buterez ; Jon Paul Janet ; Dino Oglic ; Pietro Lio
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: The design of powerful and general purpose GNNs, however, requires significant research efforts and often relies on handcrafted, carefully-chosen message passing operators. Motivated by this, we propose a remarkably simple alternative for learning on graphs that relies exclusively on attention.

64, TITLE: Retrieve Only When It Needs: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models
AUTHORS: Hanxing Ding ; Liang Pang ; Zihao Wei ; Huawei Shen ; Xueqi Cheng
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs.

65, TITLE: MultiPoT: Multilingual Program of Thoughts Harnesses Multiple Programming Languages
AUTHORS: XIANZHEN LUO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The effectiveness of each language varies depending on the specific scenarios. Inspired by this, we propose a task and model agnostic approach called MultiPoT, which harnesses strength and diversity from various languages.

66, TITLE: Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation
AUTHORS: Ziyang Wang ; Chao Ma
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: This paper introduces Weak-Mamba-UNet, an innovative weakly-supervised learning (WSL) framework that leverages the capabilities of Convolutional Neural Network (CNN), Vision Transformer (ViT), and the cutting-edge Visual Mamba (VMamba) architecture for medical image segmentation, especially when dealing with scribble-based annotations.

67, TITLE: A Condensed Transition Graph Framework for Zero-shot Link Prediction with Large Language Models
AUTHORS: Mingchen Li ; Chen Ling ; Rui Zhang ; Liang Zhao
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Even though Large Language Models (LLMs) offer a promising solution to predict unobserved relations between the head and tail entity in a zero-shot manner, their performance is still restricted due to the inability to leverage all the (exponentially many) paths' information between two entities, which are critical in collectively indicating their relation types. To address this, in this work, we introduce a Condensed Transition Graph Framework for Zero-Shot Link Prediction (CTLP), which encodes all the paths' information in linear time complexity to predict unseen relations between entities, attaining both efficiency and information preservation.

68, TITLE: Steering Conversational Large Language Models for Long Emotional Support Conversations
AUTHORS: Navid Madani ; Sougata Saha ; Rohini Srihari
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this study, we address the challenge of consistently following emotional support strategies in long conversations by large language models (LLMs).

69, TITLE: Multi-modal Preference Alignment Remedies Regression of Visual Instruction Tuning on Language Model
AUTHORS: Shengzhi Li ; Rongyu Lin ; Shichao Pei
CATEGORY: cs.CL [cs.CL, cs.AI, cs.CV, cs.LG]
HIGHLIGHT: In conclusion, we propose a distillation-based multi-modal alignment model with fine-grained annotations on a small dataset that reconciles the textual and visual performance of MLLMs, restoring and boosting language capability after visual instruction tuning.

70, TITLE: BitDistiller: Unleashing The Potential of Sub-4-Bit LLMs Via Self-Distillation
AUTHORS: DAYOU DU et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper introduces BitDistiller, a framework that synergizes Quantization-Aware Training (QAT) with Knowledge Distillation (KD) to boost the performance of LLMs at ultra-low precisions (sub-4-bit).

71, TITLE: Parallel Play Saves Quantifiers
AUTHORS: MARCO CARMOSINO et. al.
CATEGORY: cs.LO [cs.LO, cs.CC]
HIGHLIGHT: The number of quantifiers needed to express first-order properties is captured by two-player combinatorial games called multi-structural (MS) games. We play these games on linear orders and strings, and introduce a technique we call "parallel play", that dramatically reduces the number of quantifiers needed in many cases.

72, TITLE: PaLM2-VAdapter: Progressively Aligned Language Model Makes A Strong Vision-language Adapter
AUTHORS: Junfei Xiao ; Zheng Xu ; Alan Yuille ; Shen Yan ; Boyu Wang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, we observe that the vision-language alignment with perceiver resampler exhibits slow convergence and limited scalability with a lack of direct supervision. To address this issue, we propose PaLM2-VAdapter, employing a progressively aligned language model as the vision-language adapter.

73, TITLE: U$^2$MRPD: Unsupervised Undersampled MRI Reconstruction By Prompting A Large Latent Diffusion Model
AUTHORS: Ziqi Gao ; S. Kevin Zhou
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: Implicit visual knowledge in a large latent diffusion model (LLDM) pre-trained on natural images is rich and hypothetically universal to natural and medical images. To test this hypothesis, we introduce a novel framework for Unsupervised Undersampled MRI Reconstruction by Prompting a pre-trained large latent Diffusion model ( U$^2$MRPD).

74, TITLE: Smaller Language Models Are Capable of Selecting Instruction-Tuning Training Data for Larger Language Models
AUTHORS: Dheeraj Mekala ; Alex Nguyen ; Jingbo Shang
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we introduce a novel training data selection based on the learning percentage of the samples.

75, TITLE: Exploring Hybrid Question Answering Via Program-based Prompting
AUTHORS: QI SHI et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose HProPro, a novel program-based prompting framework for the hybrid question answering task.

76, TITLE: LinkNER: Linking Local Named Entity Recognition Models to Large Language Models Using Uncertainty
AUTHORS: Zhen Zhang ; Yuhua Zhao ; Hang Gao ; Mengting Hu
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: Furthermore, non-public and large-scale weights make tuning LLMs difficult. To address these challenges, we propose a framework that combines small fine-tuned models with LLMs (LinkNER) and an uncertainty-based linking strategy called RDC that enables fine-tuned models to complement black-box LLMs, achieving better performance.

77, TITLE: How Reliable Are Automatic Evaluation Methods for Instruction-Tuned LLMs?
AUTHORS: Ehsan Doostmohammadi ; Oskar Holmstr�m ; Marco Kuhlmann
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Work on instruction-tuned Large Language Models (LLMs) has used automatic methods based on text overlap and LLM judgments as cost-effective alternatives to human evaluation. In this paper, we study the reliability of such methods across a broad range of tasks and in a cross-lingual setting.

78, TITLE: Conversational SimulMT: Efficient Simultaneous Translation with Large Language Models
AUTHORS: Minghan Wang ; Thuy-Trang Vu ; Ehsan Shareghi ; Gholamreza Haffari
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper, we propose a conversational SimulMT framework to enhance the inference efficiency of LLM-based SimulMT through multi-turn-dialogue-based decoding.

79, TITLE: Pushing The Limits of Zero-shot End-to-End Speech Translation
AUTHORS: Ioannis Tsiamas ; Gerard I. G�llego ; Jos� A. R. Fonollosa ; Marta R. Costa-juss�
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, achieving competitive results typically requires some ST data. For this reason, we introduce ZeroSwot, a method for zero-shot ST that bridges the modality gap without any paired ST data.

80, TITLE: Chain of Logic: Rule-Based Reasoning with Large Language Models
AUTHORS: Sergio Servantez ; Joe Barrow ; Kristian Hammond ; Rajiv Jain
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Reasoning about compositional rules is challenging because it requires multiple reasoning steps, and attending to the logical relationships between elements. We introduce a new prompting method, Chain of Logic, which elicits rule-based reasoning through decomposition (solving elements as independent threads of logic), and recomposition (recombining these sub-answers to resolve the underlying logical expression).

81, TITLE: Proving Membership in LLM Pretraining Data Via Data Watermarks
AUTHORS: Johnny Tian-Zheng Wei ; Ryan Yixiang Wang ; Robin Jia
CATEGORY: cs.CR [cs.CR, cs.CL, cs.LG]
HIGHLIGHT: Detecting whether copyright holders' works were used in LLM pretraining is poised to be an important problem. This work proposes using data watermarks to enable principled detection with only black-box model access, provided that the rightholder contributed multiple training documents and watermarked them before public release.

82, TITLE: Fully Differentiable Lagrangian Convolutional Neural Network for Continuity-Consistent Physics-Informed Precipitation Nowcasting
AUTHORS: Peter Pavl�k ; Martin V�boh ; Anna Bou Ezzeddine ; Viera Rozinajov�
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, I.2.1; J.2]
HIGHLIGHT: This paper presents a convolutional neural network model for precipitation nowcasting that combines data-driven learning with physics-informed domain knowledge.

83, TITLE: Provably Sample Efficient RLHF Via Active Preference Optimization
AUTHORS: Nirjhar Das ; Souradip Chakraborty ; Aldo Pacchiano ; Sayak Ray Chowdhury
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: To this end, we frame RLHF as a contextual preference bandit problem with prompts as contexts and show that the naive way of collecting preference data by choosing prompts uniformly at random leads to a policy that suffers an $\Omega(1)$ suboptimality gap in rewards.

84, TITLE: Linear Transformers with Learnable Kernel Functions Are Better In-Context Models
AUTHORS: YAROSLAV AKSENOV et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: Mirroring the Transformer's in-context adeptness, it became a strong contender in the field. In our work, we present a singular, elegant alteration to the Based kernel that amplifies its In-Context Learning abilities evaluated with the Multi-Query Associative Recall task and overall language modeling process, as demonstrated on the Pile dataset.

85, TITLE: Border Subrank Via A Generalised Hilbert-Mumford Criterion
AUTHORS: Benjamin Biaggi ; Chia-Yu Chang ; Jan Draisma ; Filip Rupniewski
CATEGORY: math.AG [math.AG, cs.CC, 15A69, 14L24, 68Q17]
HIGHLIGHT: We show that the border subrank of a sufficiently general tensor in $(\mathbb{C}^n)^{\otimes d}$ is $\mathcal{O}(n^{1/(d-1)})$ for $n \to \infty$.

86, TITLE: Experiments with Encoding Structured Data for Neural Networks
AUTHORS: Sujay Nagesh Koujalgi ; Jonathan Dodge
CATEGORY: cs.AI [cs.AI, I.2.4]
HIGHLIGHT: The project's aim is to create an AI agent capable of selecting good actions in a game-playing domain called Battlespace.

87, TITLE: On Explaining Unfairness: An Overview
AUTHORS: Christos Fragkathoulas ; Vasiliki Papanikou ; Danae Pla Karidi ; Evaggelia Pitoura
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: In this paper, we focus on their interplay, a research area that is recently receiving increasing attention.

88, TITLE: AutoSAT: Automatically Optimize SAT Solvers Via Large Language Models
AUTHORS: YIWEN SUN et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: Therefore, it typically requires to refine specific solvers for specific problem instances. In this context, we present AutoSAT, a novel framework for automatically optimizing heuristics in SAT solvers.

89, TITLE: Cloud Kitchen: Using Planning-based Composite AI to Optimize Food Delivery Process
AUTHORS: Slavom�r ?vanc�r ; Luk�? Chrpa ; Filip Dvo?�k ; Tom�? Balyo
CATEGORY: cs.AI [cs.AI, cs.LO]
HIGHLIGHT: This paper presents the Cloud Kitchen platform as a decision-making tool for restaurants with food delivery and a simulator to evaluate the impact of the decisions.

90, TITLE: Learning Planning Action Models from State Traces
AUTHORS: TOM�? BALYO et. al.
CATEGORY: cs.AI [cs.AI]
HIGHLIGHT: We define two levels of trace quality based on which information is provided and present an algorithm for each.

91, TITLE: Explainability for Machine Learning Models: From Data Adaptability to User Perception
AUTHORS: julien Delaunay
CATEGORY: cs.AI [cs.AI, cs.HC, cs.LG]
HIGHLIGHT: This thesis explores the generation of local explanations for already deployed machine learning models, aiming to identify optimal conditions for producing meaningful explanations considering both data and user requirements.

92, TITLE: Robust Agents Learn Causal World Models
AUTHORS: Jonathan Richens ; Tom Everitt
CATEGORY: cs.AI [cs.AI, cs.LG]
HIGHLIGHT: However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents.

93, TITLE: InSaAF: Incorporating Safety Through Accuracy and Fairness | Are LLMs Ready for The Indian Legal Domain?
AUTHORS: YOGESH TRIPATHI et. al.
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this study, we explore the ability of Large Language Models (LLMs) to perform legal tasks in the Indian landscape when social factors are involved.

94, TITLE: Strong Hallucinations from Negation and How to Fix Them
AUTHORS: Nicholas Asher ; Swarnadeep Bhar
CATEGORY: cs.CL [cs.CL, cs.AI, I.2.7]
HIGHLIGHT: We call such responses \textit{strong hallucinations} and prove that they follow from an LM's computation of its internal representations for logical operators and outputs from those representations. Focusing on negation, we provide a novel solution in which negation is treated not as another element of a latent representation, but as \textit{an operation over an LM's latent representations that constrains how they may evolve}.

95, TITLE: How to Discern Important Urgent News?
AUTHORS: Oleg Vasilyev ; John Bohannon
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We verified our finding across different news datasets, dataset sizes, clustering algorithms and embeddings.

96, TITLE: Neural Paraphrasing By Automatically Crawled and Aligned Sentence Pairs
AUTHORS: ACHILLE GLOBO et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this paper we present a method for the automatic generation of large aligned corpora, that is based on the assumption that news and blog websites talk about the same events using different narrative styles.

97, TITLE: The Optimal Placement of The Head in The Noun Phrase. The Case of Demonstrative, Numeral, Adjective and Noun
AUTHORS: Ramon Ferrer-i-Cancho
CATEGORY: cs.CL [cs.CL, physics.soc-ph]
HIGHLIGHT: We find that, across preferred orders in languages, the noun tends to be placed at one of the ends, confirming the theoretical prediction.

98, TITLE: Properties and Challenges of LLM-Generated Explanations
AUTHORS: Jenny Kunz ; Marco Kuhlmann
CATEGORY: cs.CL [cs.CL, cs.AI, cs.HC, cs.LG]
HIGHLIGHT: By analysing the outputs for a multi-domain instruction fine-tuning data set, we find that generated explanations show selectivity and contain illustrative elements, but less frequently are subjective or misleading.

99, TITLE: Zero-shot Sampling of Adversarial Entities in Biomedical Question Answering
AUTHORS: R. PATRICK XIAN et. al.
CATEGORY: cs.CL [cs.CL, cs.CR, stat.AP]
HIGHLIGHT: Here, we propose a powerscaled distance-weighted sampling scheme in embedding space to discover diverse adversarial entities as distractors.

100, TITLE: Can We Verify Step By Step for Incorrect Answer Detection?
AUTHORS: Xin Xu ; Shizhe Diao ; Can Yang ; Yang Wang
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: To make full use of information in multiple reasoning chains, we propose the process discernibility score (PDS) framework that beats the answer-checking baseline by a large margin.

101, TITLE: Exploring Precision and Recall to Assess The Quality and Diversity of LLMs
AUTHORS: Le Bronnec Florian ; Verine Alexandre ; Negrevergne Benjamin ; Chevaleyre Yann ; Allauzen Alexandre
CATEGORY: cs.CL [cs.CL, cs.LG]
HIGHLIGHT: This paper introduces a novel evaluation framework for Large Language Models (LLMs) such as Llama-2 and Mistral, focusing on the adaptation of Precision and Recall metrics from image generation to text generation.

102, TITLE: Rethinking Human-like Translation Strategy: Integrating Drift-Diffusion Model with Large Language Models for Machine Translation
AUTHORS: HONGBIN NA et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, prior work on LLM-based machine translation has mainly focused on better utilizing training data, demonstrations, or pre-defined and universal knowledge to improve performance, with a lack of consideration of decision-making like human translators. In this paper, we incorporate Thinker with the Drift-Diffusion Model (Thinker-DDM) to address this issue.

103, TITLE: Evaluating and Improving Continual Learning in Spoken Language Understanding
AUTHORS: Muqiao Yang ; Xiang Li ; Umberto Cappellazzo ; Shinji Watanabe ; Bhiksha Raj
CATEGORY: cs.CL [cs.CL, cs.AI, cs.SD]
HIGHLIGHT: In this work, we propose an evaluation methodology that provides a unified evaluation on stability, plasticity, and generalizability in continual learning.

104, TITLE: Fine Tuning Named Entity Extraction Models for The Fantasy Domain
AUTHORS: Aravinth Sivaganeshan ; Nisansa de Silva
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This work compares the accuracy of the monster name identification against; the zero-shot Trankit model and two FLAIR models.

105, TITLE: Improving Demonstration Diversity By Human-Free Fusing for Text-to-SQL
AUTHORS: Dingzirui Wang ; Longxu Dou ; Xuanliang Zhang ; Qingfu Zhu ; Wanxiang Che
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, human labeling suffers from the limitations of insufficient diversity and high labeling overhead. Therefore, in this paper, we discuss how to measure and improve the diversity of the demonstrations for text-to-SQL.

106, TITLE: Multi-Hop Table Retrieval for Open-Domain Text-to-SQL
AUTHORS: Xuanliang Zhang ; Dingzirui Wang ; Longxu Dou ; Qingfu Zhu ; Wanxiang Che
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, existing retrieval methods that retrieve in a single hop do not pay attention to the text-to-SQL challenge of schema linking, which is aligning the entities in the question with table entities, reflected in two aspects: similar irrelevant entity and domain mismatch entity. Therefore, we propose our method, the multi-hop table retrieval with rewrite and beam search (Murre).

107, TITLE: Understanding In-Context Learning with A Pelican Soup Framework
AUTHORS: Ting-Rui Chiang ; Dani Yogatama
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Many existing theoretical analyses of in-context learning for natural language processing are based on latent variable models that leaves gaps between theory and practice. We aim to close these gaps by proposing a theoretical framework, the Pelican Soup Framework.

108, TITLE: Construction of A Syntactic Analysis Map for Yi Shui School Through Text Mining and Natural Language Processing Research
AUTHORS: Hanqing Zhao ; Yuehan Li
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: The key information extraction of TCM texts plays an important role in mining and studying the academic schools of TCM. In order to solve these problems efficiently using artificial intelligence methods, this study constructs a word segmentation and entity relationship extraction model based on conditional random fields under the framework of natural language processing technology to identify and extract the entity relationship of traditional Chinese medicine texts, and uses the common weighting technology of TF-IDF information retrieval and data mining to extract important key entity information in different ancient books.

109, TITLE: Multi-Cultural Commonsense Knowledge Distillation
AUTHORS: Tuan-Phong Nguyen ; Simon Razniewski ; Gerhard Weikum
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge.

110, TITLE: Let's Learn Step By Step: Enhancing In-Context Learning Ability with Curriculum Learning
AUTHORS: Yinpeng Liu ; Jiawei Liu ; Xiang Shi ; Qikai Cheng ; Wei Lu
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We advocate the few-shot in-context curriculum learning (ICCL), a simple but effective demonstration ordering method for ICL, which implies gradually increasing the complexity of prompt demonstrations during the inference process.

111, TITLE: Instruction Diversity Drives Generalization To Unseen Tasks
AUTHORS: Dylan Zhang ; Justin Wang ; Francois Charton
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: %To understand the driving factors of generalization, In this paper, we experiment with string rewrites, a symbolic task that serves as a building block for Turing complete Markov algorithms while allowing experimental control of "inputs" and "instructions".

112, TITLE: EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models
AUTHORS: Muhammad Shihab Rashid ; Jannat Ara Meem ; Yue Dong ; Vagelis Hristidis
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: We propose a suite of budget-constrained methods to perform text re-ranking using a set of LLM APIs.

113, TITLE: Enhancing Numerical Reasoning with The Guidance of Reliable Reasoning Processes
AUTHORS: Dingzirui Wang ; Longxu Dou ; Xuanliang Zhang ; Qingfu Zhu ; Wanxiang Che
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: However, current methods have the limitation that most methods generate reasoning processes with large language models (LLMs), which are "unreliable" since such processes could contain information unrelated to the answer. To address this limitation, we introduce Enhancing NumeriCal reasOning with Reliable procEsses (Encore), which derives the reliable reasoning process by decomposing the answer formula, ensuring which fully supports the answer.

114, TITLE: German Text Simplification: Finetuning Large Language Models with Semi-Synthetic Data
AUTHORS: Lars Kl�ser ; Mika Beele ; Jan-Niklas Schagen ; Bodo Kraft
CATEGORY: cs.CL [cs.CL, I.2.7]
HIGHLIGHT: This study pioneers the use of synthetically generated data for training generative models in document-level text simplification of German texts.

115, TITLE: An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient Generative LLM Inference
AUTHORS: Atsuki Yamaguchi ; Aline Villavicencio ; Nikolaos Aletras
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: In this paper, we perform an empirical study of various cross-lingual vocabulary adaptation methods on five generative LLMs (including monolingual and multilingual models) across four typologically-diverse languages and four natural language understanding tasks.

116, TITLE: In Search of Needles in A 10M Haystack: Recurrent Memory Finds What LLMs Miss
AUTHORS: YURI KURATOV et. al.
CATEGORY: cs.CL [cs.CL, cs.AI, cs.LG]
HIGHLIGHT: To evaluate different approaches, we introduce BABILong, a new benchmark designed to assess model capabilities in extracting and processing distributed facts within extensive texts.

117, TITLE: AbsInstruct: Eliciting Abstraction Ability from LLMs Through Explanation Tuning with Plausibility Estimation
AUTHORS: ZHAOWEI WANG et. al.
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: In this work, we design the framework AbsInstruct to enhance LLMs' abstraction ability through instruction tuning.

118, TITLE: Understanding Survey Paper Taxonomy About Large Language Models Via Graph Representation Learning
AUTHORS: Jun Zhuang ; Casey Kennington
CATEGORY: cs.CL [cs.CL, cs.AI, cs.IR, cs.LG]
HIGHLIGHT: In this paper, we develop a method to automatically assign survey papers to a taxonomy.

119, TITLE: Reviewer2: Optimizing Review Generation Through Prompt Generation
AUTHORS: Zhaolin Gao ; Kiant� Brantley ; Thorsten Joachims
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: While initial methods for automated review generation already exist, these methods tend to produce reviews that lack detail, and they do not cover the range of opinions that human reviewers produce. To address this shortcoming, we propose an efficient two-stage review generation framework called Reviewer2.

120, TITLE: Can Separators Improve Chain-of-Thought Prompting?
AUTHORS: Yoonjeong Park ; Hyunjin Kim ; Chanyeol Choi ; Junseong Kim ; Jy-yong Sohn
CATEGORY: cs.CL [cs.CL, cs.AI]
HIGHLIGHT: Inspired by human cognition, we introduce CoT-Sep, a novel method that strategically employs separators at the end of each exemplar in CoT prompting.

121, TITLE: Generalizability of Mixture of Domain-Specific Adapters from The Lens of Signed Weight Directions and Its Application to Effective Model Pruning
AUTHORS: Tuc Nguyen ; Thai Le
CATEGORY: cs.CL [cs.CL]
HIGHLIGHT: Thus, in this study, we conduct a comprehensive analysis to elucidate the generalizability of domain-specific adapter mixtures in in-domain evaluation.

122, TITLE: Quantum Automating $\mathbf{TC}^0$-Frege Is LWE-Hard
AUTHORS: Noel Arteche ; Gaia Carenini ; Matthew Gray
CATEGORY: cs.CC [cs.CC]
HIGHLIGHT: We show that under Learning with Errors (LWE), the standard lattice-based cryptographic assumption, no quantum algorithm can weakly automate $\mathbf{TC}^0$-Frege.

123, TITLE: Alphabet Reduction for Reconfiguration Problems
AUTHORS: Naoto Ohsaka
CATEGORY: cs.CC [cs.CC, cs.DM, cs.DS]
HIGHLIGHT: We present a reconfiguration analogue of alphabet reduction \`a la Dinur (J. ACM, 2007) and its applications.

124, TITLE: Training Class-Imbalanced Diffusion Model Via Overlap Optimization
AUTHORS: Divin Yan ; Lu Qi ; Vincent Tao Hu ; Ming-Hsuan Yang ; Meng Tang
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the observed appearance overlap between synthesized images of rare classes and tail classes, we propose a method based on contrastive learning to minimize the overlap between distributions of synthetic images for different classes.

125, TITLE: Deep Spectral Meshes: Multi-Frequency Facial Mesh Processing with Graph Neural Networks
AUTHORS: ROBERT KOSK et. al.
CATEGORY: cs.CV [cs.CV, cs.CG, cs.GR, 68T10, 68T45, 68U05, I.5.4; I.5.1; I.3.5; I.3.7; I.4.5; I.4.2; I.5.1; I.5.2]
HIGHLIGHT: In this work, spectral meshes are introduced as a method to decompose mesh deformations into low-frequency and high-frequency deformations.

126, TITLE: Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification
AUTHORS: Joohyung Lee ; Heejeong Nam ; Kwanhyung Lee ; Sangchul Hahn
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: However, existing MIL methods ignore that all patches from normal slides are normal. Using this free annotation, we introduce a semi-supervision signal to de-bias the inter-slide variability and to capture the common factors of variation within normal patches.

127, TITLE: Efficient Multi-task Uncertainties for Joint Semantic Segmentation and Monocular Depth Estimation
AUTHORS: Steven Landgraf ; Markus Hillemann ; Theodor Kapler ; Markus Ulrich
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: Additionally, we reveal the benefits of multi-task learning with regard to the uncertainty quality compared to solving both tasks separately. Based on these insights, we introduce EMUFormer, a novel student-teacher distillation approach for joint semantic segmentation and monocular depth estimation as well as efficient multi-task uncertainty quantification.

128, TITLE: HI-GAN: Hierarchical Inpainting GAN with Auxiliary Inputs for Combined RGB and Depth Inpainting
AUTHORS: Ankan Dash ; Jingyi Gu ; Guiling Wang
CATEGORY: cs.CV [cs.CV, cs.AI, cs.LG]
HIGHLIGHT: Despite speed and affordability, ToF cameras create imperfect depth maps with missing pixels. To address the above challenges, we propose Hierarchical Inpainting GAN (HI-GAN), a novel approach comprising three GANs in a hierarchical fashion for RGBD inpainting.

129, TITLE: Spike-EVPR: Deep Spiking Residual Network with Cross-Representation Aggregation for Event-Based Visual Place Recognition
AUTHORS: CHENMING HU et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the aforementioned issues, we propose a novel deep spiking network architecture called Spike-EVPR for event-based VPR tasks.

130, TITLE: CodaMal: Contrastive Domain Adaptation for Malaria Detection in Low-Cost Microscopes
AUTHORS: Ishan Rajendrakumar Dave ; Tristan de Blegiers ; Chen Chen ; Mubarak Shah
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: In this work, we present an end-to-end learning framework, named CodaMal (Contrastive Domain Adpation for Malaria).

131, TITLE: VATr++: Choose Your Words Wisely for Handwritten Text Generation
AUTHORS: BRAM VANHERLE et. al.
CATEGORY: cs.CV [cs.CV, cs.AI]
HIGHLIGHT: By doing so, we aim to establish a foundation for fair and meaningful comparisons between HTG strategies, fostering progress in the field.

132, TITLE: Optimizing Skin Lesion Classification Via Multimodal Data and Auxiliary Task Integration
AUTHORS: Mahapara Khurshid ; Mayank Vatsa ; Richa Singh
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: This research introduces a novel multimodal method for classifying skin lesions, integrating smartphone-captured images with essential clinical and demographic information.

133, TITLE: Question-Instructed Visual Descriptions for Zero-Shot Video Question Answering
AUTHORS: David Romero ; Thamar Solorio
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present Q-ViD, a simple approach for video question answering (video QA), that unlike prior methods, which are based on complex architectures, computationally expensive pipelines or use closed models like GPTs, Q-ViD relies on a single instruction-aware open vision-language model (InstructBLIP) to tackle videoQA using frame descriptions.

134, TITLE: STF: Spatio-Temporal Fusion Module for Improving Video Object Detection
AUTHORS: Noreen Anwar ; Guillaume-Alexandre Bilodeau ; Wassim Bouachir
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: Consecutive frames in a video contain redundancy, but they may also contain relevant complementary information for the detection task. The objective of our work is to leverage this complementary information to improve detection.

135, TITLE: Evaluating NeRFs for 3D Plant Geometry Reconstruction in Field Conditions
AUTHORS: MUHAMMAD ARBAB ARSHAD et. al.
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We evaluate different Neural Radiance Fields (NeRFs) techniques for reconstructing (3D) plants in varied environments, from indoor settings to outdoor fields.

136, TITLE: Fusion of Diffusion Weighted MRI and Clinical Data for Predicting Functional Outcome After Acute Ischemic Stroke with Deep Contrastive Learning
AUTHORS: CHIA-LING TSAI et. al.
CATEGORY: cs.CV [cs.CV, cs.LG]
HIGHLIGHT: The aim of this study is to investigate the efficacy of diffusion-weighted MRI modalities combining with structured health profile on predicting the functional outcome to facilitate early intervention.

137, TITLE: Dynamic Patch-aware Enrichment Transformer for Occluded Person Re-Identification
AUTHORS: Xin Zhang ; Keren Fu ; Qijun Zhao
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: To address the aforementioned challenges, we present an innovative end-to-end solution known as the Dynamic Patch-aware Enrichment Transformer (DPEFormer).

138, TITLE: Explaining Generative Diffusion Models Via Visual Analysis for Interpretable Decision-making Process
AUTHORS: Ji-Hoon Park ; Yeong-Joon Ju ; Seong-Whan Lee
CATEGORY: cs.CV [cs.CV, cs.AI, 68T01]
HIGHLIGHT: Nevertheless, explaining the diffusion process remains challenging due to it being a sequence of denoising noisy images that are difficult for experts to interpret. To address this issue, we propose the three research questions to interpret the diffusion process from the perspective of the visual concepts generated by the model and the region where the model attends in each time step.

139, TITLE: Enhancement-Driven Pretraining for Robust Fingerprint Representation Learning
AUTHORS: Ekta Gavas ; Kaustubh Olpadkar ; Anoop Namboodiri
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: In this paper, we propose a unique method for deriving robust fingerprint representations by leveraging enhancement-based pre-training.

140, TITLE: PEGASUS: Personalized Generative 3D Avatars with Composable Attributes
AUTHORS: Hyunsoo Cha ; Byungjun Kim ; Hanbyul Joo
CATEGORY: cs.CV [cs.CV]
HIGHLIGHT: We present, PEGASUS, a method for constructing personalized generative 3D face avatars from monocular video sources.

141, TITLE: Connect The Dots: Dataset Condensation, Differential Privacy, and Adversarial Uncertainty
AUTHORS: Kenneth Odoh
CATEGORY: cs.CR [cs.CR, cs.AI]
HIGHLIGHT: Our work focuses on understanding the underpinning mechanism of dataset condensation by drawing connections with ($\epsilon$, $\delta$)-differential privacy where the optimal noise, $\epsilon$, is chosen by adversarial uncertainty \cite{Grining2017}.

142, TITLE: On Permutation Selectors and Their Applications in Ad-Hoc Radio Networks Protocols
AUTHORS: Jordan Kuschner ; Yugarshi Shashwat ; Sarthak Yadav ; Marek Chrobak
CATEGORY: cs.DS [cs.DS, cs.CC]
HIGHLIGHT: Given a set $X$ and an element $x\in X$, to isolate $x$ from $X$, at least one of the sets in the selector must intersect $X$ on exactly $x$. We study (k,N)-permutation selectors which have the property that they can isolate each element of each $k$-element subset of $\{0,1,...,N-1\}$ in each possible order.

143, TITLE: Core Stability in Additively Separable Hedonic Games of Low Treewidth
AUTHORS: Tesshu Hanaka ; Noleen K�hler ; Michael Lampis
CATEGORY: cs.DS [cs.DS, cs.CC, cs.GT]
HIGHLIGHT: Since both finding a core stable partition and verifying that a given partition is core stable are intractable problems ($\Sigma_2^p$-complete and coNP-complete respectively) we study their complexity from the point of view of structural parameterized complexity, using standard graph-theoretic parameters, such as treewidth.

144, TITLE: Darwin Turing Dawkins: Building A General Theory of Evolution
AUTHORS: Leonard M. Adleman
CATEGORY: cs.GL [cs.GL, cs.AI, q-bio.PE]
HIGHLIGHT: The next time you run for president, fight a war, or just deal with the ordinary problems humans are heir to, perhaps this book will be of use.

145, TITLE: LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing
AUTHORS: BRYAN WANG et. al.
CATEGORY: cs.HC [cs.HC, cs.AI, cs.CL, cs.MM]
HIGHLIGHT: Video creation has become increasingly popular, yet the expertise and effort required for editing often pose barriers to beginners. In this paper, we explore the integration of large language models (LLMs) into the video editing workflow to reduce these barriers.

146, TITLE: UMAIR-FPS: User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style
AUTHORS: Yan Kang ; Hao Lin ; Mingjian Yang ; Shin-Jye Lee
CATEGORY: cs.IR [cs.IR, cs.AI]
HIGHLIGHT: In addition, most multi-modal recommendation research is constrained by tightly coupled datasets, limiting its applicability to anime illustrations. We propose the User-aware Multi-modal Animation Illustration Recommendation Fusion with Painting Style (UMAIR-FPS) to tackle these gaps.

147, TITLE: EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for The Acceleration of Lightweight LLMs on The Edge
AUTHORS: XUAN SHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CL]
HIGHLIGHT: In this paper, we propose EdgeQAT, the Entropy and Distribution Guided QAT for the optimization of lightweight LLMs to achieve inference acceleration on Edge devices.

148, TITLE: Theoretical Understanding of Learning from Adversarial Perturbations
AUTHORS: Soichiro Kumano ; Hiroshi Kera ; Toshihiko Yamasaki
CATEGORY: cs.LG [cs.LG, cs.CV, stat.ML]
HIGHLIGHT: In this study, we provide a theoretical framework for understanding learning from perturbations using a one-hidden-layer network trained on mutually orthogonal samples.

149, TITLE: QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large Language Model Tuning
AUTHORS: HOSSEIN RAJABZADEH et. al.
CATEGORY: cs.LG [cs.LG, cs.CL]
HIGHLIGHT: This paper proposes QDyLoRA -Quantized Dynamic Low-Rank Adaptation-, as an efficient quantization approach for dynamic low-rank adaptation.

150, TITLE: Adversarial Curriculum Graph Contrastive Learning with Pair-wise Augmentation
AUTHORS: Xinjian Zhao ; Liang Zhang ; Yang Liu ; Ruocheng Guo ; Xiangyu Zhao
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Nevertheless, precise control over similarity during sample generation presents a formidable challenge, often impeding the effective discovery of representative graph patterns. To address this challenge, we propose an innovative framework: Adversarial Curriculum Graph Contrastive Learning (ACGCL), which capitalizes on the merits of pair-wise augmentation to engender graph-level positive and negative samples with controllable similarity, alongside subgraph contrastive learning to discern effective graph patterns therein.

151, TITLE: Backdoor Attack Against One-Class Sequential Anomaly Detection Models
AUTHORS: He Cheng ; Shuhan Yuan
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR, cs.IT, math.IT]
HIGHLIGHT: In this paper, we explore compromising deep sequential anomaly detection models by proposing a novel backdoor attack strategy.

152, TITLE: Unlink to Unlearn: Simplifying Edge Unlearning in GNNs
AUTHORS: Jiajun Tan ; Fei Sun ; Ruichen Qiu ; Du Su ; Huawei Shen
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CR]
HIGHLIGHT: This concept is pivotal in enforcing the right to be forgotten, which entails the selective removal of specific data from trained GNNs upon user request. Our research focuses on edge unlearning, a process of particular relevance to real-world applications, owing to its widespread applicability.

153, TITLE: Policy Learning for Off-Dynamics RL with Deficient Support
AUTHORS: Linh Le Pham Van ; Hung The Tran ; Sunil Gupta
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: In this paper, our emphasis shifts to addressing large dynamics mismatch adaptation.

154, TITLE: Pretext Training Algorithms for Event Sequence Data
AUTHORS: Yimu Wang ; He Zhao ; Ruizhi Deng ; Frederick Tung ; Greg Mori
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This paper proposes a self-supervised pretext training framework tailored to event sequence data.

155, TITLE: Subgraph-level Universal Prompt Tuning
AUTHORS: Junhyun Lee ; Wooseong Yang ; Jaewoo Kang
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Nevertheless, the capacity of such simple prompts to fully grasp the complex contexts found in graphs remains an open question, necessitating further investigation. Addressing this challenge, our work introduces the Subgraph-level Universal Prompt Tuning (SUPT) approach, focusing on the detailed context within subgraphs.

156, TITLE: Towards Cohesion-Fairness Harmony: Contrastive Regularization in Individual Fair Graph Clustering
AUTHORS: Siamak Ghodsi ; Seyed Amjad Seyedi ; Eirini Ntoutsi
CATEGORY: cs.LG [cs.LG, cs.AI, cs.IT, cs.SI, math.IT]
HIGHLIGHT: Conventional fair graph clustering methods face two primary challenges: i) They prioritize balanced clusters at the expense of cluster cohesion by imposing rigid constraints, ii) Existing methods of both individual and group-level fairness in graph partitioning mostly rely on eigen decompositions and thus, generally lack interpretability. To address these issues, we propose iFairNMTF, an individual Fairness Nonnegative Matrix Tri-Factorization model with contrastive fairness regularization that achieves balanced and cohesive clusters.

157, TITLE: Selective Prediction for Semantic Segmentation Using Post-Hoc Confidence Estimation and Its Performance Under Distribution Shift
AUTHORS: Bruno Laboissiere Camargos Borges ; Bruno Machado Pacheco ; Danilo Silva
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: This paper investigates selective prediction for semantic segmentation in low-resource settings, thus focusing on post-hoc confidence estimators applied to pre-trained models operating under distribution shift. We propose a novel image-level confidence measure tailored for semantic segmentation and demonstrate its effectiveness through experiments on three medical imaging tasks.

158, TITLE: Can Transformers Predict Vibrations?
AUTHORS: Fusataka Kuniyoshi ; Yoshihide Sawada
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: However, current damping technologies only detect resonance after the vibration amplitude of the drive shaft torque reaches a certain threshold, leading to significant loads on the shaft at the time of detection. In this study, we propose a novel approach to address this issue by introducing Resoformer, a transformer-based model for predicting torsional resonance.

159, TITLE: Polyhedral Complex Derivation from Piecewise Trilinear Networks
AUTHORS: Jin-Hwa Kim
CATEGORY: cs.LG [cs.LG, cs.AI, cs.CV, cs.GR]
HIGHLIGHT: Focusing on trilinear interpolating methods as positional encoding, we present theoretical insights and an analytical mesh extraction, showing the transformation of hypersurfaces to flat planes within the trilinear region under the eikonal constraint.

160, TITLE: Developing An Optimal Model for Predicting The Severity of Wheat Stem Rust (Case Study of Arsi and Bale Zone)
AUTHORS: Tewodrose Altaye
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: This research utilized three types of artificial neural network (ANN) methodologies, namely Backpropagation Neural Network (BPNN) with varied training, transfer, divide, and learning functions; Radial Basis Function Neural Network (RBFNN); and General Regression Neural Network (GRNN), to forecast the severity of stem rust.

161, TITLE: ManiFPT: Defining and Analyzing Fingerprints of Generative Models
AUTHORS: Hae Jin Song ; Mahyar Khayatkhoei ; Wael AbdAlmageed
CATEGORY: cs.LG [cs.LG, cs.CV]
HIGHLIGHT: Recent works have shown that generative models leave traces of their underlying generative process on the generated samples, broadly referred to as fingerprints of a generative model, and have studied their utility in detecting synthetic images from real ones.

162, TITLE: FedD2S: Personalized Data-Free Federated Knowledge Distillation
AUTHORS: Kawa Atapour ; S. Jamal Seyedmohammadi ; Jamshid Abouei ; Arash Mohammadi ; Konstantinos N. Plataniotis
CATEGORY: cs.LG [cs.LG, cs.AI, cs.DC, eess.IV]
HIGHLIGHT: The model-drift issue, arising from the noniid nature of client data, often results in suboptimal personalization of a global model compared to locally trained models for each client. To tackle this challenge, we propose a novel approach named FedD2S for Personalized Federated Learning (pFL), leveraging knowledge distillation.

163, TITLE: ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling
AUTHORS: YUQI CHEN et. al.
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: It is challenging yet demanding to concurrently model the relationship between input data points and capture the dynamic changes of the continuous-time system. To tackle this problem, we propose ContiFormer that extends the relation modeling of vanilla Transformer to the continuous-time domain, which explicitly incorporates the modeling abilities of continuous dynamics of Neural ODEs with the attention mechanism of Transformers.

164, TITLE: Graph-based Forecasting with Missing Data Through Spatiotemporal Downsampling
AUTHORS: Ivan Marisca ; Cesare Alippi ; Filippo Maria Bianchi
CATEGORY: cs.LG [cs.LG, cs.AI]
HIGHLIGHT: Nonetheless, most existing methods rely on the often unrealistic assumption that inputs are always available and fail to capture hidden spatiotemporal dynamics when part of the data is missing. In this work, we tackle this problem through hierarchical spatiotemporal downsampling.

165, TITLE: Does Twinning Vehicular Networks Enhance Their Performance in Dense Areas?
AUTHORS: Sarah Al-Shareeda ; Sema F. Oktug ; Yusuf Yaslan ; Gokhan Yurdakul ; Berk Canberk
CATEGORY: cs.NI [cs.NI, cs.AI]
HIGHLIGHT: Moreover, they exhibit faster computational speeds, with cloud-based twins being 1.7 times faster than edge twins in certain scenarios. These findings provide insights for efficient vehicular communication and underscore the potential of virtual twins in enhancing vehicular networks in crowded areas while emphasizing the importance of considering real-world factors when making deployment decisions.

166, TITLE: Fitness-based Linkage Learning and Maximum-Clique Conditional Linkage Modelling for Gray-box Optimization with RV-GOMEA
AUTHORS: Georgios Andreadis ; Tanja Alderliesten ; Peter A. N. Bosman
CATEGORY: cs.NE [cs.NE]
HIGHLIGHT: In this work, we combine fitness-based linkage learning and conditional linkage modelling in RV-GOMEA.

167, TITLE: RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model
AUTHORS: JIANHAO YUAN et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: Moreover, the prohibitively expensive training requirements of MLLM and the unsolved problem of catastrophic forgetting further limit their generalisability post-deployment. To address these challenges, we present RAG-Driver, a novel retrieval-augmented multi-modal large language model that leverages in-context learning for high-performance, explainable, and generalisable autonomous driving.

168, TITLE: On The Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting The Risks and Vulnerabilities
AUTHORS: XIYANG WU et. al.
CATEGORY: cs.RO [cs.RO, cs.AI]
HIGHLIGHT: In this paper, we highlight the critical issues of robustness and safety associated with integrating large language models (LLMs) and vision-language models (VLMs) into robotics applications.

169, TITLE: AutoGPT+P: Affordance-based Task Planning with Large Language Models
AUTHORS: Timo Birr ; Christoph Pohl ; Abdelrahman Younes ; Tamim Asfour
CATEGORY: cs.RO [cs.RO, cs.AI, I.2]
HIGHLIGHT: However, these approaches face the challenge of dynamically capturing the initial state of the task planning problem. To alleviate this issue, we propose AutoGPT+P, a system that combines an affordance-based scene representation with a planning system.

170, TITLE: A Novel Integrated Industrial Approach with Cobots in The Age of Industry 4.0 Through Conversational Interaction and Computer Vision
AUTHORS: ANDREA PAZIENZA et. al.
CATEGORY: cs.RO [cs.RO, cs.CL, cs.CV, cs.LG]
HIGHLIGHT: The contribution starts from an innovative vision that sees an ever closer collaboration between Cobot, able to do a specific physical job with precision, the AI world, able to analyze information and support the decision-making process, and the man able to have a strategic vision of the future.

171, TITLE: Multi-Model 3D Registration: Finding Multiple Moving Objects in Cluttered Point Clouds
AUTHORS: David Jin ; Sushrut Karmalkar ; Harry Zhang ; Luca Carlone
CATEGORY: cs.RO [cs.RO, cs.CV]
HIGHLIGHT: We then propose a simple approach based on Expectation-Maximization (EM) and establish theoretical conditions under which the EM approach converges to the ground truth. We evaluate the approach in simulated and real datasets ranging from table-top scenes to self-driving scenarios and demonstrate its effectiveness when combined with state-of-the-art scene flow methods to establish dense correspondences.

172, TITLE: Network Formation and Dynamics Among Multi-LLMs
AUTHORS: Marios Papachristou ; Yuan Yuan
CATEGORY: cs.SI [cs.SI, cs.AI, cs.CL, cs.MA]
HIGHLIGHT: As large language models (LLMs) increasingly integrate into social and professional environments, understanding their behavior within the context of social networks and interactions becomes essential.

173, TITLE: Emoji Driven Crypto Assets Market Reactions
AUTHORS: Xiaorui Zuo ; Yao-Tsung Chen ; Wolfgang Karl H�rdle
CATEGORY: q-fin.CP [q-fin.CP, cs.AI, cs.CL, cs.LG, q-fin.ST]
HIGHLIGHT: In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets.

174, TITLE: Modelling Crypto Markets By Multi-agent Reinforcement Learning
AUTHORS: Johann Lussange ; Stefano Vrizzi ; Stefano Palminteri ; Boris Gutkin
CATEGORY: q-fin.CP [q-fin.CP, cs.AI, cs.GT, cs.MA]
HIGHLIGHT: Building on a previous foundation work (Lussange et al. 2020), this study introduces a multi-agent reinforcement learning (MARL) model simulating crypto markets, which is calibrated to the Binance's daily closing prices of $153$ cryptocurrencies that were continuously traded between 2018 and 2022.

175, TITLE: In-Vivo Hyperspectral Human Brain Image Database for Brain Cancer Detection
AUTHORS: H. FABELO et. al.
CATEGORY: eess.IV [eess.IV, cs.CV]
HIGHLIGHT: The work described in this paper was developed within the framework of the European project HELICoiD (HypErspectraL Imaging Cancer Detection), which had as a main goal the application of hyperspectral imaging to the delineation of brain tumors in real-time during neurosurgical operations.

176, TITLE: DABS-LS: Deep Atlas-Based Segmentation Using Regional Level Set Self-Supervision
AUTHORS: Hannah G. Mason ; Jack H. Noble
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: Localization is challenging because the ANFs are so small they are not directly visible in clinical imaging. In this work, we hypothesize the position of the ANFs can be accurately inferred from the location of the internal auditory canal (IAC), which has high contrast in CT, since the ANFs pass through this canal between the cochlea and the brain.

177, TITLE: HistoSegCap: Capsules for Weakly-Supervised Semantic Segmentation of Histological Tissue Type in Whole Slide Images
AUTHORS: Mobina Mansoori ; Sajjad Shahabodini ; Jamshid Abouei ; Arash Mohammadi ; Konstantinos N. Plataniotis
CATEGORY: eess.IV [eess.IV, cs.CV, cs.LG]
HIGHLIGHT: To aid pathologists, Computer Aided Diagnosis (CAD) systems offer visual assistance in efficiently examining WSIs and identifying diagnostically relevant regions. This paper presents a novel histopathological image analysis method employing Weakly Supervised Semantic Segmentation (WSSS) based on Capsule Networks, the first such application.

178, TITLE: Power-Efficient Indoor Localization Using Adaptive Channel-aware Ultra-wideband DL-TDOA
AUTHORS: Sagnik Bhattacharya ; Junyoung Choi ; Joohyun Lee
CATEGORY: eess.SP [eess.SP, cs.AI]
HIGHLIGHT: In this paper, we propose and implement a novel low-power channel-aware dynamic frequency DL-TDOA ranging algorithm.
